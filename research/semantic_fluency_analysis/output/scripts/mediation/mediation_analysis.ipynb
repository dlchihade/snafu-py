{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y1RwUUbuVBy5"
      },
      "source": [
        "**Setup environment**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "2uZYZp5hmTWS",
        "outputId": "b5f330c0-9dbf-4996-a50f-e4cdb094dafd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/AusterweilLab/snafu-py\n",
            "  Cloning https://github.com/AusterweilLab/snafu-py to /tmp/pip-req-build-h06qm85f\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/AusterweilLab/snafu-py /tmp/pip-req-build-h06qm85f\n",
            "  Resolved https://github.com/AusterweilLab/snafu-py to commit f1d347c4c7c4f5e455a677be04b153e43927d820\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from pysnafu==2.6.3) (2.0.2)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from pysnafu==2.6.3) (3.5)\n",
            "Collecting en-core-web-md==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-3.8.0/en_core_web_md-3.8.0-py3-none-any.whl (33.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.5/33.5 MB\u001b[0m \u001b[31m32.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_md')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n",
            "Requirement already satisfied: wordfreq in /usr/local/lib/python3.11/dist-packages (3.1.1)\n",
            "Requirement already satisfied: ftfy>=6.1 in /usr/local/lib/python3.11/dist-packages (from wordfreq) (6.3.1)\n",
            "Requirement already satisfied: langcodes>=3.0 in /usr/local/lib/python3.11/dist-packages (from wordfreq) (3.5.0)\n",
            "Requirement already satisfied: locate<2.0.0,>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from wordfreq) (1.1.1)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.7 in /usr/local/lib/python3.11/dist-packages (from wordfreq) (1.1.1)\n",
            "Requirement already satisfied: regex>=2023.10.3 in /usr/local/lib/python3.11/dist-packages (from wordfreq) (2024.11.6)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from ftfy>=6.1->wordfreq) (0.2.13)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes>=3.0->wordfreq) (1.3.0)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes>=3.0->wordfreq) (1.2.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from marisa-trie>=1.1.0->language-data>=1.2->langcodes>=3.0->wordfreq) (75.2.0)\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.manifold import TSNE\n",
        "import spacy\n",
        "import io\n",
        "import re\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "\n",
        "!pip install git+https://github.com/AusterweilLab/snafu-py\n",
        "!python -m spacy download en_core_web_md\n",
        "\n",
        "# Set the style for plots\n",
        "plt.style.use('ggplot')\n",
        "sns.set_context(\"talk\")\n",
        "plt.rcParams['figure.figsize'] = (12, 8)\n",
        "plt.rcParams['font.size'] = 12\n",
        "plt.rcParams['svg.fonttype'] = 'none'\n",
        "\n",
        "# Load spaCy model for word vectors\n",
        "nlp = spacy.load(\"en_core_web_md\")\n",
        "\n",
        "!pip install wordfreq\n",
        "from wordfreq import zipf_frequency\n",
        "from wordfreq import top_n_list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_DW34bXQYnl"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FcwhbIUjVHuF"
      },
      "source": [
        "**Load Data**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# pull down the top 50 000 English words (most → least frequent)\n",
        "freq_list = top_n_list(\"en\", 50000)\n",
        "def word_rank(word:str, freq_list:list[str]) -> int:\n",
        "    \"\"\"\n",
        "    Return 1-based rank of `word` in `freq_list`,\n",
        "    or 0 if it’s not in the top-N.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        return freq_list.index(word) + 1\n",
        "    except ValueError:\n",
        "        return 0\n",
        "\n",
        "print(word_rank(\"the\", freq_list))    # → 1\n",
        "print(word_rank(\"computer\", freq_list))  # e.g. → 899\n",
        "print(word_rank(\"foobarxyz\", freq_list)) # → 0 (not in top 50 000)\n",
        "\n",
        "from wordfreq import top_n_list\n",
        "\n",
        "# Get top 10 words in English\n",
        "top_10 = top_n_list('en', 10)\n",
        "print(top_10)\n",
        "# Returns: ['the', 'to', 'and', 'of', 'a', 'in', 'i', 'is', 'for', 'that']\n",
        "\n",
        "# Get top 50,000 words (your use case)\n",
        "top_50k = top_n_list('en', 50000)\n",
        "print(top_50k)\n",
        "\n",
        "# Specify wordlist type for larger dataset\n",
        "top_50k_large = top_n_list('en', 50000, wordlist='large')\n",
        "\n",
        "# Scientific notation also works\n",
        "top_100k = top_n_list('en', 1e5, wordlist='large')  # 100,000 words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pprq3YyBzxzO",
        "outputId": "4b18eff1-8bc1-4acd-b070-86f8fcb0416d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "1136\n",
            "0\n",
            "['the', 'to', 'and', 'of', 'a', 'in', 'i', 'is', 'for', 'that']\n",
            "['the', 'to', 'and', 'of', 'a', 'in', 'i', 'is', 'for', 'that', 'you', 'it', 'on', 'with', 'this', 'was', 'be', 'as', 'are', 'have', 'at', 'he', 'not', 'by', 'but', 'from', 'my', 'or', 'we', 'an', 'your', 'all', 'so', 'his', 'they', 'me', 'if', 'one', 'can', 'will', 'just', 'like', 'about', 'up', 'out', 'what', 'has', 'when', 'more', 'do', 'no', 'were', 'who', 'had', \"it's\", 'their', 'there', 'her', 'which', 'time', 'get', 'been', 'would', 'she', 'new', 'people', 'how', \"don't\", 'some', 'also', 'them', 'now', 'other', \"i'm\", 'its', 'our', 'than', 'good', 'only', 'after', 'first', 'him', 'into', 'know', 'see', 'two', 'make', 'over', 'think', 'any', 'then', 'could', 'back', 'these', 'us', 'want', 'because', 'go', 'well', 'said', 'way', '1', '2', 'most', 'much', 'very', 'where', 'even', 'should', 'may', 'here', 'need', 'really', 'did', 'right', 'work', 'year', 'years', 'being', 'day', 'too', 'going', 'before', 'off', 'why', 'made', 'still', 'take', '3', 'got', 'many', 'never', 'those', 'life', 'say', 'world', 'down', 'great', 'through', \"you're\", 'last', 's', \"that's\", 'while', 'best', 'such', 'love', 'man', 'home', 'long', 'look', 'something', 'use', \"can't\", 'same', 'used', 'both', 'every', '4', 'am', 'come', 'part', 'state', 'three', 'around', 'between', 'always', 'better', 'find', '5', 'help', 'high', 'little', 'old', 'since', 'another', 'does', 'own', 'things', 'under', 'during', 'game', \"i've\", 'thing', 'give', 'house', 'place', 'school', 'again', 'next', 'each', 'mr', 'without', 'against', \"didn't\", 'end', 'found', 'must', 'show', 'big', 'feel', 'sure', 'team', 'ever', 'family', 'keep', 'might', 'please', 'put', 'money', 'free', 'second', 'someone', 'away', 'left', 'number', 'city', 'days', 'lot', 'name', 'night', 'play', 'until', 'company', 'doing', 'few', \"he's\", 'let', 'real', '6', 'called', 'different', 'having', 'set', 'thought', 'done', 'however', 'getting', 'god', 'government', 'group', 'looking', 'public', 'top', 'women', 'business', 'care', 'start', 'system', 'times', 'week', '7', 'already', 'anything', 'case', 'nothing', 'person', 'today', 'change', 'enough', 'everything', 'full', 'live', 'making', 'point', 'read', \"there's\", 'told', 'yet', 'bad', \"doesn't\", 'four', 'hard', 'mean', 'once', 'support', 'tell', 'including', 'music', 'power', 'seen', 'states', 'stop', 'water', 'based', 'believe', 'call', 'head', 'men', 'national', 'small', 'took', 'white', 'came', 'far', 'job', 'side', 'though', 'try', 'went', 'yes', 'actually', 'american', 'later', 'less', 'line', 'order', 'party', 'run', 'says', 'service', '8', 'country', 'open', 'season', 'shit', 'thank', 'children', 'everyone', 'general', \"they're\", 'trying', 'united', 'using', 'area', 'black', 'd', 'following', 'law', 'makes', 'together', 'war', 'whole', 'car', 'face', 'five', 'kind', 'maybe', 'per', 'president', 'story', 'working', 'course', 'games', 'health', 'hope', 'important', 'least', 'means', 'news', 'within', 'able', 'book', 'early', 'friends', \"i'll\", 'information', 'local', 'oh', 'post', 't', 'thanks', 'video', 'young', 'ago', 'others', 'social', 'talk', '9', 'court', 'fact', 'given', 'guys', 'half', 'hand', \"isn't\", 'level', 'mind', 'often', 'single', 'become', 'body', 'coming', 'control', 'death', 'food', 'guy', 'hours', 'office', 'pay', 'problem', 'south', 'true', \"we're\", 'almost', 'fuck', 'history', 'known', 'large', 'lost', 'm', 'research', 'room', 'several', 'started', 'taking', 'university', 'win', 'wrong', 'along', 'anyone', 'else', 'girl', 'john', 'matter', 'pretty', 'remember', 'air', 'bit', 'friend', 'hit', 'needs', 'nice', 'playing', 'probably', 'saying', 'understand', 'yeah', 'york', 'class', 'close', 'comes', \"i'd\", 'idea', 'international', 'looks', 'past', 'possible', 'wanted', 'b', 'cause', 'due', 'happy', 'human', 'members', 'months', 'move', 'question', 'r', 'series', 'wait', 'woman', 'ask', 'community', 'data', 'late', 'leave', 'north', 'saw', 'special', 'watch', \"won't\", 'c', 'either', 'fucking', 'future', 'light', 'low', 'million', 'morning', 'police', 'short', 'stay', 'taken', 'age', 'buy', 'deal', 'rather', 'reason', 'red', 'report', 'soon', 'third', 'turn', 'whether', 'among', 'check', 'development', 'form', 'further', 'heart', 'minutes', 'myself', 'services', 'u.s', 'yourself', 'act', 'although', 'asked', 'child', 'fire', 'fun', 'living', 'major', 'media', 'phone', 'players', 'art', 'behind', 'building', 'easy', 'gonna', 'market', 'near', 'non', 'plan', 'political', 'quite', 'six', 'talking', 'west', 'works', 'according', 'available', 'e', 'education', 'final', 'former', 'front', 'kids', 'list', 'ready', 'sometimes', 'son', 'street', \"wasn't\", 'bring', 'college', 'current', 'example', 'experience', 'heard', 'london', 'meet', 'program', 'type', 'baby', 'chance', 'father', 'march', 'process', \"she's\", 'song', 'study', 'word', 'across', 'action', 'clear', 'gave', 'gets', 'himself', 'month', 'outside', 'self', 'students', 'words', 'board', 'cost', 'cut', 'dr', 'field', 'held', 'instead', 'main', 'moment', 'mother', 'road', 'seems', 'thinking', 'town', 'wants', 'de', 'department', 'energy', 'fight', 'fine', 'force', 'hear', 'issue', 'played', 'points', 'price', 're', 'rest', 'results', 'running', 'shows', 'space', 'summer', 'term', 'wife', '0', 'america', 'beautiful', 'date', 'goes', 'killed', 'land', 'miss', 'project', 'sex', 'shot', 'site', 'strong', \"you'll\", 'account', 'co', 'especially', 'eyes', 'include', 'june', 'parents', 'period', 'position', 'record', 'similar', 'total', 'w', 'above', 'club', 'common', 'died', 'film', 'happened', 'knew', 'lead', 'likely', 'military', 'perfect', 'personal', 'security', 'share', 'st', 'tv', \"what's\", 'won', 'x', 'april', 'center', 'county', 'couple', 'dead', 'english', 'happen', 'hold', 'industry', 'inside', 'issues', 'online', 'player', 'private', 'problems', 'return', 'rights', 'sense', 'star', 'test', 'view', 'weeks', 'break', 'british', 'companies', 'event', 'higher', 'hour', 'l', 'member', 'middle', 'needed', 'present', 'result', 'sorry', 'takes', 'training', 'wish', \"wouldn't\", 'answer', 'boy', 'design', 'finally', 'girls', 'gold', 'gone', 'guess', 'interest', 'july', 'king', 'learn', 'policy', 'society', 'added', 'al', 'alone', 'average', 'bank', 'brought', 'certain', 'church', 'east', 'hands', 'hot', \"let's\", 'longer', 'medical', 'movie', 'original', 'park', 'performance', 'press', 'received', 'role', 'sent', 'themselves', 'tried', 'worked', 'worth', 'areas', 'became', 'bill', 'books', 'cool', 'director', 'exactly', 'giving', 'ground', 'meeting', 'n', 'provide', 'questions', 'relationship', 'september', 'sound', 'source', 'usually', 'value', 'evidence', 'follow', 'lives', 'official', 'ok', 'production', 'rate', 'reading', 'round', 'save', 'stand', 'stuff', 'tax', 'whatever', 'amount', 'blue', 'countries', 'david', 'drive', 'eat', 'fall', 'fast', 'federal', 'feeling', 'felt', 'green', 'league', 'management', 'match', 'model', 'p', 'picture', 'size', 'step', 'trust', \"you've\", 'central', 'changes', 'england', 'forward', 'groups', 'hey', 'key', 'mom', 'o', 'page', 'paid', 'range', 'review', 'science', 'trade', 'uk', 'upon', 'various', 'attention', 'brother', 'cannot', 'character', 'chief', 'cup', 'football', 'hate', \"haven't\", 'james', 'led', 'looked', 'lower', 'natural', 'october', 'property', 'quality', 'send', 'style', 'u', 'vote', 'amazing', 'august', 'blood', 'china', 'complete', 'dog', 'economic', 'hell', 'involved', 'itself', 'language', 'lord', 'november', 'oil', 'related', 'serious', 'stage', 'terms', 'title', 'add', 'article', 'attack', 'born', \"couldn't\", 'damn', 'decided', 'decision', 'enjoy', 'entire', 'french', 'january', 'kill', 'met', 'perhaps', 'poor', 'release', 'situation', 'technology', 'turned', 'website', 'written', 'choice', 'code', 'considered', 'continue', 'council', 'cover', 'currently', 'door', 'election', 'european', 'events', 'f', 'financial', 'foreign', 'hair', 'increase', 'legal', 'lose', 'michael', 'pick', 'race', 'seem', 'seven', 'sign', 'simple', 'simply', 'staff', 'super', 'union', 'walk', 'washington', 'bed', 'began', 'built', 'career', 'changed', 'crazy', 'daily', 'daughter', 'december', 'die', 'difficult', 'figure', 'hospital', 'knows', 'loss', 'modern', 'ones', 'paper', 'parts', 'popular', 'published', 'safe', 'starting', 'systems', 'version', 'voice', 'whose', 'writing', 'army', 'australia', 'earth', 'forget', 'goal', 'h', 'huge', 'internet', 'listen', 'okay', 'practice', 'rules', 'sea', 'sir', 'success', 'towards', 'v', 'waiting', 'ways', 'access', \"aren't\", 'base', 'below', 'created', 'deep', 'followed', 'la', 'lol', 'mark', 'missing', 'offer', 'pass', 'professional', 'released', 'risk', 'schools', 'sleep', 'table', 'ten', 'truth', 'ball', 'box', 'build', 'card', 'cases', 'dark', 'district', 'europe', 'george', 'india', 'mine', 'minister', 'note', 'percent', 'piece', 'products', 'recent', 'seeing', 'straight', 'visit', 'wall', 'wanna', \"we've\", 'wrote', 'allowed', 'boys', 'culture', 'etc', 'fans', 'february', 'gives', 'growth', 'included', 'married', 'officer', 'pain', 'paul', 'places', 'respect', 'response', 'river', 'rock', 'shall', 'speak', 'specific', 'standard', 'tonight', 'write', 'y', 'album', 'century', 'charge', 'cold', 'create', 'effect', 'eight', 'except', 'eye', 'funny', 'ii', 'limited', 'moving', 'network', 'peace', 'provided', 'recently', 'required', 'sales', 'spent', 'store', 'student', 'tomorrow', 'track', 'via', 'watching', 'weight', 'addition', 'ahead', 'allow', 'anti', 'association', 'beat', 'brown', 'capital', 'chinese', 'committee', 'conference', 'difference', 'double', 'expect', 'gas', 'island', 'moved', 'normal', 'plans', 'population', 'potential', 'pressure', 'radio', 'russian', 'station', 'text', 'treatment', 'western', 'ass', 'beginning', 'california', 'campaign', 'certainly', 'completely', 'content', 'credit', 'cross', 'described', 'despite', 'female', 'focus', 'g', 'hi', 'husband', 'ice', 'individual', 'interesting', 'j', 'join', 'kept', 'leading', 'loved', 'message', 'miles', 'nearly', 'particular', 'previous', 'quickly', 'region', 'reported', 'section', 'sort', 'speed', 'travel', 'consider', 'contact', 'drop', 'fair', 'feet', 'jesus', 'kid', 'link', 'positive', 'sale', 'throughout', 'tour', 'welcome', 'absolutely', 'additional', 'beyond', 'conditions', 'earlier', 'extra', 'forces', 'immediately', 'jobs', 'leaving', 'minute', 'nature', 'numbers', 'quick', 'sell', 'significant', 'studies', 'unless', 'winning', 'agree', 'canada', 'clean', 'computer', 'construction', 'episode', 'favorite', 'income', 'justice', 'levels', 'manager', 'movement', 'photo', 'posted', 'safety', 'san', 'scene', 'sold', 'sounds', 'spend', 'statement', 'sun', 'teams', 'ability', 'announced', 'asking', 'calling', 'coach', 'collection', 'continued', 'costs', 'definitely', 'designed', 'expected', 'friday', 'gun', 'happens', 'heavy', 'includes', 'knowledge', 'particularly', 'search', 'subject', 'train', 'wide', 'wow', 'author', 'centre', 'claim', 'dad', 'developed', 'fear', 'fit', 'generally', 'german', 'global', 'goals', 'gotta', 'hotel', 'interested', 'judge', 'lady', 'leader', 'letter', 'lines', 'material', 'named', 'nobody', 'opportunity', 'plus', 'pre', 'product', 'regular', 'secretary', 'sister', 'stories', 'unit', 'workers', 'annual', 'anymore', 'bar', 'battle', 'brain', 'contract', 'degree', 'families', 'features', 'finished', 'floor', 'france', 'growing', 'hurt', 'image', 'insurance', 'majority', 'meant', 'opening', 'opinion', 'physical', 'pro', 'reach', 'rule', 'seriously', 'sports', 'stupid', 'successful', 'active', 'administration', 'approach', 'australian', 'biggest', 'cancer', 'civil', 'dance', 'defense', 'direction', 'independent', 'master', 'none', 'reasons', 'russia', 'ship', 'stock', 'trump', 'weekend', 'wonder', 'worst', 'africa', 'awesome', 'band', 'beach', 'cash', 'clearly', 'commercial', 'compared', 'effort', 'ended', 'fan', 'fighting', 'imagine', 'impact', 'lack', 'latest', 'learning', 'multiple', 'older', 'operation', 'organization', 'passed', 'pictures', 'protect', 'secret', 'senior', 'spring', 'sunday', 'telling', 'wear', 'activities', 'address', 'analysis', 'anyway', 'bought', 'calls', 'choose', 'christmas', 'color', 'commission', 'competition', 'details', 'direct', 'dream', 'easily', 'finish', 'grand', \"here's\", 'increased', 'indian', 'k', 'literally', 'luck', 'marriage', 'names', 'necessary', 'patients', 'resources', 'rich', 'skin', 'speaking', 'supposed', 'sweet', 'thus', 'touch', 'yesterday', 'caught', 'closed', 'congress', 'damage', 'directly', 'disease', 'doctor', 'doubt', 'drink', 'driving', 'established', 'facebook', 'feels', 'fish', 'gay', 'germany', 'glad', 'greater', 'grow', 'largest', 'machine', 'notice', 'overall', 'planning', 'professor', 'programs', 'records', 'reports', 'shown', 'sit', 'trip', 'associated', 'basic', 'captain', 'carry', 'cars', 'crime', 'effective', 'effects', 'explain', 'fully', 'highly', 'holding', 'japan', 'laws', 'male', 'mrs', 'parties', 'plant', 'reality', 'smith', 'spot', 'texas', \"we'll\", 'winter', 'worse', 'advice', 'agreement', \"ain't\", 'award', 'block', 'broken', 'caused', 'challenge', 'characters', 'christian', 'comment', 'equipment', 'eventually', 'helped', 'holy', 'killing', 'lived', 'lots', 'nation', 'otherwise', 'peter', 'prices', 'primary', 'purpose', 'rates', 'responsible', 'shop', 'showing', 'sick', 'teacher', 'theory', 'uses', 'william', 'agency', 'avoid', 'camera', 'catch', 'cell', 'coast', 'comments', 'drug', 'economy', 'environment', 'executive', 'foot', 'hall', 'mass', 'meaning', 'mission', 'nine', 'officers', 'operations', 'politics', 'pop', 'produced', 'ran', 'saturday', 'status', 'therefore', 'trial', 'truly', 'weather', 'activity', 'app', 'application', 'claims', 'coffee', 'complex', 'condition', 'division', 'evening', 'flight', 'freedom', 'google', 'heat', 'highest', 'interview', 'library', 'located', 'location', 'murder', 'obama', 'offered', 'putting', 'queen', 'seconds', 'showed', 'sitting', 'standing', 'stars', 'walking', 'accept', 'actual', 'appear', 'attempt', 'broke', 'channel', 'distance', 'eating', 'exchange', 'fat', 'fell', 'finding', 'glass', 'learned', 'losing', 'mobile', 'northern', 'opened', 'placed', 'powerful', 'prior', 'protection', 'reached', 'receive', 'religious', 'ride', 'robert', 'royal', 'screen', 'serve', 'signed', 'slow', 'species', 'speech', 'traffic', 'tree', 'types', 'vs', 'wearing', \"who's\", 'whom', 'wonderful', 'agreed', 'airport', 'animals', 'appears', 'begin', 'benefits', 'bottom', 'cities', 'demand', 'engine', 'everybody', 'famous', 'ideas', 'investment', 'keeping', 'lie', 'notes', 'partner', 'plays', 'raised', 'runs', 'sad', 'solution', 'songs', 'sources', 'southern', 'square', 'stopped', 'structure', 'thomas', 'traditional', 'twice', 'wind', 'worry', '1st', 'americans', 'appeared', 'becomes', 'brand', 'bus', 'cent', 'chicago', 'count', 'covered', 'critical', 'digital', 'forced', 'fourth', 'fresh', 'lake', 'mental', 'mentioned', 'missed', 'mostly', 'mouth', 'owner', 'photos', 'previously', 'realize', 'remain', 'scale', 'score', 'separate', 'smart', 'starts', 'surface', 'throw', 'tom', 'totally', 'twitter', 'views', 'wedding', \"you'd\", 'acting', 'actions', 'african', 'arms', 'benefit', 'budget', 'click', 'estate', 'failed', 'faith', 'fashion', 'feature', 'fund', 'generation', 'hearing', 'hill', 'jack', 'larger', 'louis', 'metal', 'mid', 'paris', 'profile', 'pull', 'push', 'returned', 'rose', 'seat', 'seemed', 'sexual', \"shouldn't\", 'target', 'understanding', 'village', 'agent', 'animal', 'apply', 'authority', 'basis', 'becoming', 'chris', 'draw', 'dude', 'employees', 'enter', 'ex', 'follows', 'foundation', 'gain', 'http', 'individuals', 'japanese', 'leaders', 'memory', 'prime', 'projects', 'ring', 'rise', 'selling', 'served', 'silver', 'soul', 'spread', 'supply', 'waste', 'weird', 'adult', 'apparently', 'artist', 'chairman', 'edition', 'engineering', 'grade', 'happening', 'healthy', 'institute', 'method', 'mike', 'monday', 'nations', 'obviously', 'option', 'prison', 'provides', 'remains', 'senate', 'smaller', 'somebody', 'stone', 'strength', 'users', 'wild', 'window', 'winner', 'arrived', 'bag', 'bet', 'camp', 'cast', 'christ', 'continues', 'correct', 'dangerous', 'ed', 'extremely', 'firm', 'greatest', 'handle', 'improve', 'indeed', 'leaves', 'movies', 'negative', 'prevent', 'removed', 'richard', 'spirit', 'television', 'till', 'trouble', 'usa', 'videos', 'advantage', 'apart', 'aware', 'cat', 'customers', 'decide', 'dinner', 'dollars', 'eastern', 'fifth', 'function', 'gift', 'helping', 'herself', 'impossible', 'influence', 'items', 'joe', 'los', 'marketing', 'mary', 'materials', 'nor', 'produce', 'progress', 'proud', 'require', 'shooting', 'shut', 'standards', 'tells', 'thinks', 'van', 'wood', 'background', 'birth', 'bridge', 'carried', 'charles', 'classes', 'completed', 'concept', 'copy', 'dear', 'dogs', 'drugs', 'efforts', 'garden', 'host', 'housing', 'inc', 'israel', 'journal', 'labor', 'leadership', 'length', 'lucky', 'neither', 'onto', 'patient', 'possibly', 'prove', 'rare', 'setting', 'skills', 'software', 'thousands', 'tough', 'units', 'ad', 'alive', 'apple', 'balance', 'birthday', 'bitch', 'boss', 'cards', 'changing', 'connection', 'dress', 'easier', 'fellow', 'florida', 'horse', 'knowing', 'liked', 'magic', 'managed', 'map', 'net', 'owned', 'request', 'stick', \"they've\", 'turns', 'vehicle', 'volume', 'wake', 'aid', 'beauty', 'believed', 'billion', 'busy', 'buying', 'cells', 'concerned', 'conversation', 'corner', 'criminal', 'cultural', 'develop', 'driver', 'ends', 'existing', 'farm', 'file', 'fix', 'fly', 'frank', 'guide', 'images', 'investigation', 'mexico', 'operating', 'paying', 'presented', 'raise', 'responsibility', 'roll', 'slightly', 'suggest', 'surprise', 'technical', 'thoughts', 'treat', 'unique', 'variety', 'violence', 'weapons', 'yours', 'youth', '2nd', 'appreciate', 'bigger', 'breaking', 'discovered', 'dont', 'dry', 'edge', 'evil', 'excited', 'forever', 'funds', 'helps', 'henry', 'injury', 'iron', 'lovely', 'mad', 'magazine', 'martin', 'models', 'offers', 'ordered', 'parliament', 'prepared', 'reference', 'religion', 'sites', 'somewhere', 'stated', 'strategy', 'teachers', 'web', 'wine', 'accounts', 'angeles', 'arm', 'audience', 'bay', 'blog', 'closer', 'core', 'democratic', 'description', 'dropped', 'excellent', 'exist', 'figures', 'forms', 'guard', 'honest', 'issued', 'joined', 'jones', 'lee', 'lies', 'likes', 'medicine', 'mention', 'mountain', 'nuclear', 'orders', 'port', 'presence', 'reaction', 'reduce', 'shoot', 'sides', 'solid', 'spanish', 'sport', 'steps', 'stress', 'taste', 'tea', 'victory', 'afternoon', 'assistant', 'britain', 'citizens', 'classic', 'clothes', 'decisions', 'electric', 'emergency', 'entered', 'entirely', 'facts', 'failure', 'festival', 'flat', 'fuel', 'harry', 'hello', 'houses', 'ill', 'initial', 'introduced', 'johnson', 'kick', 'links', 'mail', 'massive', 'matters', 'pair', 'picked', 'pieces', 'plane', 'plenty', 'prince', 'proper', 'providing', 'quarter', 'regional', 'scott', 'session', 'shape', 'sky', 'teaching', 'toward', 'transfer', 'upper', 'useful', 'valley', 'watched', 'willing', 'windows', 'zone', 'accident', 'advanced', 'alternative', 'anywhere', 'articles', 'awards', 'bear', 'boat', 'bringing', 'capacity', 'cheap', 'climate', 'communities', 'discussion', 'drinking', 'duty', 'fantastic', 'feelings', 'flying', 'governor', \"hasn't\", 'hundred', 'industrial', 'joint', 'mix', 'museum', 'options', 'path', 'plants', 'policies', 'promise', 'proposed', 'purchase', 'rain', 'remove', 'signs', 'spending', 'steel', 'steve', 'supporting', 'terrible', \"they'll\", 'tired', 'treated', 'turning', 'vice', 'warm', '°', 'afraid', 'arts', 'beer', 'border', 'canadian', 'command', 'crew', 'crowd', 'dating', 'dick', 'elements', 'enemy', 'ensure', 'environmental', 'filled', 'fixed', 'forest', 'intelligence', 'intended', 'labour', 'limit', 'moon', 'ocean', 'powers', 'profit', 'proof', 'republican', 'soldiers', 'suit', 'wins', \"women's\", 'appearance', 'asian', 'attorney', 'banks', 'behavior', 'ben', 'bodies', 'brothers', 'buildings', 'chair', 'creating', 'debt', 'domestic', 'expensive', 'grew', 'historical', 'homes', 'honestly', 'honor', 'im', 'jump', 'launch', 'listed', 'minimum', 'native', 'noted', 'originally', 'planned', 'pm', 'ray', 'sets', 'suddenly', 'supreme', 'survey', 'tech', 'trees', 'update', 'user', 'writer', 'yellow', 'younger', 'ancient', 'attacks', 'charges', 'combined', 'communication', 'connected', 'contains', 'download', 'email', 'ending', 'exercise', 'express', 'flow', 'formed', 'girlfriend', 'hero', 'illegal', 'increasing', 'joke', 'loan', 'methods', 'officials', \"people's\", 'performed', 'planet', 'relationships', 'restaurant', 'scotland', 'selected', 'shared', 'shopping', 'soft', 'stuck', 'sugar', 'suggested', 'supported', 'surprised', 'taught', 'transport', \"weren't\", 'accepted', 'adding', 'affairs', 'allows', 'appeal', 'applied', 'appropriate', 'artists', 'boston', 'ca', 'confirmed', 'device', 'drama', 'entry', 'era', 'factor', 'feed', 'golden', 'grant', 'grown', 'heads', 'hoping', 'keeps', 'lawyer', 'legs', 'lying', 'measures', 'mistake', 'ms', 'muslim', 'organizations', 'platform', 'pool', 'pulled', 'regarding', 'relations', 'requires', 'route', 'saved', 'schedule', 'scientific', 'shoes', 'smoke', 'squad', 'teach', 'testing', 'tests', 'values', 'walked', 'williams', 'ya', 'abuse', 'angry', 'businesses', 'candidate', 'comfortable', 'concern', 'developing', 'discuss', 'elections', 'emotional', 'et', 'everywhere', 'facilities', 'falling', 'fox', 'guns', 'hole', 'holiday', 'interests', 'internal', 'ireland', 'italian', 'italy', 'jersey', 'laugh', 'leg', 'letters', 'liberal', 'listening', 'll', 'loves', 'lunch', 'max', 'milk', 'pack', 'payment', 'perform', 'recorded', 'relatively', 'sector', 'sharing', 'snow', 'storm', 'streets', 'strike', 'studio', 'sub', 'weak', 'youtube', '3rd', 'actor', 'advance', 'apartment', 'asia', 'chain', 'chapter', 'committed', 'confidence', 'cook', 'cute', 'equal', 'fake', 'finance', 'focused', 'hits', 'identity', 'journey', 'kitchen', 'korea', 'leads', 'maintain', 'measure', 'mm', 'numerous', 'owners', 'posts', 'properties', 'quiet', 'revealed', 'specifically', 'split', 'task', 'taxes', 'taylor', 'twenty', 'urban', 'acts', 'affected', 'aircraft', 'applications', 'approved', 'approximately', 'argument', 'arrested', 'claimed', 'conflict', 'considering', 'corporate', 'debate', 'determined', 'distribution', 'documents', 'escape', 'extended', 'factors', 'faster', 'fault', 'fill', 'films', 'flowers', 'friendly', 'ladies', 'lay', 'lights', 'millions', 'mixed', 'phase', 'properly', 'pure', 'reduced', 'requirements', 'residents', 'revenue', 'sam', 'sat', 'secure', 'smile', 'strange', 'talent', 'temperature', 'thousand', 'tony', 'troops', 'truck', 'votes', 'ah', 'authorities', 'basically', 'besides', 'bird', 'blame', 'bob', 'bowl', 'causes', 'chicken', 'collected', 'context', 'coverage', 'determine', 'display', 'dying', 'elected', 'examples', 'experienced', 'falls', 'false', 'fired', 'forgot', 'funding', 'identified', 'iii', 'incredible', 'inspired', 'launched', 'ma', 'meat', 'ministry', 'mode', 'neck', 'noticed', 'novel', 'obvious', 'passing', 'positions', 'remaining', 'scored', 'shirt', 'shots', 'slowly', 'stadium', 'stores', 'surgery', 'trading', 'tuesday', 'vision', 'whenever', 'worried', 'zero', 'alex', 'allowing', 'begins', 'champion', 'charged', 'cream', 'crisis', 'daniel', 'delivered', 'editor', 'estimated', 'eu', 'giant', 'iran', 'jail', 'jim', 'kingdom', 'literature', 'mayor', 'minor', 'moments', 'opposite', 'orange', 'ourselves', 'pages', 'remained', 'selection', 'serving', 'signal', 'stream', 'struggle', 'suicide', 'talked', 'theme', 'thursday', 'tiny', 'typically', 'un', 'unfortunately', 'usual', 'vehicles', 'virginia', 'voted', 'voting', 'walls', 'wave', 'alcohol', 'assembly', 'breakfast', 'bright', 'brings', 'capable', 'carrying', 'chosen', 'combination', 'conservative', 'customer', 'cutting', 'desire', 'destroyed', 'draft', 'drunk', 'essential', 'fail', 'familiar', 'finds', 'granted', 'guilty', 'humans', 'hundreds', 'id', 'improved', 'jewish', 'largely', 'laughing', 'markets', 'medium', 'ohio', 'opportunities', 'papers', 'perfectly', 'recommend', 'referred', 'relevant', 'seek', 'sending', 'solo', 'spoke', 'stands', 'talks', 'ticket', 'unable', 'upset', 'wing', \"world's\", 'answers', 'birds', 'bomb', 'creative', 'cycle', 'dealing', 'directed', 'don', 'educational', 'entertainment', 'extreme', 'facility', 'fields', 'goods', 'hang', 'holds', 'info', 'mainly', 'maximum', 'newspaper', 'offering', 'painting', 'republic', 'reserve', 'returns', 'row', 'salt', 'scared', 'scottish', 'shares', 'statistics', 'switch', 'territory', 'threat', 'tickets', 'wales', 'adults', 'affect', 'appointed', 'armed', 'aside', 'assistance', 'bell', 'blow', 'bond', 'boyfriend', 'careful', 'circumstances', 'communications', 'concerns', 'controlled', 'corporation', 'cry', 'danger', 'deals', 'delivery', 'deserve', 'devices', 'dollar', 'dreams', 'empty', 'enjoyed', 'explained', 'faces', 'folks', 'fucked', 'gender', 'instance', 'kim', 'kinda', 'matches', 'mile', 'motion', 'moves', 'nick', 'pacific', 'prize', 'realized', 'reasonable', 'receiving', 'register', 'resolution', 'rural', 'ryan', 'saving', 'sees', 'singing', 'spain', 'tools', 'typical', 'universe', 'warning', 'wars', 'wednesday', 'admit', 'attitude', 'branch', 'brazil', 'conducted', 'decades', 'dedicated', 'definition', 'drawing', 'favor', 'flag', 'frame', 'guest', 'ha', 'heaven', 'independence', 'institutions', \"it'll\", 'jackson', 'kiss', 'load', 'plot', 'possibility', 'random', 'recovery', 'rent', 'replace', 'represent', 'reviews', 'scenes', 'seeking', 'senator', 'sentence', 'teeth', 'tips', 'trained', 'understood', 'academic', 'academy', 'accurate', 'achieve', 'adam', 'afford', 'andrew', 'assume', 'bbc', 'bottle', 'bunch', 'category', 'chat', 'cheese', 'chemical', 'clinton', 'competitive', 'detail', 'diet', 'em', 'favourite', 'fruit', 'harder', \"he'd\", 'index', 'item', 'lane', 'mess', 'navy', 'normally', 'occurred', 'opposition', 'parent', 'permanent', 'personally', 'pleasure', 'prefer', 'programme', 'representative', 'scheme', 'shift', 'stood', 'storage', 'tank', 'tend', 'tight', 'transportation', 'ultimately', 'unlike', 'weekly', 'yard', 'anybody', 'assets', 'basketball', 'button', 'candidates', 'combat', 'constitution', 'consumer', 'counter', 'creation', 'crown', 'crying', 'dc', 'defined', 'depending', 'depression', 'describe', 'drivers', 'el', 'employment', 'exclusive', 'excuse', 'expert', 'frequently', 'golf', 'grace', 'hopefully', 'identify', 'importance', 'kevin', 'laid', 'latter', 'manufacturing', 'mining', 'object', 'partners', 'pattern', 'performing', 'personnel', 'perspective', 'pregnant', 'premier', 'promote', 'q', 'revolution', 'rooms', 'severe', 'sleeping', 'suppose', 'tool', 'tournament', 'turkey', 've', 'victim', 'victims', '4th', 'agents', 'amazon', 'arrest', 'attend', 'ban', 'brilliant', 'carbon', 'catholic', 'chose', 'circle', 'concert', 'crash', 'declared', 'deliver', 'depth', 'deputy', 'dirty', 'doctors', 'earned', 'electronic', 'error', 'existence', 'experiences', 'expression', 'factory', 'headed', 'interior', 'joy', 'jr', 'legislation', 'maintenance', 'manner', 'mate', 'matt', 'nearby', 'noise', 'origin', 'pakistan', 'panel', 'personality', 'plate', 'practices', 'prepare', 'relief', 'replaced', 'resistance', 'retail', 'rice', 'roads', 'roof', 'shame', 'ships', 'somewhat', 'staying', 'stronger', 'surely', 'tip', 'updated', 'writers', 'absolute', 'advertising', 'agencies', 'baseball', 'bathroom', 'bible', 'cable', 'calm', 'championship', 'checked', 'client', 'constant', 'da', 'dates', 'degrees', 'democrats', 'doors', 'driven', 'dumb', 'empire', 'exciting', 'expansion', \"he'll\", 'heavily', 'hide', 'incident', 'irish', 'linked', 'manage', 'messages', 'michigan', 'multi', 'nfl', 'politicians', 'print', 'quit', 'refused', 'reporting', 'sight', 'significantly', 'sing', 'soviet', 'weapon', 'wet', 'widely', 'worldwide', 'ages', 'anniversary', 'attractive', 'bike', 'broad', 'burn', 'cake', 'causing', 'closely', 'constantly', 'contest', 'deaths', 'depends', 'drawn', 'e.g', 'fees', 'francisco', 'haha', 'hardly', 'hat', 'height', 'hidden', 'hong', 'invited', 'letting', 'loud', 'manchester', 'marine', 'motor', 'officially', 'pc', 'peak', 'portion', 'pounds', 'princess', 'protein', 'puts', 'raw', 'reform', 'regions', 'represented', 'respond', 'retirement', 'sample', 'seats', 'secondary', 'solar', 'somehow', 'stayed', 'suffering', 'sydney', \"today's\", 'tries', 'ultimate', 'unknown', 'wilson', 'wondering', 'attached', 'attacked', 'automatically', 'balls', 'battery', 'bills', 'blind', 'breath', 'brief', 'carolina', 'chest', 'conduct', 'debut', 'decade', 'destroy', 'differences', 'edward', 'engaged', 'experts', 'expressed', 'external', 'fantasy', 'ft', 'grab', 'hollywood', 'i.e', 'immediate', 'introduction', 'joseph', 'license', 'paint', 'pilot', 'pink', 'presidential', 'principal', 'recognize', 'recognized', 'registered', 'regularly', 'representatives', 'rising', 'seasons', 'shipping', 'singer', 'smoking', 'steam', 'suffered', 'survive', 'tall', 'thats', 'theatre', 'therapy', 'witness', 'adopted', 'aim', 'campus', 'cap', 'chances', 'childhood', 'clinical', 'clubs', 'comedy', 'commander', 'comparison', 'covers', 'dan', 'defeat', 'defence', 'democracy', 'detailed', 'entitled', 'exact', 'exposed', 'fed', 'fee', 'injured', 'jan', 'jordan', 'kinds', 'lets', 'loans', 'lock', 'musical', 'nose', 'objects', 'opposed', 'organized', 'plastic', 'protected', 'purposes', 'quote', 'recording', 'semi', 'statements', 'suspect', 'swear', 'techniques', 'tie', 'tim', 'trend', 'valuable', 'wealth', 'wise', 'yards', 'aged', 'approval', 'aspects', 'attempts', 'bread', 'burning', 'champions', 'contain', 'convention', 'dancing', 'document', 'eggs', 'employee', 'en', 'engineer', 'equivalent', 'facing', 'fairly', 'fingers', 'ford', 'founded', 'functions', 'gang', 'graduate', 'greek', 'hanging', 'inner', 'islands', 'le', 'lift', 'marked', 'memories', 'miller', 'monthly', 'mountains', 'neighborhood', 'operate', 'outstanding', 'permission', 'porn', 'racing', 'recommended', 'regulations', 'reply', 'republicans', 'rid', 'roman', 'scientists', 'shoulder', 'shower', 'solutions', 'sons', 'stations', 'stephen', 'tower', 'tradition', 'visited', 'visual', 'wheel', 'zealand', 'achieved', 'admitted', 'appointment', 'authors', 'barely', 'bc', 'bush', 'cabinet', 'celebrate', 'challenges', 'chocolate', 'coal', 'colour', 'contemporary', 'criticism', 'davis', 'dna', 'effectively', 'eric', 'extensive', 'faced', 'filed', 'formation', 'fought', 'gained', 'gallery', 'highway', 'historic', 'hunt', 'improvement', 'inch', 'initially', 'junior', 'jury', 'kong', 'korean', 'marks', 'monster', 'obtained', 'olympic', 'philosophy', 'pride', 'promised', 'repeat', 'returning', 'riding', 'rough', 'santa', 'settlement', 'smell', 'sought', 'speaker', 'studied', 'suggests', 'surrounding', 'tone', 'topic', 'toronto', 'universal', 'vast', 'visitors', 'wanting', 'auto', 'consistent', 'continuing', 'earn', 'exists', 'finger', 'grey', 'guitar', 'heading', 'howard', 'ignore', 'involving', 'latin', 'lewis', 'meal', 'meanwhile', 'meetings', 'naturally', 'necessarily', 'offices', 'pants', 'partnership', 'payments', 'percentage', 'pocket', 'practical', 'primarily', 'proved', 'rape', 'regardless', 'relative', 'represents', 'rescue', 'resulting', 'rush', 'sarah', 'sessions', 'sharp', 'simon', 'soccer', 'stable', 'structures', 'supplies', 'symptoms', 'temporary', 'tested', 'trick', 'attended', 'audio', 'bone', 'brian', 'bullshit', 'chamber', 'chart', \"children's\", 'circuit', 'clothing', 'complicated', 'confused', 'consequences', 'defend', 'divided', 'elizabeth', 'everyday', 'extent', 'fishing', 'format', 'gap', 'gate', 'gotten', 'harm', 'healthcare', 'household', 'immigration', 'impressive', 'jews', 'joining', 'killer', 'lesson', 'limits', 'loving', 'ltd', 'managers', 'membership', 'miami', 'mirror', 'mount', 'nights', 'occur', 'parking', 'proposal', 'province', 'purchased', 'recognition', 'reputation', 'rolling', 'shortly', 'situations', 'strongly', 'tears', 'technique', 'thin', 'tied', 'z', '3d', 'accused', 'adventure', 'argue', 'assessment', 'atmosphere', 'awful', 'bedroom', 'belief', 'bound', 'breaks', 'carefully', 'cats', 'ceo', 'choices', 'closing', 'cloud', 'colorado', 'colors', 'contrast', 'courses', 'courts', 'donald', 'drew', 'egg', 'element', 'elsewhere', 'establish', 'extension', 'files', 'founder', 'gear', 'georgia', 'hills', 'hip', 'hitting', 'increases', 'infrastructure', 'jason', 'locations', 'loose', 'machines', \"men's\", 'moral', 'offensive', 'pa', 'package', 'pointed', 'poverty', 'processes', 'processing', 'qualified', 'railway', 'reaching', 'ridiculous', 'sensitive', 'server', 'shock', 'silence', 'soldier', 'superior', 'supporters', 'thick', 'threw', 'tons', 'transition', 'violent', 'voters', 'wash', 'acid', 'actress', 'administrative', 'alan', 'alongside', 'angel', 'anxiety', 'babies', 'bars', 'bonus', 'castle', 'charity', 'clients', 'compare', 'contained', 'cooking', 'covering', 'curious', 'directors', 'discovery', 'discussed', 'duke', 'egypt', 'encourage', 'enforcement', 'featuring', 'finals', 'flash', 'formal', 'formula', 'fort', 'governments', 'gray', 'gross', 'horses', 'hungry', 'informed', 'innocent', 'jeff', 'losses', 'luke', 'mac', 'math', 'minds', 'mistakes', 'mystery', 'networks', 'olympics', 'palace', 'passes', 'penalty', 'pet', 'phones', 'photography', 'producing', 'protest', 'publication', 'rating', 'refer', 'respectively', 'rome', 'scheduled', 'select', 'silent', 'spoken', 'successfully', 'suffer', 'temple', 'tracks', 'trail', 'uncle', 'unusual', 'waters', 'woods', 'yo', 'arrival', 'asks', 'assault', 'awareness', 'badly', 'bath', 'captured', 'chase', 'components', 'concrete', 'dave', 'deeply', 'expectations', 'explanation', 'exposure', 'featured', 'fiction', 'guarantee', 'happiness', 'harris', 'hearts', 'horrible', 'ideal', 'illinois', 'injuries', 'islamic', 'jimmy', 'kelly', 'legend', 'lieutenant', 'mini', 'mood', 'muscle', 'muslims', 'p.m', 'passion', 'picking', 'pleased', 'procedure', 'producer', 'pushing', 'rank', 'replacement', 'retired', 'roles', 'sand', 'savings', 'settled', 'shadow', 'singles', 'tag', 'tape', 'thread', 'victoria', 'visiting', 'wage', \"we'd\", 'wings', 'andy', 'avenue', 'bags', 'beating', 'believes', 'blocks', 'boring', 'charlie', 'checking', 'clock', 'commissioner', 'commitment', 'confident', 'containing', 'copies', 'crimes', 'custom', 'denied', 'desk', 'drinks', 'ear', 'electricity', 'episodes', 'farmers', 'fbi', 'grounds', 'gym', 'helpful', 'horror', 'iphone', 'iraq', 'label', 'liverpool', 'locked', 'naked', 'ny', 'opens', 'output', 'persons', 'pitch', 'pizza', 'plain', 'pushed', 'raising', 'rear', 'reveal', 'romantic', 'scores', 'sisters', 'speaks', 'stages', 'strategic', 'swimming', 'welfare', 'winners', 'wire', 'worker', '5th', 'afterwards', 'alright', 'android', 'anger', 'architecture', 'assist', 'attempted', 'behalf', 'belt', 'capture', 'centers', 'ceremony', 'comic', 'cops', 'cuts', 'dallas', 'designer', 'diamond', 'disappointed', 'dressed', 'economics', 'efficient', 'electrical', 'employed', 'enjoying', 'entering', 'essentially', 'establishment', 'expecting', 'explains', 'flower', 'ghost', 'guests', 'handed', 'hockey', 'houston', 'https', 'hunting', 'industries', 'islam', 'jane', 'judges', 'kit', 'lab', 'languages', 'maps', 'min', 'morgan', 'moscow', 'na', 'nervous', 'newly', 'odd', 'op', 'ordinary', 'participate', 'philadelphia', 'prayer', 'principles', 'racist', 'rarely', 'references', 'sexy', 'skill', 'soil', 'solve', 'stomach', 'struck', 'studying', 'suck', 'supports', 'trash', 'ugly', 'vegas', 'virus', 'walker', 'whoever', 'amounts', 'anthony', 'arthur', 'aspect', 'banned', 'boost', 'bureau', 'colonel', 'comfort', 'controls', 'cousin', 'crack', 'deck', 'demands', 'dies', 'dragon', 'dramatic', 'dust', 'dutch', 'engineers', 'evolution', 'foods', 'hired', 'illness', 'inspiration', 'institution', 'kings', 'knife', 'lately', 'lowest', 'memorial', 'mexican', 'minority', 'mum', 'opinions', 'patterns', 'presents', 'priority', 'promotion', 'rail', 'readers', 'remote', 'repair', 'root', 'saint', 'steal', 'stolen', 'telephone', 'tho', 'titles', 'trans', 'ups', 'vol', 'whereas', 'abandoned', 'acquired', 'actors', 'alexander', 'alliance', 'annoying', 'ap', 'bid', 'bro', 'buddy', 'buried', 'butter', 'cares', 'columbia', 'conclusion', 'confirm', 'congratulations', 'contracts', 'convinced', 'crap', 'crystal', 'dean', 'decent', 'decline', 'delay', 'describes', 'desert', 'downtown', 'elite', 'enemies', 'forgotten', 'forth', 'gods', \"hadn't\", 'hire', 'hop', 'hopes', 'insane', 'installed', 'israeli', 'landing', 'layer', 'managing', 'marry', 'nah', 'nowhere', 'nurse', 'obtain', 'organic', 'ownership', 'participants', 'pennsylvania', 'poetry', 'pot', 'pray', 'printed', 'recall', 'rugby', 'sake', 'sheet', 'signing', 'smooth', 'spiritual', 'stops', 'string', 'sudden', 'sweden', 'syria', 'throwing', 'thrown', 'vacation', 'abroad', 'arab', 'assigned', 'associate', 'assumed', 'atlantic', 'bench', 'bother', 'broadcast', 'bye', 'cambridge', 'citizen', 'cleaning', 'compete', 'consists', 'consumers', 'contributed', 'cricket', 'critics', 'damaged', 'disaster', 'discover', 'disney', 'entrance', 'equally', 'fallen', 'figured', 'fitness', 'francis', 'friendship', 'gary', 'handling', 'idiot', 'intense', 'keys', 'lawyers', 'lifetime', 'liquid', 'makeup', 'medal', 'mortgage', 'narrative', 'narrow', 'nba', 'observed', 'occasionally', \"one's\", 'pan', 'physics', 'posting', 'potentially', 'reduction', 'reflect', 'refuse', 'researchers', 'resource', 'roger', 'ross', 'sciences', 'seattle', 'serves', 'shell', 'silly', 'subsequent', \"they'd\", 'towns', 'translation', 'visible', 'yep', 'adds', 'allen', 'amendment', 'angle', 'arizona', 'arrive', 'belong', 'berlin', 'bishop', 'channels', 'clark', 'commonly', 'connect', 'defensive', 'designs', 'efficiency', 'enterprise', 'experiment', 'feb', 'females', 'findings', 'firms', 'forum', 'gifts', 'grass', 'hence', 'increasingly', 'incredibly', 'iv', 'jay', 'journalist', 'kicked', 'lessons', 'lists', 'maintained', 'mill', 'mo', 'occasion', 'oxford', 'pace', 'passenger', 'pen', 'pope', 'possession', 'pp', 'races', 'rapid', 'regulation', 'resident', 'rocks', 'shaped', 'sixth', 'spin', 'styles', 'subjects', 'sucks', 'suitable', 'thirty', 'valid', 'vital', 'whilst', \"year's\", 'agriculture', 'alleged', 'anna', 'atlanta', 'bands', 'christians', 'collect', 'commerce', 'cop', 'creek', 'currency', 'emotions', 'exhibition', 'fraud', 'funeral', 'genuine', \"god's\", 'gordon', 'honey', 'honour', 'hook', 'hunter', 'immigrants', 'improving', 'instructions', 'introduce', 'kansas', 'km', 'lands', 'legacy', 'log', 'matthew', 'merely', 'monitor', \"mother's\", 'nov', 'patrick', 'phil', 'prisoners', 'programming', 'publishing', 'ratio', 'regret', 'rejected', 'remind', 'resort', 'resulted', 'reverse', 'routine', 'scary', 'seed', 'settle', 'sin', 'spell', 'summary', 'survival', 'sword', 'tongue', 'ward', 'waves', 'wayne', 'achievement', 'anderson', 'argued', 'asleep', 'austin', 'automatic', 'begun', 'behaviour', 'cd', 'cents', 'coat', 'comprehensive', 'consent', 'daddy', 'destruction', 'diego', 'diseases', 'divorce', 'doc', 'drove', 'ears', 'engage', 'extraordinary', 'fate', 'frequency', 'gaming', 'gene', 'glory', 'headquarters', 'heritage', 'initiative', 'interviews', 'jean', 'juice', 'landscape', 'logic', 'meets', 'melbourne', 'microsoft', 'objective', 'organisation', 'privacy', 'procedures', 'profits', 'reducing', 'regard', 'representing', 'residence', 'roughly', 'salary', 'scoring', 'script', 'searching', 'sections', 'strip', 'surrounded', 'threatened', 'transferred', 'tube', 'universities', 'walter', 'wisconsin', \"would've\", 'writes', 'a.m', 'ambassador', 'ann', 'apps', 'awarded', 'banking', 'breast', 'cant', 'carter', 'chelsea', 'chemistry', 'concluded', 'consumption', 'corruption', 'cotton', 'crossed', 'detroit', 'discount', 'dozen', 'engines', 'epic', 'exception', 'exit', 'expand', 'fancy', 'gorgeous', 'grateful', 'heroes', 'holes', 'impression', 'inches', 'indicate', 'input', 'johnny', 'josh', 'knock', 'leather', 'lips', 'luxury', 'lyrics', 'manufacturers', 'masters', 'movements', 'oct', 'operated', 'ought', 'outcome', 'painted', 'poll', 'preferred', 'pulling', 'ranked', 'referring', 'removal', 'rep', 'reporter', 'rio', 'risks', 'rob', 'screaming', 'sept', 'sequence', 'singapore', 'stretch', 'tear', 'tennis', 'terrorist', 'theater', 'ties', 'twelve', 'versions', 'virgin', 'voices', 'wishes', 'wolf', 'absence', 'agricultural', 'asshole', 'ate', 'athletes', 'bears', 'blues', 'boxes', 'bruce', 'bull', 'cameras', 'commonwealth', 'contribute', 'contribution', 'contributions', 'couples', 'delicious', 'deny', 'deserves', 'ease', 'extend', 'fame', 'flood', 'generated', 'genetic', 'glasses', 'impressed', 'indicated', 'instant', 'investors', 'involves', 'kate', 'kills', 'liberty', \"man's\", 'maria', 'ministers', 'monitoring', 'occurs', 'passengers', 'photographs', 'principle', 'producers', 'progressive', 'punishment', 'rally', 'rapidly', 'reader', 'representation', 'restaurants', 'reveals', 'roots', 'samples', 'shops', 'sum', 'swing', 'tail', 'texts', 'twin', 'upcoming', 'veterans', 'alert', 'arena', 'arguments', 'aug', 'billy', 'boom', 'boots', 'brave', 'claiming', 'column', 'commit', 'compensation', 'composition', 'computers', 'conservation', 'constitutional', 'crossing', 'd.c', 'defending', 'density', 'di', 'difficulty', 'dropping', 'drops', 'elementary', 'ethnic', 'expenses', 'fleet', 'foster', 'fuckin', 'fundamental', 'gen', 'genius', 'greatly', 'guidance', 'hospitals', 'infection', 'instagram', 'intention', 'iowa', 'jokes', 'knee', 'mechanical', 'nigeria', 'parks', 'participation', 'periods', 'precious', 'pregnancy', 'premium', 'preparing', 'pretend', 'priest', 'prominent', 'proven', 'radical', 'remembered', 'requested', 'residential', 'reward', 'rings', 'robin', 'russell', 'satellite', 'shake', 'shore', 'spots', 'stats', 'struggling', 'substantial', 'teen', 'temperatures', 'transmission', 'trap', 'uniform', 'wildlife', 'wooden', 'ads', 'aggressive', 'anne', 'answered', 'apparent', 'bang', 'blast', 'bones', 'brands', 'centuries', 'communist', 'complaint', 'component', 'connections', 'courage', 'cure', 'del', 'desperate', 'diversity', 'duties', 'encouraged', 'eve', 'faculty', 'feedback', 'fighter', 'frozen', 'guards', 'hiding', 'humanity', 'ian', 'il', 'innovation', 'instruments', 'invest', 'jacket', 'justin', 'legislative', 'listing', 'manual', 'mothers', 'murdered', 'nursing', 'occupied', 'ongoing', 'operator', 'painful', 'pound', 'preparation', 'punch', 'purple', 'railroad', 'registration', 'releases', 'rick', 'romance', \"someone's\", 'submitted', 'sufficient', 'survived', 'suspended', 'technologies', 'tissue', 'trailer', 'trends', 'trials', 'ukraine', 'underground', 'versus', 'virtual', 'walks', 'wounded', 'ali', 'amongst', 'announcement', 'arranged', 'arsenal', 'attending', 'attracted', 'biological', 'bite', 'blocked', 'boards', 'burned', 'categories', 'checks', 'chip', \"company's\", 'concerning', 'dare', 'database', 'define', 'discrimination', 'disorder', 'distributed', 'districts', 'documentary', 'domain', 'dynamic', 'edited', 'engagement', 'explore', 'favour', 'fewer', 'footage', 'giants', 'grave', 'hamilton', 'implementation', 'indiana', 'investigate', 'jazz', 'jon', 'jonathan', 'laboratory', 'lawrence', 'lincoln', 'literary', 'mask', 'massachusetts', 'midnight', 'minnesota', 'mouse', 'oscar', 'packed', 'piano', 'praise', 'presentation', 'psychology', 'relation', 'restrictions', 'rocket', 'ruin', 'saudi', 'sean', 'sec', 'secrets', 'slave', 'stability', 'steady', 'stones', 'symbol', 'terminal', 'toilet', 'treaty', 'triple', 'unlikely', 'updates', 'vietnam', 'viewed', '6th', 'affair', 'agenda', 'bat', 'bow', 'calendar', 'cape', 'collective', 'conversations', 'cooperation', 'craft', 'darkness', 'deeper', 'devil', 'edit', 'enable', 'equity', 'estimates', 'failing', 'finishing', 'fortune', 'gates', 'goodbye', 'graham', 'hardware', 'hillary', 'hurts', 'intellectual', 'invite', 'involvement', 'kentucky', 'madrid', 'mi', 'nuts', 'oregon', 'partly', 'petition', 'phrase', 'physically', 'protecting', 'racial', 'rated', 'regime', 'rivers', 'rounds', 'ruled', 'sa', 'sauce', 'seal', 'separated', 'shield', 'similarly', 'slide', 'stem', 'summit', 'talented', 'throat', 'tiger', 'touched', 'toy', 'visits', 'warriors', 'wisdom', 'accounting', 'alien', 'attacking', 'awkward', 'beast', 'beef', 'candy', 'carrier', 'celebration', 'celebrity', 'certificate', 'cited', 'clay', 'coaching', 'colleagues', 'constructed', 'dated', 'dec', 'default', 'delhi', 'derived', 'dialogue', 'disabled', 'distinct', 'drag', 'educated', 'eligible', 'estimate', 'execution', 'existed', 'fifty', 'followers', 'fool', 'framework', 'franchise', 'funded', 'furniture', 'generations', 'guaranteed', 'integrated', 'intelligent', 'interaction', 'jet', 'journalists', 'lifestyle', 'lighting', 'lisa', 'loop', 'mall', 'mp', 'overseas', 'performances', 'philippines', 'polish', 'recommendations', 'recover', 'regarded', 'relax', 'reliable', 'rely', 'remarkable', 'responses', 'ruling', 'sacrifice', 'se', 'sole', 'stopping', 'strategies', 'succeed', 'tables', 'tale', 'targets', 'timing', 'ton', 'volunteers', 'witnesses', 'wore', 'worship', 'worthy', 'acted', 'alarm', 'bass', 'bloody', 'breathing', 'butt', 'characteristics', 'cnn', 'collaboration', 'con', 'consideration', 'counts', 'creates', 'crucial', 'daughters', 'dependent', 'discussions', 'drives', 'dual', 'edinburgh', 'equipped', 'expanded', 'experimental', 'feeding', 'filter', 'galaxy', 'globe', 'grades', 'greece', 'gulf', 'highlights', 'hoped', 'intent', 'involve', 'judgment', 'kennedy', 'knight', 'larry', 'las', 'lmao', 'logo', 'malaysia', 'mature', 'moore', 'nazi', 'netherlands', 'odds', 'peaceful', 'philip', 'photographer', 'pin', 'prevention', 'printing', 'promoting', 'publicly', 'pump', 'repeated', 'replied', 'requests', 'revenge', 'satisfied', 'seeds', 'signals', 'slip', 'spaces', 'spare', 'specialist', 'stocks', 'stranger', 'submit', 'surprising', 'tap', 'thompson', 'threats', 'tourism', 'turkish', 'volunteer', '7th', 'acceptable', 'allies', 'attempting', 'auction', 'bonds', 'challenging', 'chaos', 'churches', 'cleveland', 'cm', 'composed', 'concentration', 'copper', 'corp', 'corps', 'counting', 'credits', 'dawn', 'dispute', 'earnings', 'editing', \"everyone's\", 'executed', 'firing', 'fits', 'frequent', 'gardens', 'gathered', 'hilarious', 'huh', 'ignored', 'improvements', 'investments', 'isis', 'margin', 'mars', 'maryland', 'mechanism', 'moderate', 'murray', 'oklahoma', 'opera', 'overcome', 'parallel', 'passage', 'pit', 'psychological', 'publications', 'quest', 'radiation', 'shocked', 'sized', 'stroke', 'stunning', 'tanks', 'tokyo', 'topics', 'trains', 'traveling', 'treating', 'tune', 'utility', 'vessel', 'weed', 'wherever', '©', 'acquisition', 'addressed', 'alabama', 'alice', 'angels', 'anime', 'announce', 'autumn', 'backed', 'barry', 'bold', 'borders', 'breathe', 'cameron', 'choosing', 'classical', 'classified', 'clip', 'coaches', 'coins', 'concepts', 'conspiracy', 'controversy', 'convince', 'cooper', 'disappeared', 'eh', 'encounter', 'equality', 'exam', 'examination', 'fails', \"father's\", 'federation', 'fi', 'fiscal', 'guardian', 'hd', 'homeless', 'instrument', 'intervention', 'jerry', 'lover', 'mainstream', 'menu', 'missouri', 'mounted', 'mutual', 'nope', 'occasions', 'offense', 'oral', 'panic', 'pays', 'peoples', 'pursue', 'realise', 'refugees', 'removing', 'requirement', 'responded', 'rip', 'ruined', 'scope', 'segment', 'spectrum', 'stays', 'ted', 'terror', 'uh', 'va', 'venture', 'virtually', 'waited', 'warren', 'worn', 'yea', 'ac', 'accompanied', 'adams', 'aids', 'aimed', 'alpha', 'approaches', 'arguing', 'arrangement', 'beliefs', 'boats', 'boundaries', 'brick', 'brooklyn', 'colleges', 'considerable', 'conventional', 'danny', 'des', 'designated', 'dvd', 'emperor', 'employers', 'enormous', 'errors', 'focusing', 'forgive', 'gains', 'garage', 'gathering', 'guidelines', 'handled', 'hosted', 'indians', 'indonesia', 'inquiry', 'inspector', 'jumped', 'khan', 'li', 'lion', 'loaded', 'lonely', 'maintaining', 'measured', 'mercy', 'nevertheless', 'newspapers', 'outer', 'oxygen', 'pipe', 'pissed', 'poem', 'powder', 'powered', 'promises', 'quotes', 'racism', 'ratings', 'reads', 'recovered', 'refers', 'roy', 'rude', 'screw', 'seventh', 'shelter', 'signature', 'sooner', 'spider', 'stewart', 'strikes', 'suggesting', 'suits', 'toys', 'tracking', 'tribute', 'trigger', 'vary', 'venue', 'wages', 'wells', 'wheels', 'ye', '😂', '8th', 'abc', 'abortion', 'accuracy', 'albert', 'applying', 'artificial', 'belongs', 'beneath', 'bitcoin', 'bullet', 'burns', 'carl', 'celebrated', 'consistently', 'conversion', 'copyright', 'counties', 'democrat', 'deposit', 'destination', 'dirt', 'diverse', 'divine', 'emails', 'er', 'exclusively', 'export', 'fastest', 'formerly', 'functional', 'gather', 'grandfather', 'habit', 'harvard', 'indicates', 'isolated', 'jealous', 'knocked', 'landed', 'laughed', 'laura', 'lazy', 'mama', 'marshall', 'mitchell', 'modified', 'municipal', 'naval', 'neighbors', 'nelson', 'neutral', 'noble', 'oldest', 'pat', 'picks', 'poland', 'popularity', 'professionals', 'pussy', 'reactions', 'relate', 'robot', 'sacred', 'securities', 'shoe', 'speakers', 'springs', 'spy', 'steven', 'suggestions', 'supplied', 'susan', 'suspension', 'terrorism', 'terry', 'toxic', 'treasury', 'tunnel', 'unions', 'upgrade', 'warrant', 'wider', 'wound', 'aaron', 'actively', 'afghanistan', 'ai', 'applies', 'arrangements', 'asset', 'assuming', 'backing', 'baker', 'barcelona', 'blessed', 'brazilian', 'brush', 'burden', 'campbell', 'carries', 'casual', 'certified', 'charter', 'chef', \"city's\", 'civilian', 'coalition', 'cock', 'complain', 'complaints', 'controversial', 'denver', 'describing', 'differently', 'directions', 'discipline', 'discussing', 'disgusting', 'dj', 'dominant', 'earning', 'emma', 'essay', 'expense', 'explaining', 'furthermore', 'graphic', 'greg', 'healing', 'hiring', 'hosts', 'implemented', 'instantly', 'invasion', 'jacob', 'jumping', 'laptop', 'legendary', 'leo', 'maker', 'margaret', 'mario', 'opponents', 'outdoor', 'palm', 'parker', 'photograph', 'pole', 'pub', 'quarters', 'queensland', 'rangers', 'ranks', 'reception', 'recipe', 'regulatory', 'reviewed', 'rolls', 'rubber', 'secured', 'serial', 'settings', 'shed', 'snake', 'sponsored', 'stealing', 'strict', 'subsequently', 'substance', 'suggestion', 'switzerland', 'syndrome', 'tasks', 'trips', 'ultra', 'unexpected', 'usage', 'utah', 'worlds', 'accidentally', 'affordable', 'amateur', 'appeals', 'argentina', 'baltimore', 'batman', 'bearing', 'beats', 'bin', 'biology', 'bobby', 'briefly', 'canal', 'cancelled', 'charlotte', 'cheaper', 'christopher', 'climb', 'com', 'competing', 'completion', 'cruise', 'custody', 'delete', 'demonstrated', 'departure', 'developers', 'developments', 'dig', 'eagles', 'employer', 'evans', 'explosion', 'fever', 'fluid', 'folk', 'generate', 'gop', 'handsome', 'ho', 'holidays', 'hotels', 'imagination', 'integration', 'integrity', 'interpretation', 'leaf', 'legitimate', 'lightning', 'loads', 'longest', 'magical', 'mills', 'motivation', 'nasty', 'oliver', 'outfit', 'pension', 'permit', 'perry', 'plates', 'pleasant', 'portrait', 'productive', 'reminds', 'reserves', 'ron', 'safely', 'shirts', 'shorter', 'slight', 'socialist', 'streaming', 'sue', 'targeted', 'tension', 'thailand', 'theories', 'touching', 'transactions', 'twist', 'ugh', 'unemployment', 'unity', 'useless', 'viewers', 'winds', 'woke', 'wtf', '_', 'abilities', 'advocate', 'aims', 'arc', 'backup', 'beaten', 'bitter', 'blown', 'branches', 'campaigns', 'chips', 'cia', 'clever', 'clinic', 'closest', 'collections', 'continuous', 'converted', 'correctly', 'creator', 'creatures', 'criteria', 'declined', 'detective', 'difficulties', 'disability', 'dish', 'douglas', 'du', 'duck', 'egyptian', 'ep', 'evaluation', 'excess', 'farming', 'fence', 'fifa', 'fighters', 'flights', 'forcing', 'forming', 'franklin', 'fred', 'gradually', 'gravity', 'habits', 'hawaii', 'highlight', 'holder', 'hood', 'hung', 'identical', 'imperial', 'investigations', 'jose', 'ken', 'legally', 'lied', 'listened', 'males', 'manufacturer', 'meters', 'nail', 'nasa', 'negotiations', 'nonsense', 'ontario', 'operational', 'orleans', 'owns', 'phoenix', 'playoffs', 'poet', 'quoted', 'relating', 'repeatedly', 'robinson', 'rolled', 'scientist', 'sink', 'skip', 'slavery', 'snap', 'sorts', 'souls', 'stole', 'swedish', 'swim', 'swiss', 'tennessee', 'transaction', 'transformation', 'veteran', 'vulnerable', 'wealthy', 'additionally', 'amy', 'attract', 'barbara', 'beta', 'blowing', 'bored', 'bronze', 'bug', 'caring', 'catching', 'cave', 'cheating', 'chronic', 'cleared', 'communicate', 'convicted', 'cultures', 'dealt', 'delayed', 'demonstrate', 'departments', 'depend', 'developer', 'diagnosis', 'dismissed', 'distinguished', 'dose', 'eighth', 'experiments', 'fa', 'flesh', 'flip', 'forty', 'generous', 'germans', 'hated', 'hr', 'implement', 'incorporated', 'influenced', 'jerusalem', 'kidding', 'laser', 'loyal', 'marijuana', 'md', 'mentally', 'missions', 'occupation', 'opponent', 'paintings', 'patch', 'patience', 'pic', 'pointing', 'pollution', 'precisely', 'prisoner', 'privilege', 'proposals', 'protests', 'punk', 'radar', 'regards', 'relatives', 'resist', 'solely', 'stepped', 'striking', 'terrorists', 'th', 'tourist', 'transit', 'trucks', 'trusted', 'vessels', 'villa', 'volumes', 'websites', 'wireless', 'wondered', 'wrap', 'wright', 'yoga', 'adopt', 'airlines', 'alaska', 'albums', \"america's\", 'anytime', 'bacteria', 'beings', 'beside', 'blade', 'boot', 'bottles', 'bucks', 'bulk', 'camps', 'cargo', 'census', 'christianity', 'coastal', 'coin', 'colored', 'commentary', 'confusion', 'congressional', 'corn', 'cried', 'customs', 'dealer', 'deemed', 'destiny', 'distant', 'electronics', 'emerging', 'emotion', 'emphasis', 'ethics', 'excitement', 'exploration', 'fights', 'filling', 'filming', 'glasgow', 'graphics', 'helen', 'humor', 'insight', 'invested', \"it'd\", 'jennifer', 'lit', 'louisiana', 'mar', 'marie', 'meals', 'mississippi', 'nerve', 'netflix', 'nightmare', 'operators', 'overnight', 'partially', 'participating', 'pie', 'platforms', 'populations', 'poster', 'pr', 'practically', 'preserve', 'produces', 'qualify', 'raid', 'ram', 'ranging', 'ranking', 'receives', 'respective', 'restricted', 'routes', 'samuel', 'sandy', 'scenario', 'sheep', 'situated', 'slaves', 'sony', 'spotted', 'spreading', 'stanley', 'sustainable', 'sustained', 'taxi', 'themes', 'threatening', 'tobacco', 'trace', 'trapped', 'turner', 'uncomfortable', 'wasted', 'weakness', 'widespread', 'xbox', 'accepting', 'accessible', 'acknowledge', 'advised', 'advisory', 'animation', 'assignment', 'balanced', 'bare', 'basement', 'bases', 'battles', 'bias', 'birmingham', 'bits', 'cancel', 'carpet', 'ceiling', 'cherry', 'chill', 'classification', 'clue', 'codes', 'cole', 'collapse', 'collecting', 'compound', 'conscious', 'consecutive', 'contents', 'costume', 'craig', 'deleted', 'devoted', 'didnt', 'displayed', 'dominated', 'earl', 'endless', 'escaped', 'examine', 'floating', 'garbage', 'gospel', 'grain', 'grid', 'grows', 'heating', 'identification', 'knees', 'lap', 'lions', 'liver', 'metro', 'metropolitan', 'mines', 'mixture', 'nominated', 'oak', 'parliamentary', 'patent', 'perception', 'physician', 'portland', 'proceed', 'proceedings', 'pupils', 'reserved', 'restore', 'rifle', 'rival', 'rs', 'runner', 'sadly', 'sc', \"she'd\", \"she'll\", 'shoulders', 'significance', 'sits', 'sizes', 'slept', 'soap', 'spray', 'stored', 'stressed', 'structural', 'suite', 'tbh', 'tropical', 'ukrainian', 'unnecessary', 'verse', 'victor', 'vintage', 'warned', 'watson', 'acres', 'adapted', 'adoption', 'anonymous', 'antonio', 'approaching', 'artistic', 'attendance', 'aviation', 'barrel', 'beds', 'beloved', 'bless', 'boxing', 'celebrating', 'charging', 'chemicals', 'chuck', 'cinema', 'colonial', 'comics', 'compliance', 'contrary', 'controlling', 'corporations', 'couch', \"country's\", 'crush', 'dam', 'decrease', 'defeated', 'diabetes', 'dressing', 'expanding', 'fears', 'fires', 'genre', 'gentle', 'grammar', 'hiv', 'idk', 'illustrated', 'invented', 'jake', 'jam', 'jamie', 'jessica', 'keith', 'kent', 'layers', 'lease', 'lens', 'licensed', 'loyalty', 'madison', 'magnetic', 'metres', 'monsters', 'mysterious', 'notion', 'partial', 'piss', 'placing', 'propaganda', 'rat', 'reflection', 'reminded', 'resolve', 'revolutionary', 'scandal', 'shine', 'si', 'simultaneously', 'substitute', 'surveillance', 'tactics', 'testimony', 'thai', 'treasure', 'trophy', 'tweet', 'tyler', 'underlying', 'unfair', 'villages', 'von', 'wa', 'acceptance', 'accidents', 'affects', 'annually', 'apologize', 'appreciated', 'approached', 'arriving', 'ash', 'aunt', 'benjamin', 'blake', 'bubble', 'buyers', 'casino', 'charts', 'clouds', 'connecting', 'counsel', 'creature', 'deadly', 'decides', 'der', 'desired', 'determination', 'embrace', 'emerged', 'exhibit', 'flew', 'gentleman', 'gm', 'halloween', 'hammer', 'hitler', 'hosting', 'icon', 'imposed', 'indigenous', 'infinite', 'installation', 'inter', 'interactions', 'introducing', 'iranian', 'kicking', 'laying', 'legislature', 'liability', 'maine', 'makers', 'manhattan', 'marathon', 'marvel', 'michelle', 'moreover', 'mps', 'neil', 'organisations', 'ours', 'parade', 'paradise', 'perceived', 'pics', 'planes', 'politician', 'preliminary', 'premiere', 'presidency', 'reaches', 'react', 'realistic', 'remarks', 'retain', 'roberts', 'rocky', 'russians', 'saints', 'satisfaction', 'scratch', 'shade', 'sheets', 'sheriff', 'shy', 'sometime', 'spirits', 'sporting', 'strictly', 'sunshine', 'teens', 'thou', 'tier', 'tommy', 'travelling', 'vancouver', 'vocal', 'warrior', \"woman's\", 'worries', 'yield', 'accomplished', 'admission', 'adventures', 'aka', 'appearing', 'bacon', 'barrier', 'belgium', 'believing', 'blacks', 'bombs', 'burst', 'caps', 'casting', 'cattle', 'cc', 'classroom', 'collins', 'colours', 'compromise', 'convenient', 'costa', 'criminals', 'crop', 'earthquake', 'elderly', 'eliminate', 'embarrassing', 'farmer', 'finest', 'grants', 'harbor', 'harvey', 'hates', 'incidents', 'inform', 'ion', 'jeremy', 'lesbian', 'lovers', 'lt', 'mathematics', 'medication', 'minded', 'morris', 'norway', 'par', 'podcast', 'portfolio', 'productivity', 'promoted', 'protocol', 'quietly', 'rachel', 'replacing', 'responsibilities', 'salad', 'scholarship', 'screening', 'sends', 'smiling', 'soup', 'southeast', 'stake', 'stating', 'strain', 'suspected', 'swift', 'tackle', 'tigers', 'timeline', 'torture', 'traded', 'translated', 'tricks', 'twins', 'urgent', 'vegetables', 'vertical', 'violation', 'wallet', 'welsh', 'workshop', 'wrapped', '9th', 'aboard', 'abstract', 'accent', 'addiction', 'associates', 'awake', 'beam', 'beans', 'binding', 'blank', 'buffalo', 'cbs', 'commons', 'conservatives', 'contacts', 'conviction', 'corrupt', 'cow', 'curve', 'depressed', 'deserved', 'dining', 'disorders', 'duration', 'eddie', 'emily', 'encouraging', 'farms', 'fifteen', 'flows', 'ga', 'genes', 'graduated', 'grandmother', 'harsh', 'heights', 'horn', 'hurry', 'immune', 'inflation', 'ingredients', 'inspection', 'install', 'instruction', 'intensity', 'inventory', 'investigated', 'invitation', 'judicial', 'justify', 'kyle', 'lakes', 'lean', 'lecture', 'libraries', 'logical', 'mason', 'meaningful', 'migration', 'missile', 'motivated', 'muscles', 'nancy', 'norman', 'northwest', 'nurses', 'organ', 'patrol', 'pearl', 'peer', 'pepper', 'pig', 'pile', 'plug', 'provision', 'releasing', 'requiring', 'revised', 'rod', 'scream', 'stairs', 'staring', 'statistical', 'sticks', 'strangers', 'succeeded', 'sweat', 'switched', 'syrian', 'tattoo', 'teenage', 'thunder', 'tours', 'tragedy', 'trauma', 'vincent', 'wrestling', 'zoo', 'accordance', 'acquire', 'activist', 'activists', 'addresses', 'alike', 'applicable', 'arrow', 'availability', 'aw', 'ba', 'bend', 'boundary', 'breach', 'cabin', 'cage', 'chancellor', 'cheers', 'circles', 'closet', 'combine', 'companion', 'comparing', 'consciousness', 'consultant', 'controller', 'corresponding', 'courtesy', 'cuba', 'damages', 'demanding', 'disc', 'dishes', 'dozens', 'eagle', 'eaten', 'embassy', 'engaging', 'fascinating', 'financing', 'fitted', 'flexible', 'gaining', 'gentlemen', 'goodness', 'guilt', 'haven', 'helicopter', 'homework', 'households', 'hp', 'iconic', 'infected', 'keen', 'kenya', 'lesser', 'liberals', 'lip', 'mandatory', 'manufactured', 'mechanics', 'mere', 'miracle', 'mt', 'mud', 'murphy', 'nathan', 'observation', 'operates', 'owe', 'permitted', 'phenomenon', 'pittsburgh', 'playoff', 'precise', 'profession', 'prospect', 'protective', 'providers', 'publisher', 'putin', 'reportedly', 'retreat', 'rookie', 'sandwich', 'seeks', 'sentences', 'separation', 'sexually', 'ski', 'skilled', 'sterling', 'stuart', 'surgeon', 'theft', 'um', 'understands', 'valve', 'visa', 'washing', 'adjacent', 'agreements', 'appreciation', 'arabia', 'athletic', 'authorized', 'banner', 'beijing', 'blew', 'blocking', 'brad', 'caribbean', 'charm', 'chasing', 'climbing', 'colony', 'complaining', 'cookies', 'cruel', 'curriculum', 'deadline', 'deer', 'delta', 'demanded', 'dive', 'divide', 'easter', 'electoral', 'eleven', 'entity', 'excessive', 'exercises', 'feminist', 'governing', 'ham', 'heal', 'interface', 'ios', 'jewelry', 'journalism', 'juan', 'julia', 'jungle', 'linear', 'mg', 'occasional', 'oriented', 'pete', 'pilots', 'prayers', 'predicted', 'pressed', 'preventing', 'prof', 'provisions', 'pursuit', 'rap', 'reflected', 'reminder', 'restored', 'resume', 'rev', 'richmond', 'ridge', 'samsung', 'scholars', 'sealed', 'sounded', 'sri', 'streams', 'strongest', 'tends', 'tribe', 'unfortunate', 'variable', 'victorian', 'worrying', 'xi', 'zones', 'ace', 'adjusted', 'alternate', 'arrives', 'artwork', 'ashley', 'athlete', 'attraction', 'babe', 'bankruptcy', 'canon', 'capabilities', 'cared', 'catherine', 'chains', 'closure', 'cognitive', 'competitors', 'connecticut', 'convert', 'cooked', 'ct', 'cups', 'deciding', 'defender', 'dental', 'diplomatic', 'divisions', 'drum', 'editorial', 'enabled', 'entertaining', 'est', 'establishing', 'eternal', 'freeze', 'generic', 'grandma', 'grip', 'handful', 'happily', 'harmony', 'hmm', 'humble', 'hurting', 'hybrid', 'intentions', 'investing', 'keyboard', 'lasting', 'locally', 'loses', 'mild', 'minimal', 'mixing', 'molecular', 'nearest', 'neighbor', 'noon', 'nowadays', 'openly', 'overview', 'pairs', 'palestinian', 'parish', 'pathetic', 'poems', 'possibilities', 'potato', 'potter', 'preference', 'promising', 'proportion', 'purchases', 'rage', 'rd', 'reflects', 'respected', 'restoration', 'selfish', 'sergeant', 'silk', 'stamp', 'throne', 'thy', 'urge', 'voter', 'warner', 'wasting', 'witch', 'advantages', 'ally', 'archives', 'array', 'assisted', 'backs', 'belly', 'booth', 'breakdown', 'bridges', 'brutal', 'calculated', 'cam', 'centres', 'chapters', 'citizenship', 'civilians', 'cliff', 'conflicts', 'consensus', 'cycling', 'declaration', 'dennis', 'derby', 'distinction', 'donations', 'dragons', 'draws', 'examined', 'facial', 'faithful', 'fatal', 'fig', 'fitting', 'genuinely', 'hardest', 'holland', 'honored', 'hunger', 'hurricane', 'implications', 'import', 'innovative', 'ipad', 'jurisdiction', 'laughter', 'lemon', 'les', 'lifted', 'loading', 'lung', 'matching', 'mighty', 'monetary', 'novels', 'nutrition', 'ore', 'os', 'outcomes', 'outta', 'pine', 'polls', 'poorly', 'portugal', 'pose', 'pour', 'proteins', 'provider', 'publish', 'purely', 'ralph', 'rental', 'resolved', 'rewards', 'sang', 'seemingly', 'senators', 'severely', 'shark', 'shocking', 'southwest', 'ss', 'studios', 'survivors', 'tales', 'technically', 'titled', 'traditions', 'unlimited', 'washed', 'watches', 'advise', 'anxious', 'appearances', 'bee', 'bombing', 'cafe', 'carlos', 'challenged', 'cigarettes', 'colin', 'consisting', 'cult', 'dairy', 'dakota', 'darling', 'delighted', 'delivering', 'destroying', 'diary', 'disagree', 'disappear', 'drill', 'earliest', 'edges', 'entries', 'euro', 'evolved', 'exports', 'fixing', 'fl', 'flags', 'flies', 'forecast', 'fr', 'governance', 'heated', 'hug', 'importantly', 'indicating', 'indoor', 'influential', 'intend', 'invisible', 'jeans', 'jets', 'julie', 'karen', 'lasted', 'lawsuit', 'leak', 'lighter', 'lucas', 'marcus', 'mentions', 'meter', 'mice', 'musicians', 'olive', 'passionate', 'potatoes', 'prevented', 'receiver', 'recommendation', 'riot', 'rogers', 'roster', 'safer', 'sells', 'sentenced', 'servant', 'setup', \"should've\", 'skull', 'slot', 'smash', 'statue', 'surprisingly', 'surrender', 'suspicious', \"team's\", 'teenager', 'tender', 'thoroughly', 'todd', 'treatments', 'tweeted', 'vacuum', 'variations', 'vi', \"where's\", 'wi', 'wont', 'acknowledged', 'advances', 'agrees', 'allegations', 'anticipated', 'approve', 'architect', 'basin', 'beneficial', 'bleeding', 'breed', 'breeding', 'bride', 'broadway', 'bros', 'bud', 'butler', 'careers', 'cartoon', 'celebrities', 'chick', 'coke', 'comparable', 'confirmation', 'console', 'contractor', 'contributing', 'diameter', 'dubai', 'dublin', 'dump', 'duo', 'dynamics', 'elephant', 'enhanced', 'essays', 'exhausted', 'fabric', 'fabulous', 'fairy', 'fathers', 'focuses', 'fold', 'freak', 'frustrated', 'gambling', 'gently', 'glorious', 'grief', 'harrison', 'historically', 'hub', 'hughes', 'inevitable', 'investigating', 'kg', 'labels', 'lacking', 'laughs', 'layout', 'lined', 'lodge', 'lords', 'merchant', 'merit', 'micro', 'myth', 'nintendo', 'objectives', 'obsessed', 'organised', 'overwhelming', 'pale', 'particles', 'pastor', 'penalties', 'permanently', 'pets', 'pockets', 'poison', 'predict', 'presenting', 'presidents', 'pressing', 'prints', 'provincial', 'raped', 'realised', 'rebel', 'repairs', 'rotation', 'separately', 'shaking', 'shaw', 'societies', 'solved', 'starring', 'struggles', 'subtle', 'tastes', 'throws', 'toll', 'tooth', 'torn', 'tragic', 'trainer', 'transformed', 'unbelievable', 'underneath', 'variation', 'viewing', 'viral', 'warehouse', 'wears', 'widow', 'wives', '®', 'adjust', 'administrator', 'affecting', 'allied', 'altogether', 'animated', 'answering', 'assess', 'assumption', 'assured', 'austria', 'avoided', 'avoiding', 'basket', 'beard', 'bio', 'blanket', 'brains', 'bucket', 'burger', 'capability', 'charming', 'chiefs', 'commented', 'computing', 'concentrate', 'conducting', 'consequence', 'continent', 'cookie', 'cruz', 'curse', 'displays', 'drain', 'emissions', 'ethical', 'excellence', 'flame', 'forests', 'freely', 'fruits', 'grabbed', 'graduation', 'hint', 'horizon', 'hostile', 'imagined', 'inhabitants', 'ink', 'inn', 'intel', 'kicks', 'legends', 'lo', 'lucy', 'magazines', 'matrix', 'measuring', 'miserable', 'momentum', 'monkey', 'montreal', 'motorcycle', 'nationwide', 'nest', 'newcastle', 'nicely', 'ninth', 'nomination', 'notable', 'obligation', 'optical', 'outlook', 'penny', 'petty', 'phd', 'ports', 'preserved', 'programmes', 'prospects', 'publishers', 'quantity', 'quantum', 'rainbow', 'rebels', 'recognised', 'reed', 'reign', 'responding', 'retained', 'rises', 'saves', 'scan', 'scare', 'sectors', 'shorts', 'span', 'specialized', 'spencer', 'submission', 'sunny', 'supporter', 'te', 'testament', 'toe', 'tops', 'tremendous', 'valued', 'wounds', 'ab', 'accommodation', 'achievements', 'addressing', 'adorable', 'allegedly', 'ambulance', 'ar', 'ashamed', 'assure', 'bailey', 'ballot', 'batteries', 'blessing', 'btw', 'cemetery', 'chambers', 'cheat', 'cheer', 'chile', 'cigarette', 'compact', 'completing', 'consulting', 'cooling', 'corners', \"could've\", 'deficit', 'demo', 'demon', 'demonstration', 'detected', 'detection', 'doll', 'donated', 'elaborate', 'elder', 'encountered', 'expertise', 'exploring', 'fc', 'fiber', 'filmed', 'fried', 'grocery', 'guided', 'guinea', 'halfway', 'happier', 'heels', 'holmes', 'hull', 'independently', 'indication', 'insisted', 'instances', 'intensive', 'interactive', 'intimate', 'laundry', 'lbs', 'lifting', 'linda', 'martial', 'nigerian', 'northeast', 'observe', 'packing', 'panels', 'password', 'pokemon', 'politically', 'presumably', 'pretending', 'priorities', 'pronounced', 'prosecution', 'proves', 'pulse', 'purchasing', 'qualities', 'queens', 'rational', 'realm', 'reforms', 'revenues', 'rides', 'ripped', 'rope', 'shadows', 'shout', 'sierra', 'smartphone', 'specified', 'spectacular', 'stan', 'streak', 'subscription', 'switching', 'technological', 'temporarily', 'tolerance', 'tourists', 'traditionally', 'traveled', 'treats', 'unhappy', 'whites', 'yup', 'accomplish', 'adequate', 'alter', 'apology', 'arkansas', 'attributed', 'beg', 'belonging', 'booked', 'bout', 'bowling', 'brass', 'buzz', 'clarke', 'comeback', 'cos', 'crops', 'declare', 'designers', 'detect', 'diagnosed', 'diesel', 'dimensions', 'dip', 'disturbing', 'doesnt', 'dot', 'dresses', 'dylan', 'effectiveness', 'eliminated', 'ellen', 'embarrassed', 'exceptional', 'filing', 'fled', 'foul', 'frankly', 'freezing', 'graph', 'hack', 'hannah', 'hatred', 'ignorant', 'influences', 'interact', 'judging', 'knights', 'lamp', 'limitations', 'majesty', 'measurement', 'measurements', 'median', 'medieval', 'milan', 'mobility', 'montana', 'murders', 'nc', 'ne', 'nyc', 'omg', 'orientation', 'oven', 'owen', 'passport', 'penis', 'pills', 'planets', 'proceeds', 'rabbit', 'raises', 'ranges', 'rats', 'retire', 'rhythm', 'ruth', 'savage', 'servers', 'shook', 'shooter', 'siblings', 'slim', 'someday', 'sophisticated', 'spam', 'speeds', 'stack', 'stance', \"state's\", 'static', 'subway', 'supportive', 'surgical', 'symbols', 'tablet', 'tent', 'thesis', 'tide', 'travels', 'wallace', 'warfare', 'warming', \"week's\", 'weekends', 'withdraw', 'withdrawal', 'youngest', 'aging', 'airline', 'alternatives', 'anyways', 'argues', 'audit', 'authentic', 'ave', 'backwards', 'bi', 'blonde', 'blows', 'bolt', 'brooks', 'bugs', 'bust', 'clearing', 'clips', 'collar', 'columbus', 'comply', 'cope', 'counted', 'crashed', 'creepy', 'cum', 'denmark', 'divorced', 'donate', 'drawings', 'dried', 'ebay', 'echo', 'editors', 'edwards', 'emotionally', 'enhance', 'experiencing', 'extending', 'finale', 'flavor', 'floors', 'freaking', 'gloves', 'harper', 'hart', 'ignorance', 'ignoring', 'immigrant', 'induced', 'inspiring', 'intermediate', 'invention', 'ip', 'jesse', 'joins', 'joking', 'lgbt', 'likewise', 'lineup', 'logan', 'magnificent', 'mathematical', 'meantime', 'nails', 'nevada', 'newest', 'nonetheless', 'nut', \"o'clock\", 'opposing', 'origins', 'orlando', \"person's\", 'physicians', 'pipeline', 'placement', 'planted', 'pricing', 'pt', 'puerto', 'questioning', 'recreation', 'renewed', 'resigned', 'rt', 'shallow', 'shanghai', 'shitty', 'singh', 'sins', 'sketch', 'smells', 'soda', 'spite', 'sponsor', 'strengthen', 'strings', 'sunset', 'taiwan', 'thanksgiving', 'thee', 'thermal', 'trades', 'transform', 'witnessed', 'workplace', 'yelling', 'yorkshire', 'achieving', 'aliens', 'amsterdam', 'analyst', 'arabic', 'arctic', 'assists', 'bennett', 'bristol', 'burnt', 'buyer', 'calories', 'cannabis', 'cease', 'championships', 'chapel', 'cloth', 'conferences', 'considers', 'container', 'cowboys', 'crushed', 'deployed', 'differ', 'dimensional', 'eager', 'elect', 'elevated', 'essence', 'executives', \"family's\", 'flames', 'fork', 'fur', 'gps', 'harold', 'harvest', 'headline', 'hudson', 'hype', 'identifying', 'impacts', 'insist', 'jo', 'junk', 'kenny', 'kidney', \"king's\", 'ladder', 'lloyd', 'lobby', 'marc', 'mechanisms', 'mineral', 'mob', 'modest', 'motors', 'mph', 'navigation', 'nicholas', 'orbit', 'paragraph', 'passive', 'peninsula', 'phillips', 'pill', 'pork', 'portuguese', 'profitable', 'provinces', 'ranch', 'rays', 'reasonably', 'reject', 'remainder', 'schemes', 'screens', 'seized', 'semester', 'sentiment', 'servants', 'shipped', 'socks', 'sp', 'sr', 'suited', 'supplement', 'surviving', 'thereby', 'threshold', 'til', 'tin', 'tires', 'tribal', 'tribes', 'trunk', 'uncertainty', 'vampire', 'varied', 'verdict', 'abandon', 'accommodate', 'accordingly', 'aesthetic', 'algorithm', 'altered', 'anchor', 'angela', 'apr', 'arch', 'associations', 'au', 'audiences', 'axis', 'badge', 'bernard', 'bizarre', 'bounce', 'broadcasting', 'bs', 'bullets', 'buses', 'cannon', 'carol', 'carriers', 'chairs', 'cleaned', 'complexity', 'confusing', 'consultation', 'continental', 'convenience', 'deliberately', 'diamonds', 'diana', 'dictionary', 'dignity', 'dimension', 'disappointing', 'diving', 'doug', 'duncan', 'ego', 'enthusiasm', 'environments', 'equation', 'extract', 'favorites', 'ferry', 'fisher', 'flexibility', 'flowing', 'fm', 'fridge', 'functioning', 'fusion', 'gauge', 'goat', 'graduates', 'gut', 'heck', 'helmet', 'holders', 'ideology', 'idiots', 'inclusion', 'initiatives', 'innings', 'insects', 'instructor', 'isolation', 'ive', 'justified', 'keeper', 'lamb', 'liar', 'machinery', 'mansion', 'mega', 'mercury', 'namely', 'nbc', 'needing', 'nerves', 'nhl', \"obama's\", 'observations', 'ordering', 'palmer', 'paths', 'peers', 'pending', 'platinum', 'possess', 'praised', 'premises', 'probability', 'ps', 'questioned', 'refuses', 'resignation', 'rider', 'ritual', 'ruins', 'shelf', 'slam', 'stakes', 'starter', 'sticking', 'subscribe', 'superman', 'surfaces', 'ta', 'territories', 'tire', 'tl', 'towers', 'transfers', 'utterly', 'voltage', 'warn', 'width', 'workout', 'aa', 'abu', 'activated', 'adaptation', 'advisor', 'aluminum', 'apartments', 'attitudes', 'attorneys', 'bail', 'barriers', 'belonged', 'bradley', 'brandon', 'broader', 'buck', 'cal', 'caroline', 'characterized', 'civilization', 'congrats', 'contractors', 'creativity', 'dealers', 'delicate', 'den', 'derek', 'desires', 'disappointment', 'disk', 'enters', 'evaluate', 'formally', 'frames', 'goddess', 'gov', 'hampshire', 'harassment', 'hats', 'hugh', 'insert', 'joan', 'lebanon', 'leeds', 'legit', 'leonard', 'liquor', 'loser', 'malcolm', 'massage', 'matched', 'messed', 'milwaukee', 'musician', 'nato', 'nephew', 'notably', 'orchestra', 'oz', 'packages', 'pad', 'pakistani', 'participated', 'precision', 'preservation', 'priests', 'privately', 'prizes', 'pulls', 'qualifying', 'reasoning', 'relaxed', 'reporters', 'roses', 'rumors', 'sail', 'salmon', 'secretly', 'seller', 'sen', 'seo', 'sheer', 'shifts', 'simpson', 'smallest', 'specially', 'stark', 'struggled', 'sympathy', 'tan', 'teenagers', 'theoretical', 'thumb', 'timber', 'transparent', 'travis', \"trump's\", 'tweets', 'tx', 'upside', 'urged', 'visitor', 'vitamin', 'void', 'voluntary', 'wheat', 'whip', 'wipe', 'wolves', 'wrist', '™', 'abused', 'acute', 'admiral', 'amanda', 'arnold', 'arrange', 'banana', 'behave', 'betting', 'blair', 'bo', 'borrow', 'camping', 'capitol', 'celtic', 'chan', 'chin', 'civic', 'clerk', 'conclusions', 'considerably', 'contacted', 'cottage', 'coup', 'criticized', 'crude', 'dash', 'decreased', 'defended', 'demons', 'deposits', 'disclosure', 'disposal', 'distinctive', 'documented', 'donation', 'dragged', 'drone', \"else's\", 'encounters', 'ensuring', 'enterprises', 'escort', 'exams', 'firmly', 'flour', 'gdp', 'geneva', 'hindu', 'holdings', 'indie', 'indirect', 'inspire', 'institutional', 'interim', 'interviewed', 'java', 'jefferson', 'jerk', 'karl', 'kindly', 'kindness', 'leaked', 'locals', 'lottery', 'louise', 'magnitude', 'mc', 'minus', 'nhs', 'noting', 'nude', 'organs', 'outlet', 'outlets', 'parameters', 'pause', 'pledge', 'portal', 'prescription', 'protesters', 'proving', 'publicity', 'punished', 'puppy', 'recruitment', 'screwed', 'shades', 'shakespeare', 'silicon', 'slice', 'spelling', 'spurs', 'subscribers', 'surveys', 'survivor', 'telegraph', 'tits', 'vaccine', 'vinyl', 'westminster', 'wished', 'wonders', 'accurately', 'adelaide', 'affiliate', 'alfred', 'asylum', 'barn', 'bent', 'bernie', 'brussels', 'cathedral', 'centered', \"child's\", 'clause', 'cluster', 'complained', 'compounds', 'consistency', 'cr', 'cracked', 'cylinder', 'dancer', 'deaf', 'debts', 'denial', 'digging', 'dock', 'entrepreneur', 'evident', 'expectation', 'expedition', 'expressing', 'extends', 'facilitate', 'failures', 'feat', 'fossil', 'founding', 'freight', 'generating', 'goddamn', 'guides', 'honesty', 'inappropriate', 'infant', 'initiated', 'injection', 'instrumental', 'insult', 'interference', 'interstate', 'julian', 'launching', 'liking', 'linux', 'luis', 'mates', 'mediterranean', \"nation's\", 'neat', 'negotiate', 'neo', 'nicole', 'obligations', 'offset', 'outbreak', 'pal', 'palestine', 'perfection', 'pigs', 'pirates', 'posters', 'practicing', 'praying', 'probe', 'prohibited', 'projected', 'propose', 'quarterly', 'recipes', 'recruiting', 'refusing', 'rehabilitation', 'reid', 'remix', 'resistant', 'reynolds', 'riders', 'robots', 'rockets', 'roller', 'sailing', 'shapes', 'skinny', 'slipped', 'sneak', 'solving', 'sore', 'spark', 'speculation', 'steep', 'stevens', 'straw', 'successor', 'targeting', 'triggered', 'troubles', 'uncertain', 'upload', 'vector', 'violations', 'weigh', 'whatsoever', 'wicked', 'abraham', 'absent', 'acoustic', 'adapt', 'ancestors', 'archive', 'atomic', 'bean', 'bicycle', 'bryan', 'bump', 'buttons', 'cart', 'circus', 'claire', 'cocaine', 'cohen', 'colleague', 'compelling', 'compiled', 'complications', 'construct', 'cord', 'crowded', 'cyber', 'dale', 'debates', 'defendant', 'delays', 'dense', 'desperately', 'doctrine', 'expose', 'financially', 'freshman', 'furious', 'gameplay', 'geography', 'gig', \"government's\", 'habitat', 'harbour', 'hazard', 'hydrogen', 'implies', 'intact', 'intake', 'irrelevant', 'jaw', 'jin', 'kitty', 'lauren', 'lawn', 'manufacture', 'martha', 'medals', 'mercedes', 'mistaken', 'moses', 'nashville', 'nebraska', 'needle', 'ol', 'olds', 'organize', 'ottawa', 'oval', 'pity', 'pond', 'porter', 'portions', 'prey', 'prophet', 'raymond', 'recalled', 'reduces', 'referendum', 'refugee', 'regulated', 'rounded', 'ruby', 'rushed', 'sanders', 'satisfy', 'scales', 'seasonal', 'segments', 'sensible', 'sequel', 'shifted', 'shifting', 'shining', 'slower', 'spinning', 'stanford', 'stepping', 'teammates', 'touches', 'township', 'travelled', 'twisted', 'usb', 'vienna', 'wade', 'whale', 'writings', 'admire', 'af', 'amber', 'ankle', 'armor', 'autism', 'bachelor', 'berry', 'billions', 'brady', 'brisbane', 'bulls', 'bullying', 'capitalism', 'caution', 'certification', 'characteristic', 'clan', 'clash', 'columns', 'compatible', 'concerts', 'condemned', 'configuration', 'continuously', 'convincing', 'coupled', 'curiosity', 'delight', 'determining', 'entities', 'exceptions', 'explosive', 'flooding', 'fortunate', 'fortunately', 'foundations', 'frontier', 'frustrating', 'frustration', 'geographic', 'glenn', 'grande', 'grasp', 'handy', 'hardcore', 'harmful', 'headache', 'hers', 'hispanic', 'incentive', 'inclusive', 'infections', 'jackie', 'joel', 'kissing', 'lanes', 'licence', 'lungs', 'madness', 'mandate', 'manga', 'memorable', 'merger', 'minorities', 'nj', 'occurring', 'organizing', 'performs', 'ph', 'po', 'poker', 'portable', 'priced', 'quebec', 'randomly', 'rankings', 'realizing', 'resign', 'revealing', 'rico', 'robbery', 'rub', 'runners', 'sally', 'scattered', 'scout', 'searched', 'sexuality', 'shouting', 'slap', 'steak', 'succession', 'superintendent', 'suspicion', 'sweep', 'tactical', 'talents', 'therapist', 'thereafter', 'thorough', 'tuition', 'tumor', 'usd', 'variables', 'varying', 'wholesale', 'wwe', 'administered', 'affiliated', 'apples', 'architectural', 'artillery', 'assembled', 'bangladesh', 'barack', 'beaches', 'bees', 'boarding', 'bothered', 'canvas', 'canyon', 'casey', 'cheek', 'chen', 'cincinnati', 'circular', 'circulation', 'clearance', 'closes', 'coincidence', 'comedian', 'commands', 'commissioned', 'concentrated', 'conscience', 'cooler', 'countless', 'curry', 'dame', 'deceased', 'dedication', 'defining', 'detention', 'disputes', 'drake', 'employ', 'enforce', 'explicit', 'explicitly', 'eyed', 'florence', 'flu', 'forbidden', 'fraction', \"girl's\", 'hes', 'infantry', 'integral', 'investor', 'janet', 'judged', 'katie', 'kidnapped', 'lectures', 'lightly', 'linking', 'maintains', 'marble', 'maritime', 'melt', 'modes', 'monica', 'mumbai', 'nominee', 'oath', 'offence', 'packaging', 'patriots', 'pee', 'pillow', 'pirate', 'polar', 'prediction', 'preview', 'processed', 'pursuing', 'puzzle', 'rapper', 'rebecca', 'reconstruction', 'renowned', 'revelation', 'sara', 'scholar', 'sharks', 'shoots', 'skirt', 'socially', 'spa', 'spike', 'sprint', 'stir', 'stuffed', 'substantially', 'suburbs', 'superb', 'supposedly', 'tab', 'tendency', \"that'll\", 'theirs', 'toast', 'toes', 'touchdown', 'traits', 'trek', 'tricky', 'triumph', 'uber', 'underwear', 'unto', 'viable', 'waist', 'welcomed', 'wit', 'wreck', 'absurd', 'accessories', 'adrian', 'advocates', 'ag', 'ambitious', 'amid', 'annoyed', 'appealing', 'appointments', 'assumptions', 'ballet', 'bargain', 'binary', 'blend', 'blogs', 'brake', 'builds', 'businessman', 'cab', 'ch', 'chi', 'col', 'collision', 'colombia', 'compassion', 'consumed', 'corrected', 'correction', 'cough', 'cousins', 'critic', 'czech', 'defenders', 'denying', 'depot', 'distress', 'documentation', 'doubts', 'dramatically', 'drank', 'dudes', 'eats', 'elegant', 'elevator', 'ellis', 'exchanges', 'excuses', 'execute', 'factories', 'feast', 'finland', 'frederick', \"friend's\", 'frost', 'goin', 'herald', 'hike', 'hollow', 'homeland', \"how's\", 'imported', 'ing', 'internationally', 'iraqi', 'itunes', 'kane', 'kissed', 'lame', 'licensing', 'lily', 'limiting', 'locker', 'mainland', 'marking', 'meditation', 'messenger', 'metals', 'missiles', 'munich', 'norwegian', 'pencil', 'philosophical', 'pierre', 'pipes', 'plasma', 'plea', 'punish', 'purse', 'quarterback', 'reagan', 'ref', 'relieved', 'replies', 'reservation', 'rhetoric', 'rivals', 'rushing', 'salvation', 'sanctions', 'secular', 'sensitivity', 'shane', 'sigh', 'sixteen', 'sovereign', 'specifications', 'spends', 'spouse', 'stat', 'supervisor', 'synthetic', 'teaches', 'tense', 'terrifying', 'toyota', 'tracked', 'traders', 'troy', 'varieties', 'vegan', 'waking', 'walmart', 'wang', 'wilderness', 'admits', 'adviser', 'aggregate', 'anal', 'anatomy', 'annie', 'announces', 'applicants', 'automobile', 'barnes', 'breasts', 'cement', 'chess', 'citing', 'colonies', 'composite', 'consequently', 'consist', 'councils', 'cox', 'curtis', 'decorated', 'delegates', 'dreaming', 'dull', 'enables', 'fare', 'fashioned', 'feared', 'float', 'generator', 'grind', 'grinding', 'grove', 'guessing', 'gum', 'hobby', 'hunters', 'idol', 'illusion', 'incorrect', 'jun', 'junction', 'lance', 'leap', 'locate', 'locks', 'lou', 'lynch', 'manages', 'masses', 'medicare', 'modeling', 'motive', 'nazis', 'neighbourhood', 'networking', 'newer', 'newton', 'oppose', 'optimal', \"other's\", 'overtime', 'packs', 'permits', 'playstation', 'pops', 'postal', 'predictions', 'prep', \"president's\", 'profound', 'prosecutor', 'rebellion', 'recipient', 'refund', 'remembering', 'rescued', 'risky', 'robust', 'scam', 'sci', 'sep', 'shareholders', 'sided', 'simulation', 'sober', 'spice', 'squeeze', 'storms', 'supervision', 'suspects', 'swap', 'swept', 'terrain', 'terrified', 'themed', 'threaten', 'thrilled', 'towel', 'trio', 'tubes', 'unconscious', 'und', 'varies', 'vegetable', 'verified', 'vibe', 'virtue', 'wifi', 'wishing', 'workforce', 'zombie', 'acre', 'airports', 'alot', 'amen', 'andrews', 'arise', 'ashes', 'automotive', 'battlefield', 'begging', 'berkeley', 'bloom', 'bore', 'bundle', 'butterfly', 'buys', 'casualties', 'catches', 'chad', 'clown', 'committees', 'conjunction', 'costly', 'cows', 'cries', 'cuban', 'cycles', 'darker', 'davies', 'descent', 'desktop', 'dial', 'directory', 'disabilities', 'discharge', 'discusses', 'dodge', 'downs', 'drilling', 'drums', 'elimination', 'enjoys', 'es', 'espn', 'ginger', 'governors', 'guild', 'halt', 'han', 'henderson', 'ibm', 'imaging', 'implied', 'impress', 'inability', 'incoming', 'isaac', 'jar', 'kay', 'lb', 'leicester', 'liam', 'litigation', 'mentor', 'merchandise', 'minerals', 'miners', 'monk', 'neighborhoods', 'ni', 'noah', 'norm', 'obtaining', 'occupy', 'offended', 'orthodox', 'overhead', 'pac', 'painter', \"party's\", 'perth', 'pierce', 'pistol', 'printer', 'prone', 'raiders', 'readily', 'reflecting', 'regiment', 'remembers', 'reunion', 'revival', 'sanctuary', 'satan', 'satisfying', 'seas', 'securing', 'sensors', 'seoul', 'shells', 'siege', 'sixty', 'sleeve', 'sonic', 'soundtrack', 'speeches', 'spine', 'steering', 'substances', 'sullivan', 'sustain', 'tenure', 'texture', 'thankful', 'translate', 'treasurer', 'triangle', 'unclear', 'upgraded', 'venezuela', 'venice', 'vladimir', 'wizard', 'yankees', 'absorbed', 'admin', 'affection', 'airplane', 'altitude', 'athens', 'attributes', 'baked', 'baking', 'beautifully', 'betty', 'biblical', 'bmw', 'boo', 'cardiff', 'collapsed', 'coloured', 'competent', 'countryside', 'cracking', 'crane', 'debris', 'delegation', 'demographic', 'descriptions', 'donor', 'easiest', 'educate', 'enabling', 'enrolled', 'enrollment', 'essex', 'exceed', 'excluding', 'expressions', 'fierce', 'forgetting', 'gabriel', 'garlic', 'gaza', 'gratitude', 'hail', 'heroin', 'honda', 'hooked', 'illustration', 'impose', 'indicator', 'inequality', 'ins', 'interpreted', 'jamaica', 'joey', 'joshua', 'journals', 'leisure', 'lend', 'lengths', 'leon', 'lounge', 'luckily', 'manuscript', 'marco', 'marines', 'mint', 'molecules', 'montgomery', 'notification', 'nova', 'oakland', 'outline', 'pasta', 'pi', 'polite', 'productions', 'professors', 'quicker', 'randy', 'receipt', 'recognise', 'reliability', 'researcher', 'retailers', 'reviewing', 'romans', 'runway', 'sculpture', 'senses', 'sensor', 'seth', 'sharon', 'showcase', 'smoked', 'su', 'subsidiary', 'tampa', 'tenth', 'theology', 'topped', 'trails', 'underwater', 'uploaded', 'velocity', 'venues', 'wax', 'wikipedia', 'winston', 'yay', 'yu', '♫', 'accountability', 'aerial', 'albeit', 'alcoholic', 'amazed', 'ambition', 'ammunition', 'anthem', 'architects', 'automated', 'bake', 'batch', 'borrowed', 'carson', 'catalog', 'catalogue', 'charitable', 'christine', 'clicking', \"club's\", 'collector', 'compliment', 'consisted', 'continually', 'coordinator', 'damaging', 'danish', 'def', 'deployment', 'drafted', 'enjoyable', 'exotic', 'exterior', 'feminine', 'firearms', 'fountain', 'fury', 'gb', 'genocide', 'glance', 'glow', 'hay', 'headlines', 'hebrew', 'hometown', 'humanitarian', 'hungary', 'idaho', 'immunity', 'implementing', 'inherited', 'killers', 'l.a', 'labeled', 'lebron', 'liberation', 'likelihood', 'lone', 'massacre', 'meme', 'mitch', 'mod', 'nationalist', 'nationals', 'necessity', 'nickname', 'nixon', 'observer', 'offshore', 'optional', 'papa', 'parked', 'paste', 'ph.d', 'pioneer', 'plaza', 'prescribed', 'pressures', 'prosperity', 'ps4', 'recreational', 'reds', 'refuge', 'religions', 'renewable', 'richardson', 'ricky', 'rode', 'ronald', 'sack', 'settlements', 'sheffield', 'shortage', 'skies', 'smarter', 'smiles', 'sophie', 'sphere', 'sponsors', 'stamps', 'stare', 'suburban', 'sung', 'suppliers', 'tablets', 'terribly', 'territorial', 'thirds', 'thriller', 'toss', 'transgender', 'troubled', 'turtle', 'ur', 'verbal', 'violated', 'vocals', 'wool', 'yang', 'accountable', 'advocacy', 'aftermath', 'aggression', 'analyzed', 'angles', 'arguably', 'armies', 'armstrong', 'assessed', 'attractions', 'balloon', 'beers', 'bells', 'blamed', 'blunt', 'boobs', 'bosses', 'brakes', 'brigade', 'bulgaria', 'burial', 'canceled', 'cardinal', 'champ', 'champagne', 'cheated', \"china's\", 'chorus', 'chrome', 'clarity', 'classics', 'cleaner', 'combining', 'conclude', 'confidential', 'coordination', 'cracks', 'cs', 'dancers', 'delaware', 'directing', 'discretion', 'ditch', 'dome', 'dope', 'drought', 'ducks', 'dumped', 'elevation', 'entrepreneurs', 'epa', 'esteem', 'eva', 'explored', 'fe', 'finances', 'finishes', 'fog', 'framed', 'fucks', 'gesture', 'ghana', 'gibson', 'gif', 'gilbert', 'gosh', 'griffin', 'historian', 'horizontal', 'hospitality', 'hostage', 'hottest', 'individually', 'inevitably', 'jeffrey', 'kenneth', 'lad', 'lakers', 'lasts', 'leagues', 'leslie', 'listings', 'literacy', 'marriages', \"mcdonald's\", 'migrants', 'mins', 'misleading', 'moisture', 'monument', 'mortality', 'ng', 'notices', 'obsession', 'opt', 'particle', 'peanut', 'penn', 'persistent', 'personalities', 'petroleum', 'pharmaceutical', 'progression', 'quinn', 'ra', 'rack', 'rebuild', 'recordings', 'rejection', 'relaxing', 'reservoir', 'respects', 'riley', 'scrap', 'sebastian', 'sensation', 'shaft', 'shepherd', 'shuttle', 'slope', 'snack', 'sounding', 'specialists', 'spotlight', 'stabbed', 'stern', 'stiff', 'striker', 'sudan', 'sued', 'sums', 'sworn', 'tel', 'terrific', 'theres', 'titans', 'tomatoes', 'tory', 'trafficking', 'transparency', 'trinity', 'unemployed', 'unite', 'unlock', 'vault', 'vet', 'vince', 'wagon', 'walt', 'withdrawn', 'accessed', 'adverse', 'aiming', 'allah', 'alumni', 'ana', 'awhile', 'aye', 'bastard', 'behaviors', 'bikes', 'biography', 'br', 'broker', 'browser', 'bury', 'cellular', 'cocktail', 'cod', 'conditioning', 'consuming', 'contracted', 'costumes', 'counseling', 'crews', 'cubs', 'cuz', 'dangers', 'designing', 'destructive', 'develops', 'dislike', 'doubled', 'doubles', 'economies', 'embedded', 'emerge', 'excluded', 'expects', 'f1', 'farewell', 'feeds', 'fist', 'fond', 'foolish', 'frog', 'fry', 'garcia', 'gifted', 'hacking', 'hawks', 'heir', 'highlighted', 'holocaust', 'homer', 'hon', 'hopkins', 'imprisonment', 'indonesian', 'irs', 'isnt', 'jenny', 'ji', 'lacks', 'landlord', 'landmark', 'lanka', 'launches', 'leaning', 'liable', \"life's\", 'memphis', 'midst', 'misery', 'module', 'mommy', 'monroe', 'mosque', 'moss', 'museums', 'mvp', 'nursery', 'obamacare', 'onion', 'perspectives', 'peru', 'phrases', 'plague', 'plains', 'positively', 'powell', 'prevents', 'profiles', 'pursued', 'raids', 'recruit', 'resting', 'rex', 'rogue', 'roosevelt', 'salaries', 'sd', 'seated', 'sharply', 'showers', 'sincerely', 'sings', 'solidarity', 'specialty', 'supernatural', 'surprises', 'td', 'tens', 'thirteen', 'tomb', 'touring', 'traces', 'trademark', 'trim', 'umbrella', 'utilities', 'voyage', 'weaker', 'willie', 'yields', 'abbey', 'accepts', 'adjustment', 'andrea', 'assignments', 'attachment', 'baron', 'beatles', 'belfast', 'blah', 'blaming', 'bomber', 'bt', 'bunny', 'candle', 'carved', 'choir', 'clutch', 'coconut', 'committing', 'comprising', 'confession', 'consume', 'corridor', 'credibility', 'credited', 'critically', 'dem', 'distracted', 'dm', 'dolphins', 'estates', 'ferguson', 'ferrari', 'filters', 'fools', 'fourteen', 'fu', 'geometry', 'gf', 'ghosts', 'gossip', 'gp', 'grandparents', \"group's\", 'haul', 'header', 'headphones', 'highways', 'holly', 'immense', 'imports', 'incentives', 'interfere', 'intersection', 'investigators', 'juvenile', 'karma', 'ki', 'knocking', 'kurt', 'leaks', 'leverage', 'lil', 'lining', 'luther', 'manila', 'mankind', 'mapping', 'masks', 'med', 'metric', 'militia', 'naming', 'ncaa', \"night's\", 'nike', 'node', 'obstacles', 'opener', 'overwhelmed', 'performers', 'pg', 'pl', 'pointless', 'poles', 'preferences', 'prompted', 'proximity', 'qualification', 'qualifications', 'ranger', 'rendered', 'rented', 'reversed', 'robbed', 'sadness', 'scenarios', 'selective', 'seniors', 'sf', 'shiny', 'socialism', \"son's\", 'sour', 'spoon', 'stressful', 'stretched', 'sucking', 'teddy', 'tenants', 'terrace', 'thief', 'transported', 'tribunal', 'undoubtedly', 'uniforms', 'verify', 'villain', 'whats', 'whistle', \"wife's\", 'workshops', 'yale', 'yearly', 'yemen', '⠀', 'abusive', 'alley', 'announcing', 'appetite', 'backyard', 'beth', 'beverly', 'bids', 'billboard', 'blades', 'boris', 'bully', 'burke', 'cables', 'calculate', 'calculations', 'chicks', 'conceived', 'consult', 'crashes', 'crowds', 'cunt', 'damned', 'dissolved', 'distinguish', 'dominate', 'dynasty', 'economist', 'endorsed', 'europeans', 'examining', 'extensively', 'fda', 'festivals', 'forehead', 'foreigners', 'forgiveness', 'gem', 'glen', 'graves', 'gregory', 'haunted', 'hayes', 'heather', 'hiking', 'hypothesis', 'illegally', 'illustrations', 'inclined', 'informal', 'jew', 'learnt', 'lending', 'marker', 'marsh', 'marshal', 'maturity', 'maya', 'messy', 'mia', 'minneapolis', 'molly', 'morrison', 'mtv', 'muhammad', 'neighboring', 'neighbours', 'ninja', 'optimistic', 'outlined', 'owl', 'parenting', 'peaks', 'pharmacy', 'pools', 'preparations', 'problematic', 'proceeded', 'processor', 'promotional', 'pros', 'prospective', 'psychiatric', 'regulate', 'renaissance', 'repeal', 'reuters', 'riots', 'roast', 'robertson', 'rubbish', 'saga', 'salon', 'seventeen', 'shields', 'sliding', 'sodium', 'surplus', 'swallow', 'systematic', 'theaters', 'transmitted', 'tuned', 'unacceptable', 'unaware', 'uncommon', 'underway', 'unified', 'unstable', 'upstairs', 'vague', 'wee', 'woo', 'xd', 'zip', 'a00', 'abs', 'abundance', 'advancing', 'ahh', 'alberta', 'ant', 'antique', 'autonomy', 'baptist', 'behavioral', 'biden', 'booking', 'breeze', 'brett', 'browns', 'canadians', 'carnival', 'commodity', 'congressman', 'containers', 'cooperative', 'coral', 'correlation', 'correspondent', 'coupon', 'covid', 'crosses', 'curtain', 'curves', 'defines', 'delivers', 'demonstrates', 'dentist', 'dodgers', 'dough', 'dug', 'endangered', 'envelope', 'exhibited', 'fade', 'fatigue', 'fellowship', 'fictional', 'fragile', 'fringe', 'fulfill', 'gaps', 'granite', 'greens', 'handbook', 'hardy', 'honors', \"india's\", 'insights', 'instinct', 'inviting', 'irony', 'ivan', 'joyce', 'judgement', 'judiciary', 'jumps', 'lads', 'legion', 'lethal', 'lime', 'lively', 'logistics', 'lowered', 'lynn', 'maid', 'manning', 'manuel', 'maple', 'mickey', 'midfielder', 'mindset', 'mistress', 'moms', 'mon', 'monkeys', 'morality', 'mortal', 'mounting', 'nonprofit', 'nsa', 'oils', 'operative', 'outs', 'owed', 'panama', 'patches', 'pickup', 'portraits', 'pouring', 'prestigious', 'prompt', 'quantities', 'radius', 'referee', 'relay', 'rig', 'risen', 'rows', 'sacramento', 'scroll', 'searches', 'sh', 'smiled', 'snacks', 'snakes', 'sovereignty', 'strips', 'stunt', 'subjected', 'sucked', 'sunlight', 'surf', 'symbolic', 'sync', 'taxpayer', 'tempted', 'thrust', 'trevor', 'trilogy', 'url', 'weights', 'wheelchair', 'whore', 'wiped', 'yahoo', 'youre', 'yourselves', 'accompanying', 'accusations', 'acids', 'administrators', 'aired', 'allowance', 'andre', 'apologies', 'arbitrary', 'atm', 'autonomous', 'averaged', 'bait', 'bark', 'bets', 'blogger', 'bra', 'brighton', 'brotherhood', 'buddhist', 'builder', 'cakes', 'carriage', 'celebrations', 'censorship', 'cf', 'cl', 'clarify', 'climbed', 'comp', 'compilation', 'composer', 'comprises', 'constitute', 'correspondence', 'cowboy', 'defendants', 'desirable', 'devastating', 'diagram', 'dismiss', 'editions', 'erected', 'explorer', 'farther', 'favorable', 'feminism', 'flaws', 'forums', 'freed', 'galleries', 'gasoline', 'genesis', 'geographical', 'governed', 'governmental', 'grandson', \"guy's\", 'halls', 'handles', 'heavier', 'herbert', 'hints', \"husband's\", 'incomplete', 'incorporate', 'interrupted', 'ivory', 'kerry', 'kirk', 'lang', 'lengthy', 'levy', 'lp', 'manipulation', 'merchants', 'misses', 'mlb', 'mock', 'necklace', 'niche', 'nina', \"o'brien\", 'obscure', 'ot', 'para', 'peterson', 'popped', 'porch', 'portrayed', 'possessed', 'princeton', 'proposition', 'railways', 'readings', 'recession', 'richards', 'rim', 'seals', 'secondly', 'sequences', 'settling', 'sherman', 'spinal', 'spiral', 'spit', 'splash', 'stretching', 'successive', 'superhero', 'taxpayers', 'therapeutic', 'threads', 'ti', 'timely', 'tomato', 'tub', 'ufc', 'undergraduate', 'undertaken', 'uranium', 'utter', 'vietnamese', 'volleyball', 'walsh', 'wires', 'yell', '2d', 'advertisement', 'analysts', 'analyze', 'atmospheric', 'bangkok', 'batting', 'bb', 'bitches', 'bracket', 'branded', 'bryant', 'cairo', 'cardiac', 'catholics', 'commanding', 'confirms', 'confronted', 'crashing', 'crawford', 'creep', 'daylight', 'dee', 'dems', 'devon', 'disclose', 'doe', 'donna', 'elbow', 'encourages', 'enthusiastic', 'envy', 'establishments', 'exile', 'exploitation', 'felix', 'futures', 'gel', 'genetics', 'goose', 'grill', 'grounded', 'hating', 'heel', 'heroic', 'hut', 'inmates', 'instructed', 'ira', 'jenkins', 'johns', 'knives', 'louisville', 'malaysian', 'margins', 'marina', 'mat', 'melissa', 'milton', 'miranda', 'ml', 'monopoly', 'nash', 'nationally', 'nobel', 'norfolk', 'outrage', 'owning', 'pains', 'paperwork', 'pdf', 'pitched', 'poets', 'poisoning', 'promptly', 'que', 'rains', 'recovering', 'renewal', 'repeating', 'rifles', 'robbie', 'ruler', \"school's\", 'screams', 'sellers', 'sights', 'sincere', 'skating', 'skiing', 'slaughter', 'smashed', 'sox', 'sperm', 'spill', 'steadily', 'stripped', 'supplier', 'swamp', 'swan', 'switches', 'synthesis', 'tasty', 'tattoos', 'teammate', 'testify', 'tolerate', 'tournaments', 'travelers', 'treason', 'trustees', 'typing', 'urine', 'vanilla', 'vermont', 'vic', 'vii', 'violet', 'weighing', 'wendy', 'activation', 'afghan', 'afterward', 'agreeing', 'ahmed', 'allocated', 'appealed', 'applause', 'bald', 'barrels', 'boil', 'borough', 'boyd', 'bp', 'breakthrough', 'calif', 'ce', 'charities', 'cheering', 'chooses', 'churchill', 'combinations', 'commenting', 'competitions', 'cone', 'connects', 'convey', 'critique', 'crushing', 'curved', 'cyrus', 'decay', 'declining', 'depressing', 'dessert', 'destinations', 'diagnostic', 'diane', 'differential', 'discourse', 'distances', 'dominance', 'donors', 'downloaded', \"earth's\", 'economically', 'entertain', 'evaluated', 'exploit', 'fireworks', 'flown', 'floyd', 'founders', 'freeman', \"game's\", 'gandhi', 'gateway', 'ge', 'guarantees', 'humidity', 'humour', 'imagery', 'imply', 'indicators', 'inherent', 'inland', 'inning', 'innocence', 'investigator', 'isle', 'ivy', 'justification', 'ka', 'katherine', 'lego', 'licenses', 'livestock', 'liz', 'llc', 'mafia', 'manners', 'merry', 'mick', 'missionary', 'nationalism', 'naughty', 'nepal', 'newman', 'notified', 'notorious', 'obey', 'olivia', 'organizational', 'outfits', 'outright', 'overly', 'oversight', 'panthers', 'persian', 'phases', 'photographers', 'polling', 'popping', 'prisons', 'prototype', 'pumpkin', 'pumps', 'punched', 'ramp', 'rand', 'reactor', 'reef', 'refined', 'refreshing', 'refusal', 'reinforced', 'remedies', 'reset', 'sage', 'shave', 'sickness', 'simpler', 'sinking', 'slots', 'sorted', 'sq', 'staged', 'startup', 'statute', 'stems', 'straightforward', 'strengths', 'suffers', 'superstar', 'telecommunications', 'thieves', 'thoughtful', 'thru', 'tissues', 'toddler', 'utilized', 'vicious', 'victories', 'vikings', 'vodka', 'vr', 'wholly', 'zoom', 'accidental', 'accounted', 'addicted', 'adjustments', 'apollo', 'archbishop', 'assassination', 'athletics', 'basics', 'bats', 'belgian', 'bibliography', 'bot', 'broadly', 'calcium', 'calvin', 'candles', 'capita', 'certainty', 'cheeks', 'chickens', 'christina', 'citation', 'clues', 'collectively', 'commercials', 'commissions', 'compression', 'comprised', 'confess', 'confined', 'congregation', 'consolidated', 'coordinate', 'coordinates', 'cube', 'dana', 'declaring', 'decoration', 'decree', 'definitions', 'deliberate', 'despair', 'discovering', 'dividend', 'dragging', 'drift', 'dye', 'eden', 'educators', 'electron', 'endure', 'enzyme', 'evolutionary', 'exhibits', 'extensions', 'fellows', 'fragments', 'fraser', 'fuels', 'geological', 'globally', 'grams', 'guru', 'hacked', 'hans', 'hatch', 'hindi', 'historians', 'hm', 'hormone', 'inadequate', 'indianapolis', 'infinity', 'intentionally', 'joints', 'kilometers', 'labs', 'lace', 'libya', 'losers', 'louder', 'maiden', 'marching', 'marketplace', 'membrane', 'messing', 'metallic', 'methodology', 'modifications', 'monitors', 'murderer', 'nap', 'nickel', 'niece', 'nm', 'nominations', 'numbered', 'offerings', 'overlooked', 'pardon', 'partnerships', 'persuade', 'pier', 'poured', 'practiced', 'predecessor', 'premise', 'quiz', 'rainfall', 'recipients', 'reckless', 'redemption', 'relates', 'relied', 'remedy', 'replay', 'revision', 'rooted', 'scent', 'slate', 'spells', 'stimulus', 'strengthening', 'structured', 'sunrise', 'surge', 'tagged', 'tags', 'tapes', 'tee', 'testified', 'timothy', 'token', 'tornado', 'tracy', 'tunes', 'tunnels', 'twilight', 'unprecedented', 'vagina', 'verses', 'vocabulary', 'wellington', 'whoa', 'willingness', 'woody', 'worthless', 'yacht', 'a000', 'aberdeen', 'absorb', 'accompany', 'accord', 'advancement', 'albany', 'algorithms', 'alt', 'alternatively', 'anglo', 'archer', 'asap', 'assurance', 'barber', 'bash', 'battalion', 'bidding', 'boycott', 'bricks', 'bruno', 'buddies', 'bulgarian', 'carpenter', 'ceased', 'chester', 'coding', 'competitor', 'creators', 'cuisine', 'detained', 'dioxide', 'dolls', 'doom', 'dubbed', 'ea', 'eclipse', 'eighteen', 'eleanor', 'elephants', 'enjoyment', 'exhaust', 'expired', 'flee', 'forbes', 'forwards', 'fries', 'fundraising', 'gal', 'glimpse', 'hahaha', 'hawk', 'healthier', 'homemade', 'honorable', 'infectious', 'inferior', 'injustice', 'inquiries', 'insulin', 'interpret', 'intro', 'jackets', 'jill', 'kindle', 'lid', 'lindsay', 'logs', 'manor', 'masterpiece', 'melody', 'memo', 'mic', 'mirrors', \"mom's\", 'myanmar', 'narrator', 'nate', 'nets', 'nsw', 'obesity', 'partisan', 'planting', 'pony', 'posed', 'possessions', 'privileged', 'prolonged', 'promo', 'protestant', 'pumping', 'pupil', 'qb', 'recruited', 'reliance', 'relies', 'reluctant', 'relying', 'respiratory', 'retention', 'rewarded', 'ribbon', 'rochester', 'rodgers', 'roommate', 'rotten', 'sands', 'schedules', 'selecting', 'shah', 'shawn', 'shotgun', 'singers', 'snapped', 'sofa', 'solomon', 'southampton', 'spoil', 'spoiled', 'stephanie', 'submarine', 'suburb', 'surgeons', 'sympathetic', 'taxation', 'temper', 'undergo', 'venus', 'weighed', 'wu', 'acquiring', 'additions', 'admitting', 'afl', 'aligned', 'allan', 'altar', 'amp', 'arrows', 'atlas', 'austrian', 'automation', 'awe', 'balancing', 'banning', 'bishops', 'boeing', 'broncos', 'builders', 'burton', 'caesar', \"canada's\", 'cans', 'carroll', 'cavalry', 'clara', 'coffin', 'collectors', 'colorful', 'combo', 'communism', 'conductor', 'confront', 'constraints', 'crow', \"dad's\", 'davidson', 'decisive', 'decorative', 'definitive', 'disclosed', 'displaced', 'disturbed', 'diy', 'doin', 'epidemic', 'eternity', 'eugene', 'evolve', 'explode', 'extraction', 'fatty', 'filthy', 'fletcher', 'flush', 'font', 'freestyle', 'glue', 'grandpa', 'hairy', 'homicide', 'horns', 'ie', 'inheritance', 'introduces', 'ironic', 'lacked', 'lin', 'luggage', 'lyon', 'm00', 'madame', 'maggie', 'marion', 'mel', 'melting', 'messaging', 'microwave', 'midwest', 'minimize', 'modi', 'morocco', 'natalie', 'ops', 'organisms', 'originated', 'ounce', 'pablo', 'peel', 'pensions', 'performer', 'picnic', 'pins', 'practitioners', 'predominantly', 'primitive', 'providence', 'psychic', 'psychologist', 'puppet', 'reproductive', 'requesting', 'responds', 'restrict', 'retiring', 'retrieved', 'ribs', 'righteous', 'rivalry', 'rosa', 'royalty', 'sandra', 'sausage', 'seize', 'sim', 'skeleton', 'spicy', 'sticky', 'sting', 'sufficiently', 'thankfully', 'thrones', 'tick', 'traced', 'trent', 'trusts', 'tutorial', 'twentieth', 'unpleasant', 'unrelated', 'ussr', 'vacant', 'vent', 'vicinity', 'wan', 'wandering', 'wardrobe', 'warmth', 'weaknesses', 'wines', 'wired', 'amendments', 'analyses', 'asses', 'assessments', 'assisting', \"australia's\", 'axe', 'backgrounds', 'baldwin', 'belle', 'bf', 'bites', 'bombers', 'bonuses', 'bred', 'brexit', 'bubbles', 'buddha', 'bulletin', 'capitalist', 'cautious', 'clinics', 'commitments', 'companions', 'comparisons', 'constable', 'cooperate', 'coordinated', 'copied', 'counselor', 'cp', 'curb', 'dances', 'darren', 'deeds', 'destined', 'detached', 'devils', 'discounts', 'distribute', 'dong', 'edgar', 'efficiently', 'eliminating', 'elliott', 'encouragement', 'enforced', 'evan', 'explosives', 'faction', 'fascist', 'feathers', 'fixtures', 'flooded', 'fuller', 'gamble', 'goalkeeper', 'grandchildren', 'gt', 'guardians', 'harmless', 'hearings', 'hesitate', 'hid', 'hips', 'hopeful', 'horny', 'hungarian', 'hygiene', 'iceland', 'imaginary', 'imprisoned', 'inconsistent', 'int', 'iso', 'jared', 'johnston', 'judy', 'kindergarten', 'latino', 'lopez', 'loudly', \"master's\", 'mechanic', 'megan', 'mls', 'modify', 'neglect', 'northwestern', 'nz', 'offenders', 'oppression', 'patriotic', 'phillip', 'pictured', 'pitcher', 'playground', 'populated', 'poses', 'positioned', 'prejudice', 'preston', 'probable', 'probation', 'projection', 'promotes', 'pumped', 'rails', 'raven', 'receptor', 'rehab', 'remake', 'rendering', 'reproduction', 'res', 'reservations', 'rey', 'rhode', 'shrimp', 'similarities', 'skins', 'slopes', 'spelled', 'spokesman', 'springfield', 'stained', 'stall', 'starving', 'strap', 'subjective', 'surround', 'surroundings', 'sweeping', 'swinging', 'tearing', 'traumatic', 'trillion', 'tucker', 'vatican', 'vendor', 'watts', 'yr', '♪', 'abbott', 'aboriginal', 'academics', 'adopting', 'alignment', 'allergic', 'allison', 'amended', 'apparatus', 'assumes', 'avengers', 'backpack', 'balcony', 'banker', 'bliss', 'bodily', 'buffer', 'calgary', 'chapman', 'chopped', 'collaborative', 'commenced', 'compensate', 'compromised', 'constructive', 'conventions', 'cosmic', 'crystals', 'daisy', \"daughter's\", 'definite', 'demonstrations', 'departed', 'depths', 'developmental', 'disco', 'distraction', 'dom', 'dorothy', 'doses', 'drawer', \"driver's\", 'drones', 'durham', 'ecological', 'ecosystem', 'elvis', 'euros', 'exclude', 'exempt', 'exposing', 'faint', 'fertility', 'ff', 'fines', 'finn', 'floods', 'flynn', 'foam', 'folded', 'foremost', 'forge', 'greenhouse', 'hears', 'hierarchy', 'ideals', 'identities', 'installations', 'invalid', 'jade', 'jointly', 'jung', 'kits', 'lancaster', 'lightweight', 'lowering', 'mb', 'melted', 'metabolism', 'neglected', 'negotiated', 'negotiating', 'negotiation', 'newborn', 'newport', 'nodes', 'notch', 'omega', 'onions', 'packers', 'paired', 'parental', 'parody', 'parole', 'participant', 'penguin', 'phantom', 'photoshop', 'pitt', 'precedent', 'prevalent', 'prom', 'promotions', 'python', 'qatar', 'questionable', 'queue', 'quo', 'regrets', 'render', 'respondents', 'retaining', 'romania', 'sailor', 'seventy', 'shouted', \"show's\", 'simmons', 'sims', 'slides', 'sociology', 'somerset', 'soo', 'specify', 'splitting', 'stab', 'supermarket', 'sweater', 'tenant', 'tensions', 'thomson', 'tortured', 'traction', 'tractor', 'trout', 'turnover', 'uganda', \"university's\", 'unwanted', 'upgrades', \"valentine's\", 'variant', 'vegetarian', 'vernon', 'visibility', 'warnings', 'wherein', 'whiskey', 'worms', 'wyoming', 'aaa', 'abundant', 'africans', 'alexandria', 'algebra', 'analytics', 'antenna', 'attribute', 'audition', 'bankers', 'biting', 'branding', 'bravo', 'busted', 'cardinals', 'carrie', 'certificates', 'charleston', 'chatting', 'chop', 'circuits', 'clifford', 'co2', 'cody', 'coleman', 'commanded', 'commissioners', 'communicating', 'comparative', 'complement', 'connor', 'conquer', 'conquest', 'contested', 'continuity', 'cornwall', 'crawl', 'credible', 'cursed', \"day's\", 'db', 'deepest', 'defects', 'delightful', 'depicted', 'determines', 'digit', 'dinosaur', 'doomed', 'drainage', 'drowning', 'embarrassment', 'equations', 'evolving', 'exploded', 'fairness', 'favored', 'felony', 'flats', 'flint', 'floral', 'fortress', 'fulfilled', 'fundamentally', 'grabbing', 'guts', 'hairs', 'hammond', 'handing', 'hearted', 'herb', 'herd', 'husbands', 'ideological', 'immortal', 'incumbent', 'insider', 'insufficient', 'interval', 'jelly', 'kai', 'kanye', 'kidnapping', 'kilometres', 'ky', 'lenses', 'lick', 'literal', 'lunar', 'maternal', 'matthews', 'maxwell', 'mccain', 'mcdonald', 'medicines', 'memoir', 'messi', 'miguel', 'modification', 'mold', 'nailed', 'napoleon', 'neighbouring', 'nigel', 'objection', 'obliged', 'observers', 'occurrence', 'offspring', 'ou', 'outrageous', 'packet', 'pads', 'patents', 'pathway', 'peach', 'persuaded', 'plots', 'polo', 'presenter', 'proclaimed', 'prohibition', 'prop', \"queen's\", 'recognizing', 'recommends', 'registry', 'relieve', 'remarkably', 'repaired', 'rotating', 'sanchez', 'sandwiches', 'satellites', 'scar', 'scouts', 'scripture', 'seating', 'seminar', 'shores', 'silva', 'simplicity', 'slightest', 'softly', 'specimens', 'starbucks', 'stereo', 'supplements', 'surrey', 'sustainability', 'symphony', 'tesla', 'textbook', 'theological', 'trader', 'undercover', 'valentine', 'vegetation', 'vein', 'velvet', 'vendors', 'viewer', 'webb', 'welcoming', 'whales', 'wheeler', 'worm', 'zombies', 'accountant', 'activate', 'admissions', 'alison', 'amusing', 'arabs', 'beams', 'behold', 'betrayed', 'biased', 'billionaire', 'bloggers', 'brewing', 'brooke', 'bypass', 'calculation', 'cancellation', 'cane', 'capturing', 'catalyst', 'cedar', 'celebrates', 'claude', 'concentrations', 'concludes', 'cons', 'corpse', 'crab', 'cruelty', 'darwin', 'dawson', 'decorations', 'dementia', 'demonstrating', 'designation', 'dev', 'dice', 'diploma', 'disasters', 'discharged', 'dispatch', 'disputed', 'dots', 'ds', 'duchess', 'dunno', 'economists', 'eds', 'elders', 'exceeded', 'explanations', 'extinction', 'factions', 'fb', 'foil', 'formats', 'freddie', 'gardner', 'geology', 'gerald', 'graduating', 'gram', 'greene', 'heath', 'heavenly', 'hormones', 'horrific', 'hugo', 'infants', 'insect', 'iris', 'issuing', 'lifts', 'locking', 'logging', 'lookin', 'maurice', 'medications', 'mentality', 'metre', 'minecraft', 'miracles', 'nascar', 'neural', 'newsletter', 'nineteenth', 'nitrogen', 'norms', 'oceans', 'ooh', 'patricia', 'paulo', 'payroll', 'phenomenal', 'philippine', 'photographic', 'pinch', 'ping', 'polished', 'pots', 'predictable', 'privileges', 'prix', 'professionally', 'protesting', 'protocols', 'pushes', 'queer', 'rebounds', 'reckon', 'recycling', 'restriction', 'resumed', 'resurrection', 'rover', 'scars', 'scholarships', 'shannon', 'shelves', 'shipment', 'slut', 'sparks', 'spatial', 'stainless', 'statutory', 'stellar', 'stockholm', 'stripes', 'stubborn', 'summoned', 'sussex', 'swords', 'syrup', 'tackles', 'tamil', 'tapping', 'teachings', 'tightly', 'tina', 'tones', 'tories', 'transplant', 'traps', 'tu', 'turf', 'twitch', 'unlocked', 'unusually', 'unveiled', 'username', 'vaccines', 'veins', 'ventures', 'vip', 'visions', 'voiced', 'volcano', 'warmer', 'webster', 'weddings', 'yelled', 'zach', 'accelerated', 'accomplishments', 'advertised', 'advertisements', 'ark', 'armour', 'assaulted', 'atoms', 'attach', 'awaiting', 'bayern', 'bind', 'blessings', 'blu', 'bluetooth', 'boiling', 'borrowing', 'bowls', 'bradford', 'bum', 'butcher', \"c'mon\", 'café', 'chandler', 'cheapest', 'chloe', 'communists', 'compares', 'conception', 'congo', 'counterparts', 'cue', 'deed', 'disciplinary', 'dreamed', 'dwarf', 'eighty', 'elena', 'eligibility', 'embraced', 'enacted', 'endorsement', 'enlisted', 'eyebrows', 'fcc', 'finite', 'flagship', 'forensic', 'forthcoming', 'gallon', 'gems', 'glowing', 'glucose', 'gore', 'govt', 'gown', 'greedy', 'halo', 'hilton', 'ideally', 'identifies', 'improves', 'infamous', 'inspirational', 'internally', 'kashmir', 'knox', 'lateral', 'leigh', 'lent', 'lib', 'lifelong', 'limestone', 'liner', 'majors', 'marched', 'marrying', 'maths', 'memes', 'mentioning', 'merge', 'mesh', 'migrant', 'mohammed', 'monitored', 'moron', 'mortar', 'myths', 'naive', 'nat', 'noises', 'norton', 'noticeable', 'nt', 'observing', 'omar', 'opted', 'palestinians', 'paula', 'paypal', 'pedro', 'pens', 'perfume', 'pitching', 'pleasing', 'premiums', 'prestige', 'protects', 'pyramid', 'realizes', 'relevance', 'remotely', 'resorts', 'retailer', 'rica', 'rigid', 'rita', 'rm', 'rom', 'ronaldo', 'sailors', 'samantha', 'sampling', 'screenshot', 'selfie', 'settlers', 'shattered', 'signatures', 'spacecraft', 'specification', 'spiders', 'splendid', 'strokes', 'successes', 'summers', 'sundays', 'supplying', 't00', 'telescope', 'temp', 'tended', 'terminated', 'textile', \"that'd\", 'thickness', 'threatens', 'tossed', 'tray', 'uae', 'ucla', 'unreasonable', 'unsure', 'upwards', 'utilize', 'valuation', 'veterinary', 'villagers', 'violate', 'vivid', 'waving', 'accusing', 'aided', 'alexis', 'allocation', 'americas', 'amusement', 'antibiotics', 'anticipation', \"anyone's\", 'appropriately', 'arrests', 'arrogant', 'assessing', 'authorization', 'auxiliary', 'b.c', 'baggage', 'beacon', 'bella', 'belts', 'bounty', 'boxer', 'briefing', 'brook', 'budgets', 'canterbury', 'cartoons', 'ceramic', 'cereal', 'challenger', 'chased', 'clergy', 'coats', 'cola', 'coma', 'comfortably', 'commanders', 'compass', 'considerations', 'consultants', 'contempt', 'contributes', 'credentials', 'croatia', 'cured', 'descended', 'disappearance', 'doyle', 'drowned', 'drying', 'dwelling', 'dwight', 'ecology', 'einstein', 'eli', 'elliot', 'emergence', 'enclosed', 'endurance', 'equals', 'erotic', 'evacuation', 'exceptionally', 'exchanged', 'expenditure', 'falcon', 'favors', 'fernando', 'folder', 'frequencies', 'frightened', 'gavin', 'groove', 'hbo', 'hedge', 'homosexuality', 'icons', 'ingredient', 'initiate', 'inserted', 'interventions', 'invaded', 'ironically', 'istanbul', 'jacobs', 'jealousy', 'jewellery', 'joker', 'jonas', 'kingston', 'kisses', 'laden', 'learns', 'limbs', 'lionel', 'liu', 'mccarthy', 'medicaid', 'meta', 'mil', 'mit', 'newark', 'nod', 'notebook', 'offline', 'offs', 'overweight', 'palette', 'payne', 'phenomena', 'pneumonia', 'policeman', 'postponed', 'potent', 'preceding', 'predators', 'psycho', 'rainy', 'rams', 'ranged', 'recognizes', 'renovation', 'reverend', 'rewarding', 'rust', 'salty', 'scots', 'scrutiny', 'seizure', 'serum', 'singular', 'skate', 'sofia', 'storyline', 'stray', 'stud', 'subsidies', 'sunk', 'supper', 'sweetheart', 'systemic', 'tempo', 'thereof', 'thirsty', 'torch', 'transferring', 'tumblr', 'turbo', 'unchanged', 'understandable', 'upright', 'uprising', 'vain', 'vanity', 'violin', 'wh', 'whereby', 'whisper', 'worthwhile', 'xx', 'acceleration', 'aerospace', 'ak', 'aluminium', 'analog', 'analytical', 'anticipate', 'arcade', 'arlington', 'arose', 'asthma', 'aurora', 'averaging', 'bacterial', 'bankrupt', 'blink', 'brighter', \"brother's\", 'carey', 'castro', 'ceremonies', 'chang', 'childish', 'chili', 'clayton', 'clearer', 'coil', 'combines', 'commodities', 'confessed', 'constituents', 'contention', 'converting', 'covenant', 'crafts', 'das', 'denies', 'devotion', 'dilemma', 'dis', 'discoveries', 'disgrace', 'dixon', 'emirates', 'emmy', 'employing', 'employs', 'escaping', 'ethiopia', 'ethnicity', 'eventual', 'excel', 'exercising', 'faded', 'firstly', 'flavour', 'flex', 'fluids', 'franco', 'gangs', 'gases', 'genus', 'gloria', 'glove', 'grabs', 'grammy', 'grapes', 'greed', 'greet', 'hank', 'hose', 'hq', 'impacted', 'imposing', 'inflammation', 'innovations', \"john's\", 'ko', 'lambert', 'lamps', 'lava', 'ln', 'longtime', 'madonna', 'magnet', 'mann', 'metaphor', 'millionaire', 'mn', 'motives', 'myers', 'mysteries', 'negro', 'nightmares', 'notify', 'null', 'ole', 'oops', 'oriental', 'owing', 'pact', 'paramount', 'paranoid', 'patriot', 'patron', 'pearson', 'popcorn', 'positioning', 'preserving', 'proxy', 'quantitative', 'regain', 'reminding', 'renew', 'resemble', 'retarded', 'retro', 'revolt', 'rightly', 'roasted', 'ruining', 'rumor', 'sacked', 'saddle', 'schmidt', 'schooling', 'sherlock', 'shirley', 'shrine', 'shrink', 'sniper', 'solitary', 'sorrow', 'squares', 'starters', 'stoke', 'sutton', 'talkin', 'taller', 'termination', 'thames', 'thigh', 'thrive', 'tr', 'troll', 'ty', 'uncovered', 'undertake', 'unpaid', 'unsuccessful', 'usc', 'vest', 'vine', 'violating', 'viruses', 'warns', 'warranty', 'weakened', 'windsor', 'xxx', 'yen', 'zimbabwe', 'admired', 'airways', 'aisle', 'almighty', 'amino', 'ants', 'apparel', 'arbitration', 'arising', 'artifacts', 'ashton', 'atom', 'auburn', 'awakening', 'bedrooms', 'bilateral', 'bleed', \"boy's\", 'brace', 'burgers', 'caption', 'captures', 'choke', 'cholesterol', 'classy', 'clicks', 'clyde', 'compelled', 'concealed', 'condemn', 'confrontation', 'constitutes', 'contributor', 'cpu', 'damon', 'deluxe', 'devastated', 'dinosaurs', 'disguise', 'dismissal', 'domains', 'downstairs', 'empathy', 'ensemble', 'ernest', 'feasible', 'flawed', 'forged', 'generals', 'genres', 'gettin', 'gi', 'goats', 'grease', 'greeks', 'guessed', 'haiti', 'hallway', 'harley', 'heavens', 'helicopters', 'homosexual', 'hulk', 'hydraulic', 'impulse', 'incapable', 'indies', 'inflammatory', 'insanity', 'insecure', 'institutes', 'integrate', 'intentional', 'ish', 'jeep', 'knot', 'laboratories', 'landscapes', 'lebanese', 'lecturer', 'lust', 'marilyn', 'markers', 'mayo', 'michel', 'microphone', 'miniature', 'monks', 'motto', 'mouths', 'murdering', 'nationality', 'natives', 'nottingham', 'nw', 'obstacle', 'occupational', 'og', 'onset', 'owes', 'pe', 'perceive', 'persecution', 'petrol', 'philosopher', 'photographed', 'pits', 'pixel', 'plantation', 'presently', 'props', 'prose', 'prostitution', 'quoting', 'radioactive', 'raining', 'rang', 'razor', 'realization', 'reconciliation', 'removes', 'restoring', 'reunited', 'rocking', 'rory', 'royals', 'rug', 'sacrifices', 'salvador', 'scanning', 'screamed', 'shaping', 'slogan', 'specimen', 'sponsorship', 'steals', 'steer', 'stefan', 'strains', 'strawberry', 'strive', 'sunglasses', 'surfing', 'tate', 'temptation', 'thrill', 'tile', 'tonnes', 'tow', 'trainers', 'translations', 'trusting', 'turtles', 'uc', 'unarmed', 'undertaking', 'unfinished', 'unhealthy', 'unlawful', 'unpopular', 'ut', 'vanessa', 'vanished', 'verb', 'versa', 'viii', 'volatile', 'voluntarily', 'vp', 'whitney', 'withdrew', 'abnormal', 'accredited', 'accuse', 'ada', 'adjusting', 'ample', 'analogy', 'analyzing', 'apex', 'apocalypse', 'appliances', 'assholes', \"baby's\", 'backward', 'badass', 'barred', 'beck', 'bingo', 'blogging', 'boiler', 'bon', 'boulder', 'brock', 'calf', 'cambodia', 'capt', 'cb', 'clarence', 'coating', 'commentators', 'consolidation', 'continuation', 'convictions', 'convoy', 'cork', 'cosmetic', 'cubic', 'cyprus', 'declares', 'defeats', 'defenses', 'dept', 'deputies', 'descendants', 'detector', 'digest', 'diplomacy', 'directive', 'disadvantage', 'disruption', 'distract', \"doctor's\", 'downward', 'ebook', 'eco', 'emphasized', 'energetic', 'engineered', 'fest', 'fills', 'friction', 'fulfilling', 'funk', 'greatness', 'grilled', 'guiding', 'hackers', 'hazardous', 'hooker', 'hopeless', 'hourly', 'illustrate', 'imo', 'impressions', 'indirectly', 'induction', 'infrared', 'insists', 'instability', 'installing', 'invites', 'irene', 'irving', 'ja', 'jacques', 'jong', 'klein', 'limitation', 'linguistic', 'listeners', 'litter', 'ls', 'lump', 'macro', 'mag', 'magistrate', 'marginal', 'masculine', 'milestone', 'mug', 'municipality', 'mushrooms', 'nd', 'ned', 'neurons', 'ninety', 'nutrients', 'observatory', 'oi', 'openings', 'outdoors', 'pcs', 'pedestrian', 'penetration', 'pod', 'posing', 'predator', 'preferably', 'programmed', 'projections', 'prophecy', 'proudly', 'rebuilding', 'recorder', 'recurring', 'relaxation', 'resembles', 'respectable', 'respectful', 'richer', 'rn', 'rodriguez', 'roma', 'romeo', 'routinely', 'rubbing', 'sailed', 'salute', 'scripts', 'scum', 'serbia', 'severity', 'shady', 'shutting', 'sketches', 'slack', 'sleeps', 'slick', 'slowed', 'slowing', 'sm', 'spontaneous', 'starred', 'stationed', 'sticker', 'stove', 'submissions', 'tactic', 'tb', 'template', 'teresa', 'texting', 'theorem', 'theresa', 'tiles', 'tn', 'tore', 'tract', 'treaties', 'tri', 'tribune', 'u.k', 'undergoing', 'unexpectedly', 'upward', 'val', 'vera', 'vista', 'vogue', 'volcanic', 'wagner', 'wildly', 'winding', 'acclaimed', 'accumulated', 'adore', 'afc', 'akin', 'alphabet', 'announcements', 'appoint', 'apprentice', 'auckland', 'bananas', 'baseline', 'beasts', 'benedict', 'beware', 'bieber', 'bikini', 'bisexual', 'boulevard', 'bracelet', 'capsule', 'captive', 'carr', 'cha', 'christie', 'chronicle', 'cinnamon', 'comprehend', 'compulsory', 'confederate', 'contaminated', 'contamination', 'contests', 'coping', 'corey', 'counterpart', 'creed', 'crisp', 'crust', 'cutter', 'daring', 'delegate', 'deploy', 'dietary', 'dissertation', 'dividends', 'domination', 'downloading', 'ec', 'emission', 'ethan', 'evaluating', 'everton', 'expelled', 'fin', 'fined', 'flora', 'folding', 'fracture', 'frances', 'functionality', 'gamma', 'gays', 'gaze', 'genome', 'grains', 'grape', 'gravel', 'haircut', 'haired', 'hangs', 'hastings', 'highland', 'histories', 'honoured', 'hugs', 'hustle', 'hyde', 'ia', 'idle', 'indictment', 'insulting', 'irregular', 'juicy', 'jumper', 'justices', 'kardashian', 'leaking', 'limb', 'mack', 'mammals', 'manually', 'meaningless', 'millennium', 'misunderstanding', 'modelling', 'modules', 'moody', 'nam', 'needles', 'noodles', 'offender', 'oracle', 'overlap', 'patrons', 'pd', 'peek', 'pentagon', 'peters', 'petersburg', 'pokémon', 'porsche', 'pos', 'pottery', 'prairie', 'prank', 'premature', 'psychiatrist', 'quad', 'quartz', 'quitting', 'rb', 'residency', 'resolutions', 'responsive', 'richest', 'roar', 'ronnie', 'rooney', 'rot', 'rulers', 'salem', 'sank', 'santos', 'sb', 'seahawks', 'sidney', 'sleeves', 'songwriter', 'sophia', 'spear', 'spies', 'stain', 'stella', 'stimulation', 'stranded', 'stretches', 'stylish', 'subs', 'sur', 'tasted', 'technician', 'temples', 'tidal', 'transcript', 'treasures', 'trench', 'trousers', 'unwilling', 'uruguay', 'utc', 'validity', 'variants', 'varsity', 'verification', 'vows', 'vulnerability', 'wesley', 'whichever', 'whipped', \"who've\", 'wo', 'wrath', 'yuan', 'zen', '4k', 'abuses', 'accomplishment', 'acquisitions', 'aide', 'allegiance', 'apt', 'attracting', 'avatar', 'bali', 'bangalore', 'bans', 'battling', 'beads', 'beverage', 'blaze', 'brendan', 'brent', 'broadband', 'bullied', 'bumper', 'butterflies', 'carlo', 'caves', 'chalk', 'chilling', 'coaster', 'coated', 'constituency', 'contingent', 'cornell', 'corrections', 'costing', 'councillor', 'cyclists', 'daniels', 'deprived', 'diplomat', 'disciplines', 'dos', 'drained', 'eldest', 'emphasize', 'entirety', 'everytime', 'exodus', 'explosions', 'fallout', 'feather', 'figuring', 'financed', 'firearm', 'fisheries', 'flock', 'flyers', 'footballer', 'footsteps', 'forestry', 'ghetto', 'grim', 'helpless', 'hemisphere', 'hides', 'housed', 'hs', 'hyper', 'inconvenience', 'incorporating', 'injected', 'insured', 'intends', 'intervals', 'intriguing', 'invasive', 'ipod', 'iq', 'irrigation', 'ix', 'killings', 'lastly', 'liberties', 'lipstick', 'macdonald', 'manipulate', 'mart', 'martinez', 'meyer', 'midlands', 'midway', 'minors', 'moist', 'monarch', 'monte', 'monuments', 'mortgages', 'mourning', 'mu', 'mustard', 'negatively', 'neighbour', 'nissan', 'norwich', 'nothin', 'objections', 'patterson', 'persona', 'plaque', 'pls', 'plymouth', 'poetic', 'preach', 'preaching', 'princes', 'proposing', 'punjab', 'purity', 'rabbi', 'ramsey', 'realism', 'receipts', 'retrieve', 'rhodes', 'ri', 'scheduling', 'scoop', 'scotch', 'scrub', 'separating', 'sewing', 'shale', 'shin', 'shootings', 'simplified', 'slipping', 'smartphones', 'sol', 'solicitor', 'sophomore', 'spreads', 'squadron', 'squirrel', 'stalin', 'stickers', 'stigma', 'strengthened', 'taco', 'takeover', 'taliban', 'tapped', 'thor', 'thumbs', 'tinder', 'titan', 'trait', 'traitor', 'troop', 'truths', 'underestimate', 'uni', 'updating', 'urges', 'wallpaper', 'wasnt', 'watt', 'weighs', 'willis', 'willow', 'x00', 'addict', 'ale', 'api', 'archaeological', 'assistants', 'az', 'banging', 'bathing', 'bending', 'bengal', 'betrayal', 'boiled', 'bonding', 'bounds', 'breeds', \"britain's\", 'byron', 'cardiovascular', 'chic', 'clone', 'clusters', 'communal', 'compliments', 'consortium', 'controllers', 'copying', 'countdown', 'courier', 'danced', 'dd', 'debating', 'decreasing', 'defect', 'disastrous', 'displaying', 'drown', 'drummer', 'durable', 'efficacy', 'erik', 'erin', 'exaggerated', 'exclusion', 'exhibitions', 'exploited', 'extracted', 'faults', 'filipino', 'flashing', 'freelance', 'gerard', 'gin', 'girlfriends', 'granting', 'greeting', 'hawaiian', 'headaches', 'honeymoon', 'ignition', 'impaired', 'incomes', 'investigative', 'ir', 'jewel', 'jupiter', 'leonardo', 'manifest', 'mans', 'marx', 'mets', 'mourinho', 'mutually', 'navigate', \"o'neill\", 'obese', 'outreach', 'overlooking', 'pandemic', 'passages', 'perceptions', 'perimeter', 'pike', 'piper', 'preacher', 'preceded', 'procurement', 'protector', 'pulp', 'rabbits', 'ransom', 'recruits', 'reel', 'refs', 'reg', 'rehearsal', 'reinforce', 'restart', 'revive', 'rigorous', 'ringing', 'rna', 'scarf', 'scenery', 'selections', 'sensory', 'shelters', 'sidewalk', 'skeptical', 'skype', 'sleepy', 'smoothly', 'speeding', 'staple', 'steelers', 'stereotypes', 'stirring', 'strand', 'stunned', 'suppression', 'sushi', 'suspend', 'sw', 'swelling', 'tails', 'terminology', 'theatrical', 'timer', 'travellers', 'trustee', 'turnout', 'tying', 'unanimous', 'unpredictable', 'urging', 'validation', 'vengeance', 'verizon', 'visually', 'waits', 'wakes', 'weighted', 'wii', 'xl', 'zhang', 'acc', 'activism', 'advent', 'airborne', 'alas', 'astonishing', 'aww', 'bakery', 'barracks', 'bart', 'bathrooms', 'baths', 'believer', 'benefited', 'blankets', 'borne', 'brokers', 'bunker', 'caffeine', 'capped', 'carlton', 'chaotic', 'chargers', 'cite', 'classrooms', 'commentator', 'commercially', 'confirming', 'confuse', 'contributors', 'copenhagen', 'cosmetics', 'coward', 'dammit', 'dell', 'dent', 'depart', 'destroys', 'detectives', 'diminished', 'disappears', 'disappoint', 'dl', 'dolphin', 'dove', 'dumping', 'dunn', 'dusty', 'embracing', 'enduring', 'enlightenment', 'fibre', 'finnish', 'fixture', 'focal', 'friendships', 'frightening', 'fucker', 'gala', 'gardening', 'garrett', 'garrison', 'gears', 'generates', 'gladly', 'goodwill', 'govern', 'gradual', 'greetings', 'groceries', 'hacker', 'hal', 'harness', 'hashtag', 'hassan', 'heartbeat', 'heh', 'highlighting', 'holt', 'honourable', 'illnesses', 'imminent', 'inaugural', 'insulation', 'intern', 'irresponsible', 'jakarta', 'johannesburg', 'judith', 'kathy', 'lag', 'lays', 'lenders', 'lg', 'locality', 'lure', 'malicious', 'mattress', 'meredith', 'merged', 'merits', 'mist', 'mole', 'molecule', 'monarchy', 'mormon', 'muscular', 'neutrality', 'nikki', 'noisy', 'notre', 'orgasm', 'otto', 'panties', 'parcel', 'partition', 'peculiar', 'penguins', 'prayed', 'prefers', 'proposes', 'proprietary', 'prostate', 'protagonist', 'punching', 'puppies', 'rafael', 'randall', 'rant', 'rash', 'realities', 'recalls', 'receivers', 'referenced', 'reflections', 'rejects', 'replica', 'representations', 'reside', 'richie', 'ripe', 'rituals', 'riverside', 'roberto', 'rodney', 'rp', 'sac', 'sacrificed', 'sane', 'savior', 'scenic', 'sip', 'slapped', 'snail', 'somalia', 'spotify', 'spun', 'statistically', 'stimulate', 'strangely', 'surveyed', 'susceptible', 'theodore', 'thighs', 'tipped', 'toby', 'toilets', 'torres', 'translates', 'translator', 'transmit', 'trophies', 'ts', 'tuning', 'tutor', 'unsafe', 'verge', 'vibrant', 'wander', 'wong', 'xp', 'yeast', '█', '🙂', 'abdul', 'absorption', 'accelerate', 'acne', 'advertise', \"alzheimer's\", 'apologise', 'aspirations', 'assassin', 'assign', 'aston', 'audi', 'backlash', 'balloons', 'bbq', 'believers', 'blockchain', 'bonnie', 'brewery', 'bulb', 'cardboard', 'casually', 'chartered', 'chew', 'circumstance', 'cliffs', 'collateral', 'congestion', 'conquered', 'courtney', 'creditors', 'criticised', 'criticisms', 'crossover', 'crunch', 'curtains', 'daytime', 'debbie', 'deliveries', 'demise', 'dependence', 'deutsche', 'dictator', 'diets', 'differs', 'digits', 'dime', 'dire', 'disagreement', 'disciples', 'disregard', 'distributor', 'dominion', 'downhill', 'drafting', 'dreadful', 'drunken', 'earnest', 'eng', 'erase', 'evacuated', 'exp', 'extinct', 'forbid', 'forgiven', 'freezer', 'genetically', 'greeted', 'hare', 'healed', 'herein', 'hoffman', 'honorary', 'immature', 'imperative', 'ineffective', 'interacting', 'jerome', 'jess', 'julius', 'knit', 'kumar', 'kuwait', 'laps', 'lester', 'manly', 'marvin', 'maternity', 'meanings', 'misconduct', 'morale', 'mornings', 'mute', 'needless', 'nerd', 'nokia', 'nominees', 'notifications', 'novelty', 'optimism', 'optimization', 'outdated', 'oxide', 'paints', 'peasants', 'pence', 'peppers', 'percy', 'perez', 'peripheral', 'pinned', 'pint', 'pleaded', 'poop', 'pornography', 'ppl', 'prepares', 'prevalence', 'proceeding', 'pronounce', 'proportions', 'provisional', 'punches', 'ravens', 'reddit', 'remark', 'repay', 'roland', 'ropes', 'rouge', 'rumours', \"russia's\", 'santiago', 'saturated', 'scares', 'screened', 'shaved', 'shooters', 'shove', 'skipped', 'smashing', 'sms', 'snaps', 'soaked', 'softball', 'southeastern', 'spears', 'specials', 'spectators', 'spur', 'stevie', 'storytelling', 'stumbled', 'stupidity', 'suppress', 'sweating', 'swings', 'tangible', 'tara', 'textbooks', 'theo', 'tilt', \"tonight's\", 'tougher', 'trivial', 'turks', 'unofficial', 'veil', 'versatile', 'warsaw', 'wed', 'wr', 'yi', 'zoe', 'à', 'acknowledging', 'alec', 'anthropology', \"apple's\", 'artery', 'bamboo', 'basil', 'blackberry', 'bolton', 'bombay', 'booze', 'brennan', 'bronx', 'buzzing', 'caliber', 'cbd', 'cellphone', 'chord', 'clare', 'concessions', 'contracting', 'cooks', 'corporal', 'courtyard', 'crafted', 'crest', 'crowned', 'cynthia', 'dang', 'deception', 'decor', 'defeating', 'derivative', 'discomfort', 'dominican', 'drastically', 'driveway', 'duel', 'edwin', 'elf', 'ev', 'evenly', 'exemption', 'fashionable', 'fetch', 'fishermen', 'flipped', 'fo', 'formidable', 'frankie', 'furnished', 'fuzzy', 'gibbs', 'gmt', 'gothic', 'graffiti', 'grenade', 'guitars', 'hague', 'hamlet', 'hampton', 'hc', 'helm', 'herbs', 'herman', 'higgins', 'highlands', 'honours', 'hooks', 'hrs', 'html', 'hugely', 'hypocrisy', 'imagining', 'inaccurate', 'inception', 'incompetent', 'indefinitely', 'intervene', \"japan's\", 'jerseys', 'jessie', 'jp', 'jules', 'katy', 'kin', 'kirby', 'kobe', 'kris', 'laurie', 'legislators', 'lobster', 'logged', 'loneliness', 'loops', 'mae', 'malaria', 'manifesto', 'manuscripts', 'masked', 'maze', 'methodist', 'monaco', 'monastery', 'morals', 'mutations', 'naomi', 'narrowly', 'negligence', 'nexus', 'nicer', 'nightclub', 'numerical', 'obsolete', 'offences', 'optic', 'panda', 'panther', \"paul's\", 'peas', 'perkins', 'posture', 'prague', 'preseason', 'qaeda', 'raging', 'rc', 'receptors', 'refresh', 'resonance', 'ruthless', 'salvage', 'samurai', 'sasha', 'satire', 'saul', 'seafood', 'shakes', 'signaling', 'simplest', 'slash', 'spaghetti', 'speedy', 'spying', 'staging', 'standpoint', 'statues', 'stein', 'sway', 'tasting', 'tempting', 'terminate', 'torque', 'towels', 'trailers', 'transforming', 'trinidad', \"uk's\", 'unconstitutional', 'undermine', 'underwent', 'vacancy', 'var', 'veto', 'villains', 'vocational', 'wenger', 'wickets', 'withstand', 'woodland', 'zinc', 'a1', 'accustomed', 'adequately', 'ahmad', 'alicia', 'amazingly', 'ambitions', 'applicant', 'approximate', 'assemble', 'averages', 'baghdad', 'ballots', 'bam', 'bargaining', 'barrett', 'bates', 'baton', 'beginnings', 'births', 'breakup', 'brew', 'bulldogs', 'c00', 'camel', 'canberra', 'catering', 'charger', 'checkout', 'chefs', 'chronicles', 'chunk', 'classmates', 'coca', 'cocoa', 'comet', 'compartment', 'compositions', 'conditioned', 'contestants', 'cooled', 'corpus', 'coupons', 'cove', 'cozy', 'culturally', 'currents', 'deficiency', 'deported', 'deposited', 'derivatives', 'deserted', 'dictatorship', 'disrespectful', 'dread', 'dub', 'dummy', 'ecuador', 'edmonton', 'electorate', 'enhancing', 'entertained', 'erosion', 'explores', 'expo', 'favourites', 'fibers', 'fitzgerald', 'flank', 'flare', 'fleeing', 'flirting', 'forex', 'gallons', 'gamers', 'generators', 'geoffrey', 'goodnight', 'gus', 'handmade', 'hartford', 'hawkins', 'hazards', 'hostages', 'icc', 'incidence', 'intimacy', 'italians', 'jul', 'kat', 'kerr', 'kitten', 'knicks', 'koch', 'lagos', 'lan', 'lender', 'leone', 'lever', 'lisbon', 'lu', 'marketed', 'marty', 'mileage', 'morton', 'multiplayer', 'municipalities', 'mutant', 'mutation', 'mythology', 'neal', 'neon', 'nile', 'nolan', 'northeastern', 'noticing', 'nun', 'nutritional', 'ow', 'p00', 'pathways', 'pedal', 'pest', 'pillar', 'pitches', 'plausible', 'pledged', 'poly', 'polymer', 'precipitation', 'prosecutors', 'protections', 'pup', 'quarantine', 'query', 'raf', 'rallies', 'rapids', 'reacted', 'restraint', 'rests', 'retains', 'revived', 'rift', 'romney', 'russ', 'salesman', 'scarlet', 'screws', 'sensing', 'serena', 'sewer', 'shipments', 'shits', 'smack', 'sonny', 'southwestern', 'spared', 'spokesperson', 'stalking', 'standardized', 'stitch', 'substrate', 'sultan', 'supremacy', 'swallowed', 'swell', 'symptom', 'thanked', 'theoretically', 'thirst', 'transitional', 'tuna', 'unused', 'valleys', 'viewpoint', 'vinegar', 'wards', 'warrants', 'wig', '─', 'accessory', 'advisors', 'advocating', 'affiliation', 'aggressively', 'align', 'allergies', 'amnesty', 'angus', 'anita', 'apologized', 'assad', 'assertion', 'astronomy', 'atop', 'attic', 'attracts', 'australians', 'autobiography', 'av', 'await', 'bastards', 'becky', 'bing', 'bothering', 'broadcaster', 'buddhism', 'buds', 'cache', 'carmen', 'carrots', 'cds', 'chewing', \"clinton's\", 'coherent', 'comfy', 'comrades', 'conceded', 'condo', 'conflicting', 'conrad', 'consulted', 'criticize', 'crooked', 'cultivation', 'dads', 'decreases', 'dicks', 'ding', 'discontinued', 'displacement', 'disrespect', 'distorted', 'divers', 'dividing', 'dow', 'downloads', 'drastic', 'edible', 'edmund', 'ella', 'emerson', 'endorse', 'enhancement', 'evenings', 'fax', 'fiat', 'fiona', 'firefighters', 'flick', 'fowler', 'funky', 'gag', 'gee', 'gigantic', 'gill', 'groom', 'guarded', 'guitarist', 'halftime', 'hamas', 'harriet', 'hash', 'helena', 'hogan', 'holden', 'hydro', 'ig', 'illustrates', 'inactive', 'inputs', 'inspect', 'inspections', 'inspectors', 'instincts', 'interpretations', 'je', 'jj', 'knots', 'lana', 'laurel', 'lawsuits', 'leftist', 'legitimacy', 'linkedin', 'lizard', 'lyric', 'maximize', 'morally', 'mp3', 'mushroom', 'naples', 'nigga', 'noel', 'occupying', 'organizers', 'owens', 'paradox', 'peacefully', 'periodic', 'philly', 'plead', 'podium', 'portray', 'practitioner', 'pradesh', 'progressed', 'puck', 'ratios', 'reconsider', 'redskins', 'reductions', 'refrain', 'replaces', 'reproduce', 'researching', 'rigged', 'rite', 'rum', 's00', 'safari', 'saunders', 'scaling', 'scorer', 'seldom', 'shareholder', 'simone', 'sis', 'slams', 'slices', 'soy', 'spilled', 'squash', 'stacked', 'statewide', 'stationary', 'styled', 'subdivision', 'succeeding', 'sunderland', 'surrendered', 'tar', 'tariffs', 'temporal', 'tracker', 'turbine', 'tyson', 'unavailable', 'universally', 'unlucky', 'utilizing', 'uv', 'volunteered', 'vomiting', 'warden', 'warp', 'whisky', \"who'd\", 'winters', 'womb', 'yogurt', 'abe', 'abolished', 'abusing', 'algeria', 'alpine', 'ambient', 'aquatic', 'argentine', 'armored', 'assert', 'atheist', 'balances', 'bandwidth', 'barbecue', 'beforehand', 'bipolar', 'bladder', 'blossom', \"body's\", 'bolts', 'bombed', 'campaigning', 'canned', 'captains', 'caravan', 'carrot', 'chanting', 'chevrolet', 'clive', 'compressed', 'comprise', 'computational', 'conceptual', 'coolest', 'currencies', 'damp', 'danielle', 'databases', 'debit', 'demolition', 'denis', 'detailing', 'differentiate', 'dim', 'discouraged', 'discovers', 'donkey', 'doo', 'downstream', 'earrings', 'earthquakes', 'ebola', 'eg', 'elites', 'ellie', 'empirical', 'enlarged', 'enzymes', 'esther', \"everybody's\", 'fantasies', 'faulty', 'fertile', 'feud', 'filmmaker', 'formations', 'fortunes', 'frankfurt', 'freedoms', 'furnace', 'fuse', 'fuss', 'gale', 'gamer', 'generosity', 'gerry', 'gluten', 'goodman', 'gorilla', 'guatemala', 'hamburg', 'harvested', 'hath', 'heavyweight', 'humane', 'humanities', 'inflicted', 'interviewing', 'jedi', 'jennings', 'journeys', 'labelled', 'lawful', 'lawmakers', 'leased', 'lena', 'loosely', \"lord's\", 'lotus', 'luna', 'mails', 'malik', 'mantle', 'mascot', 'metabolic', 'meth', 'mf', 'midfield', 'militant', 'missionaries', 'mohammad', 'nicolas', 'nostalgia', 'ottoman', 'paddy', 'paperback', 'paved', 'pavilion', 'peasant', 'perks', 'philosophers', 'pillars', 'pointer', 'policing', 'predicting', 'presume', 'presumed', 'printers', 'rapist', 'reacting', 'rebuilt', 'rec', 'rectangular', 'regulator', 'renting', 'restructuring', 'ridden', 'ro', 'rudy', 'sabotage', 'sanctioned', 'sarcasm', 'savannah', 'scans', 'seekers', 'sentencing', 'sexist', 'shaving', 'shutdown', 'sic', 'slammed', 'snp', 'stresses', 'suffolk', 'surpassed', 'swansea', 'sweets', 'syracuse', 'tally', 'tehran', 'termed', 'tha', 'thriving', 'timed', 'tm', 'trending', 'trolls', 'tucked', 'tumors', 'u.s.a', 'ui', 'unanimously', 'undefeated', 'unfamiliar', 'upgrading', 'vale', 'valencia', 'vastly', 'vile', 'violently', 'wedge', 'wisely', 'wizards', 'wrecked', \"yesterday's\", 'yuri', 'adaptive', 'addictive', 'affinity', 'alloy', 'apartheid', 'arises', 'arthritis', 'authorised', 'ay', 'b00', 'bale', 'barton', 'beaver', 'boasts', 'brunswick', 'buenos', 'caller', 'carnegie', 'casualty', 'cavity', 'chap', 'cites', 'colts', 'comforting', 'conway', 'courthouse', 'crank', 'cv', 'dante', 'darn', 'deborah', 'decks', 'diaries', 'differing', 'disgust', 'dispatched', 'dissolution', 'disturbance', \"dog's\", 'dominic', 'doubling', 'ee', 'emerges', 'enclosure', 'evangelical', 'examinations', 'exceeding', 'expresses', 'exquisite', 'factual', 'fading', 'falsely', 'famine', 'fares', 'feminists', 'fiji', 'flavors', 'fraudulent', 'freeway', 'freshly', 'gazette', 'geek', 'geo', 'granny', 'handicap', 'hansen', 'hmmm', 'homage', 'homo', 'hostility', 'hymn', 'hypothetical', 'informative', 'infringement', 'internship', 'interrupt', 'invade', 'irritating', 'jacksonville', 'jasmine', 'katrina', \"kid's\", 'knockout', 'lantern', 'linen', 'lookout', 'misunderstood', 'moonlight', 'moose', 'mosquito', 'motel', 'motherfucker', 'mueller', 'narratives', \"nobody's\", 'noun', 'novelist', 'nsfw', 'oaks', 'omaha', 'onwards', 'overthrow', 'paradigm', 'pavement', 'payday', 'perpetual', 'pga', 'physiology', 'pigeon', 'plateau', 'playlist', 'plc', 'possesses', 'possessing', 'precinct', 'premiership', 'presentations', 'proliferation', 'prosecuted', 'pseudo', 'pudding', 'reformed', 'refrigerator', 'regeneration', 'regina', 'remembrance', 'reminiscent', 'reps', 'resentment', 'resin', 'resisted', 'rosie', 'rotary', 'rupert', 'rusty', 'scarce', 'sibling', 'simulator', 'sl', 'slippery', 'slips', 'snyder', 'soak', 'sock', 'sorting', 'spectacle', 'stint', 'storey', 'suicidal', 'suv', 'symposium', 'tabs', 'tailor', 'terminals', 'thrilling', 'tottenham', 'toughest', 'trajectory', 'triggers', 'tt', 'underrated', 'unidentified', 'unrest', 'unseen', 'utmost', 'waiter', 'weary', 'wiki', 'wills', 'willy', 'wimbledon', 'witches', 'wwii', 'youths', '■', '●', 'accusation', 'adapter', 'adjustable', 'adulthood', 'advisers', 'advocated', 'affiliates', 'agony', 'allergy', 'armenian', 'astronaut', 'attain', 'attendant', 'authenticity', 'avery', 'backstage', 'banners', 'bedford', 'benchmark', 'benghazi', 'benny', 'benson', 'beverages', 'binge', 'biscuits', 'bloc', 'bouncing', 'bourbon', 'breaker', 'breathtaking', 'browsing', 'brutality', 'bumps', 'calculus', 'cancers', 'capitals', 'careless', 'caste', 'cellar', 'cerebral', 'champs', 'chant', 'cheerful', 'cinematic', 'climax', 'clippers', 'cockpit', 'cocktails', 'colon', 'communion', 'condom', 'consul', 'contender', 'crimson', 'crypto', 'cultivated', 'curly', 'debated', 'degradation', \"devil's\", 'dexter', 'disappearing', 'discs', 'distributors', 'duh', 'dundee', 'elaine', 'electrons', 'emerald', 'ensures', 'equilibrium', 'europa', 'evelyn', 'evidently', 'exhausting', 'extras', 'famed', 'fargo', 'fascinated', 'fences', 'fetus', 'flaw', 'flawless', 'fooled', 'forrest', 'gigs', 'grad', 'granddaughter', 'gymnastics', 'hale', 'helmets', 'hercules', 'hereby', 'honduras', 'hotter', 'humorous', 'ignores', 'incurred', 'indications', 'indoors', 'intercourse', 'interestingly', 'isaiah', 'isolate', \"israel's\", 'jurisdictions', 'kathleen', 'kendall', 'knocks', 'lancashire', 'lawson', 'lesbians', 'lindsey', 'listens', \"london's\", 'mailing', 'manipulated', 'mao', 'mare', 'marxist', 'meadow', 'meadows', 'ministries', 'motivate', 'mound', 'muddy', 'mystic', 'ness', 'nominal', 'norris', \"o'connor\", 'ohh', 'ordinance', 'osborne', 'oscars', 'outlines', 'pairing', 'pam', 'parsons', 'pertaining', 'poke', 'poorer', 'portsmouth', 'praising', 'pres', 'presbyterian', 'prick', 'prolific', 'proportional', 'prosperous', 'quarry', 'referral', 'repost', 'respecting', 'restless', 'rugged', 'sammy', 'sap', 'sarcastic', 'scholarly', 'segregation', 'seymour', 'shaken', 'sheikh', \"sheriff's\", 'shines', 'sinclair', 'sinister', 'stared', 'strait', 'suppressed', 'sylvia', 'teamed', 'tents', 'testosterone', 'thicker', 'tis', \"town's\", 'ventilation', 'viking', 'weaver', 'weber', 'wes', 'williamson', 'yankee', 'yarn', '5k', 'abide', 'accumulation', 'admiration', 'aesthetics', 'aj', 'altering', 'anton', 'archie', 'asserted', 'attacker', 'augusta', 'authoritarian', 'avail', 'bahrain', 'banquet', 'barker', 'behaved', 'bentley', 'benz', 'billed', 'billing', 'booty', 'brackets', 'bravery', 'brit', 'browse', 'brutally', 'buff', 'calorie', 'cdc', 'chamberlain', 'cis', 'claw', 'collects', 'coloring', 'commence', 'compatibility', 'conditional', 'congratulate', 'constructing', 'converts', 'coordinating', 'cortex', 'courageous', 'crawling', 'crusade', 'cynical', 'damascus', 'devised', 'discarded', 'disrupt', 'donating', 'donovan', 'drills', 'duplicate', 'dynamite', 'echoes', 'economical', 'elastic', 'empowered', 'examines', 'exceeds', 'exposition', 'fart', 'fearing', 'fetish', 'fixes', 'fla', 'fluffy', 'fundamentals', 'fundraiser', 'funniest', 'fx', 'gadgets', 'gaga', 'garment', 'geometric', 'gestures', 'goldman', \"google's\", 'gracious', 'grin', 'gta', 'halifax', 'hanna', 'happiest', 'heap', 'highs', 'hum', 'humility', 'impeachment', 'inherently', 'insults', 'inventor', 'isa', 'jailed', 'jasper', 'jewels', 'juliet', 'karachi', 'kickstarter', 'kurdish', 'leopard', 'librarian', 'lobbying', 'lumber', 'lydia', 'mackenzie', 'madam', 'marital', 'mayer', 'meds', 'mis', 'mma', 'multitude', 'muse', 'nanny', 'nineteen', 'nipples', 'nucleus', 'oc', 'orbital', 'organism', 'outgoing', 'overhaul', 'pancakes', 'pas', 'patriotism', 'periodically', 'piles', \"player's\", 'plumbing', 'poppy', 'pratt', 'precautions', 'predecessors', 'protested', 'raced', 'raleigh', 'readiness', 'redundant', 'regulators', 'rejecting', 'remarked', 'resemblance', 'rested', 'rib', 'rods', 'roth', 'sacks', 'seizures', 'sermon', 'shes', \"sister's\", 'slender', 'sloppy', \"smith's\", 'snapchat', 'socialists', 'societal', 'soviets', 'spec', 'sponge', 'steele', 'sucker', 'suns', 'superiority', 'supervised', 'surreal', 'tease', 'tendencies', 'tiffany', 'titanic', \"tomorrow's\", 'transitions', 'transmitter', 'transporting', 'typhoon', 'unreal', 'upheld', 'vaccination', 'valerie', 'valves', 'vampires', 'vibration', 'vitamins', 'wartime', 'weakest', 'wicket', 'winnipeg', 'worcester', 'zurich', 'abdominal', 'adolescent', 'advertisers', 'airing', 'announcer', 'awaited', 'baba', 'backdrop', 'bae', 'beau', 'begged', 'blackout', 'bluff', 'bollywood', 'brushes', 'bushes', 'cartel', 'casts', 'catastrophic', 'caucus', 'charcoal', 'cheesy', 'cheryl', 'choking', 'cindy', 'citrus', 'clad', 'clocks', 'coached', 'coded', 'columnist', 'competence', 'condolences', 'constituent', 'constituted', 'contacting', 'contagious', 'contexts', 'conveniently', 'courtroom', 'cushion', 'cyclist', 'darkest', 'diaz', 'dictate', 'directs', 'discounted', 'distributing', 'dnc', 'dominating', 'doris', 'dorm', 'drafts', 'drip', 'duct', 'eccentric', 'educating', 'electro', 'electromagnetic', 'emblem', 'endured', 'ew', 'expands', 'fabrics', 'facto', 'falcons', 'fascism', 'fats', 'fearful', 'festive', \"film's\", 'flyer', 'forecasts', 'foreman', 'framing', 'g00', 'gallagher', 'geared', 'geoff', \"george's\", 'giles', 'gina', 'glacier', 'gomez', 'gs', 'hindus', 'hu', 'hunted', 'hurricanes', 'implying', 'improper', 'influx', 'informing', 'installment', 'isles', 'jen', 'judaism', 'keller', 'kernel', 'kung', 'larvae', 'lexington', 'liaison', 'lima', \"mary's\", 'memoirs', 'miner', 'mk', 'mosaic', 'mustang', 'mw', \"n't\", 'needy', 'nichols', 'offenses', 'optics', 'orphan', 'passions', \"patient's\", 'patty', 'peyton', 'pies', 'pineapple', 'pissing', 'plaintiffs', 'plastics', 'poisoned', 'potassium', 'priceless', 'projecting', 'prostitute', 'reflective', 'rents', 'residing', 'resilience', 'resisting', 'romanian', 'roofs', 'rotate', 'royce', 'sans', 'saxon', 'scissors', 'seaside', 'semitic', 'shampoo', 'shaun', 'shri', 'silently', 'similarity', 'smelling', 'socio', 'stabbing', 'staircase', 'stamped', 'steroids', 'stitches', 'subsidiaries', 'swipe', 'tang', 'tango', 'telecom', 'tighter', 'tolerant', 'touchdowns', 'toxicity', 'trumpet', 'tuberculosis', 'ukip', 'undergone', 'willingly', 'woah', 'wrapping', 'youthful', '2a', 'accents', 'adhere', 'adidas', 'advising', 'affirmative', 'agnes', 'alarms', 'alliances', 'alma', 'ambiguous', 'archaeology', 'arse', 'attained', 'aus', 'autopsy', 'baltic', 'berries', 'blitz', 'blockade', 'bosnia', 'brightness', 'bruins', 'brushed', 'burma', 'calculating', 'campuses', 'cartridge', 'cashier', 'cigar', 'circa', 'citations', 'claudia', 'cloak', 'cologne', 'colombian', 'colt', 'combustion', 'comprehension', 'concession', 'condoms', 'crescent', 'crises', 'criticizing', 'defective', 'denise', 'deportation', 'deserving', 'discourage', 'disgusted', 'disposable', 'distressed', 'dover', 'dumbass', 'dungeon', 'dwell', 'e00', 'edison', 'edith', 'enforcing', 'entrepreneurship', 'eps', 'erie', 'essentials', 'fasting', 'fiery', 'finalists', 'flipping', 'flux', 'fueled', 'gc', 'georgetown', 'gimme', 'goofy', 'hai', 'hancock', 'handwriting', 'hassle', 'heartbreaking', 'hector', 'hicks', 'hobbies', 'hog', 'homeowners', 'ibrahim', 'immensely', 'inauguration', 'incorrectly', 'ind', 'indicative', 'inexpensive', 'instructors', 'intercept', 'intuitive', 'invent', 'irwin', 'isabel', 'jamaican', 'jockey', 'jolly', 'jorge', 'ju', 'kazakhstan', 'kenyan', 'landlords', 'latitude', 'lea', 'libertarian', 'luxembourg', 'majestic', 'mariners', 'mastered', 'mastery', 'mats', 'mccoy', 'metropolis', 'mohamed', 'mummy', 'neville', 'nominate', 'np', 'offend', 'oo', 'orchard', 'organizer', 'outraged', 'overdose', 'pamela', 'paragraphs', 'parallels', 'parameter', 'passwords', 'pathology', 'peggy', 'piercing', 'plotting', 'poisonous', 'pounding', 'pretended', 'procession', 'purge', 'reacts', 'relocation', 'rhino', 'riches', 'ripping', 'rosemary', 'rubbed', 'sandstone', 'sanitation', 'satisfactory', 'scooter', 'sculptures', \"season's\", 'secrecy', 'seeded', 'separates', 'sergio', 'shameful', 'shortest', 'sid', 'skipping', 'skirts', 'sliced', 'soils', 'springer', 'staples', 'stokes', 'storing', 'summed', 'supervisors', 'sweetie', 'swollen', 'tanzania', 'technicians', 'tor', 'transformers', 'traveler', 'tunisia', 'umm', 'unauthorized', 'undo', 'unnamed', 'upsetting', 'vans', 'venom', 'victorious', 'vines', 'visuals', 'wary', 'watering', 'wellness', 'whispers', 'windy', 'winger', 'wordpress', 'wraps', 'youngsters', '1m', 'abby', 'abdomen', 'abducted', 'abruptly', 'aha', 'aleppo', 'alerts', 'alps', 'amidst', 'antarctic', 'antibodies', 'aquarium', 'armenia', 'aspiring', 'asteroid', \"band's\", 'barbie', 'batter', 'baxter', 'bedtime', 'belongings', 'bloomberg', 'blush', 'booster', 'braves', 'bun', 'businessmen', 'calculator', 'calmly', 'captivity', 'catastrophe', 'chemotherapy', 'cinemas', 'circulating', 'claws', 'cleansing', 'clears', 'clicked', 'commute', 'complementary', 'concussion', 'connectivity', 'consulate', 'contend', 'convict', 'craving', 'culinary', 'demographics', 'departing', 'din', 'dir', 'discrete', 'disguised', 'dissent', 'disturb', 'docks', 'dt', 'earns', 'emergencies', 'eminent', 'encryption', 'endeavor', 'enthusiasts', 'erica', 'escapes', \"everything's\", 'exported', 'fencing', 'filtering', 'flashes', 'fleming', 'flop', 'follower', 'franchises', 'fraternity', 'freaks', 'frogs', 'fronts', 'furry', 'glitter', 'graveyard', 'hanged', 'hardship', 'harlem', 'hen', 'hoover', 'implication', 'induce', 'insecurity', 'interrogation', 'intimidating', 'inventions', 'irrational', 'jaws', 'josé', 'lamar', 'leafs', \"league's\", 'lennon', 'lettuce', 'liabilities', 'lithium', 'lowe', 'lucrative', 'macmillan', 'malone', 'managerial', 'mandated', 'mango', 'miley', 'militants', 'milo', 'mister', 'moderately', 'mri', 'multimedia', 'multinational', 'nationalists', 'nh', 'oasis', 'oddly', 'ons', 'oppressed', 'osaka', 'ouch', 'outsiders', 'outskirts', 'overlapping', 'overs', 'p.s', 'paced', 'pagan', 'painters', 'pals', 'planetary', 'playboy', 'porcelain', 'processors', 'programmer', 'promoter', 'psalm', 'psychiatry', 'psychologists', 'pubs', 'pursuant', 'recycled', 'renovated', 'repetitive', 'researched', 'revelations', 'reversal', 'rhyme', 'rue', 'safest', 'saturdays', 'savvy', 'scanner', 'schizophrenia', 'scratching', 'seriousness', 'sheila', 'shelby', 'sparkling', 'spree', 'stafford', 'stakeholders', 'stevenson', 'submitting', 'subsidy', 'sup', 'superficial', 'sweaty', 'tailored', 'tame', 'tanner', 'taps', 'tf', 'thinner', 'thugs', 'tipping', 'toni', 'topping', 'tracing', 'truman', 'upstream', 'vapor', 'veronica', 'vow', 'waitress', 'walnut', 'waterfront', 'wembley', 'whatsapp', 'winchester', 'witty', 'woven', 'wyatt', 'zack', '2k', '2x', 'acquaintance', 'aires', 'ambassadors', 'ambush', 'amelia', 'amend', 'arranging', 'arrogance', 'attendees', 'audrey', 'aussie', 'awaits', 'baptism', 'beirut', 'blames', 'blasting', 'bloke', 'blond', 'blur', 'blvd', 'boogie', 'booker', 'bothers', 'bowel', 'brightest', 'brow', 'budapest', 'bulbs', 'bureaucracy', 'cabbage', 'canton', 'cater', 'celtics', 'chimney', 'chrysler', 'circulated', 'cloudy', 'colourful', 'compassionate', 'comrade', 'concentrating', 'continents', 'convertible', 'cory', 'crater', 'creeping', 'cu', 'cumulative', 'curator', 'dat', 'deity', 'desperation', 'detrimental', 'diarrhea', 'disposed', 'distortion', 'doctoral', 'draining', 'drains', 'dramas', 'drifting', 'edged', 'educator', 'entitlement', 'esp', 'faux', 'favoured', 'fearless', 'finch', 'fragment', 'fulfil', 'galaxies', 'gangster', 'garner', 'gil', 'giveaway', 'graphs', 'gypsy', 'harassed', 'heater', 'hesitation', 'humiliation', 'ic', 'impairment', 'impatient', 'incorporates', 'indy', 'insisting', 'intricate', 'irvine', 'jensen', 'kang', 'kara', 'karate', 'kc', 'kingdoms', 'kite', 'labeling', 'leasing', 'lighthouse', 'longevity', 'lore', 'lush', 'luxurious', 'mal', 'mash', 'mba', 'meg', 'meltdown', 'messiah', 'meteor', 'ministerial', 'mmm', 'mocking', 'monty', 'motions', 'mystical', 'n.y', 'nu', 'obstruction', 'odyssey', 'om', 'onboard', 'oneself', 'org', 'outsider', 'overcoming', 'palms', 'penetrate', 'phelps', 'phi', 'philippe', 'pioneers', 'plaintiff', 'planners', 'plum', 'plural', 'poe', 'portrayal', 'prevail', 'prevailing', 'prostitutes', 'publishes', 'puff', 'pun', 'puzzles', 'r2', 'rag', 'raj', 'rampant', 'recommending', 'reggie', 'regulating', 'repairing', 'repeats', 'replicate', 'replying', 'retaliation', 'rf', 'risking', 'rooftop', 'rooting', 'routing', 'rv', 'safeguard', 'scaled', 'sedan', 'sentiments', 'sewage', 'sgt', \"ship's\", 'shoppers', 'simpsons', 'sitcom', 'slang', 'slid', 'sparked', 'spices', 'spirited', 'spirituality', 'spoiler', 'suitcase', 'summon', 'survives', 'sustaining', 'tavern', 'teasing', 'telegram', 'titanium', 'trailing', 'tuck', 'turbulence', 'ulster', 'unesco', 'uneven', 'urgency', 'vibes', \"victim's\", 'viktor', 'ware', 'waterproof', 'welcomes', 'whining', 'wonderfully', 'wording', 'zelda', '😍', 'abdullah', 'academia', 'accreditation', 'administer', 'admittedly', 'aforementioned', 'algae', 'alterations', 'angelo', 'apache', 'ariel', 'articulate', 'asbestos', 'atleast', 'avoidance', 'babylon', 'barney', 'bearings', 'bjp', 'boutique', 'bowie', 'brewer', 'brits', 'buffet', 'burner', 'cain', 'casa', 'catcher', 'cathy', 'charms', 'chassis', 'chores', 'clap', 'clarification', 'colder', 'concluding', 'consolation', 'consoles', 'corresponds', 'counters', 'covert', 'cringe', 'crosby', 'cunningham', 'cw', 'dagger', 'dealings', 'deferred', 'depicting', 'descriptive', 'dialect', 'dipped', 'dolly', 'downfall', 'downside', 'dryer', 'dunk', 'elijah', 'empowerment', 'endings', 'energies', 'ensuing', 'ensured', 'ethic', 'executing', 'expire', 'fireplace', 'flair', 'fossils', 'fugitive', 'gpa', 'greenwich', 'gujarat', 'hah', 'hanson', 'haunt', 'hayden', 'hazel', 'headset', 'hernandez', 'hk', 'homecoming', 'hurdles', 'hussein', 'hyped', 'icy', 'indulge', 'inmate', 'inscription', 'interpreter', 'intuition', 'invaluable', 'jaime', 'jenna', 'js', 'kaiser', 'kettle', 'kylie', 'laptops', 'lara', 'lasers', 'lax', 'lest', 'levi', 'lilly', 'malta', 'markings', 'mcconnell', 'mcgregor', 'menace', 'methane', 'mexicans', 'ming', 'misuse', 'mitigate', 'mona', \"month's\", 'nairobi', 'nana', 'nausea', 'neurological', 'nicola', 'optimum', 'ounces', 'overwhelmingly', 'oyster', 'pastoral', 'patented', 'pea', 'pearls', 'physiological', 'pioneering', 'pleasures', 'policemen', 'poo', 'poultry', 'prominence', 'prophets', 'prosecute', 'ptsd', 'quartet', 'radically', 'raping', 'reactive', 'reboot', 'renamed', 'resides', 'restrictive', 'robotic', 'runaway', 'saturn', 'sawyer', 'screenplay', 'scriptures', 'sect', 'seismic', 'seminary', 'sg', 'sheldon', 'shelley', 'shouts', 'sideways', 'sighted', 'skinned', 'skipper', 'slain', 'smuggling', 'softer', 'sonia', 'specs', 'squads', 'stash', 'stephens', 'stimulating', 'strawberries', 'striped', 'stroll', 'swiftly', 'texans', 'theatres', 'tolerated', 'transcription', 'tucson', 'tweeting', 'ul', 'unicorn', 'uniquely', 'unrealistic', 'v8', 'vase', 'vat', 'vineyard', 'viola', 'waterfall', 'waved', 'weaving', 'welding', 'whereabouts', 'yah', 'yummy', 'zeus', 'abortions', 'acknowledges', 'adobe', 'adolescents', 'ala', 'alarming', 'alexandra', 'almond', 'amenities', 'amounted', 'amused', 'antarctica', 'arabian', 'ari', 'asphalt', 'atrocities', 'aviv', 'bach', 'backbone', 'bahamas', 'beetle', 'blizzard', 'bolivia', 'booklet', 'bottoms', 'brawl', 'brittany', 'bryce', 'bu', 'burgess', 'butts', 'camden', 'cameroon', 'celestial', 'characterization', 'chevy', 'choked', 'ci', 'clashes', 'clint', 'comin', 'communicated', 'confessions', 'conform', 'conversely', 'countess', \"court's\", 'creations', 'cues', 'customary', 'dalton', 'debuted', 'declines', 'depicts', 'devote', 'dinners', 'diplomats', 'dispose', 'distinctly', 'evacuate', 'everett', 'exits', 'experimenting', 'exploding', 'exploits', 'favourable', 'ferdinand', 'flourish', 'flowering', 'fractures', 'fragrance', 'franz', 'fungus', \"germany's\", 'gloucester', 'griffith', 'guarding', 'gunfire', 'harvesting', 'havana', 'heroine', 'hilary', 'hoax', 'imf', 'impending', 'insignificant', 'insurer', 'intercepted', 'interfering', 'itv', 'jonah', 'kerala', 'knowledgeable', 'ku', 'liberated', 'lingerie', 'lite', 'localities', 'locke', 'logos', 'lurking', 'madden', 'magician', 'magistrates', 'mai', 'mali', 'maneuver', 'marrow', 'marvelous', 'mas', 'mattered', 'medicinal', 'melanie', 'mono', 'murderers', 'nas', 'numb', 'omitted', 'originals', 'overlook', 'partnered', 'pastry', 'pawn', 'pediatric', 'persist', 'personalized', 'planner', 'plaster', 'playful', 'pleading', 'professions', 'quirky', 'quota', 'quran', 'r00', 'randolph', 'rationale', 'reap', 'rebound', 'recess', 'redeem', 'reformation', 'regimes', 'replacements', 'residue', 'robotics', 'rocked', 'runoff', 'rwanda', 'salsa', 'scanned', 'screenshots', 'semiconductor', 'sentimental', 'serbian', 'severed', 'shocks', 'simultaneous', 'slaughtered', 'snatch', 'sneakers', 'somali', 'spikes', 'spooky', 'squeezed', 'staffing', 'stanton', 'stealth', 'strained', 'subscribed', 'subset', 'suspense', 'suzanne', 'swearing', 'swore', 'syntax', 'tad', 'tandem', 'tasked', 'tasmania', 'televised', 'tempered', 'tertiary', 'thyroid', 'tidy', 'timeless', 'tokens', 'uefa', 'unreliable', 'upbeat', 'usable', 'vanguard', 'vc', 'vomit', 'vulgar', 'waiver', 'walton', 'watershed', 'weave', 'wilkinson', 'wiring', 'yan', 'adrenaline', 'alexa', 'alleviate', 'amd', 'anarchy', 'ang', 'arent', \"artist's\", 'ashore', 'aura', \"bachelor's\", 'baden', 'ballroom', 'beginner', 'beginners', 'bermuda', 'bilingual', 'bombings', 'bonded', 'boosting', 'boyle', 'brenda', 'brewers', 'briggs', 'buchanan', 'buckingham', 'bundles', 'calcutta', 'caleb', 'canopy', 'chennai', 'cherish', 'chuckle', 'civilized', 'comb', 'completes', 'complexes', 'conceal', 'condemnation', 'contemplating', 'cores', 'cruiser', 'cruising', 'curl', 'dams', 'dared', 'dart', 'defends', 'demolished', 'denim', 'dependency', 'detecting', 'dew', 'dickens', 'disable', 'disconnected', 'dishonest', 'dosage', 'doubtful', 'dysfunction', 'ecosystems', 'encyclopedia', 'endowment', 'engraved', 'enrichment', 'erect', 'erection', 'eruption', 'examiner', 'exercised', 'exeter', 'expenditures', 'expires', 'fairfax', 'fam', 'fauna', 'feds', 'fidelity', 'finely', 'fischer', 'flirt', 'fluent', 'flute', 'footprint', 'fore', 'forefront', 'formulated', 'freaked', 'freshwater', 'fyi', 'gareth', 'gotham', 'gr', 'grouped', 'halted', 'harden', 'hardened', 'hateful', 'haunting', 'henri', 'hepatitis', 'honoring', 'horace', 'horrors', 'howe', 'huntington', 'ieee', 'inhabited', 'inherit', 'initiation', 'injections', 'insulted', 'integrating', 'intensely', 'ions', 'janeiro', 'jeopardy', 'joanna', 'kensington', 'ks', 'lafayette', 'lc', 'listener', 'lockdown', 'mandarin', 'mast', 'matte', 'mccartney', 'mediocre', 'middleton', 'mixes', 'morons', 'morse', 'mounts', 'nfc', 'niagara', 'nicest', 'nicotine', 'nl', 'nora', 'nordic', 'nos', 'notions', 'oranges', 'outward', 'overrated', 'packaged', 'packets', 'paige', 'passports', 'pb', 'pbs', 'peanuts', 'pep', 'piracy', 'platoon', 'practise', 'presses', 'rave', 'reactors', 'recreate', 'reeves', 'reigns', 'reno', 'resembling', 'residual', 'restricting', 'robe', 'rpg', 'rye', 'sails', 'sayin', 'sensational', 'sexism', 'smokers', 'sneaky', 'socket', 'spanning', 'specifics', 'spouses', 'starvation', 'starve', 'stool', 'stricken', 'stripping', 'subscriber', 'systematically', 'taxed', 'tc', 'tex', 'thanking', 'tibet', 'toledo', 'tread', 'tripping', 'truce', 'tsunami', 'turbines', 'turmoil', 'typed', 'tyranny', 'tyres', 'u00', 'unfit', 'uphold', 'vita', 'volunteering', 'wal', 'warwick', 'waterloo', 'weeds', 'weir', 'wellbeing', 'wikileaks', 'wonderland', 'wrestler', 'yrs', 'zimmerman', 'zoning', '░', '🤔', '4g', '5pm', '5s', 'abandoning', 'abolition', 'accessibility', 'acquainted', 'airplanes', 'airs', 'aloud', 'angular', 'anterior', 'appendix', 'approx', 'atp', 'attackers', 'auditorium', 'augustine', 'barking', 'bauer', 'beckham', 'behaving', 'benign', 'berkshire', 'bleach', 'boast', 'bowen', 'brandy', 'brethren', 'brink', \"brown's\", 'bruh', 'carving', 'cas', 'cass', 'cctv', 'cecil', 'cheeky', 'chemist', 'choi', 'coastline', 'cobra', 'collaborate', 'comparatively', 'compensated', 'competed', 'conor', 'cosmos', 'councillors', 'crafting', 'cuff', 'curling', 'cyclone', 'dedicate', 'deleting', 'delusional', 'deposition', 'derive', 'descend', 'descending', 'diligence', 'disciplined', 'discriminate', 'distributions', 'diversion', 'doorway', 'dp', 'drilled', 'dumpster', 'emailed', 'empower', 'ernst', 'ethiopian', \"europe's\", 'excerpt', 'existent', 'ezra', 'fabricated', 'fandom', 'filmmakers', 'filtered', 'foe', 'gatherings', 'georgian', 'getaway', 'glamour', \"governor's\", 'heirs', 'humphrey', 'inbox', 'incidentally', 'infinitely', 'inflated', 'influenza', 'informs', 'inspected', 'instructional', 'interviewer', 'introductory', 'iot', 'jaguar', 'jamal', 'judgments', 'laurent', 'licking', 'ling', 'loft', 'lois', 'm2', 'massively', 'mediated', 'mediation', 'merrill', 'metrics', 'millennials', 'modular', 'n00', 'nico', 'nutrient', 'occupies', 'oslo', 'outlaw', 'oversee', 'pageant', 'parachute', 'parasite', 'parenthood', 'perennial', 'persistence', 'piers', 'pleas', 'porto', 'postage', 'praises', 'preschool', 'procedural', 'profoundly', 'prohibit', 'pronunciation', 'provoked', 'quotation', 'rappers', 'registers', 'relentless', 'remnants', 'repression', 'reprinted', 'resolving', 'ridiculously', 'roaring', 'salisbury', 'scandals', 'scrapped', 'seasoned', 'shootout', 'sigma', 'simulations', 'sk', 'somethin', 'sourced', 'specializing', 'spectator', 'speculative', 'spins', 'stadiums', 'stalls', 'stripe', 'submerged', 'surgeries', 'symmetry', 'syndicate', 'tae', 'thornton', 'tibetan', 'tighten', 'townsend', 'trenches', 'trustworthy', 'tvs', 'twelfth', 'tyre', 'ultrasound', 'usher', 'vacations', 'vascular', 'vets', 'watkins', 'weiss', 'wholesome', 'wiley', 'witnessing', 'workouts', 'yielded', \"york's\", 'absorbing', 'adapting', 'addicts', 'adjoining', 'albuquerque', 'allegation', 'alternating', 'ancestry', 'ankles', 'annex', 'annexed', 'antibiotic', 'arresting', 'augmented', 'avenues', 'avid', 'avoids', 'badges', 'barbados', 'barge', 'bartender', 'bert', 'birch', 'bland', 'blended', 'bohemian', 'bong', 'bounded', 'bows', 'breastfeeding', 'bribe', 'bridal', 'broadcasts', 'broccoli', 'brushing', 'buckets', 'buckle', 'burlington', 'bursts', 'cannes', 'canoe', 'centred', 'chilly', 'chords', 'chu', 'cider', 'clowns', 'clueless', 'cobb', 'consciously', 'corpses', 'correlated', 'correspond', 'cradle', 'crappy', 'crippled', 'damien', 'dayton', 'decency', 'deficits', 'despise', 'destroyer', 'diocese', 'dispersed', 'docs', 'doorstep', 'eliot', 'embarked', 'enriched', 'equip', 'faa', 'fellas', 'foley', 'footing', 'fulton', 'garments', 'glamorous', 'goldberg', 'growers', 'handler', 'hangover', 'haters', 'havent', 'havoc', 'hee', 'hind', 'hitter', 'hive', 'homophobic', 'honolulu', 'humid', 'hyderabad', 'illuminated', 'imam', 'implants', 'indicted', 'inexperienced', 'influencing', 'invading', 'irritated', 'jackpot', 'javascript', 'jurassic', 'kangaroo', 'ke', 'klaus', 'knowingly', 'kuala', 'legged', 'lex', 'liberalism', 'liberia', 'lithuania', 'litre', 'locomotive', 'longing', 'lsu', 'mailed', 'manny', 'mantra', 'mapped', 'marcel', 'mating', 'mckay', 'mesa', 'microscope', 'milky', 'mixer', 'modeled', 'moe', 'monumental', 'moth', 'multiply', 'mv', 'narcotics', 'nicky', 'nuggets', 'nuisance', 'obedience', 'objected', 'obligated', 'organise', 'outing', 'overdue', 'overload', 'parasites', 'payable', 'paycheck', 'peaches', 'peaked', 'picturesque', 'pilgrimage', 'pillows', 'pivot', 'pivotal', 'por', 'pressured', 'preventive', 'primer', 'profitability', 'progressing', 'provoke', 'ps3', 'pulmonary', 'punishing', 'rad', 'radicals', 'raspberry', 'reconcile', 'regression', 'resilient', 'roaming', 'router', 'routines', 'ru', 'ryder', 'sabbath', 'schneider', 'schwartz', 'scouting', 'secretaries', 'selfies', 'seminars', 'shortages', 'shortened', 'shovel', 'skinner', 'smelled', 'smh', \"society's\", 'specializes', 'splits', 'staggering', 'statutes', 'striving', 'suing', 'surname', 'synonymous', 'tackling', 'tai', 'tallest', 'taped', 'tedious', 'toxins', 'troubling', 'tug', 'twists', 'utilization', 'v00', 'volkswagen', 'walkers', 'wink', 'woodward', 'yugoslavia', '★', '👌', \"a's\", 'a2', 'actresses', 'adhd', 'ae', 'alonso', 'ancestor', 'arbor', 'astronomical', 'attends', 'attire', 'authored', 'autograph', 'automobiles', 'ava', 'axle', 'barley', 'bd', 'beyonce', 'bitten', 'blasted', 'blasts', 'botanical', 'bottled', 'braces', 'brag', 'breakout', 'bumped', 'bursting', \"car's\", 'catchy', 'cbc', 'ceremonial', 'chanel', 'cheque', 'chilled', 'cho', 'choreography', 'cisco', 'clarified', 'cling', 'coco', 'coincide', 'comedians', 'commemorate', 'commits', 'concurrent', 'corrupted', 'coventry', 'crocodile', 'cub', 'derrick', 'diaper', 'differentiation', 'dine', 'disadvantaged', 'disadvantages', 'disagreed', 'dissolve', 'diverted', 'dubious', 'dudley', 'durant', 'eagerly', 'ecclesiastical', 'edt', 'egyptians', 'elk', \"england's\", 'enlightened', 'erased', 'escorted', 'eur', 'exhaustion', 'expectancy', 'famously', 'fella', 'fielding', 'fingerprint', 'fisherman', 'flap', 'folklore', 'forgiving', 'fractured', 'galactic', 'gardener', 'getty', 'glee', 'grassroots', 'gravitational', 'grazing', 'guinness', 'gunshot', 'habitats', 'hailed', 'hereditary', 'hiatus', 'homestead', 'horribly', 'horsepower', 'hue', 'icing', 'idols', 'ikea', 'insurers', 'intellect', 'intellectuals', 'intending', 'interchange', 'isabella', 'jihad', 'juventus', 'kidneys', 'knob', 'kristen', 'lahore', 'lapse', 'laundering', 'ledger', 'liga', 'loaf', 'lodged', 'login', 'loot', 'lorenzo', 'magnesium', 'malware', 'mclaren', 'mimic', 'mindful', 'motorcycles', 'mural', 'murdoch', 'musk', \"must've\", 'myriad', 'nan', 'nasal', 'nautical', 'neatly', 'negativity', 'northampton', 'noteworthy', 'nuns', 'odor', 'oprah', 'organising', 'overturned', 'overwatch', 'paddle', 'parrot', 'partying', 'patel', 'peg', 'pesticides', 'pixels', 'plunge', 'powerless', 'pragmatic', 'primaries', 'quasi', 'quentin', 'radiant', 'ramsay', 'reese', 'refinery', 'regained', 'reich', 'remorse', 'reopened', 'revoked', 'rhymes', 'rpm', 'sanity', 'scandinavian', 'scotia', 'scratched', 'sears', 'ser', 'sergei', 'sharia', 'showdown', 'shuffle', 'shuts', 'siding', 'simulated', 'skyline', 'slab', 'sprayed', 'stacks', 'startups', 'stocking', 'suarez', 'subscriptions', 'suites', 'supplemental', 'suspicions', 'swimmer', 't.co', 'tao', 'tariff', 'techno', 'teller', 'textiles', 'therapies', 'theyre', 'trance', 'translating', 'traveller', 'u.n', 'unconditional', 'unforgettable', 'vacancies', 'violates', 'volatility', 'weaken', 'webcam', 'wen', 'weston', 'wouldnt', 'xavier', 'yorker', '3m', '6pm', 'abel', 'abolish', 'aca', 'accessing', 'accommodations', 'accumulate', 'admirable', 'adventurous', \"africa's\", 'ajax', 'alarmed', 'ama', 'ammo', 'amos', 'analysed', 'andreas', 'angelina', 'anthology', 'antiques', 'anyhow', 'ape', 'arrivals', 'assaults', 'assemblies', 'auditor', 'avalanche', 'azerbaijan', 'b.a', 'badger', 'ballistic', 'banter', 'becker', 'bidder', 'birthdays', 'blackburn', 'blazing', 'blockbuster', 'blueprint', 'bodied', 'boosted', 'bowler', 'broadcasters', 'byrne', 'cadillac', 'cameo', 'canals', 'caramel', 'cassidy', 'charismatic', 'chromosome', 'chunks', \"church's\", 'clarkson', 'claus', 'comcast', 'commencement', 'concede', 'conducts', 'confiscated', 'contestant', 'contradictory', 'convent', 'converse', 'correcting', 'corrosion', 'crib', 'crossroads', 'dearly', 'defiance', 'deter', 'diner', 'dipping', 'disneyland', 'disposition', 'djs', 'documentaries', 'dripping', 'ecstasy', 'eighteenth', 'eleventh', 'eliza', 'emphasizes', 'empowering', 'engagements', 'enrique', 'envoy', 'estonia', 'expiration', 'exploiting', 'expressly', 'fabrication', 'facilitated', 'faggot', 'fascination', 'fir', 'foreigner', 'formulation', 'francs', 'frontal', 'fullest', 'fungi', 'goalie', 'gonzalez', 'gradient', 'gravy', 'grenades', 'gwen', 'haley', 'harmed', 'herring', 'hires', 'hopper', 'hugging', 'hysterical', 'implant', 'incompatible', 'inducing', 'injunction', 'innate', 'instituted', 'iphones', 'jays', 'jeremiah', 'jude', 'kathryn', 'kd', 'keynote', 'kidnap', 'kiev', 'koreans', 'krishna', 'lama', 'learners', 'liquids', 'mclean', 'meats', 'michele', 'motivational', 'naruto', 'natasha', 'nightly', 'noir', 'normandy', 'notwithstanding', 'ns', 'o2', 'ordained', 'originating', 'orphans', 'p000', 'pans', 'paralysis', 'patiently', 'patrols', 'pauline', 'paw', \"peter's\", 'pharmaceuticals', 'pianist', 'pickles', 'pilgrims', 'pinterest', 'pisses', 'placebo', 'podcasts', 'pointers', 'postpone', 'progressively', 'propelled', 'psa', 'psych', 'punt', 'rae', 'raptors', 'reinforcements', 'repetition', 'restraining', 'retrospective', 'revise', 'righteousness', 'rinse', 'robbins', 'rss', 's2', 'sal', 'scalp', 'schultz', 'scrolling', 'sealing', 'sharma', 'sheds', 'sheltered', 'shia', 'shutter', 'smartest', 'snatched', 'sooo', 'spans', 'sparrow', 'speculate', 'spinach', 'squat', 'stew', 'stirling', 'stoned', 'strauss', 'stressing', 'styling', 'sublime', 'subtitles', 'sunni', 'sweetness', 'teamwork', 'tequila', 'terrestrial', 'textures', 'thinkers', 'thorn', 'thug', 'tit', 'toned', 'totals', 'triggering', 'tulsa', 'twenties', 'ufo', 'uncover', 'unnatural', 'unstoppable', 'upfront', 'urgently', 'virginity', 'virtues', 'volvo', 'vouchers', 'waived', 'wharf', 'wiser', 'wrestle', 'xv', 'yates', 'yoo', '1a', 'aap', 'accountants', 'achilles', 'addison', 'aggravated', 'ahhh', 'alberto', 'alleging', 'alto', 'ambrose', 'analyse', 'anomaly', 'aperture', 'apostles', 'apprenticeship', 'aspire', 'benches', 'biodiversity', 'biomedical', 'blinded', 'blurred', 'boarded', 'breadth', 'bullies', 'buster', 'cascade', 'casinos', 'centralized', 'char', 'cleanse', 'complains', 'concord', 'connector', 'connie', 'consolidate', 'containment', 'coupling', 'crate', 'crave', 'crows', 'dane', 'dangerously', 'denounced', 'dillon', 'diluted', 'doping', 'eddy', 'elusive', 'espionage', 'establishes', 'existential', 'experimentation', 'extremes', 'extremists', 'fanny', 'fiancé', 'flashback', 'fluctuations', 'forecasting', 'freud', 'friedman', 'funnel', 'gail', 'gloss', 'grading', 'graft', 'grips', 'grumpy', 'guise', 'halves', 'heightened', 'horizons', 'hush', 'ibn', 'imitation', 'immersion', 'inconvenient', 'inspires', 'interfaces', 'intrigued', 'intrinsic', \"iran's\", 'irresistible', 'javier', 'jd', 'jk', 'joanne', 'kb', 'kittens', 'landmarks', 'landslide', 'lcd', 'leah', 'leash', 'makeover', 'manned', 'marcos', 'mata', 'mater', 'maureen', 'melodies', 'memorandum', 'mercer', 'mermaid', \"michael's\", 'miriam', 'moderation', 'moroccan', 'nano', 'neymar', 'ngos', 'nobility', 'notation', 'onstage', 'ordeal', 'ox', 'painfully', 'paranormal', 'paso', 'pear', 'piston', 'plugs', 'politely', 'pollen', 'principals', 'provoking', 'pts', 'puberty', 'raided', 'railroads', 'ramos', 'rbi', 'reggae', 'relegated', 'respectfully', 'rethink', 'reviewer', 'reviewers', 'rewrite', 'rodeo', 'sas', 'sheridan', 'sherwood', 'shire', 'sinks', 'slit', 'snapping', 'sobbing', 'spitting', 'starved', 'stirred', 'stockings', 'stuffing', 'substituted', 'succeeds', 'summons', 'sutherland', 'swung', 'taboo', 'teaser', 'thatcher', 'throttle', 'tides', 'trendy', 'trimmed', 'trivia', 'trumps', 'turbulent', 'twisting', 'unbearable', 'underage', 'unleashed', 'unmarried', 'vaguely', 'veggies', 'visas', 'vortex', 'voucher', 'wand', 'wanderers', 'warmed', '❤️', '😭', 'accelerating', 'advert', 'afforded', 'ain', 'alias', 'anaheim', 'anchored', 'annoy', 'antibody', 'apostle', 'appalling', 'applaud', 'arteries', 'asians', 'astronauts', 'baptized', 'barr', 'belarus', 'billie', 'bondage', 'boredom', 'bounced', 'bowman', 'breeders', 'brilliantly', 'brunch', 'buckley', 'burgundy', 'cabinets', 'carlisle', 'carolyn', 'castles', 'changer', 'che', 'chem', 'chestnut', 'cj', 'cleaners', 'cleanup', 'clemson', 'cocks', 'compose', 'concise', 'confinement', 'confronting', 'consultancy', 'contraction', 'contrasting', 'convergence', 'coughing', 'criterion', 'crossings', 'crowns', 'cummings', 'cylinders', 'deduction', 'despicable', 'detachment', 'detectors', 'dialog', 'digestive', 'diminish', 'disclaimer', 'disconnect', 'discriminatory', 'disruptive', 'dorset', 'dvds', 'endlessly', 'enthusiast', 'epilepsy', 'estimation', 'ethanol', 'excavation', 'extremist', 'feeder', 'flashlight', 'flattering', 'floats', 'forcibly', 'gao', 'garland', 'globalization', 'grail', 'graphical', 'grayson', 'groundbreaking', 'grouping', 'harding', 'holiness', 'horrifying', 'humiliating', 'iced', 'ida', 'illustrator', 'imbalance', 'immoral', 'implicated', 'inefficient', 'initials', 'instrumentation', 'intensified', 'intolerance', \"jackson's\", 'jeez', \"johnson's\", 'jurors', 'kappa', 'keepers', 'kendrick', 'ketchup', 'leukemia', 'levine', 'liars', 'lineage', 'liter', 'looting', 'lorraine', 'lyons', 'magnus', 'manpower', 'marley', 'martyr', 'masturbation', 'mitigation', 'mont', 'motorway', 'nk', 'npr', 'nypd', 'obscene', 'occupants', 'octopus', 'onward', 'operatives', 'opium', 'ovarian', 'peck', 'penal', 'permitting', 'petals', 'picasso', 'pierced', 'pistols', 'plank', 'plantations', 'plight', 'ponds', 'postseason', 'presiding', 'privy', 'propulsion', 'raft', 'registering', 'rejoice', 'relics', 'ren', 'reproduced', 'rihanna', 'roam', 'rubio', 'sandals', 'serpent', 'sesame', 'shepard', 'shi', 'shoved', 'sicily', 'simplify', 'siren', 'slater', 'sleeper', 'smear', 'snowy', 'soooo', 'spectral', 'spoilers', 'stabilize', 'stains', 'stalk', 'standings', 'statesman', 'stink', 'stormy', 'subcommittee', 'suffice', 'surrounds', 'swat', 'swine', 'symbolism', 'tangled', 'ticking', 'tram', 'tryin', 'tutorials', 'underwood', 'underworld', 'vectors', 'vertically', 'vigorous', 'vt', 'wandered', 'wei', 'wrongly', 'yum', 'zion', 'abiding', 'adele', 'alcoholism', 'amplifier', 'anc', 'apes', 'arches', \"army's\", 'astounding', 'atheism', 'auctions', 'audible', 'avocado', 'avon', 'bangs', 'bashing', 'baskets', 'bathtub', 'beep', 'beneficiaries', 'biscuit', 'bitterness', 'blatant', 'boon', 'boyfriends', 'brat', 'bunk', \"california's\", 'candid', 'caretaker', 'carts', 'ceilings', 'cervical', \"character's\", 'checklist', 'cherokee', 'cheshire', \"christ's\", 'cinderella', 'clamp', 'clans', 'competitiveness', 'composers', 'confederation', 'confidentiality', 'configurations', 'contradiction', 'coronation', 'counselling', 'cracker', 'crackers', 'crimea', 'cumberland', 'cunning', 'daly', 'depiction', 'depleted', 'diabetic', 'diaspora', 'digitally', 'discord', 'distractions', 'divides', 'divinity', 'donuts', 'dorsal', 'durability', 'empress', 'endeavour', 'enroll', 'entertainer', 'entrusted', 'ernie', 'evidenced', 'extracts', 'fallon', 'farrell', 'fatalities', 'festivities', 'ffs', 'finalist', 'footballers', 'forks', 'gadget', 'gasp', 'genital', 'glitch', 'gong', 'graded', 'graders', 'greasy', 'grieving', 'grooming', 'hacks', 'hamburger', 'heed', 'hideous', 'homepage', 'hoops', 'howell', 'ib', 'imaginative', 'imperfect', 'implicit', 'indo', 'inlet', 'insensitive', 'interpreting', 'islanders', 'iss', 'jars', 'keystone', 'knitting', 'kramer', 'kudos', 'layered', 'lieu', 'liquidity', 'loch', 'lola', 'lotion', 'lows', 'lucia', 'lutheran', 'mains', 'manipulating', 'mara', 'marquis', 'mayhem', 'mens', 'merging', 'mistakenly', 'mould', 'neuroscience', 'niger', 'nipple', 'noses', 'nostalgic', 'nra', 'nv', 'oppressive', 'pasadena', 'patronage', 'pearce', 'pinnacle', 'plagued', 'plated', 'pods', 'pong', 'poorest', 'programmers', 'prompting', 'prosper', 'psi', 'quake', 'qualitative', 'queries', 'racer', 'radial', 'realms', 'recap', 'recognizable', 'reconnaissance', 'regent', 'reigning', 'reluctantly', 'rendition', 'resumes', 'revisions', 'roadside', 'rovers', 'saskatchewan', 'scarlett', 'scientifically', 'scrambled', 'scratches', 'secretariat', 'semitism', 'sew', 'shaky', 'sham', 'shortcomings', 'shredded', 'siberia', 'sinai', 'slayer', 'smokes', 'soothing', 'spawned', 'specialised', 'stalker', 'statistic', 'stature', 'steward', 'stout', 'strategically', 'stripper', 'stump', 'submarines', 'subordinate', 'swimmers', 'synagogue', 'tentative', 'texted', 'tongues', 'topical', 'transforms', 'uhh', 'uneasy', 'unfold', 'usda', 'uss', 'variance', 'vested', 'vols', 'wagons', 'wah', 'wally', 'walters', 'wavelength', 'workload', 'xii', 'yells', '1b', 'acquitted', 'admiralty', 'ageing', 'aiding', 'artificially', 'asa', 'aux', 'barring', 'bead', 'berth', 'billionaires', 'blackmail', 'blending', 'blindness', 'bragging', 'brightly', 'burglary', 'busting', 'cafeteria', 'canary', 'cannons', 'capacities', 'cardio', 'carla', 'caucasian', 'ceramics', 'cheats', 'chilean', 'clauses', 'clumsy', 'commuter', 'composing', 'contingency', 'coworkers', 'cupboard', 'curated', 'customized', 'daft', 'dani', 'defences', 'depended', 'deprivation', 'dewey', \"disney's\", 'disqualified', 'disrupted', 'diversified', 'documenting', 'doubted', 'downing', 'duly', 'dusk', 'edits', 'enchanted', 'environmentally', 'episcopal', 'escalated', 'everlasting', 'excellency', 'executions', 'f00', 'faking', 'feasibility', 'federally', 'flavored', 'formulas', 'freddy', 'frenzy', 'fridays', 'fuckers', 'fulfillment', \"general's\", 'gg', 'godfather', 'gould', 'gran', 'groundwater', 'heidi', 'hospitalized', 'hostilities', 'hyundai', 'illusions', 'inadvertently', 'indifferent', 'inject', 'insistence', 'interiors', 'intimidated', 'invariably', 'invincible', 'jams', 'jfk', \"joe's\", 'jubilee', 'kia', 'kinetic', 'lam', 'lashes', 'latvia', 'laurence', 'lavender', 'lemonade', 'lenin', 'lodging', 'lowell', 'malls', 'mania', 'medically', 'menus', 'mule', 'mythical', 'nathaniel', 'neutron', 'newcomers', 'nicaragua', 'nicholson', 'nicknamed', 'occupations', 'oecd', 'ooo', 'orderly', 'orient', 'orion', 'outset', 'paralyzed', 'parry', 'parted', 'patio', 'peacock', 'pedestrians', 'pepsi', 'pf', 'pines', 'pitchers', 'plugged', 'postcard', 'pow', 'powerhouse', 'precursor', 'preferable', 'preparatory', 'prism', 'proclamation', 'proponents', 'provocative', 'pu', 'purposely', 'qc', 'questionnaire', 'reclaim', 'redevelopment', 'reflex', 'relocate', 'rematch', 'renal', 'repayment', 'residences', 'restrained', 'rhythms', 'riddle', 'rites', 'rivera', 'roach', 'rockefeller', 'roe', 'royalties', 'rubble', 's3', 'sacrificing', 'saddam', 'sapphire', 'screwing', 'seam', 'sectional', 'servicing', 'shrinking', 'simulate', 'sioux', 'sloan', 'sniff', 'snowden', 'soaring', 'soluble', 'solvent', \"somebody's\", 'spaced', 'squid', 'stamford', 'steph', 'stocked', 'stoked', 'strapped', 'streamed', 'sturdy', 'swarm', 'tanker', 'taxis', 'terra', 'timetable', 'tj', 'torpedo', 'traitors', 'trolley', 'trolling', 'trudeau', 'una', 'undertook', 'undocumented', 'vaginal', 'vance', 'verbs', 'viability', \"victoria's\", 'villas', 'wat', 'whispered', 'widening', 'winged', 'wiping', 'wolverine', 'wrought', 'xiii', 'yearbook', 'yikes', '😉', 'abbot', 'abduction', 'ache', 'advises', 'afro', 'ancestral', 'anchors', 'antiquity', 'apocalyptic', 'appraisal', 'aqua', 'aspen', 'atlantis', 'augustus', \"author's\", 'autistic', 'barnett', 'baylor', 'bearer', 'bernstein', 'bins', 'bk', 'bleak', 'blender', 'bmi', 'bogus', 'booming', 'bridget', 'bruises', 'btc', 'burt', 'cages', 'caldwell', 'cara', 'cavs', 'centric', 'chaired', 'chaplain', 'chlorine', 'chow', 'chubby', 'clement', 'collusion', 'contenders', 'contractual', 'coroner', 'correctional', 'correspondents', 'corridors', 'couldnt', 'creamy', 'cubes', 'd00', 'daryl', 'deterioration', 'diapers', 'dirk', 'disbelief', 'discreet', 'distracting', 'dizzy', 'dre', 'duet', 'dustin', 'dyed', 'eisenhower', 'elle', 'elsa', 'enact', 'evaluations', 'everest', 'exporting', 'expressive', 'facilitating', 'fiddle', 'fists', 'flaming', 'foes', 'folds', 'fortified', 'fran', 'françois', 'garfield', 'generalized', 'gl', 'glossy', 'gregg', 'grit', 'hammered', 'haram', 'harassing', 'hauled', 'hectares', 'hobart', 'homelessness', 'hopping', 'horrendous', 'horrified', 'hostel', 'hound', 'htc', 'hugged', 'illegitimate', 'illicit', 'importing', 'incompetence', 'insomnia', 'interception', 'invaders', 'irl', 'israelis', 'juniors', 'karaoke', 'kemp', 'kosovo', 'kw', 'lagoon', 'len', 'lesions', 'limp', 'lingering', 'linguistics', 'locating', 'logically', 'lucifer', 'lumpur', 'lunatic', 'lyrical', 'm.d', 'manifestation', 'manitoba', 'manufactures', 'mastering', 'mead', 'mergers', 'mhz', 'migrate', 'mildly', 'miraculous', 'moaning', 'mocked', 'mos', 'mosquitoes', 'mourn', 'mundane', 'narrowed', 'nay', 'nests', 'ngo', 'nielsen', 'nr', 'nutshell', 'ob', 'obsessive', 'offending', 'offseason', 'oswald', 'overboard', 'paws', 'pendant', 'petite', 'petitions', 'pharma', 'pimp', 'pipelines', 'poised', 'pol', 'posterior', 'pouch', 'predicts', 'prescriptions', 'probes', 'proficiency', 'progresses', 'protestors', 'psychotic', 'racists', 'referees', 'reinforcement', 'relegation', 'repertoire', 'repository', 'reversing', 'rican', 'rumble', 'sachs', 'saloon', 'sanction', 'sexes', 'shack', 'sinners', 'sire', 'slated', 'soaking', 'stale', 'stereotype', 'sterile', 'stride', 'stringent', 'sulfur', \"sun's\", 'surfaced', 'suzuki', 'tacos', 'therapists', 'torrent', 'tp', 'trainee', 'transmitting', 'trey', 'tripped', 'trough', 'trunks', 'tummy', 'unjust', 'upbringing', 'uploading', 'vaughan', 'venezuelan', 'vis', 'vivian', 'vivo', 'wager', 'walled', 'warehouses', 'whack', 'whoops', 'wichita', 'wilde', 'wilmington', 'zambia', '🤣', '2b', '7pm', '9am', 'accelerator', 'accuses', 'acrylic', 'ames', 'anchorage', 'annexation', 'approves', 'ascent', 'assassins', 'atkinson', 'ballad', 'banged', 'basel', 'beckett', 'bel', 'betray', 'betsy', 'bigotry', 'biotechnology', 'blanc', 'bookstore', 'boomers', 'boone', 'bots', 'breakers', 'broom', 'browne', 'brute', 'buffy', 'busiest', 'camouflage', 'cary', 'catalan', 'chiefly', 'childbirth', 'chills', 'chung', 'collaborating', 'compliant', 'conservatism', 'continuum', 'corona', 'cosplay', 'cowardly', 'cpr', 'cruises', 'css', 'cultivate', 'curls', 'cyril', 'dealership', 'dearest', 'decker', 'defy', 'della', 'denotes', 'densely', 'derives', 'devoid', 'dhabi', 'diagrams', 'dickinson', 'disparity', 'diva', 'divert', 'dlc', 'drawers', 'eater', 'eaton', 'elegance', 'elias', 'encrypted', 'englishman', 'escorts', 'exposes', 'extraordinarily', 'facade', 'farmhouse', 'fertilizer', 'filler', 'fishes', 'flea', 'footwear', 'foxes', 'fri', 'fritz', 'froze', 'frying', 'giovanni', 'goodies', 'greenland', 'handbag', 'handicapped', 'haze', 'headquartered', 'helium', 'hemp', 'hitch', 'hoc', 'hutchinson', 'ike', 'incarnation', 'inhibitors', 'intrusion', 'inverse', 'inverted', 'irritation', 'jae', 'juices', 'julio', 'keywords', 'lavish', 'libyan', 'livelihood', 'livingston', 'mansfield', 'marches', 'mckenzie', 'medic', 'merlin', 'midland', 'miscellaneous', 'misguided', 'morrow', 'motivations', 'moto', 'mozart', 'muster', 'mutants', 'muted', 'n.j', 'noodle', 'nylon', 'override', 'ozone', 'papua', 'paranoia', 'paving', 'persecuted', 'peruvian', 'phosphate', 'php', 'physicist', 'piping', 'plurality', 'prehistoric', 'prescott', 'prohibits', 'pronouns', 'proton', 'psyche', 'quickest', 'redesign', 'relocated', 'reluctance', 'rentals', 'reopen', 'replication', 'rigging', 'rotor', 'sediment', 'seeming', 'selves', 'sneaking', 'solitude', 'spacing', 'standby', 'std', 'straps', 'strikers', 'stronghold', 'stumble', 'suicides', 'supermarkets', 'talbot', \"teacher's\", 'theorists', \"there'll\", 'therein', 'triangular', 'tricked', 'trooper', 'truthful', 'turret', 'ubiquitous', 'unbelievably', 'unconventional', 'unnecessarily', 'unnoticed', 'untouched', 'v2', 'vega', 'ver', 'vibrations', 'vin', 'virgil', 'visionary', 'vitro', 'voodoo', 'wigan', 'wilder', 'witchcraft', 'withdrawals', 'withdrawing', 'wrestlers', 'yong', '8pm', 'abbas', 'adultery', 'agile', 'aides', 'anonymously', 'aristotle', 'artifact', 'austerity', 'awfully', 'axes', 'barca', 'battered', 'beatrice', 'beethoven', 'biking', 'boob', 'boosts', 'bouquet', 'boxers', 'browning', 'bullock', 'cad', 'candidacy', 'cartridges', 'carve', 'cherished', 'climbs', 'clubhouse', 'coarse', 'collegiate', 'commonplace', 'compute', 'conan', 'confidently', 'constrained', 'contemplate', 'converter', 'coop', 'cooperating', 'coronary', 'cottages', \"council's\", \"county's\", 'cps', 'crook', 'cucumber', 'cupcakes', 'darts', \"david's\", 'deco', 'depict', 'desmond', 'diagnose', 'directorate', 'disliked', 'diver', 'dora', 'dormant', 'dotted', 'drifted', 'duffy', 'embarrass', 'emmanuel', 'emulate', 'encompasses', 'endowed', 'enquiry', 'evasion', 'evergreen', 'eviction', 'excerpts', 'explodes', 'explorers', 'expulsion', 'fades', 'fedex', 'figs', 'filth', 'firefox', 'floated', 'foliage', 'foreclosure', 'forgets', 'fortnight', 'fresno', 'fs', 'funnier', 'genie', 'georges', 'glued', 'goo', 'goodwin', 'hannibal', 'heartbroken', 'heats', 'helper', 'hesitant', 'hoop', \"how'd\", 'hubby', 'humiliated', 'hurdle', 'hypertension', 'immersed', 'immortality', 'indefinite', 'indices', 'insightful', 'invitations', 'io', 'ipswich', 'irrespective', \"island's\", 'jacks', 'jeanne', 'kicker', 'kyoto', 'leaned', 'leases', 'ledge', 'levin', 'lgbtq', 'lunches', 'macbook', 'mackay', 'madeleine', 'maj', 'malt', 'mandela', 'marian', 'mayors', 'melts', 'michaels', 'mindfulness', 'mined', 'mj', 'moderator', 'momma', 'monstrous', 'moran', 'morphology', 'mustache', 'nasdaq', 'natal', 'nodded', 'novice', 'obituary', 'olivier', 'ordination', \"organization's\", 'otis', 'owls', 'parity', 'paterson', 'percentages', 'persuasive', 'pests', 'pew', 'philips', 'piled', 'poking', 'populous', 'postwar', 'presided', 'prevailed', 'proactive', 'prob', 'projector', 'prominently', 'prudent', 'qualifier', 'quincy', 'radios', 'ratified', 'realising', 'refining', 'regretted', 'reliant', 'reputable', 'revolver', 'revolving', 'ricardo', 'rink', 'ripple', 'robbers', 'routledge', 'salts', 'sampled', 'scrolls', 'seeker', 'sentinel', 'signalling', 'sirens', 'slovenia', 'solemn', 'spacex', 'spacious', 'spheres', 'spraying', 'sprung', 'stacey', 'starr', 'substantive', 'substitution', 'sugars', 'sweetest', 'taxing', 'tobago', 'torah', 'torso', 'transcripts', 'tremendously', 'trojan', 'tumble', 'unleash', 'unpublished', 'untrue', 'verbally', 'vitality', 'wc', 'weeping', 'whispering', 'windshield', 'wolfe', 'zodiac', '3a', '3g', '9pm', 'abandonment', 'abyss', 'accession', 'acquaintances', 'alvarez', 'alvin', 'amateurs', 'amir', 'anders', 'archived', 'arithmetic', 'arson', 'astronomers', 'auditions', 'authoritative', 'awarding', 'barren', 'basal', 'batsman', 'bedding', 'bender', 'bethlehem', 'bicycles', 'boi', 'bourgeois', 'braking', 'bribery', 'brunette', 'bureaucratic', 'buzzer', 'cactus', 'carlson', 'cassette', 'chants', 'characterised', 'childcare', 'chocolates', 'chronological', 'cleavage', 'clones', 'cohort', 'commandments', 'conceive', 'condensed', 'contemporaries', 'controversies', 'convened', 'conveyed', 'crabs', 'cuddle', 'culprit', 'darius', 'daunting', 'demos', 'deviation', 'diffusion', 'dildo', 'distrust', 'dominates', 'echoed', 'elbows', 'ellison', 'elves', 'embark', 'empires', 'entrepreneurial', 'ether', 'etiquette', 'exhibiting', 'extravagant', 'familiarity', 'felipe', 'fender', 'feng', 'ferris', 'fetal', 'fiance', 'finer', 'fittings', 'flushing', 'fn', 'freeing', 'fused', 'goa', 'gorge', 'greenwood', 'groves', 'gu', 'gutted', 'harp', 'hartley', 'heartfelt', 'hinted', 'hoodie', 'housewife', 'housewives', 'hubs', 'hypocrite', 'incorporation', 'insure', 'joyful', 'judah', 'kabul', 'kelley', 'kickoff', 'kimberly', 'lacrosse', 'lars', 'latex', 'leftover', 'legalization', 'lf', 'localized', 'lori', 'malibu', 'mammoth', 'martyrs', 'marvellous', 'matchup', 'meh', 'merkel', 'modem', 'mosques', 'motif', 'necks', 'newcomer', 'nic', 'nobles', 'oats', 'ominous', 'openness', 'optimized', 'overheard', 'oversized', 'pak', 'pandora', 'panicked', 'paolo', 'papal', 'patton', 'pepe', 'peril', 'pk', 'playable', 'plunged', 'polly', 'pores', 'posh', 'practising', 'precaution', 'principally', 'professionalism', 'puppets', 'pv', 'rampage', 'reassuring', 'rebirth', 'recharge', 'rehearsals', 'reliably', 'renovations', 'reservoirs', 'retina', 'revolves', 'riff', 'rosen', 'rossi', 'rr', 'rutgers', 'sahara', 'scattering', 'scrape', 'scripted', 'semantic', 'shear', 'shedding', 'sherry', 'shitting', 'silicone', 'skepticism', 'slovakia', 'sly', 'smiley', 'smithsonian', 'snoop', 'sponsoring', 'stables', 'startling', 'strands', 'strife', 'stylist', \"sunday's\", 'superheroes', 'tattooed', 'tenor', 'thrift', 'toured', 'transformations', 'traverse', 'turnaround', 'uterus', 'validate', 'vid', 'vocalist', 'vw', 'warranted', 'weakening', 'westbrook', 'wildcats', 'wipes', 'womens', 'wrists', 'xvi', 'yielding', 'zebra', 'zionist', 'α', 'a.d', 'abrams', 'aces', 'aft', 'albion', 'anesthesia', 'anonymity', 'anticipating', 'antoine', 'appropriation', 'aria', 'articulated', 'assassinated', 'babes', 'bandits', 'banished', 'barefoot', 'barrage', 'bartlett', 'beauties', 'bestowed', 'bethesda', 'blackpool', 'bordering', 'bournemouth', 'brilliance', 'britney', 'broth', 'bruised', 'buns', 'burnley', 'cabins', 'campaigned', 'centenary', 'ceos', 'checkpoint', 'chloride', 'classify', 'clinically', 'cocky', 'coefficient', 'coined', 'collapsing', 'collisions', 'condemning', 'conditioner', 'conductors', 'cones', 'conglomerate', 'consultations', 'conversions', 'cornerstone', 'correctness', 'counterfeit', 'damian', 'dazzling', 'dea', 'deacon', 'debuts', 'deceived', 'delaying', 'dentistry', 'desks', 'detainees', 'dictated', 'dino', 'disks', 'dismissing', 'dortmund', 'edgy', 'eff', 'elevators', 'elton', 'encore', 'engages', 'enormously', 'epstein', 'err', 'erupted', 'espresso', 'evade', 'fab', 'fairs', 'freaky', 'freshmen', 'futile', 'genera', 'germs', 'glacial', 'glands', 'gloomy', 'graceful', 'grievances', 'gritty', 'hanoi', 'hayley', 'heartbreak', 'heist', 'heterosexual', 'hewitt', 'hinder', 'hobbit', 'horseback', 'hospice', 'hotline', 'huang', 'inhibition', 'integer', 'interdisciplinary', 'intermittent', 'intimidation', 'islamist', 'italia', 'iteration', 'j.d', 'joys', 'kitchens', 'kremlin', 'langley', 'liners', 'liv', 'lv', 'm3', 'madagascar', 'magnum', 'malay', 'mandates', 'martian', 'mashed', 'maxim', 'mcdonalds', 'mei', 'melancholy', 'meteorological', 'milf', 'misplaced', 'misty', 'modifying', 'moines', 'monsieur', 'mop', 'multicultural', 'nearing', 'negatives', 'negligible', 'nesting', 'nudity', 'obligatory', 'oceanic', 'od', 'oooh', 'ornaments', 'outpost', 'outputs', 'overflow', 'oxidation', 'panorama', 'pascal', 'peep', 'pencils', 'pervasive', 'pickle', 'pinky', 'playwright', 'pledges', 'predatory', 'preface', 'prescribe', 'punitive', 'quits', 'rainforest', 'raphael', 'reborn', 'reddish', 'refurbished', \"region's\", 'repercussions', 'reprint', 'restroom', 'rhythmic', 'robber', 'robes', 'rockies', 'roi', 'roommates', 'roulette', 'rounding', 'rowing', 'rulings', 'rumored', 'rupees', \"sam's\", 'samoa', 'samson', 'satin', 'scatter', 'scramble', 'scraps', 'segregated', 'semantics', 'settles', 'shameless', 'sharif', 'showtime', 'silenced', 'sinner', 'skeletal', 'skeletons', 'skulls', 'slows', 'snapshot', 'soar', \"something's\", 'spherical', 'spotting', 'sprinkle', 'spruce', 'squared', 'squirrels', 'stacy', 'stamina', 'standalone', 'stimuli', 'subconscious', 'thinker', 'tonic', 'tossing', 'troublesome', 'tumour', 'twain', 'uncertainties', 'underestimated', 'utopia', 'vanish', 'vigorously', 'visibly', 'vowed', 'vpn', 'waterways', 'wetlands', 'whitman', 'wrecking', 'xiv', '👏', '3s', '4pm', 'abigail', 'abrupt', 'acronym', 'adaptations', 'adversity', 'advertiser', 'affidavit', 'amc', 'antics', 'antony', 'ao', 'appreciates', \"area's\", 'artworks', 'asserts', 'astrology', 'attachments', 'authorize', \"bank's\", 'baroness', 'barrow', 'begs', 'bengals', 'binds', 'biographical', 'biomass', 'bitcoins', 'blanche', 'blm', 'blouse', 'bodyguard', 'borrowers', 'botany', 'bras', 'bulldog', 'caterpillar', 'censored', 'chatter', 'cheered', 'chops', 'cleric', 'cn', 'colbert', 'comedic', 'compile', 'compressor', 'compton', 'conferred', 'conn', 'constantinople', 'contrasts', 'cooke', 'cougar', 'creeps', 'cutler', 'czechoslovakia', 'deadlines', 'deceive', 'defamation', 'denny', \"department's\", 'det', 'digs', 'diminishing', 'directional', 'disagreements', 'disciple', 'ditto', 'divergent', 'doctorate', 'doncaster', 'donnie', 'downright', 'dues', 'dumbest', 'dwellings', 'electrode', 'elemental', 'elevate', 'eliminates', 'encoding', 'excludes', 'exemplary', 'exited', 'expansive', 'fife', \"firm's\", 'flakes', 'flavours', 'geez', 'gemini', 'gifs', 'gland', 'gotcha', 'gst', 'guerrilla', 'gutter', 'hearty', 'highschool', 'hillside', \"hitler's\", 'hms', 'hodges', 'hoo', 'hovering', 'ht', 'hun', 'hysteria', 'impartial', 'imperialism', 'imprint', 'incremental', 'independents', 'infancy', 'infused', 'inhibitor', 'initiating', 'injuring', 'inquire', 'inscribed', 'insulated', 'jang', 'jogging', 'jumbo', 'kale', 'katz', 'keyboards', 'kraft', 'landowners', 'lash', 'latina', \"lee's\", 'leftovers', 'louie', 'lte', 'luca', 'm.a', 'madras', 'magnets', 'manageable', 'manslaughter', 'manuals', 'marianne', \"martin's\", 'mecca', 'meridian', 'midi', 'mikhail', 'mir', 'misdemeanor', 'misfortune', 'mondays', 'moons', 'mountainous', 'ndp', 'nearer', 'newfoundland', 'obnoxious', 'olsen', 'orphanage', 'overseeing', 'paused', 'penned', 'perpetrators', 'phoebe', 'pilgrim', 'plainly', 'positives', 'punishments', 'purdue', 'qualifies', 'rake', 'recalling', 'resent', 'retreated', 'retribution', 'revolutions', 'rhetorical', 'rightful', 'robbing', 'royale', 'rumour', 'safeguards', 'savages', 'sbs', 'semen', 'senegal', 'sequencing', 'shapiro', 'shea', 'shorten', 'sighs', 'sixteenth', 'slime', 'sow', 'sparkle', 'spawn', 'sql', 'successors', 'suffrage', 'superiors', 'surrogate', 'synopsis', 'tainted', 'tanya', 'ticks', 'toddlers', 'tomas', 'toothbrush', 'towed', 'trapping', 'treatise', 'tristan', 'uphill', 'upton', 'validated', 'variability', 'waltz', 'wooded', 'workings', 'zac', 'zhou', 'acl', 'adhesive', 'adolf', 'adorned', 'affluent', 'als', 'ambiguity', 'anguish', 'annals', 'antitrust', 'apologizing', 'archaeologists', 'arid', 'avg', 'bandit', 'barrister', 'bazaar', 'beneficiary', 'beyoncé', 'bianca', 'biker', 'bipartisan', 'birthplace', 'bl', 'bono', 'bracelets', 'brides', 'brochure', 'brokerage', 'buildup', 'butch', 'canucks', 'carly', 'carpets', 'carriages', 'catholicism', 'cgi', 'chained', 'chats', 'cheng', 'ching', 'chopping', 'cigars', 'civilisation', 'closures', 'coasts', 'cobalt', 'collaborated', 'collapses', 'collier', 'colossal', 'comm', 'commodore', 'compiler', 'conserve', 'constellation', 'contour', 'crispy', 'cropped', 'crore', 'crowley', 'curfew', 'd2', 'daytona', 'decidedly', 'delusion', 'demi', 'depreciation', 'designate', 'dh', 'discard', 'discontent', 'div', 'dixie', 'dopamine', 'douche', 'dunes', 'dyke', 'echoing', 'eclectic', 'ecstatic', 'ejected', 'endemic', 'enlist', 'entails', 'envisioned', 'eta', 'exchanging', 'exiled', 'eyebrow', 'fascists', 'firefighter', 'flashbacks', 'fluorescent', 'francois', 'freakin', \"friday's\", 'fulham', 'futuristic', 'gearing', 'hallmark', 'hanover', 'harrington', 'haste', 'hauling', 'heathrow', 'hybrids', 'hyun', 'identifiable', 'igor', 'illiterate', 'immaculate', 'improvised', 'inclination', 'infested', 'insurgents', 'interpersonal', 'interracial', 'intruder', 'inward', 'ipo', 'itching', 'jai', 'jarvis', 'jenner', 'johann', 'jolie', 'judas', 'judd', 'kan', 'kaplan', 'kinky', \"korea's\", 'landings', 'launcher', 'ld', 'legality', 'lenny', 'lessen', 'lifespan', 'longitudinal', 'loosen', 'ly', 'macedonia', 'mandy', 'masculinity', 'matured', 'mcgee', 'mcgraw', 'microscopic', 'midday', 'moan', 'moods', 'morphine', 'motherhood', 'motorola', 'murderous', 'n.c', 'nb', 'nirvana', 'nonstop', 'notoriously', 'nrl', 'oatmeal', 'opaque', 'ordnance', 'originate', 'otter', 'parting', 'pelvic', 'percussion', 'pigment', 'plato', 'populist', 'porous', 'preached', 'predictive', 'proofs', 'pulses', 'racially', 'racks', 'refunds', 'registrar', 'regulars', 'rein', 'relic', 'retard', 'reunite', 'reuse', 'reyes', 'risked', 'ritchie', 'rl', 'roadway', 'rollins', 'rustic', 'rutherford', 's1', 'sanitary', 'sao', 'saturation', 'scams', 'scarcity', 'scorpion', \"scott's\", 'setback', 'shaming', 'shrubs', 'sizable', 'slippers', 'smoker', 'soho', 'spartan', 'speculated', 'spilling', 'squeezing', 'stalled', 'stimulated', 'straits', 'stun', 'subdued', 'surpass', 'swapped', 'tack', 'tagging', 'tart', 'throats', 'ting', 'tiring', 'toothpaste', 'totaled', 'transformer', 'transient', 'triumphant', 'umpire', 'unborn', 'undisclosed', 'undone', 'unheard', 'vending', 'vicar', 'wallets', 'weep', 'welch', 'woes', 'woken', 'wrench', 'wretched', 'www', 'x2', '1s', '3pm', 'adler', 'adolescence', 'affirmed', 'afterlife', 'allowances', 'ammonia', 'analogous', 'anarchist', 'anecdotes', 'anglican', 'animations', 'ankara', 'appropriations', 'apron', 'archaic', 'assange', 'assaulting', 'attribution', 'avant', 'baffled', 'baird', 'barlow', 'benton', 'biochemistry', 'bm', 'boise', 'bop', 'bordeaux', 'breached', 'burr', 'carbs', 'cavaliers', 'censor', 'centennial', 'cheney', 'cher', 'civilizations', 'clapping', 'clinging', 'clover', 'cms', 'coatings', 'coils', 'colonization', 'connolly', 'cookbook', 'corinthians', 'cosmopolitan', 'counselors', 'coyote', 'crippling', 'cristina', 'cromwell', 'cy', 'decorate', 'decorating', 'deductible', 'diagonal', 'discredit', 'dodd', 'dresser', 'duff', 'dysfunctional', 'ebooks', 'elm', 'emphasizing', 'ems', 'enquiries', 'equitable', 'estrogen', 'etsy', 'exert', 'expeditions', 'faculties', 'felicity', 'fernandez', 'feudal', 'fins', 'flattened', 'fleece', 'fodder', 'forwarded', 'fumble', 'galloway', 'giggles', 'git', 'glare', 'godzilla', 'gourmet', 'gripping', 'handheld', 'handshake', 'harming', 'hayward', 'hefty', 'helsinki', 'herbal', 'herrera', 'hippie', 'hops', 'horton', 'hump', 'idiotic', 'ids', 'implements', 'incarceration', 'incest', 'infect', 'insertion', 'interruption', 'intrigue', 'itch', 'jacqueline', 'jc', 'joaquin', 'kurds', 'lattice', 'leaps', 'legitimately', 'lends', 'leroy', 'linebacker', 'lockheed', 'lowers', \"luke's\", 'm000', 'm1', 'magically', 'marketers', 'mastermind', 'materially', 'metadata', 'middlesex', \"minister's\", 'mischief', 'modernization', 'mums', 'necessities', 'neptune', 'nerds', 'nero', 'noticeably', 'occupancy', 'oman', 'oncology', 'opposes', 'outsourcing', 'overrun', 'parcels', 'pasture', 'pathological', 'payload', 'payout', 'pelosi', 'persia', 'pertinent', 'pigeons', 'plentiful', 'plumber', 'png', 'porno', 'portfolios', 'preserves', 'promoters', 'prosecuting', 'purchaser', 'rahul', 'rapes', 'rarity', 'realty', 'rebellious', 'reefs', 'referencing', 'reminders', 'repealed', 'reptiles', 'revisit', 'ribbons', 'santo', 'satirical', \"saturday's\", 'screenings', 'sensual', 'sixties', 'slapping', 'slump', 'soften', 'sos', 'souvenir', 'spaceship', 'spaniards', 'sparse', 'spinner', 'steamer', 'subsidized', 'suction', 'sunflower', 'supplementary', 'surveyor', 'swallowing', 'tailed', 'temperament', 'thirteenth', 'topless', 'torment', 'tyrant', 'unattractive', 'unbeaten', 'understatement', 'undesirable', 'unfairly', 'unification', 'vineyards', 'wastes', 'wastewater', 'wb', 'weaponry', 'webpage', 'wheeled', 'whipping', 'widows', 'wildfire', 'withheld', 'withholding', 'wreath', 'wt', 'yer', '♦', 'administrations', 'afar', 'affectionate', 'afp', 'agitated', 'akron', 'albania', 'angie', 'annuity', 'appliance', 'aroused', 'asserting', 'astros', 'authentication', 'awaken', 'azure', 'bedside', 'berger', 'besieged', 'biologist', 'blowjob', 'bn', 'boilers', 'bois', 'bonnet', 'bourne', 'braun', 'breaches', 'breeder', 'burying', 'byzantine', 'cadet', 'calming', 'casing', \"cat's\", 'catalonia', 'catfish', 'caucasus', \"chicago's\", 'clerical', 'coincided', 'collage', 'colonists', 'complimentary', 'compounded', 'computation', 'conjecture', 'conspicuous', 'constantine', 'continual', 'contradict', 'cords', 'crackdown', 'craze', 'crusaders', 'cupcake', 'cvs', 'cybersecurity', 'davenport', 'degrading', 'deli', 'deteriorated', 'distinguishing', 'dreaded', 'dui', 'dumps', 'dwayne', 'dyer', 'elongated', 'embraces', 'enamel', 'encompassing', 'escalate', 'evicted', 'evils', 'exceedingly', 'excessively', 'faked', 'farmland', 'fetched', 'fiercely', 'flashed', 'fostering', 'fourteenth', 'fps', \"france's\", 'frontline', 'geese', 'genealogy', 'geographically', 'gibraltar', 'giggle', 'goggles', 'golfer', 'grammatical', 'graphite', 'grimm', 'gupta', 'haitian', 'handgun', 'hara', \"harry's\", 'heaviest', 'hella', 'heresy', 'herpes', 'hipster', 'hispanics', 'hostess', 'hud', 'hunts', 'iceberg', 'ideologies', 'ignite', 'illumination', 'impoverished', 'improperly', 'ingenious', 'inquisition', 'interns', 'intervened', 'ist', 'jab', 'janice', 'landfill', 'larson', 'learner', 'lighten', 'lmfao', 'lowry', 'maldives', 'maroon', 'marriott', 'marxism', 'masonry', 'maui', 'mclaughlin', 'mechanically', 'mikey', 'millionaires', 'mina', 'moor', 'moreno', 'muffin', 'nadal', 'nigger', 'nih', 'novak', \"o'donnell\", 'obi', 'oily', 'olives', 'ostensibly', 'outbreaks', 'outnumbered', 'outspoken', 'pacing', 'palate', 'pancake', 'parkway', \"patrick's\", 'pedestal', 'pedigree', 'pennies', 'phony', 'pinpoint', 'pip', 'pleasantly', 'pluto', 'ponder', 'protestants', 'prowess', 'prussia', 'psychologically', 'pulitzer', 'pursuits', 'ramen', 'ramirez', 'ramon', 'rattle', 'recycle', 'reimbursement', 'reinforcing', 'reinstated', 'renault', 'renee', 'repent', 'rescuing', 'revert', 'ridges', 'rolex', 'rowe', 'rubin', 'sabrina', 'saliva', 'senseless', 'sermons', 'seventeenth', 'sha', 'shortcut', 'sikh', 'skye', 'slamming', 'slay', 'smoother', 'spence', 'spills', 'staffed', 'stumbling', 'stunts', 'summarized', 'sweeney', 'synth', 'tackled', 'takeoff', 'tammy', 'tat', 'taxable', \"taylor's\", 'trafford', 'transmissions', 'treadmill', 'trucking', 'unavoidable', 'unilateral', 'vicky', 'vie', 'vijay', 'warped', 'wasp', 'watermelon', 'webber', 'westward', 'whores', 'widened', 'yin', 'yun', 'â', '3ds', '4s', '8am', 'a4', 'academies', 'acidic', 'adherence', 'adjective', 'adjourned', \"administration's\", 'aint', 'amnesia', 'amplified', 'angola', 'angrily', 'appellate', 'approving', 'armoured', 'ascension', 'aspirin', 'atheists', 'ax', 'bard', 'bea', 'bearded', 'beetles', 'bends', 'benevolent', 'bestseller', 'bis', 'blackhawks', 'blazers', 'blends', 'blooded', 'blossoms', 'bog', 'bom', 'bombardment', 'borderline', 'boxed', 'brows', 'bungalow', 'burglar', 'calibration', 'cams', 'capitalize', 'charisma', 'cheltenham', 'chesapeake', 'chun', 'ck', 'classmate', 'claudio', 'cognition', 'cooker', 'cornish', 'coupe', 'coveted', 'craigslist', 'cristiano', 'crumbs', 'cullen', 'cures', 'curled', 'cylindrical', 'd1', 'davey', 'deceptive', 'deem', 'deficiencies', 'devastation', 'devout', 'dia', 'dickson', 'disproportionate', 'disturbances', 'divisive', 'dk', 'dod', 'dracula', 'ebony', 'eduardo', 'eileen', 'elon', 'embodied', 'embroidered', 'embryo', 'eminem', 'ensued', 'erratic', 'exiting', 'fang', 'fiesta', 'folly', 'foo', 'foreseeable', 'frenchman', 'friedrich', 'fumes', 'garde', 'garnered', 'gerrard', 'gilmore', 'glazed', 'gon', 'griffiths', 'hardwood', 'hendrix', 'highness', 'hikes', 'hindsight', 'hinges', 'homophobia', 'houghton', 'hume', 'hymns', 'hz', 'ik', 'indifference', 'indispensable', 'infirmary', 'inflict', 'ingram', 'inhibit', 'insanely', 'intellectually', 'interstellar', 'intoxicated', 'involuntary', 'isil', 'issuance', 'itchy', 'jammed', 'jojo', 'junta', 'lankan', 'laos', 'latch', 'libel', 'ligament', 'likeness', 'lizzie', 'loaned', 'lofty', 'loom', 'luc', 'ludicrous', 'maharashtra', 'maize', 'malice', 'manu', 'marginalized', \"mayor's\", 'mazda', 'mcmahon', 'melvin', 'middlesbrough', 'milestones', 'milford', 'milling', 'minnie', 'mitsubishi', 'mixtape', 'mods', 'mongolia', 'motivating', 'munitions', 'mx', 'myrtle', 'nemesis', \"o'reilly\", 'originality', 'orioles', 'ornamental', \"owner's\", 'oysters', 'pancreatic', \"parkinson's\", 'parlor', 'partnering', 'pebble', 'peeled', 'perseverance', 'persisted', 'pharmacist', 'phillies', 'picky', 'pistons', 'pizzas', 'poole', 'populace', 'pretoria', 'pricey', 'prima', 'prized', 'profiling', 'progressives', 'prompts', 'propagation', 'psychedelic', 'pune', 'quieter', 'radiator', 'randomized', 'rapists', 'rector', 'redeemed', 'regal', 'relativity', 'rene', 'revered', 'ridicule', 'ridley', 'roasting', 'rocker', 'romero', 'rotting', 'salman', 'sami', 'sculptor', 'semifinals', 'shalt', 'sheen', 'shelton', 'showcasing', 'sincerity', 'sinful', 'slander', 'sleek', 'slew', 'sling', 'socioeconomic', 'solicitors', 'spontaneously', 'steamed', 'stockton', 'stratford', 'studs', 'sturgeon', 'subpoena', 'swam', 'sweeps', 'syllabus', \"system's\", 'são', 'taiwanese', 'teaming', 'textual', 'thinkin', 'toad', 'tombs', 'troopers', 'tsa', \"tv's\", 'tyrone', 'u2', 'unaffected', 'uncles', 'undeniable', 'une', 'upstate', 'ventura', 'vigilant', 'visitation', 'viva', 'volcanoes', 'washer', 'watered', 'werner', 'wick', 'worldly', 'wp', '1k', '2m', '2pm', '3x', 'a.k.a', 'achieves', 'additive', 'adept', 'advantageous', 'aero', 'afloat', 'agility', 'airbus', 'alba', 'alteration', 'annoyance', 'anon', 'ante', 'appointing', 'archipelago', 'assembling', 'bailed', 'barkley', 'bdsm', 'behaviours', 'belmont', 'bidders', 'bloated', 'blooming', 'blooms', 'boating', 'bonfire', 'bookings', 'bowed', 'brody', 'bullpen', 'cafes', 'cali', 'canine', 'capsules', 'carb', 'carver', 'causal', 'centrally', 'cheerleader', 'christy', 'circling', 'citadel', \"client's\", 'clifton', 'climates', 'colonialism', 'comforts', 'compromising', 'corvette', 'costco', 'cowards', 'cranes', 'cunts', 'cutest', 'dashboard', 'deficient', 'degenerate', 'demonic', 'deterrent', 'disdain', 'disgraceful', 'doggy', 'dole', 'dreamt', 'dun', 'eerie', 'electing', 'enraged', 'envelopes', 'eroded', 'estimating', 'ethel', 'excursion', 'exemptions', 'exponential', 'farce', 'fatally', 'fingerprints', 'flanders', 'flickr', 'fling', 'flowed', 'flung', 'fragmented', 'frankenstein', 'frantic', 'fudge', 'gabrielle', 'gemma', 'gideon', 'glide', 'glover', 'gras', 'grieve', 'grimes', 'grossly', 'grudge', 'gucci', 'hairstyle', 'handwritten', 'hardships', 'harmonic', 'hb', 'headlights', 'heartless', 'hectic', 'holistic', 'hooper', 'hormonal', 'huffington', 'ict', 'implanted', 'informant', 'inhabit', 'intervening', 'intrusive', 'investigates', 'invoke', 'invoked', 'jackass', 'jericho', 'jonny', 'josephine', 'joyous', 'kiwi', 'latinos', 'leaflets', 'licences', 'lim', 'limo', 'lulu', 'lunchtime', 'lux', 'mace', 'maher', 'malawi', 'malignant', 'mane', 'mascara', 'matchmaking', 'maverick', 'measles', 'mend', 'mentoring', 'mich', 'microbial', \"microsoft's\", 'migraine', 'millennial', 'mitt', 'molten', 'monsoon', 'montage', 'monterey', 'morales', 'napoli', 'negligent', 'netanyahu', 'nikon', 'nil', 'norma', 'ofthe', 'opioid', 'optimize', \"pakistan's\", 'passionately', 'pastors', 'pathogens', 'penetrating', 'persuasion', 'phased', 'phyllis', 'plaid', 'playback', 'plush', 'portraying', 'portrays', 'positivity', 'practised', 'precedence', 'preferring', 'previews', 'pristine', 'prognosis', 'propeller', 'pyramids', 'quotas', 'racket', 'rags', 'rajasthan', 'realistically', 'reclaimed', 'reilly', 'relatable', 'reorganization', 'resembled', 'resided', 'retrieval', 'rotated', 'roundabout', 'saline', 'saviour', 'scarcely', 'scraping', 'serie', 'shipbuilding', 'shiva', 'shrugged', 'siemens', 'signings', 'slogans', 'smoky', 'solids', 'solos', 'spade', 'spoils', 'staffordshire', 'steroid', 'supplemented', 'surveying', 'swans', 'tata', 'tds', 'temperate', 'temps', 'thematic', 'threesome', 'thunderstorms', 'tilted', 'toaster', 'treble', 'turquoise', 'ultraviolet', 'unbiased', 'unc', 'uncanny', 'underdog', 'unfolding', 'ungrateful', 'untreated', 'usefulness', \"user's\", 'vandalism', 'vargas', 'vibrating', 'vowel', 'voyager', 'weirdo', 'weld', 'werewolf', \"wilson's\", 'wrongful', 'ww', 'xu', 'β', '🔥', '😊', 'aba', 'acknowledgement', 'adored', 'airbnb', 'alerted', 'alleges', 'alligator', 'amends', 'annoys', 'antagonist', 'apa', 'approximation', 'aromatic', 'assurances', 'attendants', 'auschwitz', 'b.s', 'baroque', 'bays', 'behavioural', 'belgrade', 'benefiting', 'berg', 'bergen', 'bethany', 'bg', 'biases', 'binder', 'blindly', 'brig', 'buggy', 'bundled', 'burnett', 'buzzfeed', 'calves', 'camille', 'canonical', 'cautiously', 'ceasefire', 'celery', 'characterize', 'chinatown', 'collaborations', 'collaborators', 'commissioning', 'cor', 'counsellor', 'countered', 'couture', 'cramps', 'croatian', 'crowdfunding', 'cutie', 'dab', 'dar', 'darcy', 'dawg', 'dentists', 'deploying', 'deserts', 'df', 'dictates', 'dion', 'dissatisfaction', 'dodgy', 'e3', 'earthly', 'eaters', 'elective', 'emitted', 'endeavors', 'enslaved', 'ent', 'entrances', 'eq', 'escalation', 'ethos', 'eureka', 'exec', 'eyewitness', 'fag', 'favours', 'fil', 'fitz', 'fleeting', 'flourished', 'forfeit', 'forging', 'foundry', 'fractions', 'fro', 'funerals', 'furnishings', 'giraffe', 'gma', 'gmail', 'grinder', 'gunman', 'hampered', 'hardcover', 'healer', 'heals', 'hermione', 'hinge', 'hubbard', 'hurley', 'illustrating', 'inaugurated', 'indexes', 'insiders', 'intestinal', 'intra', 'irons', 'islamabad', 'j.j', 'jock', 'jumpers', 'kidd', 'kneeling', 'knuckles', \"lady's\", 'lauderdale', 'lifestyles', 'lr', 'ludwig', 'macbeth', \"magazine's\", 'mamma', 'manic', 'manifold', 'margot', 'measurable', 'medina', 'meek', 'mellow', 'melon', 'mirrored', 'miscarriage', 'mla', 'mojo', 'msnbc', 'napa', 'narration', \"nasa's\", 'nassau', 'nicki', 'nip', 'nxt', 'nye', 'oblivion', 'observes', 'ohhh', 'oilers', 'ornament', 'outpatient', 'pamphlet', 'parishes', 'pats', 'penelope', 'perish', 'perpetrator', 'pervert', 'pharaoh', 'philanthropy', 'photon', 'polluted', 'potion', 'premiered', 'preparedness', 'pretends', 'prettier', 'primal', 'princesses', 'prohibiting', 'psalms', 'psg', 'psychopath', 'pups', 'qui', 'quid', 'receptive', 'redundancy', 'reelection', 'reindeer', 'relapse', 'relish', 'rendezvous', 'republics', 'reversible', 'roche', 'rodents', 'rowan', 'rudolph', 's4', 'saharan', 'scumbag', 'seams', 'seizing', 'selectively', 'sensed', 'shred', 'sideline', 'sidelines', 'simplistic', 'skater', 'skincare', 'soc', 'spawning', 'spokane', 'sta', 'stabilized', 'stares', 'staten', 'steaming', \"student's\", 'substitutes', 'supervise', 'supervising', 'supervisory', 'swapping', 'sweeter', 'syllable', 'synod', 'taipei', 'takeaway', 'tatum', 'teased', 'tees', 'tesco', 'thorpe', 'titus', 'towing', 'treacherous', 'turnbull', 'undermined', 'undermining', 'untold', 'uplifting', 'upsets', 'vaccinated', 'vaughn', 'vents', 'versatility', 'visualization', 'voicemail', 'volt', 'wakefield', 'watford', \"who'll\", 'wielding', 'wiggins', 'wilkins', 'wingers', 'winnie', 'wits', 'wrongs', 'yeh', 'abnormalities', 'allocate', 'analytic', 'ans', 'apprehended', 'ascending', 'attributable', 'aubrey', 'barb', 'bastion', 'beaumont', 'bey', 'biopsy', 'blackwell', 'bolster', 'bray', 'briefs', 'caitlin', 'calais', 'cancelling', 'canning', 'capitalists', 'categorized', 'cba', 'cbi', 'cg', 'chopper', 'chromosomes', 'chunky', 'classed', 'clerks', 'cohesive', 'comey', 'commando', 'complication', 'computed', 'conquering', 'constituencies', 'contentious', 'contra', 'corbyn', 'cosy', 'coyotes', 'crease', 'cursing', 'deadliest', 'degraded', 'dehydration', 'delights', 'denomination', 'derbyshire', 'desserts', 'digestion', 'dismantled', 'dissatisfied', 'distinctions', 'docking', 'dodging', 'donut', 'doubting', 'dungeons', 'effected', 'embargo', 'embodiment', 'emptied', 'encoded', 'engraving', 'enhances', 'entrenched', 'explanatory', 'extremism', 'fairfield', 'fairies', 'faulkner', 'fg', 'filtration', 'finalized', 'flagged', 'fleets', 'fooling', 'formatting', 'fracking', 'francesca', 'francesco', 'fungal', 'gabe', 'garry', 'garth', 'ghz', 'gillian', 'glaciers', 'glaring', 'gloom', 'goblin', 'gunner', 'hammers', 'hamster', 'heaps', 'hex', 'homosexuals', 'hooking', 'hopped', 'hydra', 'hypocritical', 'illustrious', 'incidental', 'indigo', \"individual's\", \"industry's\", 'inscriptions', 'instruct', 'insurgency', 'intimidate', 'ipa', 'irregularities', 'jamming', 'jax', 'kyrie', 'labyrinth', 'lac', 'latency', 'limbo', 'linger', 'lousy', 'luncheon', 'mailbox', 'mammal', 'mcguire', 'membranes', 'memorabilia', 'midterm', 'midtown', 'migrated', \"miller's\", 'mimi', 'muir', 'muzzle', 'myspace', 'nationalities', 'nec', 'nurture', 'oblivious', 'ode', 'oem', 'olga', 'olson', 'ortiz', 'outlining', 'overt', 'pacers', 'paisley', 'pajamas', 'palo', 'patriarch', 'penthouse', 'perjury', 'persists', 'pious', 'plotted', 'potomac', 'powdered', 'pregnancies', 'prematurely', 'presenters', 'prioritize', 'proprietor', 'putnam', 'quarrel', 'r000', 'raider', 'rained', 'raja', 'rea', 'reasoned', 'rebate', 'regulates', 'reins', 'resurgence', 'rh', 'roc', 'rollers', 'rooster', 'routed', 'rufus', 'rushes', 'rx', 's.c', 'sakura', 'salads', 'sanskrit', 'scientology', 'scooby', 'scuba', 'seamless', 'selects', 'sequels', 'shattering', 'shelly', 'sheppard', 'shite', 'shoreline', 'siberian', 'sickening', 'sidewalks', 'silhouette', 'slug', 'smackdown', 'smug', 'soprano', 'specialties', 'spectroscopy', 'spreadsheet', 'stagnant', 'startled', 'steaks', 'stephenson', 'streaks', 'strides', 'strung', 'summaries', 't1', 't2', 'tanning', 'tendon', 'thc', 'thine', 'timmy', 'tnt', 'toughness', 'tracey', 'tractors', 'turin', 'unanswered', 'unethical', 'uniting', 'unix', 'uptown', 'urinary', 'valiant', 'vigilante', 'viper', \"washington's\", 'weekday', 'weirdest', 'westwood', 'whistles', 'whitehall', 'wilhelm', 'willard', 'woe', 'wrinkles', 'ws', '3am', '6s', 'abi', 'abstraction', 'adjunct', 'administering', 'admiring', 'ami', 'ascended', 'asean', 'aspiration', 'atkins', 'attentive', 'auntie', 'austen', 'awakened', 'ballpark', 'barbarians', 'beak', 'beige', 'bellamy', 'blasphemy', 'blinds', 'blinking', 'blueberry', 'boar', 'bosch', 'bran', 'breathes', 'bribes', 'brigadier', 'broaden', 'bubba', 'bulky', 'burdens', 'busch', 'cadets', 'calendars', 'camels', 'cameraman', 'carbohydrates', 'carnage', 'cavities', 'chateau', 'chavez', 'colleen', 'comedies', 'commended', 'commune', 'compiling', 'conclusive', 'conservatory', 'considerate', 'constance', 'constructions', 'coo', 'cryptocurrency', 'cultured', 'dans', 'daycare', 'debra', 'deductions', 'depressive', 'descendant', 'dips', \"director's\", 'disperse', 'disproportionately', 'dives', 'downed', 'ecommerce', 'emery', 'enrich', 'entrants', 'epidemiology', 'errands', 'esque', 'exaggeration', 'exhaustive', 'exponentially', 'exporters', 'externally', 'fanbase', 'fermentation', 'fiasco', 'fifteenth', 'flares', 'flo', 'flops', 'flores', 'footed', 'fright', 'fruitful', 'gall', 'gastric', 'gilded', 'goddard', 'hallelujah', 'hastily', 'haynes', 'headphone', 'heinrich', 'hemingway', 'horizontally', 'hubert', 'hurtful', 'illuminate', 'inaccessible', 'incur', 'inferno', 'introductions', 'inverness', \"ireland's\", 'isabelle', 'jog', 'jt', 'jug', 'kgb', 'kinder', 'knoxville', 'labrador', 'latte', 'leafy', 'lobe', 'loo', 'luiz', 'lyle', 'maga', 'maguire', 'margarita', 'masturbating', 'mcbride', 'meddling', 'nadia', 'nods', \"nothing's\", 'ofc', 'ollie', 'omission', 'orbits', 'orchid', 'overtake', 'paramedics', 'pax', 'peabody', 'peat', 'pedophile', 'peptide', 'perfected', 'periphery', 'perished', 'physicists', 'piggy', 'piling', 'polarized', 'portals', 'pov', 'predetermined', 'prelude', 'prepaid', 'priesthood', 'punishable', 'rahman', 'rao', 'ravi', 'reaper', 'reassure', 'redesigned', 'regiments', 'remnant', 'renders', 'rhys', 'rockstar', 'ros', 'rosenberg', 'rounder', 'sanford', 'satanic', 'sausages', 'scented', 'sclerosis', 'selfless', 'serenity', 'shading', 'shrug', 'sighting', 'singled', 'sipping', 'siri', \"site's\", 'sonar', 'spat', 'stabilization', 'stacking', 'starch', 'stony', 'stormed', 'subtly', 'superstars', 'surfer', 'taj', 'taper', 'teaspoon', 'templates', 'thorne', 'tightening', 'tlc', 'tolls', 'tos', 'totaling', 'toxin', 'trademarks', 'tudor', 'turk', 'typo', 'unequal', 'unresolved', 'unspecified', 'vacated', 'veg', 'venetian', 'vhs', 'waffle', 'wanda', 'warships', 'washes', 'wasps', 'welp', 'wha', 'winery', 'wm', 'writ', 'xiao', 'yamaha', 'zara', 'zipper', 'a3', 'acclaim', 'aching', 'acquires', 'adversary', 'afflicted', 'airfield', 'akbar', 'alienated', 'angered', 'archers', 'arrays', 'ascertain', 'assam', 'audits', 'bargains', 'beards', 'believable', \"bill's\", 'billboards', 'bitterly', 'bloodshed', 'boils', 'boko', 'breaths', 'brigades', 'bumping', 'burrows', 'cairns', 'caracas', 'cassie', 'cello', 'celsius', 'certifications', 'cesar', 'chai', 'chariot', 'cheddar', 'chilli', 'cholera', 'cio', 'clinch', 'clipped', 'collide', 'commemoration', 'commuting', 'complexion', 'compulsive', 'congenital', 'construed', 'consular', 'corrective', 'costello', 'coworker', 'crumble', 'crumbling', 'cultivating', \"daddy's\", 'dangling', 'daredevil', 'decentralized', 'dei', 'denominations', 'denote', 'detox', 'didn', 'differentiated', 'discrepancy', 'dishwasher', 'doctrines', 'doj', 'donaldson', 'doodle', 'dossier', 'draper', 'dunham', 'dyes', 'easton', 'eastwood', 'edna', 'electrodes', 'embryos', 'eradicate', 'excite', 'exporter', 'extortion', 'extracting', 'ey', 'fay', 'feral', 'flips', 'flourishing', 'footprints', 'forster', 'fortnite', 'fountains', 'frameworks', 'freezes', 'generously', 'godfrey', 'grange', 'greats', 'gui', 'hangar', 'hardworking', 'harms', 'hasty', 'hathaway', 'hdmi', 'hermes', 'hijacked', 'housekeeper', 'husky', 'idf', 'iggy', 'imitate', 'imperfections', 'improbable', 'impulses', 'incarcerated', 'ineligible', 'infusion', 'iu', 'jaguars', 'jeb', 'journalistic', 'julien', 'justifying', 'kapoor', 'kart', 'kelvin', 'keyword', 'kolkata', 'laborers', 'laced', 'lai', 'lemons', 'lincolnshire', 'lipid', 'looming', 'lordship', 'louisa', 'mahogany', 'malfunction', 'mana', 'manson', 'marin', 'markedly', 'marta', 'mccann', 'mckenna', 'mcqueen', 'mediator', 'mein', 'mentors', 'meow', 'mer', 'minions', 'mirage', 'mockery', 'modulation', 'motorists', 'mozambique', 'muller', 'narrated', 'narrower', \"nature's\", 'navigating', 'navigator', 'nes', 'nightingale', 'nuke', \"o'connell\", 'occult', 'ocd', 'olympian', 'opting', 'osama', 'ovation', 'oversees', 'palaces', 'palin', 'parades', \"park's\", 'payback', 'pediatrics', 'perch', 'perpendicular', 'physique', 'pioneered', 'playbook', 'pleases', 'plywood', 'pollutants', 'ponies', 'pooh', 'ppp', 'prettiest', 'proficient', 'protagonists', 'pst', 'punctuation', 'purification', 'purported', \"putin's\", 'qi', 'quotations', 'ramifications', 'readable', 'recourse', 'regimen', 'removable', 'repaid', 'responders', 'retires', 'retrospect', 'roundup', 'rowland', \"ryan's\", 'seinfeld', 'sensations', 'sequential', 'shafts', 'signifies', 'skates', 'smelly', 'solves', 'sorta', 'specialization', 'spiritually', 'sporadic', 'stationery', 'sudanese', 'sunscreen', 'sykes', 'tau', 'tempest', 'tending', 'terraces', 'thankyou', \"there'd\", 'tightened', 'tights', 'tito', 'tobias', 'tofu', 'tragedies', 'transports', 'trenton', 'tripoli', 'truss', 'tubing', 'tuesdays', 'turnovers', 'twat', 'undue', 'unionist', 'unprotected', 'unsettling', 'upscale', 'vader', 'verde', 'viewpoints', 'vinci', 'vu', 'wacky', 'wealthiest', 'wearable', 'wilcox', 'wiltshire', 'wreckage', \"writer's\", 'xml', 'yvonne', 'zeppelin', '4a', 'a0000', 'aches', 'adamant', 'airspace', 'alejandro', 'allotted', 'almonds', 'amplitude', 'analogue', 'annotated', 'anomalies', 'archival', 'ardent', 'arenas', 'assay', 'assigning', 'assorted', 'axel', 'badminton', 'barbarian', 'bedrock', 'bihar', 'bj', 'blaine', 'boardwalk', 'boasting', 'boldly', \"book's\", 'boomer', 'booths', 'brittle', 'budding', 'cena', 'charters', 'chatham', 'cheaply', 'chiang', 'choo', 'clair', 'climbers', 'clogged', 'cohesion', 'colo', 'compel', 'complexities', 'compromises', 'conduit', 'congregations', 'constraint', 'contradictions', 'conveyor', 'cpi', 'cramped', 'crates', 'crawled', 'culminating', 'cuomo', 'cutters', 'dae', 'dalai', 'darryl', 'dashed', 'decimal', 'defensively', 'defunct', 'degrade', 'demonstrators', 'denton', 'departures', 'diablo', 'differed', 'diffuse', 'dignified', 'disapproval', 'disobedience', 'dreamer', 'dune', 'dwellers', 'eb', 'ef', 'electronically', 'emancipation', 'entropy', 'epitome', 'esa', 'esteemed', 'ethernet', 'excused', 'extradition', 'eyesight', 'fide', 'finder', 'fishy', 'flooring', 'forearm', 'frail', 'fray', 'gathers', 'geelong', 'generational', \"girlfriend's\", 'glaze', 'goldfish', 'greenville', 'grizzly', 'grotesque', 'gunners', 'hallucinations', 'harass', 'hooded', 'horrid', 'huawei', 'hussain', 'hwy', 'impractical', 'indexed', 'insecurities', 'insta', 'interchangeable', 'interrupting', 'irreversible', \"jack's\", 'jacked', 'jerks', 'joked', 'kaufman', 'kfc', 'lawless', 'leftists', 'legalized', 'leggings', 'legions', 'leveled', 'liza', 'locomotives', 'macau', 'manifested', 'marries', 'maynard', 'mayoral', 'medley', 'mercenaries', 'meyers', 'mh', \"might've\", 'minimalist', 'misled', 'msm', 'multiplied', 'narendra', 'objectively', 'orbiting', 'orchestrated', 'packard', 'pap', 'parisian', 'participates', \"partner's\", 'phoned', 'plugin', 'polishing', 'polymers', 'pore', 'postcards', 'postgraduate', 'predicament', 'predominant', 'prem', 'proverbs', 'puke', 'puzzled', 'qu', 'quadrant', 'r1', 'ramps', 'recital', 'recite', 'reckoning', 'recollection', 'reconstructed', 'refine', 'regents', 'reiterated', 'rem', 'resale', 'retake', 'rhine', 'rips', 'rj', 'robb', 'rodrigo', 'rosy', 'rupture', 'salted', 'scandalous', 'scot', 'seasoning', 'securely', 'shabby', 'showcased', 'sightings', 'sinus', 'situ', 'skid', 'solace', 'spanking', 'specialize', 'splinter', 'spoons', 'squats', 'squire', 'standout', 'stills', 'stoner', 'strengthens', 'stung', 'suppressing', 'swimsuit', 'symmetrical', 'tac', 'tacoma', 'tam', 'tenders', 'terminator', 'timers', 'tinker', 'topography', 'ua', 'unexplained', 'unintended', 'unmanned', 'uno', 'unsolved', 'unsuccessfully', 'uptake', 'vantage', 'ventured', 'versailles', 'virgins', 'waldo', 'waller', 'watchers', 'whim', 'whine', 'wil', 'withhold', 'worshipped', 'yee', 'yellowstone', 'ying', 'yosemite', 'zeal', \"zealand's\", 'abort', 'abound', 'adversely', 'afternoons', 'agendas', 'aidan', 'alfredo', 'amish', 'andersen', 'angled', 'antennas', 'assertions', 'astonished', \"attorney's\", 'audacity', 'banjo', 'barbaric', 'barbed', 'battled', 'beech', 'benchmarks', 'biz', 'blazer', 'blower', 'blurry', 'bravely', 'bret', 'breweries', 'bts', 'burmese', \"bush's\", 'camped', 'cherries', 'chevron', 'cheyenne', 'clinicians', 'coercion', 'colombo', 'comma', \"community's\", 'competency', 'concerted', 'constructs', 'cont', 'convicts', 'cora', 'cornelius', 'cravings', 'crotch', 'crucified', 'customize', 'dai', 'dartmouth', 'dashing', 'departmental', 'deposed', 'devin', 'dharma', 'dialysis', 'disclosures', 'distal', 'ditched', 'divisional', 'dogma', 'doi', 'dupont', 'emory', 'emptiness', 'encompass', 'ensign', 'escalating', 'evoke', 'expansions', 'experimented', 'facilitates', 'faithfully', 'faq', 'fern', 'fingertips', 'firepower', 'fixation', 'flanked', 'flatter', 'flushed', 'formative', 'fret', 'frontiers', 'gastrointestinal', 'geeks', 'genders', 'grader', 'granger', 'grasses', 'gratification', 'gruesome', 'guineas', 'gw', 'h.r', 'harshly', 'hedges', 'heller', 'henrik', 'hezbollah', 'hinduism', 'hiroshima', 'hitchcock', 'hodge', 'holloway', 'huts', 'hydrated', 'imaginable', 'impetus', 'impulsive', 'incense', 'inhuman', 'injure', 'inserting', 'intersections', 'inventing', 'invoice', 'jb', 'johan', 'junkie', 'kelsey', 'khalid', 'kr', 'kristin', 'kun', 'lacey', 'lao', 'latent', 'lau', 'leans', 'leipzig', 'lenovo', 'lew', 'lexus', 'limitless', 'literate', 'lm', 'localization', 'loki', 'loretta', 'lowly', 'lucid', 'lymphoma', 'makin', 'martini', 'merciful', 'mgm', 'midget', 'midwife', 'minimizing', 'mira', 'misinformation', 'mitochondrial', 'mobilization', 'monologue', 'monoxide', 'mosul', 'musically', 'mutiny', 'nagging', 'nephews', 'nervously', \"network's\", 'nighttime', 'nonlinear', 'normalized', 'northumberland', 'numbering', 'oakley', 'odi', 'orr', 'outweigh', 'parasitic', \"parent's\", 'parsley', 'pendulum', 'petit', 'petra', 'picket', 'placements', 'poignant', 'polio', 'potency', 'precarious', 'presley', 'pretext', 'privatization', 'proclaim', 'quaint', 'qualifiers', 'raccoon', 'raiding', 'rallied', 'reassurance', 'recovers', 'redistribution', 'remy', 'restrain', 'retreating', 'richly', 'rioting', 'rookies', 'sai', 'sanderson', 'saver', 'scarborough', 'scarred', 'secession', 'sectarian', 'seminal', 'serene', 'ses', 'seventies', 'shaded', 'sharpe', 'shipyard', 'shrek', 'sig', 'silica', 'simmer', 'smokey', 'snag', 'snuck', 'sob', 'socrates', 'sophistication', 'sourcing', 'str', 'straighten', 'streamlined', 'sweaters', 'syringe', 'tanaka', 'thinly', 'thursdays', 'timor', 'tinted', 'tornadoes', 'tote', 'trainees', 'transverse', 'trembling', 'triangles', 'tributes', 'trident', 'trojans', 'tweak', 'ubuntu', 'undead', 'unison', 'unlocking', 'unprepared', 'unrestricted', 'unsuitable', 'unthinkable', 'uplift', 'utilizes', 'vanderbilt', 'vanishing', 'venerable', 'visualize', 'vulcan', 'wasteful', 'waterfalls', 'wilkes', 'youngster', '😎', '6am', 'activating', 'adopts', 'adverts', 'advisable', 'algerian', 'angst', 'antiquities', 'apathy', 'arcs', 'artisan', \"association's\", 'assortment', 'attaching', 'auditing', 'bandwagon', 'bane', 'basins', 'bayer', 'bcs', 'billings', 'bios', 'birdie', 'bison', 'blacked', 'blacksmith', 'blanks', 'borg', 'brainwashed', 'brothel', 'burrito', 'bytes', 'calmed', 'camper', 'carole', 'cartilage', 'casket', 'charley', 'chattanooga', 'christchurch', 'claimants', 'cleanliness', 'clothed', 'coli', 'collided', 'commentaries', 'complicate', 'concerto', 'concurrently', 'contraception', 'convex', 'crouch', 'culmination', 'curing', 'd000', 'dank', 'daphne', 'decomposition', 'dehydrated', 'democracies', 'detriment', 'dex', 'dhs', 'dialects', 'discretionary', 'dismal', 'dismay', 'disparate', 'dissemination', 'distilled', 'dodger', 'dolan', 'dolores', 'domestically', 'electors', 'electrician', 'elise', 'endorsements', 'equator', 'estuary', 'etched', 'eternally', 'ewing', 'excise', 'expel', 'exposures', 'facets', 'fad', 'fiancée', 'fitch', 'fledged', 'fol', 'forcefully', 'foreground', 'frown', 'fruity', 'frustrations', 'fukushima', 'gals', 'germain', 'gertrude', 'gloucestershire', 'godly', 'golfers', 'graeme', 'groin', 'grounding', 'guangzhou', 'gunn', 'gunpowder', 'guthrie', 'guyana', 'hamper', 'haskell', 'hatched', 'helix', 'heroism', 'hierarchical', 'homie', 'hornets', 'hover', 'howling', 'humbled', 'icelandic', 'inducted', 'infidelity', 'internships', 'inventive', 'inversion', 'ips', 'kahn', 'keynes', 'khalifa', 'kinase', 'kirsten', 'knack', 'kodak', 'kool', 'kosher', 'lansing', 'lazarus', 'legalize', 'lehman', 'libby', 'librarians', 'licked', 'lillian', 'liquidation', 'longitude', 'lured', 'macho', 'maestro', 'magna', 'maneuvers', 'matilda', 'maxi', 'mcgill', 'mcgrath', 'meditate', 'mercenary', \"mexico's\", 'microscopy', 'missy', 'moi', 'morbid', 'motifs', 'multiplication', 'mysteriously', 'nadine', 'nav', 'nino', 'nonfiction', 'nouns', 'nuanced', 'occurrences', 'olympia', 'orb', 'orchestral', 'ordinarily', 'orthodoxy', 'outage', 'overcame', 'p2', 'packer', 'paternal', 'pellets', 'pelvis', 'penetrated', 'pla', 'plz', 'polarization', 'potty', 'powering', 'preoccupied', 'projectile', 'protracted', 'prussian', 'psychiatrists', 'puddle', 'quay', 'railing', 'realist', 'receptionist', 'reckoned', 'recruiter', 'reforming', 'reload', 'remuneration', 'replicated', 'repressed', 'reputed', 'resigning', 'restraints', 'revoke', 'richness', 'riviera', 's.a', 'sadie', 'scandinavia', 'scanners', 'secretive', 'sediments', 'serotonin', 'serviced', 'shorty', 'silky', 'sinatra', 'sirius', 'slaying', 'smallpox', 'snails', 'snoring', 'sociological', 'sorority', 'spd', 'sped', 'speechless', 'spores', 'spurred', 'stair', 'starship', 'stemming', 'strategist', 'sts', 'subaru', 'subdivisions', 'sunken', 'supremacist', 'tal', 'ter', 'toasted', 'tortoise', 'tragically', 'transitioning', 'translators', 'twenty00', 'typewriter', 'understandably', 'undisputed', 'unprofessional', 'urdu', 'uri', 'veggie', 'veiled', 'visceral', 'vividly', 'wannabe', 'welded', 'whaling', 'wiggle', 'wolfgang', 'worldview', 'wrongdoing', 'x1', 'zuckerberg', '═', 'a.j', 'abusers', 'accommodating', 'additives', 'aggregation', 'ahem', 'albanian', 'alistair', 'alkaline', 'alum', 'andré', 'antidote', 'anus', 'appalachian', 'archery', 'arterial', 'artisans', 'asparagus', 'athena', 'attest', 'attractiveness', 'auditors', 'auditory', 'avenge', 'aversion', 'awkwardly', 'badgers', 'balkans', 'ballard', 'balm', 'behaves', 'biennial', 'bikers', 'bologna', 'bolted', 'bona', 'bony', 'borrower', 'bridging', 'brighten', 'brood', 'budgeting', \"building's\", 'bulletproof', 'bundesliga', 'c4', 'cambodian', 'campers', 'cassandra', 'ceases', 'cecilia', 'cemented', 'cessation', 'charlottesville', 'charlton', 'charmed', 'chemists', 'chemo', 'chipped', 'civ', 'colby', 'collagen', 'combating', 'commencing', 'commend', 'complied', 'contemplated', 'cricketer', 'crimean', 'crochet', 'cruisers', 'csi', 'customization', 'cypress', 'dal', 'dandy', 'dependable', 'deteriorating', 'dickhead', 'disagrees', \"district's\", 'donny', 'downey', 'dresden', 'dw', 'eased', 'easing', 'eid', 'elevations', 'emeritus', 'emigration', 'emit', 'enthusiastically', 'excavated', 'excavations', 'excursions', 'extant', 'ezekiel', 'farmed', 'fathom', 'fiancee', 'fictitious', 'firsthand', 'fitzpatrick', 'flashy', 'floppy', 'fluoride', 'frat', 'gardeners', 'geologic', 'giggling', 'gillespie', 'gmo', 'goldstein', 'gospels', 'gowns', 'grasping', 'greenberg', 'grooves', 'guam', 'guantanamo', 'guideline', 'hadley', 'hawthorne', 'headmaster', \"heart's\", 'heartland', 'hedgehog', 'hehe', 'heinous', 'hens', 'hoe', 'hulu', 'hypnosis', 'iain', 'icu', 'immersive', 'impeccable', 'inbound', 'inconsistencies', 'inference', 'infiltrate', 'inflatable', 'ingrid', 'inhale', 'instinctively', 'interconnected', 'intolerant', 'isp', 'jellyfish', 'jimi', \"jordan's\", 'judo', 'karnataka', 'keane', 'keating', 'kev', 'kilos', 'kurdistan', 'lament', 'leach', 'lefty', 'legislatures', 'lsd', 'luigi', 'm4', 'mabel', 'mach', 'maddie', 'maids', 'malpractice', 'manipulative', 'marginally', 'marjorie', \"mark's\", 'mathews', 'maxine', 'mayweather', 'melinda', 'memberships', 'microbiology', 'migrating', 'modelled', 'modernity', 'motherfuckers', 'namibia', 'narrowing', 'navajo', 'nectar', 'neighbourhoods', 'nitrate', 'nvidia', \"o'malley\", 'oft', 'olympus', 'oversaw', 'pastel', 'patterned', 'payoff', 'perpetrated', 'pessimistic', 'pesticide', 'phosphorus', 'platter', 'pounded', 'preachers', 'premieres', 'prod', 'prodigy', 'prosecutions', 'prototypes', 'psychotherapy', 'pundits', 'quilt', \"qur'an\", 'radcliffe', 'rai', 'rama', 'rapping', 'realtor', 'rees', 'refreshed', 'regency', 'reptile', 'rescues', 'residues', 'revisited', 'robyn', 'rowling', 'sag', 'sama', 'sauna', 'scaring', \"scotland's\", 'scrum', 'seasonally', 'selena', 'sem', 'shan', 'sharper', 'shen', 'showcases', 'slade', 'sluggish', 'slum', 'smoothie', 'snare', 'snipers', 'snowflake', 'sod', 'spectra', 'spines', 'spoiling', 'ssr', 'stag', 'stomp', 'strangest', 'strata', 'straws', 'studded', 'submissive', 'subsection', 'suede', 'summertime', 'sundance', 'swedes', 'sylvester', 'tabloid', 'taft', 'taurus', 'teal', 'thorns', 'throwback', 'thunderstorm', 'tiers', 'timid', 'towering', 'tracts', 'triathlon', 'trickle', 'troupe', 'tsp', 'tweed', 'ultimatum', 'uncut', 'uninterrupted', 'vettel', 'webinar', 'weekdays', 'weinstein', 'widen', 'widest', 'wigs', 'workin', 'wrestlemania', 'xmas', 'yachts', 'yelp', 'yoon', '¦', '►', '👍', '5m', 'abt', 'aclu', 'affirmation', 'amassed', 'amherst', 'annette', 'aol', 'apc', 'apiece', 'appalled', 'appreciative', 'arched', 'archibald', 'ascend', 'bandage', 'bas', 'belize', 'biologists', 'bittersweet', 'blight', 'botswana', 'braid', 'branching', 'brewster', 'bulge', 'byrd', 'cabaret', 'camilla', 'caregivers', 'carmichael', 'catheter', 'centimeters', 'chemically', 'chewed', 'cinematography', 'cleans', 'coincidentally', 'collingwood', 'commandant', 'compartments', 'conducive', 'confines', 'cong', 'conscientious', 'consensual', 'consumes', 'contrasted', 'cpa', 'critiques', 'crystalline', 'cuffs', 'cyanide', 'deadpool', 'deceit', 'delusions', 'denounce', 'derogatory', 'diagnoses', 'discriminated', 'dismantle', 'dismantling', 'disrupting', 'dmv', 'dns', 'drags', 'drugged', 'durban', 'dx', 'eachother', 'eastward', 'elisabeth', 'emanuel', 'embroidery', 'emo', 'endorsing', 'enigma', 'equivalents', 'erdogan', 'estranged', 'euphoria', 'ez', 'fahrenheit', \"farmer's\", 'feelin', 'firewall', 'flattered', \"florida's\", 'fluorescence', 'fonts', 'forceful', 'forte', 'fours', 'frowned', 'gaelic', 'galveston', 'gangsters', 'gardiner', 'gibbons', 'giorgio', 'gladstone', 'gladys', 'gmbh', 'gogh', 'gracie', 'grassy', 'greener', 'greer', 'greta', 'hanger', 'hawking', 'hem', 'hitman', 'hitters', 'hobbs', 'housekeeping', 'hua', 'ifs', 'impacting', 'inequalities', 'infiltration', 'insidious', 'intimately', 'ioc', 'issa', 'jargon', 'joon', 'kayak', 'khaled', 'kilograms', 'kneel', 'knowles', 'ladders', 'lakh', 'leakage', 'liberate', 'lizards', 'loc', 'logistical', 'loophole', 'luminous', 'mah', \"majesty's\", 'malnutrition', 'maori', 'marlins', 'marseille', 'marshals', 'masterpieces', 'mathematician', 'mayonnaise', 'mccall', 'mcdonnell', 'mcdowell', \"media's\", 'meghan', 'melodic', 'memorials', 'mendoza', 'meticulous', 'michelin', 'modesty', 'motherfucking', 'moustache', 'mubarak', 'muffins', 'mugs', \"museum's\", 'naw', 'netting', 'nevermind', 'nf', \"nigeria's\", 'nigh', 'nocturnal', 'nozzle', 'nudes', \"officer's\", 'offside', 'orgy', 'orton', 'overlay', 'paleo', 'paralympic', 'pastures', 'paternity', 'patriarchal', 'peeing', 'peeling', 'perched', 'pitiful', \"planet's\", 'plethora', 'plutonium', 'powerpoint', 'prerequisite', 'psychosis', 'quantify', 'rabies', 'rallying', 'rations', 'raul', 'recon', 'recount', 'rectangle', 'recurrent', 'refill', 'reflexes', 'reinforces', 'religiously', 'relive', 'renewing', 'reopening', 'requisite', 'responsibly', 'resurrected', 'reuben', 'revolve', 'rewind', 'rightfully', 'rigs', 'ripley', 'ritz', 'rolf', 'rubs', 'russo', 's000', 'saddened', 'saddest', 'secluded', 'seduce', 'semifinal', 'sens', 'shadowy', 'shun', 'sidekick', 'skewed', 'snl', 'softened', 'soros', 'spartans', 'specifies', 'spectre', 'sprinkled', 'stallion', 'stepfather', 'strangled', \"summer's\", 'susie', 'sven', 'syllables', 'synthesized', \"t's\", 'tak', 'tapestry', 'taping', 'tenderness', 'terrier', 'tester', 'thirties', 'thistle', 'thumbnail', 'tickle', 'titties', 'toro', 'tpp', 'trays', 'tubular', 'tue', 'tumbling', 'turkeys', 'underside', 'uneducated', \"union's\", 'unload', 'unloading', 'unmarked', 'unreleased', 'upkeep', 'urn', 'v6', 'viagra', 'vigil', 'voicing', 'volley', 'voyages', 'waive', 'wallis', 'warmly', 'watergate', 'wavy', 'wednesdays', 'weibo', 'wendell', 'wept', 'whew', 'whirlwind', 'whitaker', 'wilbur', 'wildest', 'winnings', 'wis', 'woodlands', 'ww2', 'yearning', '1pm', '7am', 'accomplishing', 'accumulating', 'affleck', \"agency's\", 'alain', 'andrei', 'annapolis', 'annum', 'appreciating', 'aristocratic', 'aroma', 'arsenic', 'assigns', 'assures', 'astro', 'asus', 'aziz', 'backers', 'bain', 'barclays', 'basing', 'batches', 'beggars', 'bestselling', 'biographies', 'biologically', \"bird's\", 'bowled', \"boyfriend's\", 'bubbling', 'budge', 'bw', 'calhoun', 'ccp', 'chaplin', 'cheater', 'cheeses', 'clegg', 'cloning', 'clout', 'cochran', 'comical', 'commemorative', 'confederacy', 'converge', 'copeland', 'corny', 'countrymen', \"couple's\", 'crucible', 'cryptic', 'culminated', 'curses', 'darth', 'deb', 'declarations', 'deities', 'deletion', 'diligent', 'discern', 'dislikes', 'domino', 'donnelly', 'downgrade', 'dreamy', 'drenched', 'droid', 'dukes', 'dummies', 'dunbar', 'dung', 'dyson', 'earners', 'eel', 'eiffel', 'embryonic', 'emoji', 'encountering', 'endanger', 'eos', 'equities', 'fakes', 'fanatic', 'fav', 'feats', 'filmmaking', 'firmware', 'formulate', 'forts', 'fragmentation', 'franks', 'frederic', 'ftc', 'gated', 'girly', 'glam', 'glorified', 'goth', 'gracefully', 'gubernatorial', 'gunmen', 'hahahaha', 'hawthorn', 'healy', 'hermann', 'herr', 'hf', 'hg', 'hoard', 'horde', 'humming', 'ignited', 'imdb', 'imp', 'implicitly', 'inconsistency', 'ingenuity', 'injecting', 'inorganic', 'intestine', 'isolating', 'itinerary', 'juggling', 'justifies', 'kkk', 'koran', 'lacy', 'lair', 'lamborghini', 'lambs', 'leaping', 'liberating', 'lifeless', 'lifeline', 'lobbyists', 'looms', 'lotto', 'lovable', \"love's\", 'luka', 'lukas', 'lyndon', 'lynne', 'macarthur', 'mam', 'mani', 'mari', 'marino', 'mateo', 'messes', 'metaphors', 'miliband', 'molded', \"monday's\", 'moot', 'mortimer', 'msc', 'musicals', 'myles', 'nebula', 'neurology', 'newt', 'nguyen', 'nietzsche', 'nitro', 'noaa', 'norse', 'notebooks', 'nyt', 'odin', 'oj', 'ost', 'overflowing', 'overland', 'overshadowed', 'p1', 'pantry', 'paraguay', 'parchment', 'partake', 'pedals', 'pesos', 'peterborough', 'philosophies', 'pj', 'plagiarism', 'poked', 'polk', 'pollard', 'polled', 'pollock', 'prefix', 'proctor', 'prologue', 'proto', 'psp', 'pueblo', 'pulpit', 'puncture', 'pussies', 'qa', 'recounts', 'redhead', 'relational', 'remastered', 'renegade', 'resorted', 'ripper', 'robson', 'roofing', 'rotational', 'rudd', 'ryu', 's5', 'safeguarding', 'sash', 'scrambling', 'scully', 'seductive', 'sega', 'segmentation', 'sergey', 'shaker', 'shielding', 'shone', 'sissy', 'sizeable', 'sled', 'sloane', 'sludge', 'sniffing', 'sorrows', 'spamming', 'speedway', 'spiked', 'spongebob', 'sprouts', 'staffers', 'staffs', 'stiles', 'stretcher', 'stricter', 'subtitle', 'summarize', 'sympathies', 'taker', 'telescopes', 'tess', 'threaded', 'tong', 'torturing', 'townships', 'transplantation', 'triad', 'trimming', 'truthfully', 'unfounded', 'unicef', 'unimportant', 'uninsured', 'untitled', 'uw', 'uzbekistan', 'valor', 'vape', 'vernacular', 'virtuous', 'vox', 'vulnerabilities', 'waffles', 'waiters', 'waivers', 'warcraft', 'watercolor', 'wight', 'wolff', 'worded', 'wto', \"y'know\", '2am', '3b', 'abrasive', 'accompaniment', 'accomplice', 'adoptive', 'ailments', 'alphabetical', 'alternately', 'analysing', 'annihilation', 'arbitrarily', 'armistice', 'armory', 'ars', 'att', 'auspices', 'awakens', 'bathe', 'beheaded', 'bellevue', 'bloomington', 'boasted', \"bob's\", 'boroughs', 'breathed', 'brodie', 'calamity', 'carbonate', 'carlyle', 'carmel', 'catalytic', 'cemeteries', 'ceylon', 'chases', 'cheerleaders', 'cheesecake', 'choral', 'chronology', 'clam', 'clientele', 'coefficients', 'coldest', 'colouring', 'combatants', 'competes', 'configured', 'conflicted', 'convection', 'coronavirus', 'cosby', 'craftsman', 'creams', 'cretaceous', 'cripple', 'crooks', 'crunchy', 'ctrl', 'curvature', 'cyborg', 'dares', 'deflection', 'despised', 'dialogues', 'discouraging', 'distillery', 'diversification', 'djokovic', 'doesn', 'drumming', 'drummond', 'e000', 'effortlessly', 'eighties', 'ein', 'enactment', 'enlighten', 'envious', 'erm', 'erroneous', 'exacerbated', 'familial', 'farage', 'fashions', 'feces', 'federer', 'filings', 'fishery', 'folders', 'frazier', 'frivolous', 'fruition', 'fuji', 'fullback', 'gage', 'galley', 'galway', 'gators', 'giddy', 'gpu', 'granada', 'grandeur', 'grappling', 'grover', 'gunshots', 'hamid', 'handlers', 'hanks', 'haunts', 'heinz', \"henry's\", 'hentai', 'hodgson', 'homogeneous', 'hye', 'ich', 'ina', 'incl', 'inserts', 'intangible', 'interceptions', 'intestines', 'inventors', 'ire', 'jesuit', 'justine', \"kelly's\", 'kiddo', 'kimmel', 'knuckle', 'kt', 'landscaping', 'laureate', \"law's\", 'lds', 'lear', 'lesley', 'leveling', 'levied', 'lineman', 'litres', 'lodges', 'madman', 'maniac', 'manifestations', 'mavericks', 'mcnamara', 'medalist', 'melee', 'melo', 'melville', 'memorize', 'mendes', 'menstrual', 'merch', 'metallica', 'metaphysical', 'meteorology', 'methyl', 'mindless', 'misconception', 'mislead', 'momentarily', 'mounds', 'nadu', 'narcissistic', 'negotiable', \"neighbor's\", 'nicknames', 'nom', 'northward', 'norwood', 'nudge', 'nurturing', 'nyse', 'obscured', 'osu', 'outlawed', 'ovens', 'overturn', 'padded', 'padres', 'panicking', 'pantheon', 'payer', 'pictorial', 'pints', 'ploy', 'pours', 'prejudices', 'presumption', 'proclaiming', 'prospectus', 'prosthetic', 'pty', \"public's\", 'puma', 'racers', 'reactionary', 'reciprocal', 'reconstruct', 'redwood', 'regan', 'relieving', 'reverence', 'richter', 'rims', 'sabine', 'saigon', 'santana', 'scrubs', 'seaweed', 'seduction', 'selfishness', 'serge', 'servicemen', 'setbacks', 'sevens', 'sewers', 'sexiest', \"shakespeare's\", 'shaman', 'shatter', 'shepherds', 'shoving', 'signify', 'sinn', 'sino', 'sketchy', 'smuggled', 'snowfall', 'southbound', 'specificity', 'squirt', 'ste', 'stewardship', 'stitched', 'stoppage', 'storylines', 'straining', 'stu', 'superpower', 'suspensions', 'synergy', 'takers', 'tasmanian', 'tempt', 'terminating', 'terri', 'testifying', 'thermometer', 'thingy', 'timberlake', 'tint', 'tomlinson', 'toulouse', 'triumphs', 'unbroken', 'unsettled', 'unveiling', 'uttar', 'versed', 'vicki', 'vlad', 'vm', 'weiner', 'wharton', 'whiff', 'whopping', 'wilt', 'woodstock', 'youtubers', 'zachary', 'zhao', 'absurdity', 'achievable', 'adversaries', 'alchemy', \"amazon's\", 'ambushed', 'americana', 'anastasia', 'anatomical', 'antigen', 'apostolic', 'applauded', 'ara', 'aristocracy', 'armchair', 'aryan', 'aswell', 'aunts', 'b2b', 'babysitter', 'babysitting', 'backlog', \"bbc's\", 'bengali', 'bile', 'biochemical', 'bled', 'bling', 'boca', 'boner', 'bose', 'botched', 'bouts', 'bradshaw', 'brandt', 'brownie', 'bunnies', 'c1', 'c2', 'calibre', 'caliphate', \"captain's\", 'captives', 'carcass', 'cardigan', 'carousel', 'cartwright', 'chico', 'chihuahua', 'christi', 'circumcision', 'clandestine', 'clarifying', 'clutter', 'commuters', 'complying', 'compost', 'condemns', 'congratulated', 'conqueror', 'cot', 'coulson', 'crafty', 'crickets', 'croydon', 'crusader', 'cumming', 'cutoff', 'debacle', 'defiant', 'deformed', 'detain', 'diagnostics', 'directives', 'disarm', 'doherty', 'domingo', 'dominique', 'drawback', 'drawbacks', 'drs', 'edm', 'edo', 'elliptical', 'eloquent', 'eminence', 'emitting', 'emperors', 'entail', 'equatorial', 'eras', 'esports', 'eth', 'ethereum', 'eyeballs', 'fairytale', 'fallacy', 'feeble', 'fend', 'ferocious', 'fifties', 'filipinos', 'flake', \"ford's\", 'forensics', 'forwarding', 'fragrant', 'gallant', 'gazing', 'gd', 'generalization', 'genitals', 'geologist', 'goldsmith', 'golfing', 'goons', 'guesses', 'gums', 'haas', 'halle', 'hana', 'handcuffs', 'harmon', 'hasan', 'herds', 'hermit', 'hillsborough', 'hindered', 'hookers', 'horsemen', 'hui', 'hutton', 'ign', 'illuminating', 'indebted', 'indecent', 'inquest', 'interacts', 'interfered', 'ionic', 'ipl', 'jennie', 'jerking', 'jingle', 'johansson', 'kali', 'kilometre', 'kink', 'kira', 'lagging', 'laguna', 'lawns', 'leighton', 'leopold', 'levant', 'lice', 'loco', 'looted', 'lorry', 'loudest', 'lovin', 'macleod', 'magnolia', 'marlon', 'matty', 'mauritius', 'medial', 'mellon', 'mercantile', 'migratory', 'mingle', 'modernist', 'moths', 'mover', 'movers', 'nee', 'nomenclature', \"opponent's\", 'organisers', 'outback', 'outcry', 'p.a', 'pamphlets', 'panoramic', 'paparazzi', 'parkinson', 'pauses', 'pave', 'peng', 'philanthropic', 'playhouse', 'plow', 'prada', 'preferential', 'prescribing', 'primetime', 'probing', 'proc', 'prolong', 'propane', 'publicized', 'purest', 'pvc', 'q1', 'qt', 'queues', 'ramadan', 'rambling', 'ras', 'recruiters', 'redirect', 'redmond', 'relentlessly', 'remanded', 'reusable', 'revolutionaries', 'rin', 'robberies', 'rowdy', 'saffron', 'salford', 'sassy', 'schoolboy', 'schumacher', 'scoreboard', 'scotty', 'seeding', 'sender', 'seneca', 'septic', 'shamed', 'shenanigans', 'silas', 'skateboard', 'skiers', 'slider', 'smacked', 'smiths', 'soma', 'someones', 'ssd', 'staggered', 'staining', 'stalked', 'stemmed', 'stipulated', 'substrates', 'subversive', 'sufferers', 'suggestive', 'suitability', 'superstition', 'surfers', 'swallows', 'swanson', 'symmetric', 'synonyms', 'takin', 'theses', 'tic', 'timeout', \"tom's\", 'tome', 'tonne', 'totalitarian', 'tramp', 'transistor', 'translucent', 'trashed', 'trot', \"turkey's\", 'unbalanced', 'unfavorable', 'unintentionally', 'uniqueness', 'upto', 'vertebrae', 'vertex', 'vowels', 'vuitton', 'wheeling', 'whistling', 'wield', 'woodwork', 'yall', 'yellowish', 'youll', 'yt', 'accompanies', 'acidity', \"adam's\", 'ado', 'affirm', 'agrarian', 'airy', 'akira', 'alaskan', 'alfie', 'alloys', 'andhra', 'anecdote', 'anew', 'ani', 'antifa', 'antwerp', 'appease', 'aptitude', 'arisen', 'assassinate', 'asteroids', 'b1', 'backside', 'bassist', 'bein', 'bespoke', 'blatantly', 'blinding', 'blocker', 'blowout', 'booted', 'brisk', 'bubbly', 'bummer', 'bundy', 'c000', 'c0000', 'canceling', 'cao', 'casper', 'cauliflower', 'cebu', 'celia', 'cereals', 'chadwick', 'chainsaw', 'chalmers', 'channing', 'cheetah', 'christensen', 'climatic', 'clockwise', 'clockwork', 'coincides', 'como', 'conformity', 'confronts', 'consort', 'correlate', 'cougars', 'courteous', 'craftsmen', 'crete', 'criticise', 'cupid', 'curiously', 'damning', 'danes', 'darrell', 'defer', 'deforestation', 'delaney', 'demeanor', 'deng', 'deplorable', 'deranged', 'detergent', 'detour', 'dg', 'dhaka', 'diff', 'dissenting', 'distressing', 'docked', 'downtime', 'downwards', 'dries', 'dutton', 'enlarge', 'enlargement', 'equate', 'equestrian', 'ethereal', 'eurovision', 'expanse', 'f000', 'fabio', 'faiths', 'fanatics', 'fanfare', 'favorably', 'fidel', 'fingernails', 'fireman', 'flaps', 'flask', 'fluff', 'fondly', 'footnotes', 'fremont', 'frosty', 'galileo', 'gatsby', 'gearbox', 'germ', 'gis', 'giver', 'gnome', 'guaranteeing', 'gunpoint', 'hades', 'handedly', 'har', 'harcourt', 'harlan', 'haute', 'heartache', 'hertfordshire', 'homeowner', 'hooray', 'huskies', 'hypotheses', 'imitating', 'imposes', 'individuality', 'infiltrated', 'insurgent', 'intertwined', 'inventories', 'iranians', \"italy's\", 'jails', 'janitor', 'judgmental', 'lange', 'lanterns', 'launchers', 'legislator', 'lien', 'limousine', 'linden', 'lithuanian', 'lotta', 'lupus', 'lyme', 'lymph', 'm8', \"macy's\", 'mahal', 'mansions', 'manure', 'mariah', 'mccormick', 'meatballs', 'meningitis', 'meteorite', 'midfielders', 'mildred', 'militias', 'millie', 'milne', 'misogyny', 'mrna', 'multiplier', 'nehru', 'newbie', 'newtown', 'nominating', 'northbound', 'oblique', 'obscurity', 'odessa', 'okinawa', 'onslaught', 'opal', 'operas', 'organisational', 'oxfordshire', 'palsy', 'paralympics', 'paramilitary', 'partridge', 'patrolling', 'patti', 'payers', 'permissible', \"phone's\", 'platonic', 'polka', 'primates', \"project's\", 'q2', 'rancho', 'rattling', 'rca', 'realisation', 'recapture', 'recounted', 'recurrence', 'referrals', 'refinement', 'regis', 'relocating', 'reparations', 'repel', 'researches', 'resigns', 'revamp', 'rockwell', 'rodent', 'rohan', 'rudder', 'ruiz', 'rung', 'salah', 'satisfies', 'scraped', 'seaman', 'sensibility', 'sevilla', 'shielded', 'showered', 'sizing', 'skier', 'skyscraper', 'slabs', 'slumber', 'slums', 'sockets', 'spiderman', 'sprays', 'staunch', 'stiffness', 'stuttgart', 'swayed', 'swoop', 'synchronized', 'tahoe', 'tallahassee', 'telly', 'tentacles', 'terence', 'therapeutics', 'thom', 'tia', \"time's\", 'topology', 'transatlantic', 'tunisian', 'tutoring', 'ugandan', 'uncontrolled', 'undecided', 'unparalleled', 'unsolicited', 'unveil', 'unworthy', 'utensils', 'vaults', 'vids', 'vocation', 'volts', 'waged', 'walden', 'warmest', 'wentworth', \"when's\", 'whoop', 'williamsburg', 'winslow', 'x000', 'zu', '♥', '👀', '🙄', '2c', '2s', 'abbreviated', 'admirer', 'aerobic', 'aerodynamic', 'aesthetically', 'agitation', 'agreeable', 'airway', 'alessandro', 'alfonso', 'algebraic', 'amaze', 'analyzes', 'artefacts', 'assertive', 'assimilation', 'augment', 'avalon', 'b2', 'bachelors', 'backseat', 'balkan', 'barclay', 'baseman', 'batted', 'beale', 'beatty', 'bernardino', 'bernardo', 'bitching', 'bosnian', 'bragg', 'brainer', 'breakaway', 'breakdowns', 'breathless', 'briefed', 'brownies', 'browsers', 'brunei', 'bst', 'cabs', 'captions', 'carefree', 'caricature', 'carton', 'cayman', 'celeste', 'cert', 'ces', 'chandelier', 'chandra', 'chests', 'chute', 'cir', 'cliché', 'clipping', 'clot', 'comets', \"commission's\", 'companionship', 'complacent', 'complicit', 'concentrates', 'confer', 'contractions', 'coolant', 'copyrighted', 'corbett', 'counteract', 'courtship', 'crammed', 'craven', 'csr', 'cumbria', 'cushions', 'daley', 'debilitating', 'deepen', 'deepening', 'dependencies', 'deprive', 'derry', 'destroyers', 'devise', 'devotees', 'directories', 'disclosing', 'discrepancies', 'disparities', 'downturn', 'drier', 'duane', 'dystopian', 'efficiencies', 'electrically', 'elmer', 'ely', 'embodies', 'enclave', 'entourage', 'epoch', 'evo', 'exaggerate', 'exaggerating', 'excelled', 'extinguished', 'faber', 'farts', 'fated', 'femme', 'fibres', 'fibrosis', 'fielder', 'foggy', 'forgery', 'fremantle', 'frequented', 'functionally', 'furiously', 'gaping', 'gator', 'gentry', 'germanic', 'gigi', 'gimmick', 'gladiator', 'glendale', 'glimpses', 'glittering', 'glossary', \"grandmother's\", 'gregor', 'grinning', 'grizzlies', 'groundwork', 'gymnasium', 'hammering', 'harrisburg', 'hays', 'henley', 'hounds', \"house's\", 'implementations', 'imposition', 'impromptu', 'indulgence', 'intersect', 'invasions', 'iodine', 'jameson', 'johannes', 'johnstone', 'jos', 'josef', 'keel', 'kilometer', 'kingsley', 'kk', 'kruger', 'labourers', 'leland', 'lemme', 'lettering', 'lewd', 'lifeboat', 'liters', 'liturgy', 'livin', 'llp', 'lockhart', 'longstanding', 'lumps', 'madeline', 'magma', 'mammalian', 'marbles', 'marcia', 'milking', 'millennia', 'milner', 'miraculously', 'molding', 'mortals', 'motorbike', \"mum's\", 'mustafa', 'nodding', 'nonexistent', 'notoriety', 'nuclei', 'nutty', 'oa', 'obedient', 'oculus', 'ogden', 'orgasms', 'originates', 'ornate', 'ousted', 'palpable', 'paramedic', 'patched', 'perk', 'perpetuate', 'perverse', 'perverted', 'peta', 'philharmonic', 'photographing', 'photons', 'playlists', 'plume', 'plump', 'prequel', \"prince's\", 'prophetic', 'provocation', 'pumpkins', 'purified', 'radiology', 'raffle', 'ragged', 'rainbows', 'recoil', 'recorders', 'redo', 'rejoin', 'relays', 'remission', 'renounce', 'repentance', 'resonate', 'restitution', 'reviving', 'rewritten', 'riddled', 'ridiculed', 'romo', 'rotations', 'rotterdam', 'roxy', 'rugs', 'sacrament', 'sauces', 'scholastic', 'scourge', 'seville', 'shopper', 'shrub', 'shu', 'signage', 'skis', 'slag', 'sluts', 'sneeze', 'soaps', 'sobriety', 'som', 'songwriting', 'sorely', 'sprawling', 'sprinter', 'sprite', 'stagnation', 'stead', 'stinks', 'structurally', 'suez', 'sulfate', 'sumner', 'sv', 'swag', 'sweatshirt', 'tangent', 'tenn', 'tg', 'tori', 'touted', 'tracer', 'transporter', \"tuesday's\", 'turing', 'undergoes', 'unearthed', 'uniformly', 'unqualified', 'unquestionably', 'unravel', 'variously', 'vests', 'veterinarian', 'vidal', 'viet', 'viz', 'warms', 'wasteland', 'watchdog', 'watery', 'wavelengths', 'weasel', 'westfield', 'whips', \"why'd\", 'workplaces', 'yukon', 'zeke', 'zest', 'zoology', 'zulu', '😁', '5a', 'aborted', 'absorbs', 'abstinence', 'academically', 'activates', 'adjectives', 'adm', 'adventurer', 'adventurers', 'aeroplane', 'alcoholics', 'allege', 'alton', 'andromeda', 'announcers', 'arduous', 'asher', 'attaining', 'avi', 'bachelorette', 'bagel', 'bagged', 'bai', 'bangor', 'barometer', 'basque', 'bavaria', 'bbw', 'biggie', 'bigot', 'bit.ly', 'boa', 'branched', \"brazil's\", 'britannia', 'britt', 'bruise', 'bruising', 'bucharest', 'buffett', 'bullion', 'bumpy', 'bums', 'bureaucrats', 'burnham', 'byu', 'cahill', 'carp', 'castor', \"center's\", 'challengers', 'charting', 'cicero', 'circumference', 'classifications', 'cleopatra', 'cleverly', 'clocked', 'coasters', 'codex', 'collars', 'composure', 'computerized', 'concur', 'conte', 'conveying', 'cornered', 'cowan', 'craziest', 'crowe', 'davy', 'defying', 'delicacy', 'demolish', 'dempsey', 'deport', 'dictators', 'dictionaries', 'dilute', 'disabling', 'disillusioned', 'dispersion', 'doha', 'doomsday', 'draped', 'drinker', 'eels', 'emil', 'emphasised', 'entangled', 'enzo', 'exploratory', 'facet', 'fates', 'fei', 'fermented', 'ferries', 'finesse', 'fireball', 'firth', 'flannel', 'floss', 'foresee', \"foundation's\", 'frantically', 'frees', 'fringes', 'gaston', 'genoa', 'geothermal', 'gh', 'gist', 'github', 'grievous', 'gustav', 'handbags', 'handkerchief', 'hari', 'heaters', 'hebrews', 'hepburn', 'heres', 'hogwarts', 'hookup', 'hopelessly', 'horticulture', 'howl', 'huddersfield', 'hydration', 'ibiza', 'improv', 'impunity', 'indexing', 'infertility', 'informational', 'inline', 'insolvency', 'intermediary', 'interrogated', 'ives', 'jody', 'jokingly', 'josie', 'juveniles', 'karim', 'kimi', 'kinks', 'klan', 'kristina', 'laughable', 'lennox', \"lion's\", 'lng', 'locus', 'lucius', 'lund', 'lvl', 'makeshift', 'marquee', 'massey', 'masturbate', 'mathematically', 'matrices', 'mckinley', 'meade', 'melanoma', 'menacing', 'microbes', 'midterms', 'mobilize', 'monsanto', 'moors', 'morley', 'msu', 'nag', 'nativity', 'neglecting', 'nook', 'novo', 'nutritious', 'overdrive', 'padding', 'panasonic', 'pant', 'passover', 'peking', 'penitentiary', 'perilous', 'periodicals', 'pharmacies', 'picard', 'pikachu', 'plaques', 'plastered', 'playa', 'plucked', 'polytechnic', 'popularly', 'pornographic', 'posse', 'prepping', \"program's\", 'rankin', 'rebates', 'recognises', 'recognising', 'reconciled', 'refrigeration', 'refunded', 'rename', 'repulsive', 'respite', 'ret', 'revamped', 'revising', 'rhinos', 'rockin', 'rts', 'saber', 'sadistic', 'samba', 'scorers', 'sewn', 'shaggy', 'shelling', 'shouldnt', 'shrunk', 'sitter', 'sixers', 'slant', 'slashed', 'sleepless', 'slur', 'snowball', 'sobs', 'soles', 'soothe', 'souvenirs', 'spelt', 'stalling', 'stamping', 'steiner', 'strasbourg', 'streamline', 'suckers', 'sulphur', 'swears', 'tablespoons', 'tacky', 'tamara', 'tampering', 'tankers', 'telephones', 'terminus', 'tessa', 'testicles', 'texan', 'thaw', 'throughput', 'timelines', 'tolkien', 'tout', 'transnational', 'tripod', 'tulip', 'turnpike', 'ud', 'ulysses', 'unattended', 'unbeatable', 'undertaker', 'uniformed', 'unionists', \"united's\", 'unloaded', 'ursula', 'usps', 'uttered', 'vulture', 'wares', 'waterway', 'whistleblower', 'wv', 'xanax', 'xs', 'yves', '4d', 'absentee', 'accolades', 'admirers', 'alden', 'aldo', 'alyssa', 'amin', 'anarchists', 'anecdotal', 'anemia', 'animosity', 'appoints', 'autoimmune', 'aws', 'b000', 'bakers', 'bama', 'barons', 'battalions', 'beggar', 'bertrand', 'bismarck', 'bombarded', 'boulders', 'bounces', 'bouncy', 'buick', 'burbank', 'busts', 'calibrated', 'callahan', 'canteen', 'capacitor', 'captivating', 'carbohydrate', 'cartels', 'cavalier', 'centrist', 'cfa', 'chakra', 'chatted', 'chauffeur', 'childs', 'circled', 'circulate', 'clergyman', 'climber', 'clinched', 'clutching', 'coliseum', 'combs', 'commandment', 'complimented', 'conceivable', 'concordia', 'condone', 'congested', 'connectors', 'conner', 'consecrated', 'contaminants', 'contiguous', 'conveys', 'cosmo', 'councilman', 'cranberry', 'criticizes', 'croft', 'custard', 'darby', 'deceiving', 'defaults', 'definitively', 'deflect', 'deliberations', 'denoted', 'departs', 'deregulation', 'desolate', 'devour', 'digger', 'disarmament', 'disgraced', 'dishonesty', 'divergence', 'dmitry', 'domesticated', 'dorian', 'doubly', 'doughnut', 'douglass', 'dubois', 'duluth', 'dwarfs', 'eastenders', 'ek', 'elgin', 'embody', 'enrolling', 'envision', 'equivalence', 'erika', 'ers', 'eruptions', 'esoteric', 'eurozone', 'euthanasia', 'fabian', 'faye', 'fd', 'felon', 'flammable', 'flanagan', 'footnote', 'fostered', 'fp', 'friggin', 'frontman', 'furthest', 'garnet', 'glanced', 'goku', 'gorman', 'grapefruit', 'grate', 'greyhound', 'grossed', 'guerrero', 'guido', 'gyms', 'hahn', 'hairdresser', 'hardness', \"harper's\", 'haryana', 'helpers', 'hendricks', \"hero's\", 'hess', 'hh', 'hilly', 'hogs', 'hone', 'horne', 'hotspot', 'howie', 'humbly', 'huron', 'hw', 'hyatt', 'inciting', 'incomprehensible', 'incumbents', 'inertia', 'infestation', 'insurrection', 'intolerable', 'ironman', 'isla', 'jordanian', 'juno', 'kershaw', 'koh', 'lamont', 'larkin', 'lauded', 'laziness', 'leech', 'lei', 'libs', 'macquarie', 'madly', 'meetup', 'milano', 'minimise', 'miserably', 'moldova', 'mor', 'motivates', 'motorsport', 'mustered', 'mutilation', 'nemo', 'nerdy', 'nifty', 'nikita', 'orphaned', 'ova', 'paces', 'paine', 'palladium', 'parmesan', 'particulars', 'passer', 'pathogen', 'pci', 'pebbles', 'pelicans', 'pensioners', 'personalised', 'piazza', 'pickled', 'policymakers', 'pom', 'possessive', 'pranks', 'prefecture', 'pretentious', 'pritchard', 'promenade', 'pronoun', 'proximal', 'rapport', 'rapture', 'ration', 'ravaged', 'reconnect', 'rectify', 'reginald', 'rivalries', 'rudimentary', 'sabres', 'salle', 'sayings', 'scariest', 'schumer', 'screenwriter', 'seconded', 'seduced', 'seine', 'selector', 'shawl', 'shenzhen', 'shilling', 'shroud', 'shutters', 'sj', 'skim', 'slaps', 'slovak', 'sn', 'solicitation', 'sooooo', 'specifying', 'starboard', 'stardust', 'stereotypical', 'stewards', 'stupidest', 'superseded', 'surpassing', 'swirling', 'sy', 'tarzan', 'teas', 'telugu', 'timbers', 'tormented', 'traumatized', 'twinkle', 'tyne', 'uncharted', 'unforeseen', 'unsigned', 'unspoken', 'upholding', 'ux', 'valet', 'vehemently', 'vendetta', 'voss', 'w00', 'weakly', \"west's\", 'westchester', 'wiener', 'wildcard', 'wildfires', 'yorkers', 'ツ', '3k', '4x', '4x4', '5am', '5g', \"abc's\", 'accommodated', 'affordability', 'agatha', 'aladdin', 'alderman', 'alienation', 'altitudes', 'amor', 'amplify', 'anorexia', \"another's\", 'anthropologist', 'antidepressants', 'apologizes', 'astronomer', 'atl', 'attested', 'attrition', 'aud', 'aunty', 'autopilot', 'baggy', 'bailout', 'balfour', 'ballads', 'ballast', 'berman', 'bigfoot', 'biotech', 'blackjack', 'bloodstream', 'bluegrass', 'bordered', 'bottling', 'brasil', 'brigham', 'budgetary', 'bustling', 'camo', 'capitalized', 'carers', 'carte', 'cavendish', 'celine', 'cheerleading', 'chipping', 'cliche', 'clutches', 'cockroach', 'collaborator', 'colton', 'composites', 'consolidating', 'contends', 'contradicts', 'cortez', 'cpc', 'crossfit', 'cumbersome', 'curt', 'cyclic', 'cyclical', 'dade', 'deducted', 'deformation', 'descends', 'devotional', 'dicaprio', 'distinguishes', 'diversify', 'downloadable', 'dum', 'duplication', 'dynamo', 'eastman', 'ei', 'elixir', 'embarking', 'emile', 'emmett', 'endgame', \"enemy's\", 'enhancements', 'epiphany', 'escobar', 'evolves', 'eyeing', 'eyelids', 'eyeliner', 'fable', 'farah', 'fatality', 'favoring', 'fenced', 'ffa', 'firewood', 'foothills', 'foresight', 'forsaken', 'forsyth', 'fundamentalist', 'fw', 'g2', 'gabby', 'gaddafi', 'gayle', 'geniuses', 'ghostbusters', 'greenfield', 'greensboro', 'groomed', 'h2o', 'hackney', 'hamstring', 'heidelberg', 'hl', 'hordes', 'horseshoe', 'ico', 'imran', 'incision', 'indistinguishable', 'infer', 'inpatient', 'inspecting', 'intensify', 'invitational', 'ithaca', 'ito', 'j.p', 'jarrett', 'jiang', 'kano', 'kennel', 'kern', \"khan's\", 'khmer', 'kl', 'knitted', 'lager', 'laird', 'letterman', 'lighted', 'loathing', 'lorde', 'loyalists', 'mahmoud', 'manhood', 'martyrdom', 'mcdermott', 'mcmillan', 'menopause', 'meryl', 'michelangelo', 'misconceptions', 'mobs', 'mol', 'mortem', 'motherboard', 'moyes', 'msg', 'mussolini', 'mutilated', 'napkin', \"navy's\", 'nelly', 'neuron', 'nev', 'niall', 'nigerians', 'nuances', 'nugget', 'ono', 'opus', 'orchards', 'otc', 'outlaws', 'ovaries', 'overtly', 'painless', 'paxton', 'pears', 'perpetually', 'pharmacists', 'photoshopped', 'pitted', 'pixar', 'pleads', 'poisons', 'politico', 'prenatal', 'probabilities', 'probate', 'procure', 'propel', 'propensity', 'pryor', 'punjabi', 'purchasers', 'pvt', 'q3', 'qld', 'rattled', 'rbs', 'realises', 'receptions', 'remodeling', 'renters', 'resorting', 'retreats', 'rg', 'ringo', 'roadmap', 'roberta', 'rockford', 'rosary', 'rundown', 'ruptured', 'ruse', 'salvatore', 'sampson', 'sar', 'saudis', 'seniority', 'severance', 'sheath', 'shillings', 'shortcuts', 'shorthand', 'shortlisted', 'shreds', 'shrines', 'singularity', 'snowman', 'socialize', 'soundcloud', \"spain's\", 'sparta', 'spinoff', 'sportsman', 'springsteen', 'squarely', 'stalks', 'stepmother', 'storming', 'strippers', 'strut', 'succumbed', 'swagger', 'swirl', 'telecommunication', 'temptations', 'theorist', 'theta', 'thi', 'thong', 'thrills', 'thumping', 'timeframe', 'tk', 'tod', 'tot', 'transcribed', 'tropics', 'tsar', 'tycoon', 'unconditionally', 'uncontrollable', 'undeniably', 'unfolded', 'unorthodox', 'uproar', 'vertigo', 'vigilance', 'viscount', 'walkway', 'wd', 'westerners', 'whistler', \"white's\", 'windmill', 'workflow', 'worthington', 'wrapper', 'ymca', 'yogi', 'youtuber', 'zee', 'zoned', '4am', 'abba', 'abuja', 'acetate', 'affirming', 'airstrikes', 'aisles', 'allure', 'amps', 'anthrax', 'antisemitism', 'anwar', 'apprentices', 'aqueous', 'ariana', 'attainment', 'auctioneer', 'authorship', 'awoke', 'axial', 'barnard', 'barron', 'battleship', 'bayonet', 'bertha', 'bette', 'blanchard', 'bombshell', 'bowing', 'brewed', 'bridgewater', 'britons', 'burkina', 'burnout', 'buttocks', 'buyout', 'byte', 'cancerous', 'carat', 'carcinoma', 'carrick', 'caveat', 'caviar', 'ccc', 'chairperson', 'chong', 'chore', 'cid', 'circumvent', 'clique', 'coe', 'coles', 'conserved', 'contemplation', 'contrived', 'corolla', 'corrugated', 'coz', 'cranky', 'crept', 'crunching', 'crushes', 'csa', 'cults', 'curvy', 'd3', 'deluded', 'deployments', 'depp', 'deteriorate', 'dior', 'disbanded', 'discredited', 'disorderly', 'distraught', 'distributes', 'dogg', 'dons', 'doughnuts', 'drizzle', 'eau', 'edging', 'elaborated', 'embankment', 'embassies', 'emergent', 'emilia', 'emilio', 'enchanting', 'entertainers', 'entice', 'esq', 'eun', 'exalted', 'exchequer', \"facebook's\", 'fenton', 'filly', 'flanks', 'footy', 'formality', 'fortitude', 'fouls', 'fueling', 'gambler', 'gcse', 'gent', 'gents', 'geopolitical', 'glitches', 'goethe', 'goliath', 'governs', \"grandfather's\", 'grievance', 'grunt', 'gsm', 'gusts', 'hailing', 'haines', 'halal', 'harmonious', 'hashtags', 'hast', 'hester', 'hijab', 'hitherto', 'hogg', 'hornet', 'humboldt', 'hyperbolic', 'impeached', 'impedance', 'incline', 'incubation', 'insignia', 'installments', 'intercontinental', 'interplay', 'interpol', 'isotope', 'israelites', 'j.r', 'jehovah', 'jigsaw', 'juniper', 'jus', 'keaton', 'kessler', 'kindred', 'labelling', 'lander', 'lapd', 'larsen', 'layouts', 'lev', 'lilies', 'lollipop', 'lon', 'machete', 'mallory', 'marshes', 'marshmallow', 'masse', 'matteo', 'mcleod', 'merchandising', 'microphones', 'mika', 'mink', 'mischievous', 'misunderstand', 'mobilized', 'molested', 'monies', 'monograph', 'montenegro', 'moo', 'morphological', 'movable', 'mucus', 'mulberry', 'munro', 'nameless', 'natalia', 'naturalist', 'necklaces', 'newsroom', 'nightlife', 'nyu', 'officiating', 'omnibus', 'oof', 'opec', 'opposites', 'orwell', 'outburst', 'overarching', 'overseen', 'overwhelm', 'pathologist', 'pcb', 'pcr', 'pct', 'peacekeeping', 'pegasus', 'peptides', 'petersen', 'pharmacology', 'pitfalls', 'pixie', 'ply', 'poaching', 'powders', 'ppm', 'preventable', 'primed', 'prog', 'proponent', 'protectors', 'provenance', 'provost', 'putt', 'quadruple', 'quaker', 'rachael', 'racking', 'rana', 'raptor', 'ratchet', 'ravine', 'raving', 'recreated', 'redress', 'regenerate', 'reigned', 'reincarnation', 'renewables', 'replays', 'retirees', 'rife', 'rollercoaster', 'romances', 'rotherham', 'ruben', 'runnin', 'samaritan', 'sax', 'saxophone', 'scarves', 'schuster', 'scorpio', 'selma', 'settler', 'sever', 'sharpen', 'shellfish', 'shortening', 'showering', 'shrapnel', 'shutout', 'sickle', 'singleton', 'skateboarding', 'skips', 'skit', 'slavic', 'snowboarding', 'snuff', 'solidly', 'sonoma', 'stairway', 'starry', 'stoic', 'supersonic', 'suspending', 'suzy', 'swamps', 'swaps', 'tablespoon', 'tapered', 'tardis', 'taser', 'technologically', 'temperance', 'terrence', 'testimonies', 'textured', 'thierry', 'thrash', 'thresholds', 'thwarted', 'thx', 'tombstone', 'torches', 'torpedoes', 'toto', 'transplants', 'tributaries', 'tributary', 'trumpets', 'turd', 'turrets', 'tuscany', 'tutors', 'tweaks', 'unchecked', 'unfolds', 'unhappiness', 'unifying', 'unimaginable', 'unites', 'unsecured', 'unsustainable', 'utilised', 'utopian', 'verlag', 'walcott', 'warship', 'weathered', 'wholeheartedly', 'whooping', 'widowed', 'willed', 'woolf', 'worsening', 'wounding', 'wwf', 'wwi', 'xinjiang', 'yao', 'zane', 'zenith', 'zimmer', 'zur', 'abbreviation', 'abd', 'abuser', 'accords', 'accrued', 'acm', 'actin', 'adhesion', 'adnan', 'allie', 'andes', 'andres', 'animate', 'appropriated', 'armenians', 'arming', 'artie', 'asymmetric', 'atrocious', 'autobiographical', 'avert', 'avian', 'backstory', 'barns', 'bayou', 'bern', 'blueprints', 'bodybuilding', 'bodyguards', 'branson', 'briefings', 'bugging', 'bullish', 'c3', 'candies', 'cantor', 'carney', 'carrington', 'castillo', 'chairmen', 'chastity', 'chime', 'chromium', 'circumstantial', 'claimant', 'closeness', 'cnbc', 'coachella', 'collectible', 'commemorating', 'conceding', 'conductivity', 'contended', 'contextual', 'contradicted', 'corbin', 'cordon', 'coulter', 'cram', 'crawley', 'crazed', 'crossword', 'cuckoo', 'cuddly', 'dak', 'danube', 'dawkins', 'decaying', 'decipher', 'delve', 'depletion', 'discriminating', 'dispersal', 'displeasure', 'diss', 'doth', 'downgraded', 'dps', 'dsm', 'dumber', 'dunkirk', 'dwarves', 'effortless', 'ere', 'eyeshadow', 'faire', 'fave', 'fellowships', 'finisher', 'fluke', 'fondness', 'fsa', 'furnish', 'gauntlet', 'geologists', 'georg', 'gettysburg', 'ghanaian', 'ghostly', 'giuseppe', 'giveaways', 'gliding', 'googled', 'gopro', 'grady', 'grating', 'grilling', 'gripped', 'grouse', 'growl', 'h2', 'habitual', 'hammock', 'hater', 'hazy', 'heisman', 'het', 'hewlett', 'himalayan', 'hollis', 'horticultural', 'hpv', 'hurling', 'hurried', 'hypocrites', 'ide', 'idealistic', 'impede', 'imperialist', 'induces', 'inflamed', 'inhumane', 'innocents', 'instantaneous', 'islamists', 'isps', 'italics', 'ivf', 'jed', 'jinx', 'jobless', 'jodie', 'joo', 'jurisprudence', 'justifiable', 'kei', 'kellogg', 'kepler', \"kim's\", 'kyrgyzstan', 'l1', 'lark', 'lecturers', 'lecturing', 'linkage', 'lobes', 'louvre', 'lovingly', 'lucille', 'lyft', 'manifests', 'mardi', \"marvel's\", 'masonic', 'mathieu', 'medics', 'meng', 'ment', 'meps', 'merritt', 'messengers', 'mitigating', 'moderated', 'mohawk', 'monarchs', \"moore's\", 'mortars', 'multiples', 'murals', 'nada', 'nafta', 'nell', 'newfound', 'newsweek', 'niles', 'nineties', 'nosed', 'nukes', 'observational', 'olaf', 'oldham', 'oleg', 'ombudsman', 'ordinances', 'overtaken', 'pancreas', 'pandas', 'parlour', 'pasha', 'peoria', 'periodical', 'phew', 'pickering', 'pickups', 'pinched', 'plating', 'pont', 'postings', 'postmaster', 'potts', 'powerfully', 'prentice', 'primate', 'proverb', 'puns', 'quarterbacks', 'quarterfinals', 'quests', 'raisins', 'ranting', 'ratification', 'recited', 'reclamation', 'reece', 'refineries', 'refute', 'resettlement', 'reverted', 'rewriting', 'ric', 'saratoga', 'sculpted', 'sects', 'sedentary', 'shaq', 'sheriffs', 'shivering', 'shocker', 'shoulda', 'showroom', 'sightseeing', 'situational', 'skaters', 'slicing', 'soggy', 'someplace', 'sorcerer', 'sorcery', 'spades', 'specialising', 'speciality', 'spleen', 'starlight', 'steadfast', 'stimulates', 'stomping', 'stoop', 'stroking', 'stuffs', 'stylistic', 'supergirl', 'superpowers', 'superstitious', 'syrians', 't000', 'tay', 'tentatively', 'thinning', 'thrice', 'thu', 'touchy', 'trampoline', 'tranquil', 'transformative', 'trespassing', 'undergraduates', 'underwriting', 'unplanned', 'unsuspecting', 'unwelcome', 'unwell', 'vacate', 'venting', 'ville', 'waldorf', 'warring', 'wetland', 'whit', 'whitehead', 'yemeni', 'yoko', 'youve', 'yung', '1x', '8gb', 'abode', 'abomination', 'acer', 'acs', 'acutely', 'adherents', 'adhering', 'affiliations', 'alexei', 'allotment', 'amplifiers', 'angelic', 'antisocial', 'anxieties', 'approvals', 'aries', 'associating', 'astral', 'astray', 'audited', 'baffling', 'bal', 'banded', 'bao', 'bathed', 'betraying', 'bhai', 'bharat', 'blacklist', 'blockers', 'blunder', 'booing', 'bowlers', 'brownish', 'buddhists', 'bummed', 'burdened', 'cfo', 'chaser', 'checkpoints', 'chet', 'chipotle', 'choreographer', 'clams', 'clintons', 'coa', 'coates', 'colchester', 'commotion', 'communicates', 'completeness', 'concierge', 'congressmen', 'cummins', 'cynicism', 'darkened', 'dazed', 'debatable', 'denominator', 'devolved', 'dieting', 'diligently', 'dinah', 'diners', 'doppler', 'dowry', 'drinkers', 'duality', 'duplex', 'ect', 'egan', 'endearing', 'epilogue', 'etching', 'exemplified', 'ext', 'extermination', 'eyre', 'f2', 'fancied', 'fatima', 'feldman', 'firefly', 'fleetwood', 'flotation', 'focussed', 'foraging', 'forbids', 'foreword', \"fox's\", 'fsu', 'fy', 'gamblers', 'garages', 'goldie', 'golds', 'grandchild', 'grids', 'grossing', 'habitable', 'hails', 'hallways', 'harem', 'hawkeye', 'hegemony', 'hilda', 'himalayas', 'hippo', 'hof', 'hypnotic', 'imagines', 'inaction', 'inconclusive', 'incubator', 'inept', 'inexplicable', 'innovate', 'inseparable', 'institutionalized', 'instructing', 'intravenous', 'invests', 'juries', 'juror', 'kilo', 'kinship', 'kv', 'l2', 'lactose', 'lat', 'lenient', 'liang', 'lids', 'likened', 'lockout', 'lube', 'luton', 'macon', 'mak', 'marcelo', 'martins', 'masking', 'mastercard', 'mathematicians', 'mathew', 'maximizing', 'mccabe', 'mediate', 'methodologies', 'mfa', 'micah', 'microorganisms', 'millimeter', 'minaj', 'minh', 'moans', 'modal', 'moderates', 'modernism', 'moira', 'monasteries', 'monique', 'napier', 'narrows', 'nawaz', \"nbc's\", 'negotiator', 'niggas', 'nomadic', 'npc', 'observance', 'ont', 'overloaded', 'p3', 'parentheses', 'penance', 'peroxide', 'peugeot', 'pigments', 'pinning', 'pisa', 'planks', 'pluck', 'porte', 'postdoctoral', 'potus', 'preposterous', 'pressuring', 'preventative', 'prometheus', 'prophecies', 'proverbial', 'puffy', 'puzzling', 'qpr', 'quail', 'quirk', 'rabid', 'rafa', 'rasmussen', 'redneck', 'reformer', 'reformers', 'registrations', 'rehearsing', 'reiterate', 'resolves', 'resonant', 'resultant', 'retinal', 'rgb', 'rhodesia', 'rothschild', 'rsa', 'rw', 'scammers', 'schema', 'schizophrenic', 'schwarzenegger', 'scorn', 'screwdriver', 'shay', 'shetland', 'shippers', 'sho', 'sighed', 'sizzling', 'skillful', 'skywalker', 'slowest', 'sonata', 'soulful', 'southend', 'stampede', 'standoff', 'stately', 'steered', 'straightened', 'sugary', 'suitably', 'supernova', 'surrendering', 'synonym', 'tanned', 'tantrum', 'tapering', 'tectonic', 'tele', 'templar', 'tmz', 'tna', 'toxicology', 'transfusion', 'treachery', 'tung', 'tweaking', 'unbreakable', 'undermines', 'unmatched', 'upheaval', 'uploads', 'urbana', 'vaccinations', 'valentino', 'valuations', 'veneer', 'verona', 'viewership', 'viscosity', 'vogel', 'vouch', 'wafer', 'wai', 'wcw', 'wiz', 'worsened', 'xo', 'zoos', 'adaptable', 'adhered', 'adjutant', 'advancements', 'aggravating', 'alia', 'alta', 'altercation', 'amplification', 'amuse', 'ancients', 'appleton', 'aps', 'aptly', 'archaeologist', 'armada', 'arousal', 'arsene', 'artistry', 'asheville', 'assuring', 'atrium', 'atv', 'atypical', 'authorizing', 'autographs', 'autos', 'backups', 'bah', 'bakersfield', 'bangladeshi', 'bannon', 'barrie', 'bartholomew', 'bavarian', 'beacons', 'bearers', 'becca', 'bernadette', 'bingham', 'bouncer', 'bracing', \"brand's\", 'breezy', 'brunt', 'bucky', 'burgeoning', 'c.j', 'cadence', 'californian', \"cameron's\", 'cancels', 'candice', 'capitalization', 'cashmere', 'chaps', 'cheeseburger', 'churning', 'cipher', 'clarinet', 'clashed', 'comforted', 'condensation', 'condos', 'confesses', 'confluence', 'consented', 'constipation', 'consultative', 'contesting', 'contraband', 'cookery', 'creme', 'criminally', 'crocodiles', 'crutches', 'custodian', 'cyst', 'dah', 'decisively', 'degeneration', 'delinquent', 'democratically', 'deodorant', 'detonated', 'disappointments', 'disapprove', 'dobson', 'dodged', 'dormitory', 'dredging', 'duran', \"editor's\", 'emigrated', \"emperor's\", 'enticing', 'eradication', 'erasmus', 'esl', 'ethnically', 'evangelicals', 'evoked', 'excesses', 'exhilarating', 'eyelashes', 'fainted', 'feline', 'femininity', 'ferns', 'fickle', 'figurative', 'flared', \"fool's\", 'footwork', 'forage', 'fraught', 'freshness', 'fronted', 'g1', 'galilee', 'gallup', 'gauges', 'glastonbury', 'gonzales', \"grandma's\", 'grapple', 'grated', 'greets', 'groan', 'grub', 'gunna', 'gunned', 'handouts', 'hangout', 'hartman', 'havin', 'headers', 'henson', 'hickory', 'hives', 'hiya', 'hoist', \"hotel's\", 'hubble', 'huff', 'hunk', 'idc', 'identifier', 'incite', 'increments', 'industrialized', 'inferred', 'informally', 'inhalation', 'inhibits', 'insides', 'interruptions', 'intoxication', 'isotopes', 'jagged', 'joachim', 'josiah', 'jv', 'k00', 'kant', 'katharine', 'kavanaugh', 'l00', \"labour's\", 'laces', 'lamented', 'lasagna', 'leaflet', 'leds', 'lucian', 'marissa', 'markus', 'marlene', 'massa', 'massacred', 'massacres', 'maturing', 'mcintosh', 'mckinney', 'mediocrity', 'mediums', 'midwestern', 'minding', 'moat', 'molds', 'mori', 'morty', 'motorized', 'mouthpiece', 'muck', 'murky', 'nab', 'neonatal', 'neuronal', 'neutralize', 'nicholls', 'nickelodeon', 'omen', 'ora', 'orally', 'orchids', 'overgrown', 'overlooks', 'overpriced', 'overruled', 'painkillers', 'pallet', 'parramatta', 'partitions', 'patriarchy', 'patsy', 'paz', 'pdp', 'peaking', 'pedagogy', 'perm', 'philanthropist', 'piedmont', 'pinto', 'poc', 'pontiac', 'prc', 'predictor', 'premiers', 'priscilla', 'professed', 'qing', 'rants', 'rashid', 'readership', 'reaffirmed', 'reciting', 'reels', 'rei', 'relinquish', 'resists', 'resolute', 'restricts', 'retainer', 'rethinking', 'runways', 'salient', 'scents', 'schematic', 'scoreless', 'seawater', 'secs', 'secures', 'seedlings', 'sentient', 'separatist', 'sera', 'serb', 'serbs', 'shropshire', 'sikhs', 'skyscrapers', 'slurs', 'slutty', 'smurf', 'snippet', 'somethings', 'spielberg', 'spokeswoman', 'spotless', 'sprang', 'ssh', 'stabilizing', 'stinky', 'stitching', 'stockpile', \"stone's\", 'strenuous', 'strikingly', 'strives', 'stumps', 'subordinates', 'summarizes', 'surcharge', 'tarot', 'tcp', 'theologians', 'throbbing', 'tilting', 'trailed', 'treasured', 'tungsten', 'tw', 'twigs', 'txt', 'ucl', 'uhm', 'umpires', 'unharmed', 'unilaterally', 'unintentional', 'unspeakable', 'untimely', 'ust', 'uva', 'vfl', 'vida', 'vodafone', 'vous', 'warrington', 'wedges', \"wendy's\", 'whomever', \"winner's\", 'wondrous', 'woodrow', 'woof', 'workable', 'wrinkle', 'yak', 'z00', 'zhu', 'ó', 'ω', 'в', '5x', 'abdel', 'abstracts', 'abundantly', 'acknowledgment', 'adoration', 'affectionately', 'affliction', 'aguero', 'alluded', 'alters', 'amazon.com', 'amounting', 'ams', 'ariz', 'armageddon', 'arya', 'ashe', 'attaches', 'awww', 'backfire', 'bathurst', 'belinda', 'bethel', \"board's\", 'bonn', 'bookshop', 'bora', 'botox', 'bowers', 'bree', 'bridesmaids', 'brooding', 'burberry', 'canes', 'caregiver', \"carter's\", 'celebs', 'championed', 'chernobyl', 'chesterfield', 'clapped', 'clerics', 'cochrane', 'cockroaches', 'coerced', 'collectibles', 'conspirators', 'conspired', 'conspiring', 'contours', 'contraceptive', 'conversational', 'corrosive', 'counterpoint', 'courting', 'cowardice', 'crusher', 'cuddling', 'cyclops', 'dahl', 'daw', 'defied', 'depictions', 'derailed', 'dill', 'dimitri', 'dio', 'discontinue', 'diseased', 'disgruntled', 'dispense', 'disqualification', 'dizziness', 'ducts', 'dusted', 'dv', 'econ', 'emi', 'enacting', 'enigmatic', 'ennis', 'envisaged', 'epl', 'esquire', 'ethically', 'exhale', 'fanning', 'farley', 'fergus', 'firemen', 'fission', 'fives', 'fleas', 'flurry', 'folio', 'fosters', 'franc', 'frugal', 'fugitives', 'gainesville', 'galore', 'genomic', 'gestapo', 'gk', 'glimmer', 'goon', 'gq', 'graces', 'grandkids', 'groovy', 'gully', 'gundam', 'gurney', 'h00', 'h1', 'handball', 'harmonies', 'hectare', 'hereford', 'hickey', 'hijack', 'hikers', 'hologram', 'homicides', 'horatio', 'humankind', 'hydroelectric', \"i's\", 'immunology', 'indulging', 'ingested', 'inhibited', 'intensifies', 'interacted', 'intruders', 'ipads', 'isbn', 'ita', 'iterations', 'izzy', 'judgements', 'k2', 'karan', 'kayla', 'kiln', 'kp', 'landowner', 'latvian', 'leveraged', 'levers', 'lilac', 'limelight', 'lister', 'loathe', 'lobbied', 'logistic', 'lok', 'loopholes', 'macaroni', 'maclean', \"manager's\", 'manganese', 'mantis', 'marr', 'mattresses', 'mayan', 'merrick', 'midsummer', 'mig', \"mike's\", 'milligrams', 'mimics', 'minsk', 'misunderstandings', 'momentous', 'mora', 'mou', 'mules', 'nanoparticles', 'nasser', 'nightclubs', 'nightfall', 'nikolai', 'notary', 'observable', 'occupant', 'omissions', 'organiser', 'ott', 'outfield', 'oy', 'paddington', 'paddock', 'padre', 'pang', 'pardoned', 'parliaments', 'participatory', 'partisans', 'pavel', 'perils', 'permissions', 'pfizer', 'pia', 'plugging', 'pneumatic', 'pointy', 'polyester', 'polynomial', 'porridge', 'protester', 'pug', 'pyongyang', 'quill', 'reassured', 'refurbishment', 'renown', 'rescheduled', 'revel', 'reworked', 'rocco', 'rochelle', 'rollin', 'roundtable', 'rower', 'rut', 'salaam', 'sanjay', 'scapegoat', 'schooled', 'screeching', 'secretion', 'shambles', 'shipwreck', 'shirtless', 'shrewd', 'shudder', 'shunned', 'sia', 'sicilian', 'slalom', 'smuggle', 'snowflakes', 'solder', 'sous', 'spanned', 'sparring', 'spectacles', 'spire', 'spout', 'sprout', \"station's\", 'stench', 'stings', 'stochastic', 'stratton', 'subsistence', 'subterranean', 'sully', 'superhuman', 'synchronization', 'tajikistan', 'tellin', 'tenacity', \"thursday's\", 'thurston', 'tolerable', 'topper', 'tre', 'trespass', 'tuxedo', 'umbrellas', 'understated', 'undeveloped', 'univ', 'unknowingly', 'unplugged', 'untouchable', 'unwarranted', 'unwillingness', 'vases', 'vetting', 'vg', 'vibrator', 'wailing', \"walker's\", 'warhol', 'warwickshire', 'whisk', 'wishful', 'wrestled', 'wynn', 'yoda', 'yoruba', '😅', '4m', 'abolishing', 'accountancy', 'acoustics', 'actuality', 'addictions', 'aden', 'aeronautics', 'alam', 'alf', 'alibi', 'anand', 'anfield', 'anointed', 'apis', 'argentinian', 'arias', 'arkham', 'arturo', 'astoria', 'astute', 'attainable', 'audiobook', 'aztec', 'babcock', 'bac', 'baja', 'ballerina', 'bashed', 'batters', 'bce', 'bei', 'bennet', 'bewildered', 'bien', 'binoculars', 'blackstone', 'bonkers', 'bpd', 'brazen', 'burlesque', 'burrow', 'calculates', 'calder', 'callers', 'calvert', 'campfire', 'cashed', 'caster', 'catalysts', 'catered', 'causation', 'centerpiece', 'chameleon', 'checkers', 'cheques', 'clancy', 'clasp', 'clit', 'clooney', \"cnn's\", 'compulsion', 'concealing', 'condescending', 'condominium', 'confucius', 'conical', 'conjure', 'constitutionally', 'convincingly', 'copious', 'cordial', 'coy', 'craftsmanship', 'craziness', 'creatively', 'creditor', 'crores', 'crypt', 'custodial', 'deactivated', \"dean's\", 'decatur', 'decreed', 'deems', 'delegated', 'derelict', 'detects', 'dignitaries', 'dismisses', 'dispel', 'dissident', 'ditches', 'django', 'donetsk', 'dork', 'dory', 'doves', \"dragon's\", 'dropbox', 'droplets', 'dusting', 'edict', 'edmond', 'egos', 'egregious', \"egypt's\", 'elasticity', 'elicit', 'eo', 'epoxy', 'estonian', 'etienne', 'eton', 'evangelist', 'explorations', 'extraterrestrial', 'exxon', 'eyeball', 'faso', 'fiend', 'fledgling', 'flicker', 'flimsy', 'fob', 'footer', 'forza', 'gambit', 'giroud', 'giuliani', 'gleaming', 'glock', 'grille', 'gullible', 'gust', 'gypsies', 'hae', 'happenings', 'haw', 'hawke', 'hearth', 'heathen', 'hemorrhage', 'hereafter', 'hijacking', \"hill's\", 'hinting', 'hoarding', 'homers', 'hoods', 'horoscope', 'hou', 'humanoid', 'hurst', 'hyung', 'idealism', 'illegals', 'impeach', 'improvisation', 'influencers', 'intergovernmental', 'interspersed', 'invoking', 'irc', 'irina', 'ironing', 'isi', 'itt', 'jacobson', 'jagger', 'jaipur', 'jazeera', 'jeffery', 'jeopardize', 'jerky', 'jig', 'jodi', \"judge's\", 'juliette', 'junctions', 'jw', 'kathmandu', 'kearney', 'khz', 'kieran', 'lakeside', 'landon', 'landry', 'lawfully', 'lexicon', 'licks', 'lifetimes', 'littered', 'livery', 'livingstone', 'loader', 'lobbyist', 'loosing', 'lucknow', 'lurk', 'macintosh', 'magicians', 'marguerite', 'marius', 'maximise', 'mcintyre', 'mcpherson', 'mech', 'medallion', 'medusa', 'merseyside', 'metaphorical', 'mindy', 'mismatch', 'mlm', 'monastic', \"money's\", 'monopolies', 'mooney', 'mormons', 'mot', \"movie's\", 'mow', 'mower', 'mozzarella', 'multilateral', 'munster', 'mutated', 'naacp', 'namesake', 'nazareth', 'nazism', 'nellie', 'nia', 'nominally', 'nord', 'normative', 'nostrils', 'num', 'nurtured', 'objectivity', 'oblige', 'ogre', 'oiled', 'okc', 'overheating', 'overreacting', 'overthrown', 'palermo', 'palliative', 'pao', 'parable', 'pastime', 'patchwork', 'patrice', 'paulie', 'payton', 'pedophilia', 'peed', 'peeps', 'pell', 'pellet', 'pendleton', 'peshawar', 'pesky', 'phobia', 'pinball', 'planter', 'plat', 'plenary', 'plunder', 'poseidon', 'postman', 'ppg', 'prays', 'privatisation', 'pseudonym', 'pullman', 'purgatory', 'raps', 'rationality', 'rearing', 'rebuke', 'rebuttal', 'refrigerated', 'reliever', 'repo', 'restarted', 'retaliate', \"richard's\", 'riffs', 'riyadh', 'rockers', 'roo', 'rook', 'rouse', 'sabha', 'sampler', 'sarajevo', 'scaffolding', 'scant', 'schoolgirl', 'seamlessly', 'seater', 'sedimentary', 'semblance', 'sensei', 'sensibilities', 'sheik', 'shockingly', 'shrewsbury', 'sidelined', 'signaled', 'sine', 'skunk', 'sloth', 'slowdown', 'smugglers', 'snapshots', 'snitch', 'snowing', 'snug', 'solstice', 'songwriters', 'soups', 'sparsely', 'spindle', 'spoilt', 'spoof', 'sporty', 'spp', 'staffer', 'sterilization', 'stockholders', 'stuttering', 'subdivided', 'subtract', 'supermodel', 'susceptibility', 'sweats', \"sweden's\", 'syd', 'syphilis', 't3', 'tabletop', 'tactile', 'tangle', 'ther', 'thermodynamics', 'thermostat', 'thrives', 'tiki', 'tingling', 'todays', 'tonga', 'topeka', 'tort', 'touchscreen', 'tra', 'trackers', 'transcend', 'trope', 'tufts', 'tumours', 'undercut', 'underlined', 'unfriendly', 'universes', 'unlicensed', 'unproductive', 'valuables', 'vial', 'vick', 'vickers', 'violinist', 'vultures', 'warlord', 'whence', 'whimsical', 'wrenching', 'yusuf', 'zionism', '💯', '1d', 'a.c', 'accordion', 'addis', 'aeronautical', 'ahl', 'alimony', 'allegheny', \"allen's\", 'aloha', 'alves', 'amtrak', 'angelica', 'anthropological', 'anxiously', 'apprehension', 'arden', 'ares', 'articulation', 'asiatic', 'assailant', 'atc', 'atletico', 'atonement', 'auf', 'auspicious', 'avenger', 'bafta', 'barricade', 'baseless', 'beater', 'benefactor', 'benji', 'bhutan', 'biographer', 'blackness', 'bollocks', 'booed', 'borneo', 'boyhood', 'bridgeport', 'briefcase', 'bronson', 'brutus', 'bugged', 'bunkers', 'butte', 'camaro', 'cambridgeshire', 'campsite', 'cancellations', 'canister', 'canons', 'cate', 'caters', \"charlie's\", 'chronically', 'chuckles', 'cloths', 'clustered', 'cmc', 'coherence', \"committee's\", 'complainant', 'complemented', 'compounding', 'conforming', 'connotations', 'consonant', 'correlations', 'cpl', 'crazier', 'cricketers', 'crisps', 'criticising', 'crockett', 'crowning', 'crucifixion', 'csgo', 'cursor', 'cx', \"daniel's\", 'deduct', 'delegations', 'diaphragm', 'dichotomy', 'diminutive', 'dina', 'dispensary', 'dispensing', 'disregarded', 'dissidents', 'doubtless', 'dreamers', 'dunlop', 'dwindling', 'elisa', 'elsie', 'embellished', 'emp', 'emphatic', 'enfield', 'enlightening', 'enoch', 'enrolment', 'etf', 'exclamation', 'executioner', 'exempted', 'exerted', 'exiles', 'expressway', 'fairer', 'fairest', 'filament', 'fk', 'flemish', 'foyer', 'fra', \"frank's\", 'fresco', 'frigate', 'fuselage', 'gait', 'genitalia', 'ger', 'gillette', 'gilt', 'glider', 'goers', 'granville', 'gravely', 'grime', 'guerrillas', 'hanley', 'harman', 'heron', 'heyday', 'highlanders', \"hillary's\", 'hospitalization', 'illogical', 'illuminati', 'ima', 'imma', 'impart', 'incapacitated', 'incoherent', 'indulgent', 'inert', 'inflicting', 'initiates', 'interlude', 'internationals', 'interpreters', 'interrupts', 'invoices', 'irradiation', 'irritable', 'jace', 'jain', 'jammu', 'jl', 'jm', 'johanna', 'johnnie', 'joss', 'kendra', 'kermit', 'kwh', 'laminated', 'leaderboard', 'leung', 'leviathan', 'ligaments', 'lis', 'lj', 'lonesome', 'lps', 'lug', 'lukewarm', 'lumbar', 'lumen', 'luv', 'luxuries', 'lyman', 'lyn', 'maison', 'maneuvering', 'marathons', 'mariano', 'markup', 'marred', 'melrose', 'midwives', 'miniseries', 'mismanagement', 'mitochondria', 'mixtures', 'moffat', 'mongolian', 'monmouth', 'motley', 'mouthed', 'mowing', 'msp', 'multiculturalism', \"music's\", 'mussels', 'nbsp', 'netball', 'nieces', 'nit', 'nottinghamshire', 'nuance', 'obstruct', 'oftentimes', 'orthopedic', 'osborn', 'osha', 'outages', 'outcast', 'outings', 'overcrowded', 'overriding', 'ozil', 'pai', 'pane', 'penultimate', 'peppermint', 'percentile', 'persuading', 'pharrell', 'piety', 'pinot', 'placenta', 'planters', 'playgrounds', 'playin', 'pleasurable', 'plough', 'pogba', 'potentials', 'ppv', 'prefect', 'prevails', 'pri', 'propagate', 'qr', 'quot', 'redefine', 'reeling', 'reinstate', 'remington', 'remit', 'remixes', 'respondent', 'resumption', 'retailing', 'retrograde', 'reunification', 'reused', 'revere', 'riggs', 'robo', 'romantically', 'rosario', 'rout', 'saab', 'salmonella', 'sargent', 'savoy', 'scarecrow', 'sceptical', 'scrubbing', 'seq', 'servings', 'shiv', 'shrinks', 'siam', 'simons', 'smeared', 'softening', \"soldier's\", 'soybean', 'splashing', 'standardization', \"star's\", 'stardom', 'steamy', 'stomachs', 'stopper', 'strolling', 'subtlety', 'swells', 'swindon', 'symptomatic', 'tenets', 'tennant', 'tfw', 'thunderbolt', 'tiered', 'toggle', 'tonal', 'torrance', 'totem', 'tourney', 'tran', 'transitioned', 'transmitters', 'tripled', 'u.s.c', 'uconn', 'ulcers', 'ultrasonic', 'unicorns', 'unlawfully', 'unveils', 'unwind', 'unwise', 'valentina', 'valentines', 'vaping', 'verifying', 'vo', 'watchful', 'waterford', 'wayward', 'willoughby', \"worker's\", 'workmanship', 'wrecks', 'wren', 'wronged', 'ww1', 'yoke', 'za', 'zuma', 'μm', '😤', '6a', '7s', 'acorn', 'aga', 'ahmedabad', 'aiken', 'ailing', 'airflow', 'alamo', 'aloft', 'amalgamation', 'amazes', 'amman', \"anderson's\", 'aneurysm', 'antelope', 'antigua', 'arcadia', 'archdiocese', 'ast', 'automate', 'barre', 'basilica', 'bassett', \"ben's\", 'bertie', 'beset', 'bitchy', 'blaster', 'bleep', 'blueberries', 'blushing', 'bowels', 'boyce', 'braided', 'brazilians', 'bridesmaid', 'brie', 'brochures', 'burroughs', 'capping', 'cartier', 'cashing', 'catalogs', 'cautioned', 'cavern', 'cedric', 'certify', 'champaign', 'channeling', 'checker', 'chivalry', 'chopra', 'civilised', 'clearwater', 'cocoon', 'comms', 'confessing', 'conspiracies', 'constants', 'cooperated', 'cornerback', 'credence', 'creeks', 'crossfire', 'currie', \"customer's\", 'dada', 'dax', 'debtor', 'denouncing', 'densities', 'derail', 'desi', 'disallowed', 'dispatcher', 'dispatches', 'dissolving', 'distort', 'diverting', 'dms', 'dobbs', 'draught', 'dreary', 'dropout', 'duped', 'duplicated', 'earle', 'earring', 'elsevier', 'emptying', 'enclosures', 'endangering', 'environmentalists', 'erroneously', 'erwin', 'evaporation', 'evokes', 'fairbanks', 'fared', 'felicia', 'fingered', 'fished', 'flicks', 'foregoing', 'frighten', 'gable', 'gags', 'gallows', 'gandalf', 'gendered', 'georgina', 'goddesses', 'gorbachev', 'guernsey', 'guilds', 'gunning', 'hahah', 'haiku', 'hairstyles', 'harrow', 'hatchet', 'henceforth', 'hesitated', 'heterogeneous', 'hilltop', 'hines', 'hobo', 'housework', 'howdy', 'hoy', 'hsbc', 'huddle', 'humiliate', 'hurled', 'icloud', 'imax', 'importer', 'indignation', 'indus', 'ingrained', 'inhaled', 'injustices', 'inked', 'inspirations', 'irritate', 'j.c', 'jayne', 'jive', 'kaye', 'keenly', 'kiki', 'kilda', 'kimberley', 'kyiv', 'kyung', 'lakhs', 'lal', 'lass', 'leila', 'lesion', 'lieutenants', 'lockwood', 'lull', 'lullaby', 'macedonian', 'machining', 'mackerel', 'marge', 'marquette', 'martina', 'massages', 'mathias', 'mayfield', 'medallist', \"member's\", 'memorized', 'mep', 'metabolites', 'metaphysics', 'meticulously', 'migraines', 'mite', 'momentary', 'montague', 'moratorium', \"morgan's\", 'morgue', 'movin', 'mp4', 'mullen', 'mulligan', 'multiplying', 'munch', 'muppet', 'naps', 'nascent', 'netted', 'neurotic', 'newborns', 'noone', 'novella', 'obstructing', 'octane', 'octave', 'oda', 'oldies', 'omni', 'ong', 'organizes', 'pakistanis', 'penalized', 'piercings', 'pitbull', 'plugins', 'polaris', 'pondering', 'popes', 'postmodern', 'precincts', 'prerogative', 'procured', 'proxies', 'prudence', 'prudential', 'pry', 'psychoanalysis', 'puffs', 'purged', 'purposefully', 'pursues', 'q00', 'radiotherapy', 'rationally', 'recoveries', 'reddy', 'remarried', 'rembrandt', 'remedial', 'repealing', 'repressive', 'resonates', 'resourceful', 'rms', 'rosenthal', 'rotates', 'runtime', 'rus', 'sacrificial', 'schulz', 'scorching', 'scottsdale', 'scribe', 'sentry', 'seung', 'sexton', 'sheeran', 'shelled', 'shhh', 'shingles', 'siegel', 'silencing', 'silverware', \"singapore's\", 'skillet', 'slimy', 'slipper', 'sloping', 'snout', 'soliciting', 'southwark', 'spank', 'sparking', 'specter', 'spied', 'spinners', 'spits', 'statehood', 'steeped', 'sti', 'storyteller', 'strewn', 'stroller', 'stub', 'subgroup', 'supra', 'suspiciously', 'sutter', 'swaying', 't.j', 'tact', 'taxonomy', 'tcu', 'televisions', 'tinged', 'tirelessly', 'tiresome', 'toms', 'toolkit', 'tribunals', 'tundra', 'tunic', 'tweaked', 'ukrainians', 'uncompromising', 'undoing', 'unmistakable', 'unruly', 'v1', 'valuing', 'vaulted', 'veal', 'vegans', 'venomous', 'viceroy', 'videotape', 'walgreens', 'waxed', 'wearer', 'webs', 'whiting', 'willful', 'woodley', 'worcestershire', 'zeta', '◕', '💦', '5c', '6ft', 'a5', 'abnormally', 'abstain', 'adriana', 'affections', 'aggregates', 'ahn', 'airliner', 'alchemist', 'alexandre', 'alfa', 'allegory', 'alp', 'ambulances', 'antagonists', 'aortic', 'ard', 'ashland', 'assimilated', 'averted', \"b's\", 'backpacks', 'banish', 'bateman', 'battleground', 'beets', 'bellows', 'blisters', 'blob', 'bluntly', 'bohemia', 'bonaparte', 'boosters', 'bootleg', 'bos', 'boyz', 'brine', 'busty', 'butchers', 'callous', 'canadiens', 'cantonese', 'capcom', 'cardiology', 'carlin', 'cartoonist', 'casablanca', 'casserole', 'catalina', 'cellulose', 'cfr', 'charred', 'choreographed', 'churn', 'circuitry', 'clearances', 'cloned', 'cloves', \"college's\", 'commendable', 'competitively', 'compress', 'comptroller', 'conventionally', 'coon', 'correlates', 'creole', 'crusades', 'cubicle', 'curtailed', 'cystic', 'd.j', 'dainty', 'damnit', 'darlington', 'davison', 'decimated', 'decrees', 'deflected', 'deliverance', 'destitute', 'devi', 'dexterity', 'dietrich', 'dilution', 'dissipated', 'dolce', 'drugstore', 'dvr', 'eczema', 'ejection', 'electrolyte', 'elitist', 'emailing', 'emphasise', 'emphatically', 'engulfed', 'equine', 'exclusivity', 'exes', 'failings', 'fannie', 'faucet', 'faust', \"fbi's\", 'fdr', 'feeders', 'feisty', 'fink', 'flexing', 'foothold', 'forbidding', 'forfeited', 'formulations', 'fortifications', 'fouled', 'fourier', 'fraternal', 'frau', 'functioned', 'fuses', 'gaines', 'gamergate', 'gan', 'generalizations', 'ghastly', 'gia', 'gonzalo', 'gorillas', 'goto', 'gratifying', 'gretchen', \"grey's\", 'gymnast', 'haircuts', 'hairline', 'handcuffed', 'handset', 'harrowing', 'headlining', 'heiress', 'hells', 'herzegovina', 'hhs', 'higgs', 'hinged', 'hola', 'holster', 'horseman', 'humanist', 'hunch', 'huntsville', 'impenetrable', 'inconceivable', 'industrialization', 'inf', 'infographic', 'infringing', 'innovators', 'islington', 'issuer', \"jane's\", 'keenan', 'keg', \"kennedy's\", 'kissinger', 'kms', 'koi', 'kwon', 'lancet', 'landfall', 'lawmaker', 'layoffs', 'leningrad', 'lerner', 'lifeguard', 'limerick', 'lockers', 'lolita', 'loner', 'longed', 'loyola', 'lukaku', 'mariana', 'mau', \"may's\", 'mca', 'mcmaster', 'mimicking', 'minimally', 'mistook', 'mogul', 'moles', 'monet', \"moon's\", 'mornin', \"morning's\", 'morph', 'mort', 'motorist', 'muriel', \"murphy's\", 'musa', 'mysticism', 'nagar', 'nauseous', 'naïve', 'nicks', 'nimble', 'nomad', 'nouveau', 'nrc', \"o'leary\", \"o'neal\", \"o'sullivan\", 'objectionable', 'obliterated', 'obtainable', 'omit', 'oncoming', 'opportunistic', 'orson', 'otters', 'outlandish', 'outlying', 'oxidative', 'pacifist', 'pacquiao', 'paraphrase', 'pathfinder', 'pedagogical', 'pediatrician', 'pegged', 'pelican', 'pembroke', 'penchant', 'persians', 'planar', 'polluting', 'polygamy', 'ponytail', \"pope's\", 'poplar', 'primordial', 'projectiles', 'propositions', 'pubic', 'publicist', 'purposeful', 'purses', 'quorum', 'rabbis', 'raman', 'ranchers', 'rarest', 'rascal', 'reared', 'refuted', 'resented', 'revue', 'reza', 'rigor', 'rioters', 'rizzo', 'roanoke', 'robins', 'rochdale', 'romano', 'roosters', 'roper', 'rosters', 'sacking', 'scarring', 'sch', 'scheming', 'scorched', 'scotsman', 'scotus', 'scripting', 'seatbelt', 'shank', 'sharpened', 'shortlist', 'sidebar', 'silverman', 'skeptics', 'slashing', 'sledge', 'slotted', 'smes', 'sociopath', 'sonya', 'southward', 'sparkly', 'specialises', 'speculating', 'spock', 'sponges', 'squeaky', 'stargate', 'steamship', 'stinging', 'subbed', 'summoning', 'swann', 'tatiana', 'tbsp', 'telecast', 'tenancy', 'terre', 'testimonial', 'thence', 'thyme', 'tiniest', 'toner', 'totalling', 'trafficked', 'trampled', 'transponder', 'trashy', 'travers', 'trimester', 'tron', 'tubs', 'tully', 'tum', 'umar', \"uncle's\", 'unfaithful', 'unholy', 'unify', 'unregulated', 'unscrupulous', 'unwittingly', 'upland', 'upped', 'ushered', 'vauxhall', 'vb', 'verbatim', 'villiers', 'virgo', 'vito', 'voiceover', 'willfully', \"winter's\", 'worshipping', 'yawn', 'yiddish', 'и', '❤', 'adrift', 'aegis', 'aiden', 'ais', 'alastair', 'alleys', 'almanac', 'aloe', 'amphibious', 'analyzer', 'ancillary', \"andrew's\", 'anesthetic', 'anglia', 'antioch', 'antiquated', 'apologised', 'aquarius', 'armani', 'ascot', 'aussies', 'averse', 'bandages', 'barges', 'bds', 'beaded', 'beagle', 'beaufort', 'beavers', 'bess', 'biceps', 'blanco', 'blindfolded', 'blokes', 'boomerang', 'borussia', 'breton', 'brill', 'brim', 'broadening', 'caged', 'caine', 'calligraphy', 'capri', 'carpenters', 'carthage', 'castes', 'cauldron', 'celebratory', 'cfs', 'chalet', 'chao', 'childless', 'chimes', 'cleanser', 'clemens', 'clipper', 'closets', 'clouded', 'cma', 'coalitions', 'colossus', 'conductive', 'coney', 'congregational', 'cooperatives', 'copa', 'corals', 'corral', 'cortical', 'countering', 'crc', 'cremation', 'crt', 'cubans', 'curricular', 'curving', 'deans', 'decked', 'deepened', 'deliberation', 'dermatologist', 'detonation', 'deus', 'deviate', 'devolution', 'dey', 'dialing', 'diode', 'discharges', 'disruptions', 'distancing', 'ditching', 'dix', 'donkeys', 'dorchester', 'dorsey', 'downer', 'dreyfus', 'dribble', \"duke's\", 'dutchman', 'duval', 'dwyer', 'earbuds', 'egalitarian', 'endocrine', 'energized', 'epi', 'epithelial', 'equates', 'erickson', 'ernesto', 'ester', 'excitedly', 'excruciating', 'executes', 'farthest', 'fateful', 'fatter', 'fedora', 'fer', 'fia', 'fillers', 'finley', 'flak', 'flamboyant', 'flamingo', 'flutter', 'foodie', 'foolishness', 'forrester', 'foundational', 'frey', 'furnaces', 'fuzz', 'gills', 'gmc', 'goodyear', 'gout', 'guillermo', 'hailey', 'harlow', 'harsher', 'hatching', 'hearst', \"heaven's\", \"hell's\", 'hepatic', 'hertz', 'hirsch', 'hoboken', 'homegrown', 'hoof', 'horowitz', \"horse's\", 'housemates', \"howard's\", 'hues', 'huey', 'humbling', 'hwang', 'hydrocarbons', 'idris', 'impala', 'impurities', 'incognito', 'indestructible', 'inhibiting', 'inks', 'innocuous', 'inns', 'insofar', 'institut', 'intrinsically', 'iraqis', 'irishman', 'islander', 'ism', 'ismail', 'jana', 'janis', 'jest', 'jesuits', 'jillian', \"joseph's\", 'kal', 'kam', 'kee', 'khalil', 'lambda', \"leader's\", 'leaky', 'lehigh', 'leicestershire', 'leto', 'libido', 'lina', 'linn', 'linus', 'lizzy', 'lorna', 'loyalties', 'lynching', 'lynx', 'maddox', 'mage', 'mahatma', 'mainline', 'mainstay', 'mannequin', 'marketable', 'marlborough', 'masterful', 'matic', 'maximal', 'mcc', 'millers', 'mime', 'minivan', 'mistrust', 'mites', 'mobiles', 'modestly', 'moniker', 'morrissey', 'mpg', 'multidisciplinary', 'mythological', 'nave', 'ncis', 'needlessly', 'nel', 'neuro', 'nib', \"noah's\", 'nonviolent', 'nps', 'nuremberg', 'ozzy', 'palatable', 'parishioners', 'parkland', 'pau', 'payouts', 'pensacola', \"perry's\", 'pic.twitter.com', \"pilot's\", 'platt', 'plunging', 'polarity', 'pompous', 'portman', 'profanity', 'protruding', 'puig', 'pundit', 'purify', 'pw', 'quack', 'quarries', 'raged', 'rages', 'rah', 'regaining', 'regenerative', 'regroup', 'rehearsed', 'reimburse', 'reinvent', 'rel', 'repatriation', 'requiem', 'resurrect', 'ringer', 'rockville', 'rollout', 'ronan', 'rooftops', \"rose's\", 'rudolf', 's6', 's7', 'sae', 'salvaged', 'sari', 'sata', 'saucer', 'scrapping', 'scrappy', 'semis', 'serpentine', 'shinji', 'shuffling', 'sie', 'signup', 'skirmish', 'slough', 'snippets', 'soared', 'solicit', 'solidified', 'solvents', 'spaniard', 'spar', 'spearheaded', 'spooked', 'sprints', 'stimulant', 'stow', 'strickland', 'stylized', 'subdue', 'subscribing', 'succumb', 'suffocating', 'suisse', 'sumo', 'superbowl', 'surgically', 'susanna', 'syed', 'sympathize', 'tabernacle', 'tagline', 'talisman', 'tariq', 'thirdly', 'thwart', 'ticked', 'tins', \"toronto's\", 'tortilla', 'townhouse', 'transferable', 'transistors', 'transpired', 'transplanted', 'tres', 'tris', 'trish', 'truffle', 'tumultuous', 'ultron', 'unclean', 'unequivocally', 'unitary', 'usgs', 'vail', 'valkyrie', 'vedic', 'ventral', 'vibrate', 'vicente', 'wad', 'waging', 'waitin', \"weekend's\", 'weirdly', \"where'd\", 'whiplash', 'whos', 'wildcat', 'woodworking', 'worsen', 'worshippers', 'xenophobia', 'xenophobic', 'yakuza', 'yuck', 'ze', 'zeros', '✔', '1am', '4gb', 'acreage', 'affords', 'ajay', 'albino', \"alex's\", 'antichrist', 'antrim', 'aquaculture', 'argus', 'arrears', \"arsenal's\", 'artemis', 'asd', 'asp', 'assimilate', 'asterisk', 'asymmetrical', 'atf', 'augmentation', 'ayrshire', 'azalea', 'bacterium', 'balochistan', 'barter', 'bbl', 'beet', 'bessie', 'biggs', 'bigoted', 'bistro', 'bod', 'bonanza', 'bosom', \"boston's\", 'breakthroughs', 'breitbart', 'bribed', 'busan', 'callum', 'calmer', 'cannibal', 'catalogues', 'cato', 'centurion', 'chuckled', 'citi', 'clarendon', 'coldplay', \"collector's\", 'compendium', 'complacency', 'complements', 'confessional', 'conservancy', 'contentment', 'convoluted', 'cools', 'counterproductive', \"cousin's\", 'cowell', 'crayon', 'cremated', 'crm', 'cropping', 'crossbow', 'crowding', 'crux', 'cst', 'curators', 'cusp', 'danville', 'decoding', 'defenseless', 'defiantly', 'delia', 'delicately', 'deluge', 'desist', 'devlin', 'devoured', 'diffraction', 'dilapidated', 'dismissive', 'divas', 'doable', 'doorbell', 'drooling', 'ducking', 'dulles', 'duplicates', 'eastbound', 'emir', 'emu', 'eritrea', 'errand', 'eucharist', 'excites', 'exclaimed', 'expedite', 'extracellular', 'famer', 'fastball', 'fearsome', 'feathered', 'fertilization', 'fervor', 'fiduciary', 'fifths', 'flax', 'fractional', 'freighter', 'frosting', 'fuelled', 'für', 'g3', 'gaap', 'gallo', 'gasping', 'genevieve', 'globes', 'glorify', 'gunnar', 'guo', 'hasnt', 'heartwarming', 'henrietta', 'heretics', 'hiccups', 'hiss', 'holographic', 'hotspur', 'hrc', 'impediment', 'importation', 'inactivity', 'incendiary', 'individualized', 'insistent', 'instigated', 'intelligently', 'interferes', 'intermittently', \"iraq's\", 'isn', 'jag', 'kamal', 'kareem', 'keegan', 'kidnappers', 'kimball', 'lakewood', 'leapt', 'leia', 'leisurely', 'ligand', 'lila', 'liturgical', 'livelihoods', 'lothian', 'lubricant', 'lucie', 'm.s', 'macroeconomic', 'mags', 'maitland', 'maría', 'masquerade', 'materialism', 'maude', 'mea', 'meager', 'melodrama', 'milly', 'minimized', 'minion', 'mistreated', 'misused', 'mmmm', 'mons', 'morn', 'motherland', 'motogp', 'mundo', 'müller', 'nakamura', 'napkins', 'narcissism', 'navarro', 'niches', 'ninjas', 'nsf', 'observant', 'opioids', 'ostrich', 'overcast', 'overcrowding', 'paragon', 'parochial', 'pastries', 'perplexed', 'persistently', 'petting', 'peña', 'phenotype', 'pico', 'plankton', 'prasad', 'prejudiced', 'prius', 'propped', 'protons', 'pruning', 'punter', 'q4', 'qin', 'quark', 'queuing', 'quizzes', 'radiohead', 'rarer', 'rcmp', 'redacted', 'regretting', 'reimbursed', 'renovate', 'respiration', 'restores', 'retracted', 'reverses', 'ruff', 'rump', 'samir', 'santander', 'schiff', 'schiller', 'scranton', 'secondhand', 'shackles', 'shards', 'sheehan', 'shiver', 'simms', 'simplifying', 'sinned', 'ska', 'slugs', 'smog', 'smoothies', 'somber', 'splendor', 'springtime', 'sprinkler', 'stabs', 'standstill', 'stefano', 'stools', 'stubbs', 'subunit', 'sues', 'suffix', 'surges', 'surveyors', 'swede', 'sweepstakes', 'syndicated', \"syria's\", 'tailoring', 'tbs', 'teeny', 'tendered', 'thoracic', 'ticketing', 'trams', 'tremor', 'triplets', 'twister', 'ulrich', 'unannounced', 'uncovering', 'undivided', 'unsatisfactory', 'unskilled', 'unwritten', 'utilitarian', 'v0.0', 'vehicular', 'vetted', \"virginia's\", 'voltaire', 'wading', 'wallpapers', 'waning', \"war's\", \"wednesday's\", 'weightlifting', 'wesleyan', 'whey', 'whyte', 'willpower', 'wolverhampton', 'woolly', 'x3', 'yokohama', \"young's\", 'yuki', 'zig', 'с', '2gb', 'abbreviations', 'accra', 'acosta', 'acquittal', 'acupuncture', 'adi', 'admins', 'adv', 'aggregated', 'anakin', 'anvil', 'anzac', 'argos', 'armament', 'aron', 'ascribed', 'astra', 'asu', 'ata', 'atwood', 'auctioned', 'backfired', 'balconies', 'barbour', 'bastille', 'belligerent', 'betts', 'bibles', 'bleaching', 'bleeds', 'bloomfield', 'bookmark', 'botanic', 'boundless', 'bowles', \"brain's\", 'broadened', 'brooch', 'bulletins', 'bunting', 'burials', 'cabal', 'cabrera', 'cadre', 'campground', 'canaan', 'canyons', 'causeway', 'childrens', 'clamps', 'clearest', 'cleaver', 'cmon', 'cob', 'coexist', 'coffins', 'coinage', 'connelly', 'conquests', 'consenting', 'consummate', 'contending', 'convene', \"cooper's\", 'corresponded', 'covent', 'covington', 'cramp', 'cucumbers', 'curran', 'curricula', 'dearborn', 'decadent', 'decoy', 'defies', 'demoted', 'depraved', 'derivation', 'designations', 'detectable', 'deviations', 'diced', 'diem', 'discreetly', 'distortions', 'divorces', 'draco', 'dredge', 'drool', 'dumbledore', 'earths', 'ebb', 'ecb', 'ecu', 'emulation', 'enriching', 'enshrined', 'erasing', 'escrow', 'essendon', 'evaporated', 'evasive', 'extinguish', 'fas', 'fayetteville', 'fca', 'federalist', 'fema', 'fervent', 'fiberglass', 'fisk', 'fixer', 'flavoured', 'foray', 'forfeiture', 'forgave', 'forties', 'friar', 'fruitless', 'fussy', 'garcía', 'garnish', 'genealogical', 'genomes', 'georgie', 'glances', 'gnu', 'goody', 'gough', 'graciously', 'grammys', 'grassland', 'hackett', 'hajj', 'hampstead', 'hap', 'hatfield', 'hdd', 'hdr', 'headway', 'hearsay', 'hershey', 'hideout', 'hippies', 'hoa', 'hobbes', 'holed', 'honed', 'horned', 'horner', 'hoyt', 'hutch', 'i00', 'i5', 'idyllic', 'imaginations', 'impairments', 'impossibility', 'impotent', 'inconsiderate', 'indictments', 'insatiable', 'instalment', 'instinctive', \"institute's\", 'integrates', 'interpretive', 'intrepid', 'intuitively', 'jackman', 'jeanette', 'jetty', 'jimmie', 'jpeg', 'junkies', 'kabir', 'kawasaki', 'kew', 'khaki', 'kip', 'kirkland', 'koala', 'kohli', 'kos', 'lannister', 'lashing', 'lectured', 'lees', 'leith', 'levelled', 'lexi', 'lieberman', 'lightening', 'lombardi', 'londonderry', 'loren', 'lucien', \"m's\", 'macs', 'magnate', 'magneto', 'mahoney', 'mannered', 'marietta', 'markham', 'maud', 'mcgovern', 'merciless', 'merle', 'milder', 'millimeters', 'minn', 'misfits', 'mocks', 'molina', 'monde', 'mongols', 'monochrome', 'mortuary', 'mtg', 'muffled', 'mugabe', 'mulder', 'mullins', 'muppets', 'muses', 'n000', 'nacional', 'nationalistic', 'nervousness', 'neumann', 'neurologist', 'nik', 'notched', 'nutmeg', 'obstetrics', 'obtains', 'obtuse', 'ofcourse', 'p5', 'papi', 'particulate', 'pausing', 'penicillin', 'perfecting', 'petal', 'petitioned', 'plumbers', 'pms', 'poise', 'polygon', 'ported', 'precursors', 'prolly', 'promos', 'proportionate', 'provence', 'pta', 'purcell', 'pvp', 'quartermaster', 'radiance', 'rambo', 'rammed', 'raoul', 'reciprocity', 'recollections', 'remodeled', 'replenish', 'reproducing', 'reputations', 'responsiveness', 'rheumatoid', 'roscoe', 'rosetta', 'rubles', 'rupee', 'saeed', 'saltwater', 'sanctity', 'schoolers', 'schroeder', 'scooped', 'scrabble', 'scrimmage', 'seaboard', 'sedition', 'shoddy', 'shortstop', 'shotguns', 'sleazy', 'sleepers', 'smashes', 'smirk', 'smoothing', 'smyth', 'sneaks', 'snipe', 'snuggle', 'sochi', 'sociologist', 'spares', 'spewing', 'squishy', 'stalemate', 'stave', 'stephan', 'stinking', \"story's\", 'strangle', 'streamer', 'streetcar', 'stringer', 'summits', 'sunsets', 'supremely', 'sus', 'swami', 'swelled', 'symbolize', 'symbolizes', 't.c', 'tahiti', 'tarantino', 'tarmac', 'teh', 'tenacious', 'tireless', 'toothed', 'toshiba', 'tremble', 'trillions', 'trove', 'ue', 'unconsciously', 'undated', 'undefined', 'unpack', 'urbanization', 'vetoed', 'victimized', 'wainwright', 'walkin', 'wanders', 'weakens', 'westbound', 'westerly', 'whitehouse', 'wilfred', 'wilton', 'winch', 'winthrop', 'workstation', 'yam', 'yawning', 'yolk', '3c', 'accomplices', 'adc', 'adjusts', 'adp', 'aerosol', 'aftermarket', 'alienate', 'alphabetically', 'amer', 'ammonium', 'amour', 'andi', 'annuities', 'apprehensive', 'aquino', 'arjun', 'assent', 'assn', 'athenian', 'atrocity', 'authorisation', 'avec', 'babysit', 'backdoor', 'bagels', \"baker's\", 'banco', 'bantu', 'beaming', 'benin', 'benn', 'bh', 'bigots', 'biopic', 'bleached', 'blondie', 'bloods', 'blot', 'bode', 'boer', 'boggling', 'bolivian', 'bookstores', 'boos', 'bourgeoisie', 'bowser', 'boycotting', 'braced', 'brentwood', 'bromwich', 'bryson', 'bsc', 'buckinghamshire', 'bulging', 'burners', 'byproduct', 'bystanders', 'caspian', 'categorically', 'cathode', 'ceded', 'cheaters', \"chelsea's\", 'cheung', 'civility', 'clustering', 'cns', 'cohn', 'collin', 'commandos', 'complicity', 'conf', 'confetti', 'configure', 'confrontational', 'congolese', 'conley', 'connors', 'consequential', 'constitutions', 'contagion', 'convoys', 'corset', 'cortisol', 'coutinho', 'craters', 'crock', 'crocker', 'curate', 'cuttings', 'dataset', 'davos', 'dawned', 'daybreak', 'defected', 'defenseman', 'desolation', 'deviant', 'devine', 'devious', 'didier', 'dil', 'dilemmas', 'discography', 'dislocated', 'dispenser', 'disseminate', 'dorado', 'dragonfly', 'driscoll', 'dubstep', 'dugout', 'dunne', 'dynamically', 'e2', 'edelman', 'elizabethan', 'emanating', 'endeavours', 'ensues', 'eradicated', 'erode', 'evocative', 'faintly', 'fancies', 'federico', 'fewest', 'fielded', 'financials', 'fingering', 'flirty', 'flocks', 'forbade', 'forested', 'frauds', 'friendlies', 'fronting', 'frosted', 'fullness', 'furthering', 'g000', 'gaia', 'gallop', 'gentile', 'gentrification', \"georgia's\", 'gingerbread', 'gino', 'giro', 'gosling', 'grasshopper', 'groupings', 'guardiola', 'guildford', 'gutierrez', 'hallowed', 'halting', 'hamish', 'hampden', 'handguns', 'hebron', 'heywood', \"hospital's\", 'hove', \"hunter's\", 'hvac', 'hy', 'hydrate', 'hydrocarbon', 'incessant', 'incriminating', 'incurable', 'informants', 'informatics', 'infringed', 'inhaling', 'innumerable', 'insular', 'insurmountable', 'inundated', 'invariant', 'ionization', 'jailbreak', \"james's\", 'jarring', 'jing', 'juncture', 'karin', 'kebab', 'lago', 'lampard', 'larsson', 'latham', 'leanne', 'leinster', 'licensee', \"lincoln's\", 'locator', 'loeb', 'loyalist', 'luz', 'machado', 'macpherson', 'magnetism', 'maltese', 'manafort', 'manhunt', 'manoeuvre', 'margo', 'mariner', 'marlowe', 'marquez', 'marshmallows', 'martyn', 'masons', 'matthias', 'maximus', 'mays', 'meditating', 'merck', 'metamorphosis', 'methodological', 'middleweight', 'migrations', 'mila', 'milkshake', 'mio', 'misinterpreted', 'mixers', 'modernize', 'mozilla', 'multilingual', 'nats', 'natured', 'nested', \"nick's\", 'niki', 'nmr', 'notifying', 'nourishment', 'numerals', 'obeying', 'octavia', 'olfactory', 'organically', 'ortega', 'osbourne', 'paintball', 'parrish', 'parton', 'pedophiles', 'pertains', 'petrified', 'pheasant', 'photosynthesis', 'piccolo', 'pietro', 'piloted', 'pinching', 'pointe', 'pornhub', 'postponement', 'ppc', 'preclude', 'preorder', 'pressurized', 'prickly', 'pricks', 'priory', 'profiled', 'programmable', 'psn', 'puss', 'questionnaires', 'quintessential', 'racked', 'radiating', 'rancher', \"reader's\", 'reclaiming', 'redding', 'regularity', 'remediation', 'reprints', 'resounding', 'restrooms', 'retract', 'ria', 'ripples', 'roared', 'rondo', 'rowley', 'rumoured', 'russel', 'saban', 'salazar', 'samuels', 'sana', 'sarasota', 'scaffold', 'scavenger', 'schooner', 'scion', 'seamus', 'secularism', 'separatists', 'sephora', 'servitude', 'severn', 'showbiz', 'sickly', 'siegfried', 'simeon', 'slaughtering', 'slumped', 'smacks', 'sme', 'snooker', 'solemnly', 'sores', 'splashed', 'sprained', 'squadrons', 'starling', 'steamboat', 'steinberg', 'stingy', 'stuffy', 'stumbles', 'substituting', 'subversion', 'sufficiency', 'sui', 'suitcases', 'sumatra', 'suvs', 'syn', 'takedown', 'tas', 'tasteless', 'tensor', 'terminally', 'tian', 'ticker', 'tiff', 'tijuana', 'toil', 'tomography', \"tony's\", 'toon', 'toot', 'toulon', 'townsville', 'tru', 'truncated', 'trusty', 'twig', 'uf', 'ulcer', 'ummm', 'unconfirmed', 'undetected', 'uniformity', 'unjustified', 'unregistered', 'unsubscribe', 'untrained', 'ute', 'varnish', 'vee', 'videogames', 'vigor', 'waco', 'wag', 'walnuts', 'warhead', 'watcher', 'wealthier', 'welles', 'widower', 'wnba', 'wobbly', 'wot', 'wraith', \"ya'll\", 'yangon', 'yanks', 'yew', 'yugoslav', 'zoey', 'zoological', 'γ', '😀', 'accorded', 'afb', 'agar', 'agnostic', 'airmen', 'aisha', 'alameda', 'algiers', \"ali's\", 'aligning', 'allocations', 'alluring', 'amputation', 'anarchism', 'antagonistic', 'anthropologists', 'anya', 'apprehend', 'aquinas', 'architectures', 'axiom', 'b4', 'banger', 'barista', 'basalt', 'bashir', 'beatings', 'belated', 'bello', 'bequeathed', 'betterment', 'birthright', 'blackboard', 'blackwater', 'bor', 'breather', 'brendon', 'brothels', 'buckeyes', 'buffers', 'buffs', 'burrell', 'buzzed', 'bylaws', 'bystander', 'candace', 'carleton', 'catchment', 'chechen', 'chia', 'chino', 'cleanly', 'coffees', 'colorless', 'concave', 'confuses', 'consequent', 'contraceptives', 'corrects', 'coughs', 'cree', 'crucifix', 'cus', 'cyclones', 'daggers', 'dazzle', 'dealerships', 'decode', 'depriving', 'diagnosing', 'diarrhoea', 'dieter', 'discerning', 'disintegration', 'disposing', 'dissonance', 'dup', 'duress', 'dyslexia', 'earthy', 'editorials', 'elects', 'elevating', 'elmo', 'embezzlement', 'emigrants', 'emits', 'endorses', 'enforceable', 'ephraim', 'equinox', 'ericsson', 'erotica', 'erp', 'escalator', 'ethnicities', 'eulogy', 'eventful', 'excitation', 'f4', 'fanatical', 'fangs', 'fantastically', 'fastened', 'fawn', 'flanking', 'flinders', 'fluency', 'fresher', 'frickin', 'fructose', 'furnishing', 'gah', 'galvanized', 'gambia', 'gaul', 'gaulle', 'gcc', 'geophysical', 'gladiators', 'godwin', 'gomes', 'graphene', 'grasped', 'graze', \"green's\", 'grenada', 'grossman', 'grower', 'grunge', 'gtfo', 'gump', 'hagen', 'halsey', 'hatches', 'hawkes', 'headlined', 'helene', 'hennessy', 'hilariously', 'hoodies', 'hottie', 'huddled', 'hypothesized', 'iaea', 'ics', 'illustrative', 'imbalances', 'improvise', 'inappropriately', 'incandescent', 'indistinct', 'infallible', 'infuriating', 'insulating', 'integers', 'intracellular', 'irma', 'j.k', 'jakob', 'janus', 'jens', 'jg', 'jia', 'jolt', 'juggle', 'jukebox', 'jumpsuit', 'kami', 'kangaroos', 'kar', 'kato', 'kayaking', 'kerosene', 'keto', 'knobs', 'kroger', 'legacies', 'leveraging', 'levies', 'likeable', 'longs', 'macos', 'magenta', 'markov', 'marlboro', 'mccormack', 'mee', 'merton', 'methodical', \"michigan's\", 'middletown', 'mince', 'miniatures', 'mints', 'molotov', 'monogram', 'moray', 'mumford', 'mus', 'mythic', 'nacho', 'nailing', 'nanotechnology', 'napping', 'negroes', 'niko', 'nobleman', 'nonprofits', 'nugent', \"o'neil\", 'obeyed', 'optimist', 'osiris', 'outwardly', 'overlord', 'overuse', 'p2p', 'panned', 'papacy', 'pasted', 'patreon', 'pdt', 'perfumes', 'phonetic', 'photovoltaic', 'piccadilly', 'pied', 'piloting', 'pius', 'pkk', 'planck', 'poodle', 'populism', 'precedes', 'pus', 'racetrack', 'redirected', 'reeds', 'rejoined', 'relayed', 'rescinded', 'resuming', 'retrieving', 'rnc', 'roadblock', 'roadshow', 'roadways', 'rsvp', 'sabre', 'saleh', 'salons', 'sandbox', 'sato', 'saxons', 'scooters', 'sds', 'seagull', 'shag', 'shahid', 'sheryl', 'shifter', \"shit's\", 'shoemaker', 'shortfall', 'shrugs', 'sichuan', 'sift', 'silo', 'sion', 'smacking', 'smothered', 'sneezing', 'snooping', 'socialization', \"sony's\", 'soot', 'sopranos', 'soto', 'southport', 'sparingly', 'speck', 'spectacularly', 'spiced', 'ssc', 'sse', 'stoves', 'streep', 'stylus', 'subclass', 'submits', 'successively', 'suk', 'sumptuous', 'suture', \"sydney's\", 'synaptic', 'tailgate', 'tenuous', 'thelma', 'threes', 'tobin', 'topographic', 'trafalgar', 'tranquility', 'transmits', 'trekking', 'tuscan', 'tutu', 'tzu', 'umbilical', 'unhinged', 'uninterested', 'usaf', 'uterine', 'v3', 'vanishes', 'vapour', 'vas', 'veer', 'versace', 'warheads', 'waxing', 'weirder', 'weller', 'wheaton', 'whereupon', 'winfrey', 'winn', 'withdraws', 'wither', 'wk', 'wobble', 'yadav', 'yeon', 'yvette', 'zak', 'zed', 'é', 'a6', 'abridged', 'absences', 'acacia', 'adorn', 'aggressor', 'agm', 'ambivalent', 'amethyst', 'amit', 'angling', 'anil', 'antennae', 'antimicrobial', \"anybody's\", \"asia's\", \"assassin's\", 'atk', 'ats', 'babylonian', 'baines', 'baiting', 'barks', 'beasley', 'berserk', 'berwick', 'bickering', \"bishop's\", 'bla', 'bobo', 'bovine', 'braids', 'braille', 'butchered', 'bypassing', 'cabot', 'candlelight', 'cannibalism', 'canoes', 'capricorn', 'captivated', 'catapult', 'cbn', 'ccs', 'cdr', 'censors', 'centro', 'cervix', 'cheery', 'chimneys', 'chit', 'chomsky', 'chrissy', \"clark's\", 'clements', 'cleo', 'cog', 'cohorts', 'coloration', 'connective', 'cray', 'crayons', 'cronies', 'crusty', 'cumin', 'cutlery', 'dawes', 'decal', 'deciduous', 'degenerative', 'deloitte', 'delphi', 'detract', 'dialed', 'digested', 'diminishes', 'diplomas', 'dissection', 'dissimilar', 'dissuade', 'distillation', 'drab', 'dslr', 'dubs', 'ducked', 'dumfries', 'eeg', 'eggplant', 'ellington', 'engravings', 'enmity', 'epidemics', 'equipping', 'eucalyptus', 'eurasia', 'evaporate', 'execs', 'exhibitors', 'exo', 'exorbitant', 'expat', 'experimentally', 'expiring', 'eyelid', 'fainting', 'fecal', 'ferret', 'fertilizers', 'financier', 'fitter', 'flagrant', 'flapping', 'florist', 'foreplay', 'formatted', 'ftp', \"g's\", 'gangsta', 'garb', 'garvey', 'gassed', 'gatorade', 'gentiles', 'gilles', 'glancing', 'glaucoma', 'glazing', 'goblins', 'googling', 'goosebumps', \"gov't\", 'granular', 'greenish', 'grocer', 'groping', 'gtx', 'headless', 'healthiest', 'heineken', 'hemsworth', 'hibernation', 'hindrance', \"hollywood's\", 'hula', \"humanity's\", 'huxley', 'i7', 'ills', 'immunization', 'implantation', 'impressing', 'inaccuracies', 'inanimate', 'inca', 'inexplicably', 'infield', 'inflate', 'innovator', 'intermission', 'iqbal', 'irreplaceable', 'kanji', 'kh', 'kilogram', 'kn', 'kombat', 'kpop', 'kush', 'landline', 'lashed', 'legislate', 'liberian', 'lingo', 'lohan', 'looping', 'macy', 'marlin', 'marsden', 'marsha', 'masterchef', 'matron', 'mayfair', 'mcallister', 'mcgowan', 'meaty', 'mifflin', 'mirroring', 'mistaking', 'moderators', 'momo', 'mouthful', 'mun', 'murdock', 'mustangs', 'mutton', 'myra', 'neill', 'neoliberal', 'nestled', 'neutrons', 'newbury', 'newell', \"nfl's\", 'novelists', 'numeric', 'nunes', \"o'keefe\", 'oars', 'oates', 'ohm', 'oneplus', 'oop', 'optimizing', 'orc', 'outfielder', 'outflow', 'outperform', 'overtaking', 'overtook', 'overture', 'parma', 'parr', 'parrots', 'passively', 'paulson', 'peddling', 'pepperoni', 'perforated', 'pes', 'piero', 'pitchfork', 'placid', 'pleistocene', 'pooping', 'pox', 'pretense', 'principled', 'progesterone', 'puritan', 'quart', 'quinoa', 'rabble', 'rafters', 'raisin', 'rationing', 'reappear', 'rearrange', 'recreating', 'redeemer', 'redeeming', 'refreshments', 'reissue', 'remade', 'repulsed', 'resistor', 'restructure', 'revolting', 'rhapsody', 'rhea', 'robby', \"robert's\", 'rousseau', 'roux', 'ruddy', 'rune', 'sahib', 'salam', 'sandler', 'saucepan', 'scala', 'scarier', 'schism', 'scrubbed', 'seer', 'sepsis', 'seward', 'sharpening', 'sharpness', 'shelved', 'shh', 'shipper', 'shopped', 'shui', \"simon's\", 'sketching', 'skew', 'skimming', 'skydiving', 'smitten', 'snappy', 'sneaker', 'snort', 'snowboard', 'solitaire', \"song's\", 'sparing', 'spicer', 'spiegel', 'sportsmanship', 'sprinting', 'stakeholder', 'stanza', 'stipend', 'subsided', 'superannuation', 'surging', 'sweetened', 'sweetly', 'swims', 'swimwear', 'tamed', 'tampons', 'taunting', 'tec', 'tempe', 'tendons', 'terraced', 'testers', 'thrived', 'tickled', 'titty', 'toppings', 'traffickers', 'transcends', 'tropes', 'tsk', 'tumbled', 'twas', \"twitter's\", 'typography', 'typos', 'tyrion', 'uhhh', 'ukulele', 'ump', 'unauthorised', 'uncensored', 'unforgivable', 'uninhabited', 'unsurprisingly', 'untenable', 'unwavering', 'uranus', 'usability', 'veritable', 'vices', 'voldemort', 'wanderer', 'warts', 'watchman', \"website's\", 'whittaker', \"why's\", 'wut', 'xander', 'xerox', 'xiaomi', 'yd', 'yeo', 'yeti', 'yoghurt', '💰', 'aac', 'abject', 'actionable', 'administers', 'aes', 'affective', 'afield', 'aldrich', 'aldridge', 'alienating', 'alight', 'amazement', 'amending', 'amg', 'aoc', 'apnea', 'appointees', 'armpit', 'arr', 'asl', 'austere', 'authoritarianism', 'awkwardness', 'bab', 'backer', 'backpacking', 'bagging', 'bailiff', 'banda', 'banked', 'barnsley', 'barricades', 'beamed', \"bell's\", 'bergman', 'betrays', 'blinked', 'blissful', 'blister', 'blockage', 'blondes', 'bloodbath', 'bluffs', 'bmc', 'bnp', 'booms', 'bower', 'brah', 'bravest', 'brb', 'breasted', 'brookings', 'budgeted', 'bugger', 'buoy', 'bv', 'campaigner', 'capacitors', 'capes', 'carvings', 'cbt', 'celeb', 'cellars', 'cfl', 'chalice', 'chas', 'chichester', 'christophe', 'clippings', 'coll', 'colorectal', 'combing', 'commendation', 'compensating', 'condominiums', 'congratulating', 'consignment', 'contradicting', 'conundrum', 'corinne', 'coursework', 'coven', 'criminology', 'csu', 'czar', 'd0000', \"defendant's\", 'depots', 'dials', 'diamondbacks', 'dianne', 'discounting', 'disorganized', 'disseminated', 'dissolves', 'dmc', 'doggie', 'domes', 'duchy', 'dumplings', 'earmarked', 'ecumenical', 'electrification', 'embedding', 'encased', 'endothelial', 'engel', 'episodic', 'epsom', 'eros', 'eskimo', \"eu's\", 'ewan', 'expiry', 'extremity', 'fabregas', 'faithfulness', 'felonies', 'femur', 'ferrer', 'fluctuating', 'fong', 'fowl', 'foxy', 'franken', 'freckles', 'freelancer', 'fullerton', 'fundraisers', 'furs', 'g4', 'gelatin', 'gestation', 'guangdong', 'guggenheim', 'guillotine', 'gull', 'gulls', 'gusto', 'halfback', 'handout', 'harbors', 'havens', 'headband', 'henning', 'heralded', 'heretic', 'hernia', 'hippy', 'hitachi', 'hummus', 'ideologically', 'indiscriminate', 'individualism', 'infernal', 'infrequently', 'instill', 'invalidate', 'isolates', 'jazzy', \"jehovah's\", 'jeong', \"jerry's\", 'jeter', 'joffrey', 'kenyon', 'kingpin', 'kiosk', 'klopp', 'lags', 'lawton', 'legalizing', 'lentils', 'leprosy', 'lh', 'lisp', \"liverpool's\", 'locust', 'lombard', 'looney', 'lubbock', 'lui', 'm5', 'magnifying', 'malaya', 'mallet', 'maloney', 'mather', 'medici', 'mes', 'metastatic', 'meteorites', 'mew', 'militarily', 'minced', 'mishap', 'moby', 'mojave', 'molasses', 'monographs', 'monolithic', 'motoring', 'mott', 'moulded', 'mystique', 'nanjing', 'narcotic', 'nda', 'nefarious', 'nepali', 'nite', 'nix', 'nola', 'normalize', 'nucleotide', 'nurseries', 'olympians', 'optimus', 'orcs', 'orkney', 'outbound', 'outbursts', 'outsourced', 'overalls', 'overpowered', 'overworked', 'padilla', 'pantomime', \"parker's\", 'peacetime', 'pei', 'permian', 'peso', 'pierson', 'pilates', 'pita', 'pitting', 'plagues', 'playtime', 'pompeii', 'pompey', 'portage', 'positional', 'postcode', 'predicated', 'predictably', 'progeny', 'propagated', 'pushy', 'qualcomm', 'quell', 'r3', 'racecourse', 'railings', 'rainwater', 'rebounding', 'reflector', 'regimental', 'rehabilitate', 'renounced', 'reorganized', 'replicas', 'reread', 'revisiting', 'revolved', 'rigorously', 'roderick', 'rogues', 'roost', 'roswell', 'routers', 'salim', 'salzburg', 'savory', 'scholes', 'scorpions', 'sdf', 'seaworld', 'segmented', 'semesters', 'shalom', 'shard', 'sieve', 'signatories', 'sill', 'silvery', 'silvio', \"singer's\", 'sittin', 'smartwatch', 'snapper', 'snickers', 'soleil', 'soloist', 'somerville', 'soreness', 'southerners', 'sowing', 'sphinx', 'spore', 'stances', 'starfish', 'stifle', 'sturridge', 'succulent', 'superbly', 'supercar', 'superfluous', 'surged', 'surpasses', 'swain', 'swarming', 'sxsw', 'synchronous', 't4', 'tania', 'tasteful', 'telemetry', 'templeton', 'tenet', 'testifies', 'theologian', 'tiled', 'togo', 'tolstoy', 'tots', 'transcendental', 'transformational', 'translational', 'travesty', 'tricking', 'tunis', 'uncomfortably', 'undiscovered', 'unisex', 'upi', 'vane', 'vegetarians', 'vengeful', 'vials', 'weavers', 'westside', 'whatnot', 'whiteness', 'wicker', 'wrinkled', 'wsj', 'wynne', 'yank', 'yaya', 'aback', 'accuser', 'adrenal', 'agonizing', 'aimee', 'alluding', 'aloof', 'amulet', 'annotations', 'anticipates', 'apologetic', 'apoptosis', 'aq', 'arcane', 'argo', 'aristocrat', \"arthur's\", 'arty', 'assassinations', 'assays', 'astrid', 'astrophysics', 'atta', 'bader', 'baek', 'baku', 'bancroft', 'barbershop', 'batsmen', 'bbs', 'beal', 'beanie', 'behest', 'beit', 'benoit', 'bibi', 'biometric', 'blackened', 'blacklisted', 'blanca', 'bogged', 'boobies', 'bookkeeping', 'borden', 'braxton', 'bremen', 'brews', 'brixton', 'bronco', 'caesars', 'caitlyn', 'cajun', 'calvary', 'camaraderie', 'caravans', 'cascades', 'cask', 'catwalk', 'centimetres', 'chanted', \"christie's\", 'classically', 'clermont', 'clog', 'clubbing', 'colonized', 'columbian', 'competencies', 'confiscation', 'congresses', 'conscription', 'conserving', 'convo', 'covenants', 'cranial', 'criminality', 'croix', 'cts', 'culprits', 'custer', 'cyberspace', \"d's\", 'dao', 'dara', 'dbs', 'decapitated', 'detach', 'deterrence', 'deutsch', 'dielectric', 'dispensed', 'distanced', 'distasteful', 'dojo', 'dorms', 'dougie', 'dreading', 'droughts', 'druid', 'dud', 'duvet', 'eclipsed', 'eject', 'ell', 'emblems', 'endogenous', 'enforcer', 'ensembles', 'ephemeral', 'eponymous', 'erich', 'escorting', 'ethnographic', 'eurasian', 'examiners', 'extracurricular', 'faraway', 'fenway', 'fic', 'figurines', 'fittest', 'fleshy', 'flickering', 'fliers', 'fluctuate', 'fluttering', 'fontaine', 'footpath', 'fordham', 'forerunner', 'forgo', 'foxx', 'freer', 'frontage', 'frustrate', 'fryer', 'gaius', 'gar', 'garnett', 'ged', 'genomics', 'gingrich', 'goof', 'graced', 'grafton', 'grandad', 'grandmothers', 'greco', 'gunther', 'gurus', 'gustavo', 'hadith', 'hamburgers', 'hamlin', 'hangers', 'hannity', 'hardening', 'hippocampus', 'hoon', 'hoot', 'hoses', 'hostels', 'humanism', 'i3', 'incarnate', 'incomparable', 'informer', 'infrequent', 'infringe', 'ingestion', 'inquiring', 'internment', 'interprets', 'janine', 'jap', 'jekyll', \"jim's\", 'joni', 'jour', 'juggernaut', 'jungles', 'kalamazoo', 'kawhi', 'khartoum', 'kj', 'kushner', 'lackluster', 'langdon', 'largo', 'larva', 'laude', 'lausanne', 'layering', 'libertarians', 'lint', 'lira', 'livid', 'lobbies', 'loomis', 'loon', 'looser', 'lotte', \"lover's\", 'lowland', 'luce', 'luckiest', 'luscious', 'luxe', 'magnified', 'mainframe', \"mama's\", 'manger', 'manicure', 'mares', 'materialistic', 'materialize', \"matt's\", 'maturation', 'maury', 'mckee', 'mckinnon', 'mcmanus', 'meditations', 'menzies', 'mica', 'millar', 'minerva', 'minted', 'minuscule', 'misspelled', 'mobil', 'moisturizer', 'molar', 'molestation', 'mong', 'montrose', 'mosley', 'motorsports', 'mush', 'narcissist', 'navigational', 'neolithic', 'nestle', 'normalization', 'nous', 'oahu', 'obsessing', 'oceania', 'offends', 'ola', 'onus', 'onyx', 'oppa', 'osteoporosis', 'othello', 'outfitted', 'outwards', 'paco', 'palazzo', 'panting', 'pawns', 'peering', 'perceptive', 'peri', 'perpetuating', 'phosphorylation', 'phuket', 'pianos', 'picker', 'poached', 'precautionary', 'precipitated', 'preside', 'primo', 'ps2', 'purportedly', 'r5', 'ramona', 'rani', 'rayon', 'recessed', 'recklessly', 'redefined', 'reflux', 'regionally', 'reinhardt', 'reinstatement', 'relinquished', 'renovating', 'retriever', 'rigidity', 'ringtone', 'ritter', 'riveting', 'ronny', 'rosewood', 's.h.i.e.l.d', 'sable', 'sars', 'scoops', 'scouring', 'sedative', 'senile', 'setter', 'sheesh', 'sher', 'shredding', 'shrouded', 'shuffled', 'sil', 'sips', \"sky's\", 'sleigh', 'sliders', 'sliver', 'slush', 'smelt', 'softness', 'solidify', 'sora', 'sordid', 'soundtracks', 'soybeans', 'sportsmen', 'sprawl', 'springboard', 'squashed', 'squatting', 'stasis', 'stirs', 'stonewall', 'storied', 'streamers', 'sultry', 'sustenance', 'suárez', 'swamped', 'swivel', 'tait', 'tearful', 'teri', 'terminates', 'thier', 'thrashing', 'toolbox', 'toying', 'transsexual', 'tuff', 'twitching', 'underdeveloped', 'undisturbed', 'unhelpful', 'uninformed', 'unkind', 'unresponsive', 'unscathed', 'unsupported', 'utd', 'utica', 'utrecht', 'uzi', 'vert', 'vindicated', 'warlock', 'waterhouse', 'wayside', 'whig', 'whirlpool', 'whiskers', 'whitish', 'wholesalers', 'wickham', 'willows', 'wishlist', 'woulda', 'wrexham', 'xm', 'zealous', 'aberration', 'ade', 'aditya', 'ailment', 'airstrike', 'airwaves', 'alerting', 'alonzo', 'antoinette', 'apricot', 'arbiter', 'arbitrator', 'archangel', 'armand', 'arte', 'arundel', 'atari', 'athleticism', 'axles', 'babu', 'bailing', 'baptiste', 'baptists', 'baritone', 'bayley', 'bbb', 'benefitted', 'bestow', 'beverley', 'bezos', 'blistering', 'bloodline', 'bmx', 'booby', 'borderlands', 'breaching', 'brees', 'brice', 'britton', 'brom', 'bromley', 'broward', 'bryn', 'bucs', \"bull's\", 'buoyant', 'bushy', 'bustle', 'calculators', 'calms', 'caloric', \"campbell's\", 'captaincy', 'carbide', 'carmelo', 'carmine', 'caved', 'caverns', 'cca', 'cd00', 'cdt', 'chairmanship', 'chardonnay', 'checkmate', 'cheerfully', 'chou', 'clarissa', 'clem', 'clinician', 'clung', 'coals', 'cobain', 'coercive', 'collie', 'commenters', 'commercialization', 'conclusively', 'conduction', 'confided', 'conroy', 'constellations', 'consumerism', 'converters', 'convinces', 'copyrights', \"corporation's\", 'cosmology', 'cranston', 'criss', 'crumbled', 'curtail', 'daca', 'dakar', 'daydream', 'deafening', 'debuting', 'dedicating', 'detonate', 'dined', 'disarmed', 'disordered', 'divorcing', 'docker', 'docket', 'drifts', 'dy', 'earphones', 'edmunds', 'electrified', 'electrolytes', 'enchantment', 'endures', 'equated', 'esteban', 'expedited', 'experiential', 'faceless', 'factored', 'fascia', 'fasten', 'fatherland', 'fatigued', 'feasts', 'federalism', 'fey', 'figuratively', 'fizz', 'flatten', 'flopped', 'foiled', 'fonda', 'forester', 'fragility', 'frick', 'frigid', 'gallipoli', 'gasket', 'gemstone', 'ginny', 'goaltender', 'gonzaga', 'goodbyes', 'gory', 'granola', 'graphically', 'gre', 'groot', 'gushing', 'habitation', 'habs', \"hamilton's\", 'hatchback', 'hawley', 'heirloom', 'hoisted', 'homing', 'hough', 'huntsman', 'hustler', 'hypothermia', 'img', 'impatience', 'indiscriminately', 'inquisitive', 'instructive', 'instructs', 'interlocking', 'introspection', 'invader', 'jaffa', 'jamestown', 'janata', 'jansen', 'jeffries', 'jocelyn', 'kamala', 'kari', 'kernels', 'khrushchev', \"kingdom's\", 'kirsty', 'kors', 'lagged', 'lala', 'lancelot', 'lard', 'leblanc', 'leeway', 'lehmann', 'lexical', 'ley', 'lille', 'lob', 'lobsters', 'locale', 'loosened', 'ludlow', 'lutz', 'mademoiselle', 'maia', 'manifesting', \"martha's\", 'maserati', 'matheson', 'mcu', 'memos', 'mena', 'menswear', 'meritorious', 'methadone', 'methanol', 'mi6', 'millet', 'misogynistic', 'misrepresentation', 'mistreatment', 'mitigated', 'moa', 'mocha', 'mockingbird', 'moriarty', 'motown', 'n2', 'nagasaki', \"name's\", 'nea', 'negate', 'networked', 'nn', 'nomads', 'nonsensical', 'noor', 'noose', 'nordstrom', 'northrop', 'o.k', 'obstructed', 'offshoot', 'ointment', 'onscreen', 'onshore', 'ori', 'orthogonal', 'oss', 'ottomans', 'outnumber', 'outposts', 'overkill', 'overpowering', 'ovulation', 'pairings', 'paladin', 'parse', 'pegs', 'penises', 'perpetuated', 'petri', 'phasing', 'phnom', 'phrasing', 'pledging', 'pollination', 'pooled', 'postpartum', 'potions', 'pretzel', 'profusely', 'proletariat', 'promulgated', 'psu', 'puget', 'punctuated', 'punctured', 'punks', 'quadratic', 'raspberries', 'rebekah', 'recoup', 'rediscovered', 'remover', 'repelled', 'repertory', 'replicating', 'restructured', 'rhett', 'riddles', 'riga', 'roddy', 'rohit', 'rousing', 'roving', 'saas', 'sagan', 'sandman', \"sarah's\", 'sass', 'savor', 'schofield', 'schoolteacher', 'schwab', \"seattle's\", 'senatorial', 'sexting', 'shankar', 'shimmer', 'shingle', 'shoplifting', 'simplification', 'simulating', 'sindh', 'sls', 'snatching', 'snooze', 'spasms', 'srs', 'staked', 'stillness', 'strikeouts', 'structuring', 'stupidly', 'subculture', 'substitutions', 'suitor', 'suitors', 'supposing', 'supt', 'taint', 'tantrums', 'tarp', 'tarts', 'terrell', 'thea', 'thiago', 'thoroughbred', 'tiara', 'totality', 'tranny', 'tremors', 'tupac', 'tyrants', 'ugliest', 'ugliness', 'unaccompanied', 'uncontrollably', 'underline', 'unduly', 'unincorporated', 'unsatisfied', 'venturing', 'victors', 'vikram', 'vimeo', 'vindictive', 'vinny', 'visor', 'volta', 'walrus', \"water's\", \"wayne's\", 'weighting', 'werewolves', \"william's\", 'withers', 'wrongfully', 'yanked', '😩', '😳', 'abercrombie', 'abhorrent', 'accelerates', 'acton', \"album's\", 'alder', 'allowable', 'ame', 'amex', 'amicable', 'amortization', 'anaconda', 'anaerobic', 'anchoring', 'ange', 'anglers', 'aniston', 'annihilated', 'antisemitic', 'antonia', 'arg', 'asc', 'ashford', 'ashraf', 'atrophy', 'aung', 'aviator', 'avoidable', 'ayr', 'bales', 'baring', 'baum', 'bebe', 'behemoth', 'benfica', 'bhp', 'bib', \"bieber's\", 'blackwood', 'blip', 'blount', 'bolshevik', 'bossy', 'bottleneck', 'bradbury', 'brandi', 'brenner', 'broadest', 'buccaneers', 'bumble', 'cabo', 'californians', 'callie', 'cambrian', 'camelot', 'camry', 'caribou', 'carnal', 'caro', 'carpentry', 'cataract', 'caterpillars', 'caustic', 'censoring', 'centrifugal', 'cfb', 'chechnya', 'chelmsford', 'chimpanzees', 'chum', 'circadian', 'claremont', 'clarifies', 'cleansed', 'clemency', 'clots', 'codified', 'colds', 'collab', 'confederates', 'constables', 'constabulary', \"cook's\", 'coordinators', 'corinth', \"coroner's\", 'cote', 'crumb', 'ctr', 'cul', 'cushing', 'dames', 'darkly', 'davao', 'deactivate', 'deadlock', 'deathbed', 'deceitful', 'declan', 'deduce', 'deen', 'demented', 'denzel', 'devonshire', 'diddy', 'discernible', 'discharging', 'discourses', 'displace', 'displeased', 'dived', 'doge', 'dogged', 'dosing', 'drc', 'drury', 'duma', \"dylan's\", 'dynasties', 'ej', 'elated', 'elegantly', 'ember', 'embroiled', 'emmys', 'encampment', 'entitlements', 'equalizer', 'ergo', 'erskine', 'erupt', 'eugenics', 'evading', 'evaluates', 'evict', 'executor', 'expended', 'extremities', 'exuberant', 'f3', 'fables', 'facsimile', 'fanciful', 'faraday', 'farting', 'feinstein', 'felons', 'ferrell', 'fez', 'fha', 'fillet', 'firmer', 'formaldehyde', 'fractal', 'franck', 'frida', 'fulfilment', 'fumbled', 'gaa', 'garter', 'gbp', 'gels', \"gentleman's\", 'gerhard', 'gibberish', 'gifford', 'gifting', 'ginsburg', 'gleam', 'goff', 'goode', \"gordon's\", 'goss', 'gower', 'grandiose', 'growling', 'guerra', 'gummy', 'hag', 'handel', 'harmonica', 'hasbro', 'headlight', 'headsets', 'hera', 'hobson', 'housemate', 'hsu', 'humphreys', 'huston', 'icarus', 'idiom', 'iec', 'impersonating', 'impossibly', 'impressively', 'indulged', 'inexperience', 'inferiority', 'infuriated', 'inquired', 'inquirer', 'instilled', 'intently', 'intents', 'intoxicating', 'iota', 'j00', 'jaded', 'jihadists', 'jn', 'jovi', 'juju', 'kaepernick', 'kafka', \"kate's\", 'keyes', 'koo', 'labored', 'lambeth', 'landslides', 'leno', 'lightness', 'liquidated', 'lovell', 'lubrication', 'lunatics', 'lustre', 'maddy', 'mako', 'mandalay', 'mauricio', 'maxima', 'mcclellan', 'mcculloch', 'mehta', 'methamphetamine', 'mex', 'midas', \"mine's\", 'mobilizing', 'modernisation', 'modernized', \"modi's\", 'mongol', 'mortified', 'moshe', 'motionless', 'mpa', 'msn', 'mullet', 'naga', 'natures', 'navigable', 'negotiators', 'niggers', 'nikola', 'nothingness', 'o.o', 'obe', 'odors', 'offensively', 'openers', 'orchestras', 'ores', 'oskar', 'ota', 'overjoyed', 'pacemaker', 'pagans', 'pallets', 'pandering', 'panty', \"paper's\", 'paraphernalia', 'perl', 'pessimism', \"pete's\", 'petrie', 'petrochemical', 'plums', 'polyethylene', 'pooch', 'pooling', 'poppins', 'popularized', 'posterity', 'posthumous', 'pounce', 'pragmatism', 'projectors', 'proprietors', 'protestantism', 'qs', 'quan', 'quantified', 'receding', 'recognisable', 'recombination', 'recounting', 'rehabilitated', 'rejoicing', 'repayments', 'reprehensible', 'republished', 'resentful', 'rewatch', 'rhonda', 'rhubarb', 'riverdale', 'romanticism', 'rutland', 'ry', 's8', 'salesmen', 'sapiens', 'savers', 'scammed', 'scathing', 'scour', 'seagulls', 'serviceable', 'shanks', 'shearer', 'shimmering', 'shoals', 'shredder', 'shreveport', 'siamese', 'sienna', 'signifying', 'silvia', 'simplex', 'singaporean', 'sith', 'smokin', 'snorting', 'snows', 'sociable', 'socializing', 'soiled', 'soundly', 'speculations', 'sprinkling', 'ssi', 'standup', \"steve's\", 'stifling', 'stl', 'strayed', 'stunted', 'suh', 'supremacists', 'swastika', 'symbolically', 't.v', 'talkative', 'talon', 'teleport', 'tenths', 'tes', 'thoughtfully', 'thr', 'thrillers', 'thump', 'totalled', 'trombone', 'truer', 'tun', 'twitter.com', 'tyrannical', 'ug', 'underscore', 'unlocks', 'untill', 'unusable', 'uprisings', 'valdez', 'vandals', 'varanasi', 'vented', 'ventilator', 'vertebrate', 'violets', 'waite', 'warehousing', 'warlords', 'watermark', 'waverly', 'weathering', 'webcast', 'wellesley', 'westport', 'wielded', 'winona', 'yahweh', 'yearn', 'yolanda', 'yonder', 'zionists', 'δ', '8s', 'ababa', 'abandons', 'admires', 'affirms', 'afghans', 'agro', 'airtime', 'aldi', 'alibaba', \"alice's\", 'allocating', 'altman', 'ano', 'antithesis', 'arable', 'archetype', 'argyle', 'aristocrats', 'arlene', 'armin', 'arun', 'ashby', 'assyrian', 'ath', 'atrial', 'auditioning', 'avatars', 'avenged', 'awesomeness', 'ayn', 'bambi', 'bautista', 'bengaluru', 'bereavement', 'bertram', 'bikinis', 'bionic', 'blurring', 'boardroom', 'bobcats', 'bok', 'bondi', 'bonner', 'bottomless', 'bpm', 'brando', 'breakfasts', 'bsa', 'buena', 'bunches', 'burundi', 'caa', 'caddy', 'cade', 'caledonian', 'cautions', 'cee', 'cellphones', 'cetera', 'chandigarh', 'charted', 'chasm', 'chevalier', 'chimpanzee', 'chisel', 'choirs', 'cinder', 'cirque', \"citizen's\", 'coax', 'coincidences', 'commences', 'commenter', 'communicator', 'complies', 'comprehensively', 'condor', 'confectionery', 'confrontations', 'contented', 'coverings', 'crabtree', 'crass', 'crewe', 'cuddles', 'cull', 'culver', 'cymru', 'cz', 'd.a', 'dac', 'deference', 'delirium', 'deportations', 'descartes', 'devoting', 'diabolical', 'dilated', 'disarray', 'disinformation', 'disintegrated', 'dismayed', 'disregarding', 'dolby', \"dude's\", 'e1', 'ebert', 'edwardian', 'elector', 'eloquently', 'emojis', 'expendable', 'factoring', 'falkirk', 'falklands', 'fantastical', 'farmington', 'façade', 'fennel', 'fetching', 'fieldwork', 'filipina', 'firework', 'firsts', 'flattery', 'fleur', 'foolishly', 'foreseen', 'forgives', 'forked', 'formulating', 'fracturing', 'freedman', 'frisbee', 'futility', 'gaal', 'gabi', 'geiger', 'geraldine', 'grantham', 'greenpeace', 'gruber', 'hamlets', 'handover', 'hardin', 'hedging', 'helens', 'heroines', 'herzog', 'hexagonal', 'hipsters', 'hiro', 'hospitable', 'hummingbird', 'ight', 'impactful', 'impasse', 'impotence', 'increment', 'incursions', 'inescapable', 'infecting', 'intermediaries', 'invertebrates', 'ipc', 'jama', 'jester', 'jihadist', 'jockeys', 'juxtaposition', 'kashmiri', 'kaya', 'kazakh', 'keene', 'kinect', 'kites', 'kline', 'kofi', 'kok', \"kong's\", 'lesnar', 'ligue', 'likable', 'limping', 'lineups', 'lloyds', 'luisa', 'luster', 'luthor', 'madeira', 'maduro', 'mais', 'majoring', 'majorities', 'marcy', 'maris', 'maw', 'mbc', 'mcclure', 'mcg', 'melatonin', 'mesmerizing', 'metaphorically', 'millwall', 'mindanao', 'misread', 'misrepresented', 'mme', 'modulated', 'mousse', 'nai', 'naught', 'ncr', 'necessitated', 'nitrous', 'northamptonshire', 'obstructive', 'occupiers', 'odell', 'odour', \"oliver's\", 'ord', 'oreo', 'orientated', 'oscillation', 'oscillator', 'outrun', 'ov', 'overpass', 'pampered', 'paprika', 'patagonia', 'pathogenic', 'peeking', 'persevere', 'pfeiffer', 'pfft', 'piped', 'pisces', 'plasticity', 'playfully', 'polymerase', 'practicality', 'prawns', 'precedents', 'prerequisites', 'pretzels', 'proclaims', 'procrastination', 'profane', 'profiting', 'prospecting', 'prune', 'pte', 'putative', 'pyjamas', 'quirks', 'racine', 'radiate', 'raton', \"ray's\", 'reaping', 'rectum', 'refrigerators', 'regressive', 'regrettable', 'rené', 'reprise', 'restorative', 'rfc', 'rhyming', 'rigby', 'rojo', 'rumbling', 'salinity', \"samsung's\", 'sandusky', 'scolded', 'scrooge', 'seb', 'sena', 'serials', 'shakira', 'shep', 'shipyards', 'shovels', 'silt', 'sisterhood', 'sketched', 'slr', 'sma', 'smuggler', 'snape', 'snob', 'sodomy', 'soe', 'soldering', 'solubility', 'somers', 'sonnet', 'spacey', 'spalding', 'spectrometry', 'spurious', \"stephen's\", 'strat', 'subgroups', 'substandard', 'sugarcane', 'sundown', 'suspecting', 'swingers', 'swiping', 'synths', 'takeaways', 'talker', 'talmud', 'taunt', 'taunts', 'tensile', 'tether', 'thayer', 'thundering', 'tightness', 'tinkering', 'todo', 'toothless', 'trayvon', 'troubleshooting', 'truffles', 'turkmenistan', 'turntable', 'tuttle', 'underdogs', 'understandings', 'undressed', 'unknowns', 'uruguayan', 'usaid', 'utilise', 'valhalla', 'validating', 'vasquez', 'vermin', 'vertebrates', 'vertices', 'voltages', 'wack', 'wardens', 'weaves', 'weirdos', 'wentz', 'westinghouse', \"what'd\", 'whirl', 'widget', 'wineries', 'witt', 'woodbridge', 'workman', \"wright's\", \"x's\", 'ypg', 'zap', 'zucchini', '▄', '▒', '2g', '6m', '9mm', 'aborigines', 'abreast', 'absurdly', 'abv', 'ach', 'activision', 'adage', 'aguilera', 'airtight', 'albans', \"all's\", 'altruistic', 'amalgamated', 'amorphous', 'annulled', 'anthems', 'antioxidants', 'antlers', 'anu', 'aquaman', 'argh', 'armaments', 'arroyo', 'atms', 'audacious', 'audubon', 'aur', 'auth', 'balboa', 'battleships', 'bayesian', 'befriended', 'beheading', 'bff', 'blaring', 'bolder', 'bookies', 'boolean', 'bourke', 'boyer', 'brash', 'breads', 'brookfield', 'bumpers', 'buoyancy', 'burglars', 'businesswoman', 'buttermilk', 'bypassed', 'cai', 'caledonia', 'camila', 'campaigners', 'canisters', 'captioned', 'captors', 'cassius', 'cautionary', 'cayenne', 'centering', \"chef's\", 'chez', 'chimp', 'chromatography', 'classifying', 'cleary', 'clitoris', 'coincidental', 'colliding', 'colliery', 'consonants', 'constituting', 'corcoran', 'coriander', 'couches', 'critters', 'croc', 'crucially', 'cruelly', 'daleks', 'damnation', 'darfur', \"dave's\", 'debtors', 'debunked', 'decorator', 'deletes', 'delgado', 'delirious', 'denser', 'deo', 'dependents', 'deriving', 'detractors', 'dhoni', 'didi', 'differentiating', 'disconcerting', 'disingenuous', 'dissipate', 'dn', 'dooley', 'doran', 'dreamworks', 'dressings', 'dunedin', 'easterly', 'edema', 'edmonds', 'elapsed', 'ellsworth', 'empowers', 'encode', 'enrico', 'enterprising', 'eriksen', 'erupts', 'ets', 'exacting', 'expectant', 'exponent', 'extravaganza', 'faisal', 'falcao', 'falco', 'farr', 'fcs', 'filaments', 'findlay', 'finishers', 'flack', 'foaming', 'forma', 'forman', 'freebies', 'frye', 'fuming', 'fung', 'galen', 'ganesh', 'garza', 'geriatric', 'gleaned', 'globalisation', 'goddammit', 'goddamned', 'goodluck', 'grasslands', \"gray's\", 'guidebook', \"hall's\", 'halved', 'hardline', 'haves', 'hel', 'herding', 'hereinafter', 'hiked', 'hindustan', 'hiram', 'historia', 'hoes', 'holman', 'honk', 'hotspots', \"houston's\", 'hungover', 'hur', 'hwa', 'iam', 'importers', 'impure', 'incheon', 'incursion', 'inexcusable', 'influencer', 'inhibitory', 'installs', 'integrative', 'intl', 'inuit', 'invisibility', 'jermaine', 'jiu', 'keats', 'kilmarnock', 'kimono', 'kmart', 'knickers', 'kuhn', 'langston', 'leiden', 'lessened', 'liege', 'lightest', 'lightsaber', 'limbaugh', 'lingers', 'lipids', 'llama', 'looped', 'loosening', 'loudspeaker', \"lowe's\", 'lynda', 'macfarlane', 'macron', 'marisa', 'marketer', 'marko', 'mascots', 'mcfadden', 'mcnally', 'mcneil', 'mcs', 'mediators', 'minster', 'mongering', 'monotonous', 'morbidity', 'motherwell', 'multipurpose', 'muscat', 'muttering', 'n1', 'naturalized', 'navel', 'neanderthal', 'newbies', 'nippon', 'nitric', 'northerly', \"o'rourke\", \"o's\", 'obsidian', \"ocean's\", 'oe', 'overlaps', 'paging', 'palettes', 'parliamentarians', 'parnell', 'payed', 'pda', 'penang', 'penrith', 'pent', 'perky', 'phishing', 'plundered', 'pocahontas', 'polarizing', 'pomp', 'popper', 'priestess', 'prohibitive', \"prosecutor's\", 'psd', 'quakers', 'quarantined', 'quotient', 'rac', 'rajiv', 'raking', 'rami', 'realtors', 'rebelled', 'redefining', 'redness', 'reelected', 'resonated', 'retelling', 'reuniting', 'rios', 'roh', 'romanians', 'saba', 'sabbatical', 'sabotaging', 'sachin', 'sadder', 'sailboat', 'salaried', 'salmond', 'sancho', 'sansa', \"satan's\", 'saws', 'saxony', 'scallops', 'scammer', 'schubert', 'scottie', 'searing', 'secreted', 'sedation', 'sexier', 'shamelessly', 'shih', 'shithole', 'shivers', 'siena', 'sleepover', 'slingshot', 'slurry', 'smarts', 'sosa', 'sown', 'spc', 'spf', 'spitfire', 'sprinkles', 'src', 'stashed', 'steampunk', 'steed', \"stewart's\", 'stfu', 'stints', \"store's\", 'strongholds', 'stumped', 'stutter', 'subspecies', 'subvert', 'sunburn', 'suny', 'supplementation', 'swerve', 'tampered', 'tarnished', 'taunton', 'termites', 'testicular', \"thompson's\", 'tiller', 'tooling', 'topological', 'topple', 'transcendent', 'trapper', 'trickery', 'triton', 'trucker', 'truckers', 'tulips', 'turban', \"turner's\", 'tusk', 'ubisoft', 'undertakes', 'unending', 'unforgiving', 'uninstall', 'unplug', 'unproven', 'usain', 'vac', 'valium', 'vcr', 'ven', 'wanker', 'watchmen', 'wba', 'whitfield', 'willem', 'wl', 'wrigley', 'xy', 'yarmouth', 'yolo', 'zagreb', 'zlatan', '1c', '1h', '4wd', 'acp', \"actor's\", 'adrienne', 'aff', 'affixed', 'aguilar', 'airbags', 'albright', 'alkali', 'allusion', 'almeida', 'altruism', 'ambience', 'amphibians', 'andover', 'annabelle', 'anomalous', 'anson', 'antioxidant', 'apk', 'armitage', 'asos', 'assemblage', 'astm', 'astor', 'astounded', 'auld', 'austrians', 'autocorrect', 'baht', 'barrington', \"barry's\", 'bec', 'benito', 'bev', 'bevan', 'birdman', 'birthing', 'bobs', 'boehner', 'boggs', 'bosh', \"boss's\", 'bowden', 'boycotted', 'brandenburg', \"bride's\", 'bulgarians', 'bureaus', 'burritos', 'butthole', 'campos', 'carcasses', 'caress', \"carolina's\", 'catchphrase', 'censure', 'channeled', 'charlene', \"charlotte's\", 'chewy', 'childlike', 'chopin', 'cleanest', 'cleft', 'clump', 'cluttered', 'cmos', 'cnc', 'combos', 'communicative', 'complicating', 'conceivably', 'concussions', 'connotation', 'constitutionality', 'coughed', 'cra', 'creeper', 'cultivars', 'customizable', 'cuthbert', 'damper', \"dc's\", 'deduced', 'deepwater', 'deja', 'dep', 'dependant', 'depository', 'deuce', 'diagonally', 'dickie', 'disapproved', 'disqualify', 'dnd', 'doh', 'dona', 'donates', 'donegal', 'doorways', 'doped', 'doritos', 'dram', 'dsp', 'earner', 'edc', 'efl', 'electrostatic', 'embed', 'empathetic', 'emulator', 'encompassed', 'enlisting', 'enlistment', 'entrant', 'envoys', 'ephesians', 'eraser', 'etymology', 'evidences', 'exasperated', 'excalibur', 'exorcist', 'faceted', 'faggots', 'fags', 'fayette', 'federated', 'fgm', 'fibrous', 'fiddling', 'fitbit', 'fixated', \"francisco's\", 'freya', 'friars', 'frisco', 'fy00', 'g7', 'galatasaray', 'gasped', 'gaussian', 'gaye', 'gdr', 'gea', 'geeky', 'goings', 'gove', 'gratis', 'gratuitous', 'gud', 'guiana', 'haggard', 'headings', 'headliner', 'herod', \"home's\", 'honeycomb', 'hooligans', 'hopelessness', 'horus', 'householder', 'href', 'html5', 'hubris', 'hurrah', 'hutchison', 'hysterically', 'ias', 'idealized', 'idiosyncratic', 'ignatius', 'immerse', 'immortals', 'impassioned', 'indemnity', 'indira', 'installer', 'interoperability', 'jas', 'jitsu', 'juliana', 'juve', 'kampala', 'kasich', 'katniss', 'kelso', 'kiddie', 'kindest', 'labourer', 'langford', 'lapsed', 'lasalle', 'latitudes', 'lia', 'lili', 'lilith', 'livermore', 'lk', 'lures', 'm.e', 'mackey', 'mailer', 'malfunctioning', 'manfred', 'mangled', 'marxists', 'mausoleum', 'mccullough', 'melodramatic', 'mesopotamia', 'messaged', 'metallurgy', 'misc', 'mlk', 'mohan', 'mugged', 'mull', 'mushy', 'nauru', 'nepalese', 'newsletters', \"nixon's\", 'novices', \"now's\", 'nsc', 'nursed', 'ocular', \"old's\", 'ontology', 'opm', 'oratory', 'orbiter', 'origami', 'orthopaedic', 'oust', 'ovary', 'oxides', 'palma', 'paradoxically', 'pcp', 'pena', 'perceives', 'petro', 'pewdiepie', 'phipps', 'picturing', 'pituitary', 'plumage', 'poachers', 'poof', 'possum', 'potted', 'premeditated', 'preset', 'profess', 'proportionally', 'purging', 'raiser', 'randle', 'ratify', 'rbc', 'rearranged', 'reassigned', 'recast', 'recombinant', 'refreshment', 'rehearse', 'remakes', 'repellent', 'reproach', 'repurchase', 'rescuers', 'resins', 'retractable', 'retroactively', 'retweeted', 'reunions', 'ronda', 'rosberg', 'runny', 'ruskin', 'rwandan', 'saad', 'saddled', 'saith', 'sander', 'sarcastically', 'scepticism', 'scorecard', 'scrutinized', 'scumbags', 'seabed', 'seamen', 'sed', 'senna', 'seok', 'serenade', 'shazam', 'sideshow', 'silos', 'simba', 'skimmed', 'skirmishes', 'slaughterhouse', 'slideshow', 'smurfs', 'sociologists', 'sonja', 'sparrows', 'speculators', 'splurge', 'spotty', 'springing', 'stabilizer', 'stereotyping', 'stimulants', 'struts', 'subconsciously', 'sufferer', 'suppressor', 'sycamore', 'synthesize', 'tabled', 'tacit', 'taggart', 'takeout', 'tangerine', 'taro', 'teeming', 'terrors', 'tethered', 'thefts', 'thrusting', 'tilly', 'tonnage', 'torrents', 'totes', 'tut', 'typhoid', 'tyrell', 'ub', 'ucf', 'unclaimed', 'underwhelming', 'unofficially', 'unopened', 'untapped', 'upholstery', 'valle', \"vehicle's\", 'veracity', 'verifiable', 'vide', 'viscous', 'vitally', 'vixen', 'wank', 'waugh', 'waverley', 'wbc', 'weil', 'whatcha', 'whims', 'whitey', 'wilshere', 'windfall', 'woolwich', 'workday', 'wreak', 'wta', 'xviii', 'yap', 'yous', 'zayn', '͡', 'a.i', 'abbie', 'ablaze', 'adriatic', 'aegean', 'aerodynamics', 'agra', 'ahhhh', 'amiss', 'amphetamine', 'amputated', 'amr', 'anaesthetic', 'analogies', \"andy's\", \"animal's\", 'animator', 'anno', 'antidepressant', 'aqueduct', 'archeological', 'aruba', 'assed', 'assesses', 'attributing', 'audiovisual', 'authenticated', 'awry', 'barnaby', 'barrymore', 'bask', 'befriend', 'bellingham', 'belo', 'bilbao', \"blake's\", 'bobbi', 'bogart', 'bragged', 'brainwashing', 'breen', 'bribing', 'bristles', 'broome', 'bueno', 'busier', \"caesar's\", 'camino', 'captained', 'centralised', 'chilton', 'chiropractic', 'chopsticks', 'chp', 'citizenry', 'claudius', 'clumps', 'cocked', 'colloquial', 'combed', 'commas', 'confidant', 'config', 'confiscate', 'consecutively', 'controllable', 'conversing', 'cooley', 'coolidge', 'copped', 'cornea', 'cramer', 'crichton', 'crumpled', 'cuter', 'daimler', 'dcs', 'decompression', 'deflation', 'demeaning', 'dengue', 'denials', 'denominational', 'dermatology', 'detachable', 'deterministic', 'deux', 'devotee', 'dictating', 'diggers', 'dimes', 'directv', 'disfigured', 'disguises', 'disprove', 'disrespected', 'divulge', 'docile', 'doctrinal', 'dogmatic', 'dominica', 'doubleday', 'downton', 'droves', 'drunks', 'dryness', 'duterte', 'dyeing', 'eases', 'echelon', 'edifice', 'edu', 'ehh', 'ela', 'embossed', 'emt', 'encircled', 'endpoint', 'englewood', 'enid', 'entailed', 'ethyl', 'evanston', 'everglades', 'excels', 'expatriate', 'expats', 'expertly', 'facelift', 'fairway', 'fanboy', 'fao', 'farrow', 'fawcett', 'felton', 'fireplaces', 'fishers', 'fitzroy', 'flamenco', 'floored', 'flustered', 'follicles', 'folsom', 'formalities', 'franciscan', 'friendliness', 'gael', 'gagging', 'galloping', 'gaseous', 'geller', 'gio', 'gita', 'glows', 'goulding', 'gradients', 'grads', 'grits', 'groans', 'grosvenor', 'grueling', 'guardianship', 'gulp', 'gv', 'gypsum', 'hangin', 'hao', 'harbaugh', 'harbours', 'hasten', 'hauser', 'heady', 'healers', 'herbie', 'hindering', 'hiroshi', 'hmmmm', 'homesick', 'homme', 'hos', 'hotly', 'huber', 'humanly', 'hurd', 'husbandry', 'hushed', 'hyperbole', 'hypothetically', 'ibuprofen', 'identifiers', 'idly', 'imho', 'immigrated', 'immobile', 'impair', 'indycar', 'ipcc', 'irradiated', 'isaacs', \"jacob's\", 'jerked', 'jpg', 'jugs', 'karla', 'kharkiv', 'kinetics', 'kipling', 'knapp', 'lawler', 'layla', 'layman', 'layton', 'layup', 'leona', 'libra', \"library's\", 'lifes', \"line's\", 'luciano', 'macabre', 'macaulay', 'mackie', 'mackintosh', 'magdalene', 'magnification', 'maki', 'manziel', \"marshall's\", 'mbe', 'mcdaniel', 'medicated', 'memento', 'midwifery', 'milieu', 'mistresses', 'miz', 'mms', 'modus', 'monsignor', 'moonshine', 'msa', 'msi', 'multitasking', 'mutt', 'myocardial', 'mysore', 'n.d', 'nachos', 'nani', 'nao', 'narnia', 'naturalistic', 'nepotism', 'ngl', 'normality', 'oblong', 'olly', 'ooooh', 'operatic', 'ophthalmology', 'oppenheimer', 'orca', 'osage', 'osman', 'overcomes', 'overseer', 'overstated', 'paddling', 'painstaking', 'pall', 'panelists', 'panzer', 'parodies', 'patchy', 'paychecks', 'pecan', 'penh', 'perceptual', 'pereira', 'photoshoot', 'pimples', 'pings', 'pinocchio', 'pips', 'pique', 'plo', 'plowed', 'politeness', 'pomegranate', 'ponzi', 'porters', 'potholes', 'ppi', 'pregame', 'promiscuous', 'proudest', 'psychopaths', 'pugh', 'punta', 'pusher', 'quixote', 'rangoon', 'raza', 'rbis', \"reagan's\", 'rebranded', 'refueling', 'reprimanded', 'reproductions', 'resell', 'reserving', 'resuscitation', 'revocation', 'richland', 'roadblocks', 'rosalind', \"russell's\", 'rusted', 's.s', 'sacraments', 'sagging', 'sant', \"santa's\", 'sardines', 'sardinia', 'scalable', 'scalar', 'scalia', 'schaefer', 'schoolchildren', 'schwarz', 'scrapbook', 'selby', 'selectors', 'semiconductors', 'sensibly', 'sensitivities', 'separator', 'sequestration', 'sheraton', 'shoal', 'sigmund', 'sledgehammer', 'sleeved', 'smartly', 'smite', 'smt', 'sniping', 'socal', 'solicited', 'somatic', 'southside', 'splendour', 'ssl', 'stearns', 'steeply', 'stingray', 'stonehenge', \"storm's\", 'straightening', 'subcontinent', 'subsets', 'subsidize', 'substation', 'sufferings', 'swarms', 'symbiotic', 'tantamount', \"target's\", 'tasha', 'teaspoons', 'tetris', 'therese', 'thereto', 'thermodynamic', 'thoreau', 'thorny', 'thurman', 'tickling', 'tortillas', 'tosses', 'traversed', 'trifle', 'trixie', 'twine', 'twink', \"tyler's\", 'uav', 'uci', 'unfulfilled', 'unjustly', 'unoccupied', 'venous', 'ventricular', 'viciously', 'videogame', 'vincenzo', 'vindication', 'vinnie', 'violins', 'vishnu', 'vive', 'voila', 'voip', 'wadsworth', 'watercolour', 'wedded', 'weymouth', 'whelan', 'whiter', 'wickedness', 'wilshire', 'woodson', 'worksheet', 'wrappers', 'wylie', 'wyndham', 'xxi', 'xxiii', 'yarns', '💕', '😡', '😢', '2k00', '4c', '5d', 'abysmal', 'addams', 'adores', 'aman', 'amar', 'angelou', 'antigens', 'aorta', 'apostasy', 'aram', 'argyll', 'artistically', 'ascii', 'asda', 'ashram', 'attentions', 'aust', 'avocados', 'aya', 'ayatollah', 'b3', 'baa', 'batista', 'battlefields', 'beowulf', 'beret', 'bharatiya', 'bleu', 'bloomsbury', 'bogey', 'bol', 'bolsheviks', 'bookshelf', 'boron', 'bpa', 'brainstorming', 'brigitte', 'bronchitis', 'brotherly', 'buffering', 'bugle', 'bumblebee', 'burch', 'buren', 'busters', 'butters', 'buxton', \"c's\", 'caf', 'callaghan', 'calum', 'canvases', 'capone', 'carboniferous', 'casings', 'catchers', 'catechism', 'categorize', 'cathedrals', 'causality', 'cern', 'cesare', 'chandeliers', 'chaney', 'chatty', 'chokes', 'christened', 'chug', 'churchyard', 'clapper', 'clarion', 'coffers', 'cognac', \"cole's\", 'colette', 'combatant', 'commie', 'compels', 'compilations', 'concealer', 'concealment', 'concentric', 'conceptually', 'confine', 'congregate', 'congresswoman', 'constructor', 'coolers', 'copycat', 'corroborate', 'corroborated', 'coulda', 'cred', 'cur', 'curd', 'cursory', 'dangle', 'daniela', 'dario', 'ddos', 'dearth', 'delilah', 'delinquency', 'denominated', 'deutschland', 'dez', \"dick's\", 'disservice', 'distaste', 'dost', 'dribbling', 'dryden', 'durango', 'dwindled', 'edie', 'een', 'ejaculation', 'enveloped', 'environmentalist', 'epileptic', 'erasure', 'errol', 'este', 'euphemism', 'exacerbate', 'exemplifies', 'exonerated', 'exquisitely', 'extinguisher', 'facilitation', 'falsehood', 'falsified', 'fantasia', 'favourably', 'fellaini', 'fertilized', 'firefighting', 'firestorm', 'flange', 'flaunt', 'flawlessly', 'flier', 'flinch', 'florentine', 'fontana', \"force's\", 'forefathers', 'frankel', 'freehold', 'freeport', 'frisk', 'fta', 'fulfills', 'fundamentalism', 'gables', 'gabon', 'gad', 'galapagos', 'ganges', 'garmin', 'gasps', 'gaz', 'girth', 'goalscorer', 'godmother', 'goodell', 'gothenburg', 'governorship', 'graf', 'grunts', 'guadalupe', 'guatemalan', 'guillaume', 'guzman', 'hallmarks', 'haq', 'hardwick', 'harrogate', 'hellish', 'hemoglobin', 'hermitage', 'heyman', 'hierarchies', 'histoire', 'honeywell', 'hooves', 'hourglass', 'hungarians', 'hygienic', 'idiocy', 'imitated', 'impersonal', 'impregnated', 'incontinence', 'ine', 'inhaler', 'injures', 'intersex', 'intricacies', 'ironed', 'j.b', 'jacuzzi', \"kenya's\", 'kohler', 'lacquer', 'lakeland', 'laments', 'langer', 'lapses', 'lbj', 'ldl', 'levelling', 'linemen', 'lipsticks', 'liquefied', 'livestream', 'loaves', 'macgregor', 'madhya', 'maidens', 'malevolent', 'manchuria', 'mano', 'martyred', 'masterclass', 'matchups', 'mated', 'matrimony', 'matures', 'mechanized', 'mending', 'mercilessly', 'meteorologist', 'microprocessor', 'midweek', 'minefield', 'minogue', 'misha', 'mogadishu', 'mombasa', 'monash', 'monika', 'mta', 'murmur', \"murray's\", 'musings', 'nair', 'napoleonic', 'narrating', 'necrosis', 'ning', 'niro', 'notches', 'nou', 'nth', \"o'shea\", 'onerous', 'onsite', 'orientations', 'outsource', 'overtones', 'p.c', 'p.o', 'pained', 'paradigms', 'pardons', 'patching', 'pcc', 'peeping', 'pembrokeshire', 'peralta', 'permeability', 'pershing', 'pharmacological', 'plano', 'playmaker', 'plumb', 'plumes', 'plunger', 'pokes', 'porta', 'posey', 'presto', 'priestly', 'printable', 'priya', 'procuring', 'prodigal', 'prodigious', 'propellant', \"province's\", 'pulley', 'qualms', 'raaf', 'raccoons', 'raju', 'reappeared', 'recaptured', 'rechargeable', 'recluse', 'rectified', 'refinance', 'reformist', 'refresher', 'relaxes', 'remodel', 'replaceable', 'reschedule', 'restarting', 'retroactive', 'reverb', 'revisionist', 'ribbed', 'robs', 'rodman', 'rohingya', \"rome's\", 'sabotaged', 'sages', 'sandoval', 'sarkar', 'saskatoon', 'satoshi', 'schoolhouse', 'seashore', 'seclusion', 'selenium', 'setups', 'sewell', 'shuttles', \"side's\", 'signatory', 'silverstone', 'sinha', 'siphon', 'skelton', 'slasher', 'slimming', 'slovenian', 'snagged', 'soulmate', 'spangled', 'spiteful', 'splashes', 'sporadically', 'stefani', 'stifled', 'stinger', 'stipulation', 'stowe', 'stubbornly', 'subtropical', 'sulfide', 'summation', 'superimposed', 'surfacing', \"swift's\", 'tableau', 'taming', 'taxa', 'tbf', 'tebow', 'techs', 'tiredness', 'toi', 'toppled', 'trajectories', 'transgressions', 'transylvania', 'trotter', 'truest', 'tse', 'ufos', 'underpants', 'underprivileged', 'underscores', 'unhcr', 'unimpressed', \"unit's\", 'unreasonably', 'unrelenting', 'unsupervised', 'vassal', 'vegetative', 'velcro', 'verne', \"video's\", 'vying', 'wabash', 'walla', 'waltham', 'warranties', 'washburn', 'washers', 'weimar', 'weirdness', 'werent', 'westgate', 'wheatley', 'wheelchairs', 'wie', 'wiseman', 'withered', 'woefully', 'workmen', 'wrangler', 'yds', 'yeats', 'yonkers', 'yunnan', 'zidane', 'ziggy', 'ü', 'σ', 'aberdeenshire', 'abrasion', 'accrue', 'ackerman', 'acumen', 'admirably', 'alford', 'allele', 'alumnus', 'amon', 'amore', 'andean', 'angers', 'anniversaries', 'aphrodite', 'applauding', 'applicability', 'approachable', 'aragon', \"arm's\", 'armagh', 'asexual', 'atlético', 'auditioned', 'automata', 'babel', 'balding', 'ballon', 'banding', 'bannister', 'bellies', 'bernice', 'beryl', 'blackbird', 'bleachers', 'bluebird', 'blunders', 'boe', 'boop', 'brats', 'breech', 'breezes', 'buttery', 'cadbury', 'cafés', 'caliph', 'calle', 'cameos', 'carta', 'celiac', 'celibacy', 'cersei', 'chancery', 'chappell', 'characterizes', \"chief's\", 'chiu', 'choppy', 'chromatic', 'chronologically', 'chump', 'clamping', 'clashing', 'clenched', 'clogging', 'clove', 'columbine', 'commemorated', 'comte', 'converged', 'cordelia', 'countenance', 'crackling', 'crawls', 'creighton', 'crouching', 'crowder', 'cryptography', 'cysts', 'dali', 'damping', 'dapper', 'deathly', 'deere', 'defection', 'delightfully', 'dermatitis', 'desiring', 'determinants', 'devaluation', 'dictatorial', 'digitized', 'disinterested', 'dispensaries', 'disrespecting', 'dissected', 'dist', 'diversions', 'diwali', 'doreen', 'dota', 'downplay', \"drake's\", 'drapes', 'dss', 'dunkin', 'dynamical', 'edi', 'electra', 'elicited', 'eluded', 'ema', 'encapsulated', 'eno', 'enquire', 'ensue', 'environs', 'epics', 'errant', 'esophagus', 'estelle', 'etfs', 'ethylene', 'eunice', 'evaded', 'evie', 'exterminate', 'eyewitnesses', 'fai', 'fairchild', 'falmouth', 'faze', 'fbs', 'fdi', 'fergie', 'figaro', 'finney', 'fisa', 'flatly', 'flicked', 'flocked', 'fluently', 'forsake', 'fusing', 'gallen', 'gamestop', 'gasol', 'gatwick', 'gecko', 'generalize', 'gervais', 'gianni', 'gila', 'giraffes', 'gondola', 'grained', 'grandmaster', 'grenoble', 'grills', 'grudges', 'guacamole', 'hagan', 'hammersmith', 'hamptons', 'handcrafted', 'harbinger', 'harnessed', 'harvests', 'headshot', 'heartily', 'heb', 'helplessness', 'helpline', 'henchman', 'hiccup', 'hoffmann', 'hurl', 'hydroxide', 'ied', 'iit', 'iliad', 'ilk', 'imbued', 'impartiality', 'incessantly', 'inertial', 'intentioned', 'introvert', 'invades', 'invocation', 'involuntarily', 'iroquois', 'irreparable', 'issuers', 'ivanka', 'iz', 'jer', 'jimenez', 'journeyman', 'kandahar', 'khloe', 'kitchener', 'kobayashi', 'korra', 'kpa', 'kuwaiti', 'kwan', 'l000', 'lactic', 'laing', 'lanarkshire', 'larval', 'laterally', 'lathe', 'lawlessness', 'lcs', 'leela', 'leonid', 'leopards', 'liberally', 'lonnie', 'lopsided', 'lowlands', 'lunacy', 'magi', 'malia', 'malloy', 'mancini', 'mantel', 'marcello', 'matchday', 'mayday', 'mcafee', 'mcdonough', 'meier', 'melons', 'melton', 'mem', 'merges', 'meteors', 'methylation', 'micky', 'milligan', 'misinformed', \"mitchell's\", 'morphed', 'mumble', 'mummies', 'musketeers', 'nad', 'newmarket', 'nie', 'nonpartisan', 'norwalk', 'noxious', 'nucleic', 'oaths', 'ocs', 'octagon', 'offsets', 'oligarchs', 'opulent', 'ordinate', 'organist', 'oro', 'outed', 'outstretched', 'overbearing', 'patting', 'pectoral', 'percival', 'perplexing', 'personified', 'petr', 'plummeted', 'podesta', 'polaroid', 'preexisting', 'prepped', 'primrose', 'prohibitions', 'psyched', 'puddles', 'pulsating', 'pungent', 'putter', 'qatari', \"rachel's\", 'radioactivity', 'ranches', 'raquel', 'recessive', 'reclining', 'redford', 'reeve', 'refinancing', 'relativistic', 'relaunch', 'reloaded', 'remand', 'replete', 'repugnant', 'ringed', 'rmb', 'roaches', 'roamed', 'roars', 'rotc', 'rote', 'rotors', 'rudeness', 'ruffled', 'saa', 'sabah', 'salinas', 'salomon', 'sandal', 'sandro', 'santi', 'scat', 'scissor', 'seaport', 'sellout', 'seminole', 'serra', 'setlist', 'seychelles', 'shakers', 'shang', 'sharpest', \"shepherd's\", 'simulators', 'sixes', 'skilful', 'snot', 'sodas', 'spilt', 'spineless', 'spirals', 'stairwell', 'stalwart', 'standardised', 'stapleton', 'starfleet', 'steeper', 'stomped', 'stooges', 'streisand', 'subtraction', 'sufi', 'summing', 'sutra', 'swiped', 'sybil', 'synagogues', 'tartan', 'taut', 'teapot', 'telephoned', 'theorems', 'therefor', 'thoroughfare', 'threading', 'traversing', 'treehouse', 'tribeca', 'tripadvisor', 'triumphed', 'tuner', \"ukraine's\", 'underrepresented', 'undervalued', 'undying', 'unequivocal', 'uneventful', 'unfathomable', 'ungodly', 'unprofitable', 'unreported', 'unsung', \"usa's\", 'vaginas', 'valour', 'vanquished', 'velocities', 'vern', 'vf', 'warburton', 'waterman', 'weinberg', 'wetter', 'whittier', 'windscreen', 'wonka', 'woodhouse', 'wormhole', 'wray', 'yellows', 'youngstown', 'zanzibar', 'zola', 'zooming', '8c', 'abram', 'accented', 'adonis', 'aggrieved', 'albatross', 'alina', 'allusions', 'amal', 'androids', 'anglesey', 'annabel', 'antivirus', 'aquifer', 'arduino', 'armando', 'arouse', 'arranges', 'assemblyman', 'autocratic', 'autographed', 'avis', 'ayres', 'baez', 'bak', 'bakeries', 'bakr', 'ballarat', 'baller', 'banff', 'basements', 'bene', 'bereaved', 'bes', 'bfa', 'bigelow', 'bindings', 'bjorn', 'blackouts', 'blossomed', 'blossoming', 'blowers', 'bogota', 'boldness', 'bolstered', 'bookseller', 'borrows', 'brahms', 'brampton', 'brant', 'breakage', 'brianna', 'budweiser', 'c5', 'calc', \"candidate's\", 'capitulation', 'cardiologist', 'carelessly', 'carotid', 'catania', 'cath', 'caulfield', \"channel's\", 'chaplains', 'charade', 'chimps', 'chinook', 'christoph', 'cme', 'coconuts', 'coed', 'coexistence', \"cohen's\", 'coiled', 'coimbatore', 'compatriots', 'concourse', 'confide', 'converging', 'corning', 'countryman', 'cpt', 'cpus', 'cramping', 'craved', 'craves', 'crs', 'crutch', 'cupboards', 'cursive', 'cutout', 'daisies', 'dandelion', 'ddt', 'deafness', 'decals', 'declassified', 'deflated', 'defoe', 'dekker', 'demonstrator', 'denoting', 'destruct', 'determinant', 'deterred', 'devonian', 'devouring', 'dias', 'disagreeing', 'disenfranchised', 'disengage', 'disoriented', 'displacing', 'dissect', 'dmitri', \"domino's\", 'dowd', 'drm', 'drywall', 'dsc', 'duggan', 'eagerness', 'elba', 'elliptic', 'emitter', 'emporium', 'empties', 'endo', 'epicenter', 'epidural', 'epistle', 'equating', 'erstwhile', 'espoused', 'everyones', 'exertion', 'expend', 'facilitator', 'familia', 'fanfic', 'fathered', 'ferocity', 'flagstaff', 'fluidity', 'follies', 'fortify', 'fouling', 'frazer', 'frills', 'frodo', 'fsb', 'gabriella', 'gagged', 'galactica', 'ganga', 'garret', 'gartner', 'gaunt', 'gilchrist', 'gilman', 'gms', \"gop's\", 'grapevine', 'grinds', 'groaning', 'grotto', 'groundhog', 'gsa', 'guerilla', 'gwent', 'h.w', 'habeas', 'hain', 'hairless', 'hamm', 'healey', 'heave', 'hellfire', 'highlander', 'hilt', 'hinterland', 'hoh', 'holliday', 'homely', 'humphries', 'i.d', 'ibs', 'idlib', 'ignacio', 'inbred', 'incase', 'inclusions', 'indescribable', 'indoctrination', 'inductive', 'inevitability', 'infatuated', 'infatuation', 'infighting', 'infra', 'infraction', 'inhabiting', 'inkling', 'innuendo', 'insecticide', 'instantaneously', 'interchangeably', 'interfaith', 'interrogate', 'introspective', 'itu', 'javelin', 'jenn', 'joplin', 'juanita', 'juarez', 'judea', 'kazan', 'ketamine', 'kinney', 'klay', 'klingon', 'knoll', 'kurtz', 'laila', 'landlady', 'larceny', 'lavatory', 'leanings', 'leavenworth', \"leo's\", 'ligands', 'lingered', 'linings', 'loa', 'locales', 'lourdes', 'lucio', 'luffy', 'luminosity', 'luo', 'lw', 'magpie', 'maoist', 'masjid', 'massimo', 'materialized', 'matrimonial', 'maul', 'mayne', 'mcknight', 'meandering', \"melbourne's\", 'mendez', 'menstruation', 'messianic', 'metering', 'michaela', 'minimalism', 'misgivings', 'misogynist', 'modalities', 'motels', 'motivator', 'mts', 'mulch', 'musket', 'nader', 'nance', 'navi', \"needn't\", 'nestor', 'nether', 'neuer', \"newton's\", 'ngc', \"nintendo's\", 'nourish', 'nuh', 'numbing', 'nutritionist', 'oat', 'obscenity', 'obsess', 'ohhhh', 'onlookers', 'orator', 'oscillations', 'outweighed', 'ove', 'overhauled', 'overpaid', 'oxen', 'palais', 'palmerston', 'papyrus', 'patrolled', 'patties', 'pemberton', 'pennington', 'perpetuity', 'philipp', 'philo', 'phineas', 'pho', 'platelet', 'pliers', 'pluralism', 'polynesian', 'pooja', 'portability', 'posturing', 'pouches', \"power's\", 'pq', 'predation', 'preheat', 'prev', 'pringle', 'procter', 'pronouncing', 'propagating', 'prospered', 'protectorate', 'psychopathic', 'puffed', 'quarterfinal', 'r4', 'randomness', 'recitation', 'reconsidered', 'rectal', 'recursive', 'reevaluate', 'renaming', 'reprimand', 'rerun', 'reverting', 'riddance', 'rk', 'ruthlessly', 'sakes', 'satchel', 'saucy', 'schalke', 'scorsese', 'scr', 'sculptural', 'septum', 'servo', \"shaw's\", 'shears', 'shemale', 'shiloh', 'shrank', 'shyness', 'slimmer', 'snub', 'sobering', 'soyuz', 'spandex', 'spanked', 'sparkles', 'spew', 'spieth', 'sportswear', 'squeak', 'srinagar', 'staking', 'steakhouse', 'steers', 'stratigraphic', 'stratosphere', 'stucco', 'suave', 'subcontractors', 'succinct', 'superficially', 'sweetener', 'syncing', 'tamar', 'taxonomic', 'telltale', 'tem', 'tennyson', \"tesla's\", 'testimonials', 'thanos', \"this'll\", 'thoughtless', 'thrower', 'thud', 'tibia', \"tim's\", 'titular', 'toads', 'tok', 'torrential', 'trad', 'trashing', 'treading', 'trotting', 'tulane', 'tunneling', 'uma', 'unitarian', 'usp', 'valence', 'ventilated', 'villager', \"vincent's\", 'virtuoso', 'vos', 'wail', 'watertown', 'wedged', 'welder', 'westlake', 'wetting', 'wg', 'whitening', 'whitewater', 'whiz', 'wilds', 'wingman', 'witherspoon', 'wolverines', 'woodbury', 'woodford', 'woodruff', 'worshiped', 'xenon', 'zo', 'å', '▀', '😘', '8k', 'a.s', 'abnormality', 'acme', 'acta', 'addendum', 'adhesives', 'adsorption', 'affront', 'afoot', 'agri', 'alla', 'alludes', 'alms', 'altars', 'alternates', 'amenable', 'amity', 'amt', \"amy's\", \"angel's\", \"anna's\", 'annotation', \"anthony's\", 'antibacterial', 'antoni', 'apprenticeships', 'argumentative', 'arne', 'artsy', 'assailants', 'asymptomatic', 'atherton', 'atmospheres', 'attila', 'authorizes', 'avril', 'baccalaureate', 'bala', 'balmain', 'barcode', 'barra', 'bearable', 'beehive', 'beltway', 'bering', 'bianchi', 'biosphere', 'blackman', 'bloch', 'bodybuilder', 'bosco', 'botanist', 'bottomed', 'boutiques', 'brownsville', \"buyer's\", 'c.s', 'caches', 'calmness', \"camera's\", 'canny', 'cartons', 'cassettes', 'castile', 'caveman', 'centimeter', 'cet', 'chairwoman', 'characterisation', 'checkered', 'cheekbones', 'chengdu', \"cia's\", 'cilantro', 'circumcised', 'cit', 'civics', 'clamped', 'claps', 'clementine', 'clipboard', 'compensatory', 'concedes', 'conceptions', 'confessor', 'connoisseur', 'contemplative', 'convocation', 'corrupting', 'countermeasures', 'crosse', 'culpable', 'dag', 'damsel', \"dan's\", 'daze', 'debugging', 'deg', 'deliciously', 'dewitt', 'dickey', 'diocesan', 'disputing', 'distorting', 'disused', 'divination', 'doggo', 'dol', 'doolittle', 'douchebag', 'downsizing', 'dprk', 'drunkenness', 'dumas', 'dykes', 'eastbourne', 'ebenezer', 'ecm', 'emigrate', 'emulsion', 'epistemology', 'erick', 'esters', 'euphrates', 'evacuating', 'exorcism', 'fabled', 'fabricate', 'fatherhood', 'favre', 'fein', 'fem', 'femoral', 'ferreira', \"festival's\", 'feuds', 'fijian', 'filibuster', 'fillings', 'fillmore', 'finalize', 'financiers', 'flicking', 'flourishes', 'fluctuation', 'foia', 'fraudulently', 'fumbles', 'gander', 'gauze', 'geometrical', 'ghoul', 'giggled', 'gimmicks', 'goebbels', 'golan', 'grandstand', 'grazed', 'grumbling', 'guelph', 'guitarists', 'h000', 'hales', 'hallucination', 'hamill', 'hamza', 'hcl', 'heaton', 'heeled', 'helms', 'hibernian', 'hoi', 'hovered', 'hulls', 'huns', 'hutchins', 'hydrophobic', 'immaterial', 'imprinted', 'industrialists', 'inefficiency', 'inflationary', 'inflexible', 'inflow', 'inglis', 'intercom', 'internationale', 'intersecting', 'intrigues', 'invalidated', 'inwards', 'iw', 'jacking', 'jamieson', 'jem', 'jihadi', 'justifications', 'keanu', 'kenney', 'keyed', 'knighthood', 'kryptonite', 'laborer', 'lamenting', 'lefties', 'lengthened', \"levi's\", 'lifesaving', 'lire', 'lnp', 'lovecraft', 'lst', 'lucinda', 'lula', 'machinations', 'maha', 'mangrove', 'marmalade', 'marseilles', 'marys', 'masala', 'masts', 'maura', \"max's\", 'mecha', 'metcalf', 'mi5', \"military's\", 'milled', 'miocene', 'mirren', 'mirza', 'mississauga', 'moderating', 'modifier', 'molesting', \"moment's\", 'moored', 'naturalization', 'nene', 'nerf', \"norway's\", 'numbness', 'nunn', \"o'toole\", 'oar', 'objecting', 'occidental', 'oozing', 'opiate', 'ordinated', 'osprey', 'outscored', 'overheated', 'paddles', 'panes', 'patten', 'pattinson', 'pelt', 'pennant', 'perfectionist', 'phantoms', 'pickett', 'pitts', 'playwrights', 'poirot', \"poland's\", 'pomona', 'ponce', 'poppies', 'powys', 'praxis', 'preaches', 'primes', 'priming', 'princely', 'profited', 'psoriasis', 'putty', 'quench', 'québec', 'radicalism', 'radon', 'ramping', 'rationalize', 'reactivity', 'reassignment', 'rebrand', 'relieves', 'rennie', 'repeater', 'reprisals', 'reruns', 'retardation', 'retards', 'retort', 'revitalization', 'rework', 'reworking', 'rudely', 'runes', 's0000', 'sacha', 'saddles', 'sams', 'sanctuaries', 'saracens', 'sawmill', 'sbc', 'scribes', 'selina', 'sewed', 'sheltering', 'shogun', 'shoutout', 'showings', 'shrinkage', 'skeptic', 'slacks', 'sleeveless', 'smalls', 'smelting', 'snell', 'snowstorm', 'socialite', 'somme', 'southerly', 'spectrometer', 'spouting', 'sprague', 'squandered', 'sterilized', 'strapping', 'stuns', 'subspace', 'subsurface', 'superstructure', 'surnames', 'sustains', 'sweeper', 'swish', 'sympathizers', 'synced', 'tabloids', 'tamper', 'tampon', 'telangana', 'telephony', 'telford', 'tenerife', 'thad', 'thickened', 'timberwolves', 'tms', 'toffee', 'tomahawk', 'tomlin', 'torched', 'torre', 'torrey', 'transactional', 'transcendence', 'transgression', 'trappings', 'triage', 'ulterior', 'unambiguous', 'undertakings', 'undetermined', 'undies', 'undulating', 'unfettered', 'unpacking', 'usernames', 'venison', 'veranda', 'verdicts', 'veterinarians', 'vn', 'walpole', 'wasserman', 'wessex', 'westmoreland', 'whiny', 'whitby', 'whitley', 'wth', 'www.youtube.com', 'xt', 'xxxx', 'yamamoto', 'ys', 'zaire', 'zheng', 'zine', 'μ', 'accumulates', 'adamson', 'adapts', 'afterthought', 'aida', 'airbag', 'airman', 'airship', 'aki', 'aligns', 'alligators', 'alr', 'amigos', 'animators', 'annan', 'annihilate', 'appointee', 'archetypal', 'artful', 'ascendancy', 'asha', 'assessor', 'asymmetry', 'asynchronous', 'ati', 'attuned', \"austin's\", 'ayers', 'baal', 'baer', 'baffles', 'bahia', 'balotelli', 'banal', 'basking', 'baz', 'beattie', 'befitting', 'benched', 'blackface', 'bluish', 'boba', 'bombardier', 'boned', 'bookkeeper', 'booting', 'bountiful', 'boycotts', 'brimming', 'bub', 'bulldozer', 'byers', 'byrnes', 'cabernet', 'calico', 'camus', 'canoeing', 'canvassing', 'capillary', 'carols', 'casanova', 'categorical', 'ccd', 'chariots', 'charlemagne', 'checkup', 'chieftain', 'chisholm', 'christening', 'chs', 'cinematographer', 'cirrhosis', 'cla', 'cladding', 'clapton', 'cle', 'cleats', 'clemente', 'clings', 'clingy', 'clough', 'coburn', 'codeine', 'coeur', 'colitis', 'combative', \"commissioner's\", 'conceited', 'connell', 'connery', 'consecration', 'conspicuously', 'coors', 'correa', 'counterattack', 'courted', 'cranked', 'crested', 'cro', 'cte', 'cto', 'curie', 'cuteness', 'daddies', 'darken', 'darlin', 'dba', 'dci', 'deane', 'debian', 'defaulted', 'defuse', 'deir', 'depositing', 'dermot', 'designating', 'devs', 'dilation', 'dios', 'directorial', 'dishonor', 'disintegrate', 'disjointed', 'disparaging', 'dissenters', 'divest', 'dodo', 'draconian', 'draymond', 'drosophila', 'drummers', 'duper', 'eerily', 'eine', 'electrochemical', 'embers', 'emotive', 'empirically', \"employee's\", 'enforces', 'engels', 'entanglement', 'epsilon', 'esc', \"ex's\", 'expeditionary', 'falk', 'faqs', 'farrar', 'fec', 'federations', 'finns', 'firefight', 'firestone', 'firstborn', 'flees', 'flowery', 'foss', 'frock', 'gai', 'gamecube', 'gens', 'gerber', 'glutamate', 'goblet', 'greased', 'grimsby', 'groupon', 'gts', 'guilford', 'gyro', 'habib', 'handsomely', 'hapless', 'harnessing', 'hidalgo', 'hissing', 'hitched', 'humanistic', 'hurray', 'iconography', 'igbo', 'impervious', 'implausible', 'imposter', 'incurring', 'indeterminate', 'infidels', 'inflection', 'innocently', 'inroads', 'intractable', 'irb', 'jabs', 'jamison', 'janelle', \"jay's\", 'jh', \"jimmy's\", 'kardashians', 'katya', 'kauai', 'kenyans', 'kickboxing', 'kilt', 'kirkpatrick', \"knight's\", 'kona', 'kubrick', 'landscaped', 'leahy', 'leverkusen', 'lifesaver', 'linton', 'litany', 'localised', 'locket', 'locomotion', 'lott', 'lounging', 'lrt', 'lumia', 'lupe', 'lópez', 'macklemore', 'madre', 'mailman', 'manoeuvres', 'manus', \"market's\", 'marksman', 'maroons', 'maru', 'mathis', 'matisse', 'maven', 'mavs', 'mbps', 'mcfarland', 'mcfarlane', 'messrs', 'mikael', 'milliseconds', \"mind's\", 'minimizes', 'mittens', 'monterrey', 'montoya', 'mossad', 'mourned', 'mourners', 'mpc', 'msrp', 'munching', 'myron', 'nagoya', 'nappy', 'nbl', 'neanderthals', 'nears', 'neuter', 'newlyweds', 'nis', 'norwegians', 'nvm', 'nx', 'obj', 'och', 'odysseus', 'ofa', 'okcupid', 'omitting', 'ophelia', 'opinionated', 'oppress', 'originator', 'outfitters', 'overthrew', 'overton', 'oxidized', 'panhandle', 'paradoxical', 'paralysed', 'parched', 'passageway', 'pasty', 'pate', 'patently', 'pca', 'pecking', 'pertain', 'pesto', 'phys', 'plata', 'plowing', \"pm's\", 'pmi', 'polity', 'pooped', 'porcupine', 'portia', 'pps', 'prides', 'primacy', 'prioritized', 'prioritizing', 'probed', 'psychosocial', 'pti', 'pulaski', 'pwc', 'radiological', 'rafts', 'reagent', 'rebranding', 'reckons', 'rectory', 'referendums', 'refractive', 'refractory', 'regrettably', 'reiner', 'reintroduced', 'reorganisation', 'reprieve', 'resupply', 'resurfaced', 'retraction', 'ricci', 'riser', 'ruckus', 'rutledge', 'safeway', 'saginaw', 'salami', 'sandwiched', 'sasuke', 'schmitt', 'scopes', 'screech', 'scripps', 'sculpting', 'seared', 'sergeants', 'shakespearean', 'shaven', 'shiro', 'shopkeeper', 'shortness', 'shrill', 'signalled', 'skits', 'skyrocketed', 'slanted', 'slits', 'snowed', 'sonnets', 'soulless', 'splitter', 'spook', 'stagecoach', 'statesmen', 'stork', 'strode', 'strongman', 'subjecting', 'subordinated', 'subpoenas', 'subside', 'subways', 'sul', 'supp', 'swoon', 'syringes', 'tactically', 'tallied', 'tartar', 'tavares', 'telepathy', 'terrance', 'thane', 'thesaurus', 'thorax', 'thrusters', 'tien', 'timings', 'tithe', 'tou', 'trina', 'tripp', 'trolled', 'ttc', 'tucking', 'tugging', 'twickenham', 'ubs', 'uga', 'unattainable', 'underpinning', 'unexplored', 'unilever', 'unsold', 'unsubstantiated', 'uptight', 'valentin', 'veda', 'virulent', 'vomited', 'waterfowl', 'wesson', 'widescreen', 'windmills', 'womanhood', 'worrisome', 'wort', 'wreaths', 'wy', 'xix', 'yorke', 'yuma', 'zealanders', '😏', '2h', '4b', 'a.b', 'a7', 'ack', 'acronyms', 'adderall', 'admissible', 'airlift', 'aitken', 'alluvial', 'amarillo', \"american's\", 'amis', 'amyloid', \"anne's\", 'ansi', 'apical', 'apo', 'appetites', 'armpits', 'ascendant', 'attenborough', 'audiobooks', 'bartenders', 'barth', 'bashar', 'battering', 'battersea', 'bedfordshire', 'beecher', 'belgians', 'bimbo', 'blackmailed', 'blazed', 'blowjobs', 'blum', 'boarders', 'bongo', 'bootstrap', 'boswell', 'bouchard', 'bouquets', 'braddock', 'brahma', 'braver', 'brisket', 'buckeye', 'burnside', 'cac', 'cairn', 'callin', 'campo', 'cancun', 'cannonball', 'cappuccino', 'caricatures', 'ceasing', 'championing', 'chapels', 'chirping', 'château', 'circulatory', 'citrate', 'climactic', 'cloaked', 'clocking', 'clotting', 'cnet', 'commemorates', 'comstock', 'conjuring', 'consigned', 'constructors', 'cornelia', 'coups', 'cowgirl', 'cowl', 'crepe', 'crocs', 'culling', 'cycled', 'cypriot', 'danvers', 'darlene', 'dashes', 'daydreaming', 'decently', 'decentralization', 'decomposed', 'decorum', 'definately', 'deft', 'dehydrogenase', 'deirdre', \"destiny's\", 'detest', 'deuteronomy', 'devising', 'diabetics', 'digg', 'diodes', 'disband', 'discarding', 'discloses', 'dislocation', 'disrupts', 'distinguishable', 'drexel', 'duels', 'dwells', 'e4', 'earls', 'earnestly', 'ecg', \"ed's\", 'effecting', \"einstein's\", 'electrifying', 'elisha', 'emblematic', \"emily's\", 'emmet', 'englishmen', 'enslavement', 'entrust', 'enviable', 'epidemiological', 'epithet', 'equipments', \"espn's\", 'eww', 'f5', 'fairmont', 'fairview', 'fiercest', 'firehouse', 'flailing', 'flaky', 'fleury', 'flotilla', 'followup', 'foolproof', 'footballing', 'forgetful', 'forgettable', 'forklift', 'freeways', \"fuck's\", 'g.i', 'g8', 'gallantry', 'gamut', 'gash', 'gawker', 'gazelle', 'genotype', 'gentler', 'geronimo', 'gilead', 'girard', 'glistening', 'glycol', 'gopher', 'governess', \"graham's\", \"grant's\", 'gravitate', 'gregorio', 'grinch', 'grinned', 'guesthouse', 'gunfight', 'haifa', 'hams', 'hamsters', 'hander', \"harm's\", 'harvester', 'hattie', 'heaped', 'heartburn', 'helmut', 'heroics', 'hesse', 'hickman', 'hillbilly', 'hla', 'hmrc', 'hollister', 'homeopathy', 'hongkong', 'honouring', \"hour's\", 'huckabee', 'huntley', 'hustling', 'ica', 'imbecile', 'impeded', 'impersonation', 'impresses', 'imprison', 'inasmuch', \"indonesia's\", 'infiltrating', 'intensifying', 'intensively', 'intercultural', 'interrogating', 'interviewers', 'irvin', 'ischemic', 'jackal', 'jaeger', \"jason's\", 'jee', 'jethro', 'joes', 'jokers', 'jolla', 'jordans', 'joystick', 'kamikaze', 'karina', 'karlsson', 'kelp', 'kidman', 'kingfisher', 'kiwis', 'kjv', 'kmt', 'knotted', 'lackey', 'lain', 'laminate', 'landis', 'leeches', 'leek', 'leviticus', 'levitt', 'lifecycle', 'linguist', 'lms', 'lomax', 'lor', 'lorne', 'luring', 'lute', 'lx', 'm6', \"mac's\", 'macrophages', 'macros', 'madge', 'magee', 'magpies', 'makoto', 'mala', 'manley', 'marketplaces', 'marv', 'marvels', 'masquerading', 'mattel', 'mauritania', 'mavis', 'mchugh', 'meanest', 'meaningfully', 'meatball', 'medford', 'merino', 'mermaids', 'metastasis', 'microchip', 'mikel', 'mingled', 'mitzvah', 'mordor', 'mosaics', 'muddled', 'mumbling', 'nautilus', 'necked', 'nicht', 'nieto', 'nox', 'nymph', 'oceanography', 'oedipus', 'offsetting', 'omer', 'orpheus', 'oswego', 'paler', 'papaya', 'partisanship', 'peachy', 'pearly', 'pensioner', 'periscope', 'pernicious', 'perversion', 'phylogenetic', 'physiotherapy', 'pigmentation', 'pizzeria', 'populate', 'posthumously', 'pra', 'prawn', 'preamble', 'predates', 'preoccupation', 'prim', 'programmatic', 'propellers', 'pruitt', 'prying', 'ptolemy', 'pulsing', 'punisher', 'pur', 'puree', 'pyrenees', 'quetta', 'racketeering', 'radars', 'radford', 'rainier', 'rattlesnake', 'realignment', 'receptacle', 'regatta', 'regionals', 'regs', 'reliefs', 'remixed', 'remo', 'removals', 'reprisal', 'rescind', 'reshape', 'reshaping', 'revitalize', 'risotto', \"robinson's\", 'roku', 'sadiq', 'sagittarius', 'samoan', 'sauvignon', 'savagery', 'sca', 'scorned', 'searchable', 'seething', 'sequenced', 'sequentially', 'shamrock', 'shearing', 'shelving', 'sheng', 'sifting', 'sighing', 'sina', 'siva', 'slog', 'smithfield', 'smut', 'soars', 'socialized', 'sop', 'spiraling', 'splice', 'sponsorships', 'spoonful', 'spousal', 'sps', 'statistician', 'stds', 'storefront', 'storeys', \"street's\", 'stroud', 'stubble', 'subsystem', 'suffocated', 'summarizing', 'supple', 'swahili', 'syndromes', 'synergies', 'sánchez', 'tacked', 'talia', 'teague', 'tfl', 'tipsy', 'tirade', 'tompkins', 'topaz', 'torino', 'trickster', 'trinkets', 'triples', 'trisha', 'trotsky', 'turbocharged', 'turmeric', 'unchallenged', 'underestimating', 'undress', 'uninteresting', 'unraveling', 'vandalized', 'veneration', 'vigilantes', 'vigour', 'vistas', 'vitriol', 'vue', 'wagging', 'waned', \"warren's\", 'welt', 'wer', \"what're\", 'wheezing', 'whistleblowers', 'winded', 'wisest', 'wop', 'wordsworth', 'yaw', 'zi', 'zia', 'λ', '2p', \"5'00\", '7a', \"academy's\", 'accidently', 'accusers', 'adaptability', 'adapters', 'adheres', 'aetna', 'aggressiveness', 'ahold', 'alamos', 'alana', 'ales', \"alexander's\", 'allegorical', 'amigo', 'anode', 'apparition', 'appetizer', 'arafat', 'argon', 'arrowhead', 'asic', 'asm', 'astonishingly', 'astonishment', 'atone', 'backend', 'backhand', 'bangla', 'bankroll', 'barbra', 'barnet', 'barristers', 'belittle', 'beryllium', 'betrothed', \"biden's\", 'billiard', 'bloodthirsty', 'blumenthal', 'boisterous', 'bonneville', 'booksellers', 'bootcamp', \"brady's\", 'bri', 'briar', 'brightened', 'broderick', 'broughton', 'buckled', 'burgh', 'cacao', 'cale', 'calypso', 'capacitance', 'caper', 'caprice', 'carer', 'carlsbad', 'carriageway', 'caspar', 'cbe', 'cede', 'ceres', 'chagrin', 'champlain', 'characterizing', 'chock', 'chronicled', 'clapham', 'clawed', 'coerce', 'coffey', 'combustible', 'comebacks', 'comer', 'cometh', 'complicates', 'complimenting', 'compositional', \"computer's\", 'condenser', 'conglomerates', 'conjugate', 'conjured', 'coptic', 'cossacks', 'cpp', 'cutaneous', 'd4', 'daenerys', 'dahlia', 'dalit', 'darlings', 'deandre', 'debug', 'decadence', 'decider', 'deconstruction', 'defamatory', 'depravity', 'depress', 'disheartening', 'dugan', 'dz', 'eavesdropping', 'eclipses', 'ecuadorian', 'edibles', 'eia', 'eldridge', 'enclaves', 'encroachment', 'equaliser', 'ervin', 'ese', 'etihad', 'euclid', 'evansville', 'exe', 'farrah', 'faves', 'felled', 'fentanyl', 'ferrara', 'fertiliser', 'finalised', 'finlay', 'fintech', 'fireflies', \"franklin's\", 'freebie', 'gaby', 'garda', 'garibaldi', 'garrick', 'geezer', 'geno', 'ghent', 'giggs', 'gilmour', 'givin', 'glassware', 'gleason', 'gmp', 'gooey', 'gottlieb', 'gutters', 'habitually', 'halts', 'harlequin', 'harwood', 'hatton', 'hav', 'hdtv', 'headgear', 'hearn', 'heathens', 'hemlock', 'henchmen', 'hep', 'hist', 'hokkaido', 'holm', 'honduran', 'hydraulics', 'hydrolysis', 'hydropower', 'hyman', 'hyperactivity', 'hyuk', 'ile', 'illiteracy', 'imac', 'incitement', 'inconsequential', 'indignant', 'infamy', 'infertile', 'infractions', 'injector', 'innes', 'insolvent', 'intergalactic', 'internalized', 'irregularly', 'itc', 'iterative', 'jacoby', 'jaya', \"jersey's\", 'jot', 'julianne', 'jurgen', 'kaur', \"kevin's\", 'kitties', 'klux', 'koko', 'krueger', \"lawyer's\", 'leary', 'legumes', 'lengthening', 'lenox', 'lesotho', 'levinson', 'libre', 'lighthearted', 'littleton', 'lodgings', 'logitech', 'loma', 'lookup', 'loughborough', 'lounges', 'lupin', 'maharaj', 'marlow', 'marston', 'maximilian', 'meagre', 'meditative', 'mehdi', 'mentored', 'merced', 'metz', 'mics', 'middleman', 'mildew', 'mindedness', 'mingling', 'mishaps', 'moma', 'monologues', 'moritz', 'moulding', 'moussa', 'mufti', 'mughal', 'mukherjee', 'multivariate', \"mustn't\", 'nadir', 'nara', 'neale', 'neutralized', 'nin', 'notepad', 'numerically', 'nutcracker', 'obs', 'odisha', 'okla', 'oled', \"oregon's\", 'osce', 'outboard', 'outlier', 'outweighs', 'p4', 'pacs', 'paltry', 'parachutes', 'pars', 'parsing', 'pentecostal', 'peripherals', 'petitioner', 'pharisees', \"phil's\", 'pimps', 'pinkie', 'placer', \"plant's\", 'plucking', 'plummer', 'pollute', \"potter's\", 'precede', 'precocious', 'preconceived', 'predictors', 'presumptuous', 'probabilistic', 'proms', 'pronto', 'provo', 'prs', 'publicize', 'purview', 'qantas', 'quicken', 'quicksilver', 'quince', 'racehorse', 'raheem', 'raked', 'ravioli', 'rawlings', 'razer', 'reagents', 'rebounded', 'redone', 'reston', 'revolutionized', 'rfid', 'ricans', 'rosalie', 'rove', 'rui', 'sadler', 'saitama', 'salvo', 'sauron', 'schuyler', 'scrapes', 'sdn', 'sei', 'seizes', 'shrieking', 'silences', 'silhouettes', 'simmering', \"simpson's\", 'sitcoms', 'siu', 'smears', 'smoothed', 'sodom', 'sofas', 'soi', 'solange', 'spatula', 'splicing', 'spreadsheets', 'squatters', 'steamers', 'stepdad', 'stipulates', 'sto', 'stockport', 'strangling', 'streamlining', 'stroked', 'subunits', 'suffocate', 'surat', 'suspends', 'tandy', 'tapas', 'tenement', 'tetanus', 'thatched', 'thon', 'thrifty', 'thrombosis', 'thunderbird', 'tiberius', 'tickles', 'tiling', 'tingle', 'townspeople', 'transvaal', 'treads', 'tricia', 'trippy', 'tryout', 'tuscaloosa', 'tyra', 'tyrosine', 'unbridled', 'undersea', 'unfiltered', 'unicode', 'unopposed', 'urs', 'vacationing', 'vamp', 'vassals', 'wanton', 'wedlock', 'welterweight', 'whiteboard', \"who're\", 'wholesaler', 'witted', 'woodside', 'wry', 'xc', 'xie', 'xyz', 'yasmin', 'yom', 'yon', 'zambian', 'ziegler', 'zimbabwean', '😔', 'aas', 'abominable', 'absolution', 'accomplishes', 'adequacy', 'adopters', \"agent's\", 'aggie', 'ahmet', 'airplay', 'albrecht', 'amalgam', 'ambulatory', 'annulment', 'aoki', 'aramaic', 'arnie', 'articulating', 'asi', 'asif', 'askin', 'ato', 'atoll', 'awa', 'axioms', 'aztecs', 'babbling', 'bangers', 'bargained', 'barnabas', 'barrio', 'belleville', 'benzene', 'ber', 'bernhard', 'biennale', 'binghamton', \"black's\", 'blackish', 'blaise', 'blemish', 'bobbing', 'bogs', 'brainstorm', 'brevity', 'broadside', 'buckles', 'budd', 'burdensome', 'burley', 'buttered', 'cadmium', 'callaway', \"campaign's\", 'candida', 'carnivorous', 'cfc', 'characteristically', 'chasers', 'chf', 'chicano', 'chimera', 'chiropractor', 'chr', 'chromosomal', 'cic', 'cig', 'cigs', 'claustrophobic', 'cleave', 'clovis', 'coinciding', 'coleridge', 'colvin', 'commuted', 'conformation', 'conveniences', 'corinthian', 'cotta', 'councilor', 'counterterrorism', 'coyle', 'cq', 'crayfish', 'csf', 'cuckold', 'culled', 'czechs', 'davie', 'deanna', 'defraud', 'deftly', 'dens', 'desertion', 'detainee', 'devops', 'dike', 'dispensation', 'dit', 'domed', 'dowager', 'drips', 'ducati', 'dunning', 'eaves', 'edd', 'elie', 'emboldened', 'emc', 'enema', 'epp', 'erecting', 'eroding', 'euphoric', 'evangelism', \"evening's\", 'evoking', 'excelsior', 'exploitative', 'fabricating', 'fae', 'falkland', 'fatah', 'fdic', 'feasting', 'ferment', 'fetuses', 'figurine', 'flocking', 'flogging', 'foote', 'freshen', 'frostbite', 'fuentes', 'fulbright', 'fulltime', 'fundamentalists', 'féin', 'glories', 'gn', 'goodreads', 'goran', 'greys', 'gul', 'gulag', 'gustave', 'h3', 'hakeem', 'handyman', 'hangzhou', 'harare', 'hazing', 'heatwave', 'hellenic', 'hellenistic', 'heretical', 'herschel', 'heston', 'homeschool', 'homs', 'horst', 'hsv', 'humping', 'i000', 'icd', 'ilya', 'immeasurable', 'immorality', 'immutable', 'imogen', 'impressionable', 'impressionist', 'ims', 'indica', 'indict', 'indisputable', 'inquisitor', 'inset', 'interceptor', 'interpolation', 'ischemia', \"jamie's\", 'jena', 'kaitlyn', 'kda', 'kettering', 'kiddos', 'killin', 'kohl', 'konrad', 'kraken', 'lancer', 'landau', 'lauder', 'laurels', 'leavers', 'lewes', 'licorice', 'lighters', 'limes', 'linearly', 'linguists', 'linkages', \"lisa's\", 'litchfield', \"lot's\", 'lufthansa', 'lumped', 'lunge', 'lyra', 'mackinnon', 'maggots', 'malaga', 'malayalam', 'maliciously', 'manipulator', 'marathi', 'martino', 'meddle', 'medi', 'menagerie', 'mesut', 'metallurgical', 'mga', 'micron', 'midpoint', \"model's\", 'monoclonal', 'motorways', 'muay', 'multiverse', 'nibble', 'noonan', 'nosy', 'nullify', 'nys', 'o.j', 'ofsted', 'oligarchy', 'omelette', 'omnipotent', 'oppressors', 'orville', 'overpower', 'overthinking', 'overtures', 'paedophile', 'pagoda', 'paraded', 'parallax', 'passers', 'penniless', 'phalanx', 'photogenic', 'pilate', 'pirated', 'plantings', 'plummet', 'pn', 'pollack', 'polymerization', 'pondered', 'potters', 'pounder', 'prado', 'prairies', 'prakash', 'predicate', 'predictability', 'prov', 'puking', 'pyle', 'qe', 'quaternary', \"queensland's\", 'quintet', 'radiated', 'ramble', 'razors', 'realtime', 'reconstructive', 'reebok', 'refrained', 'retaliatory', 'revolutionize', 'revs', 'rhinoceros', \"rick's\", 'rickshaw', 'rinehart', \"rock's\", 'rodger', 'rollover', 'romain', 'romp', 'roxanne', 'rustling', 'sainte', 'salesforce', 'sanger', 'sarawak', 'sawdust', 'sba', 'scavenging', 'scoured', 'scrotum', 'scruffy', 'sdk', \"sean's\", 'sel', 'sewerage', 'shanahan', 'shangri', 'shasta', 'shenandoah', 'shithead', 'shoo', 'simplifies', 'sinuses', 'slc', 'slung', 'smelter', 'smoothness', 'smother', 'sniffed', 'snorted', 'soa', 'sparky', \"spencer's\", 'spontaneity', 'sprain', 'sprinklers', 'sss', 'stateless', 'stateside', 'stepson', 'stillwater', 'strolled', 'stunningly', 'sudbury', 'surly', 'susannah', 'sutures', 'sweeteners', 'symbolized', 'tarnish', 'tasman', 'tek', \"thailand's\", 'thermo', 'thrashed', 'thyself', 'tipton', 'tls', 'topsy', 'torsion', 'tosh', 'touchstone', 'tramway', 'treatable', 'trier', 'trouser', 'tugs', 'tumbler', 'typeface', 'uglier', 'ult', 'unaccounted', 'unbound', 'uncalled', 'undemocratic', 'undergrad', 'underpaid', 'uninvited', 'unleashing', 'unnerving', 'unpunished', 'unrecognized', 'untested', 'upping', 'urethra', 'utilising', 'uzbek', 'vaudeville', 'veils', 'verve', 'vex', 'vh1', 'vips', 'viv', 'vmware', 'vod', 'walkie', 'watchtower', \"watson's\", 'waveform', 'weighty', 'wilma', 'wollongong', 'workbook', 'workspace', 'worships', 'x4', 'xperia', 'yoshida', 'zephyr', 'zoomed', '9s', 'aberystwyth', 'abner', 'abstracted', 'adr', 'adversarial', 'aggies', 'agnew', 'aliases', 'allentown', 'alphonse', 'alvaro', 'amiable', 'amphitheatre', 'amygdala', 'angler', 'antagonism', 'antebellum', 'apathetic', 'apologists', 'appended', 'artiste', 'atty', 'backwater', 'ballistics', 'bastian', 'bequest', 'berths', 'bewildering', 'billiards', 'binders', 'biodegradable', 'biofuels', 'biomarkers', 'biosynthesis', 'blasphemous', 'bonny', 'booklets', 'bores', 'briscoe', 'briton', 'bungee', 'bureaucrat', 'cadres', 'carina', 'carnivores', 'cascading', 'chaucer', 'cherie', 'chipper', 'cli', 'cliffhanger', 'cline', 'clunky', 'colgate', 'collider', 'colosseum', 'comers', 'comme', 'commoner', 'conned', 'const', 'contemporaneous', 'contingencies', 'counsellors', \"cow's\", 'cowley', 'crediting', 'crossovers', 'cta', 'cumberbatch', 'curtin', 'cutbacks', 'cutthroat', 'dailies', 'daria', 'datasets', 'decayed', 'deceptively', 'decoder', 'decommissioning', 'degeneres', 'delano', 'demarco', 'demography', 'denham', \"detroit's\", 'devilish', 'disarming', 'disloyal', 'disowned', 'dissociation', 'donner', 'dormitories', 'dowling', 'dpi', 'dq', 'drayton', 'dreads', 'drowns', 'druids', 'dueling', 'eared', 'earthen', 'eccentricity', 'eccles', 'electricians', 'electrocuted', 'els', 'emissary', 'enclosing', 'enron', 'entrapment', 'erectile', 'esposito', 'esta', 'exchanger', 'exerting', 'expatriates', 'eyelash', 'favouring', 'fernandes', 'flaherty', 'flappy', 'flashpoint', 'flirted', 'flopping', 'foodstuffs', 'forego', 'foretold', 'formalized', 'fortification', 'fortresses', 'fragrances', 'francine', 'fraternities', 'fredericksburg', 'frigates', 'g5', 'gaba', 'gannon', 'gaol', 'genghis', 'giannis', 'gmos', 'goalkeepers', 'grafts', 'grainy', 'greenery', 'greenhouses', 'grundy', 'gwyneth', 'gynecology', 'haa', 'hakim', 'handily', 'harboring', 'hauls', 'hayek', 'heaving', 'hebrides', 'heighten', 'helluva', 'henna', 'hexagon', 'himmler', 'hinders', 'hinds', 'hinton', \"history's\", 'hock', 'holler', 'holstein', 'honking', 'hookups', 'hooters', 'husk', 'hussey', 'iberian', \"ibm's\", 'ikr', 'implicate', 'implore', 'impounded', 'indigestion', 'indra', 'infarction', 'infrastructures', 'infront', 'intakes', \"intel's\", 'interned', \"internet's\", 'intonation', 'inversely', 'irrigated', 'irritates', 'ishmael', 'islamophobia', 'j.t', 'jeannie', 'josephus', \"jury's\", 'justly', 'kaleidoscope', 'kath', 'keypad', 'kimchi', 'kita', 'krakow', 'krista', 'kutcher', 'lactation', 'laker', 'lapping', 'leyland', 'liberalization', 'lindy', 'looters', 'lorries', 'lottie', 'lough', 'ltc', 'lubricants', 'lumpy', 'lyricist', 'machined', 'mads', 'malacca', 'malaise', \"malaysia's\", 'malvern', 'mannequins', 'maricopa', 'mcnair', 'mdma', 'meatloaf', 'menial', 'mentorship', 'merriam', 'merrily', 'methinks', 'minas', 'monogamous', 'montessori', 'montpellier', 'mooring', 'moreau', 'mountaineering', 'mtn', 'nami', 'nantucket', 'napalm', 'nath', 'neared', 'neath', 'necessitate', 'negation', 'neurosurgery', 'neutrino', 'nga', 'nines', 'niv', 'nooo', 'norte', 'nur', 'nutella', 'obsessions', 'oclc', 'olden', 'omfg', 'oneness', 'opacity', 'opp', 'otherworldly', 'overdo', 'overdraft', 'overturning', 'p.j', 'paediatric', 'painstakingly', 'pantyhose', 'parametric', 'parentage', 'patna', 'pedo', 'pentecost', 'perverts', 'physio', 'picnics', 'pigmented', 'pippa', 'platte', 'pornstar', 'posner', 'postponing', 'practicable', 'privates', 'progenitor', 'protectionist', 'pryce', 'pulsed', 'punters', 'purporting', 'qua', 'quantification', 'quiver', 'radiators', 'raffles', 'rawls', 'refereeing', 'reflexive', 'refuel', 'reina', 'reinventing', 'reliving', 'reminisce', 'reminiscing', 'renegades', 'repositories', 'repurposed', 'resistors', 'riled', 'roadster', 'robben', 'rodríguez', 'rofl', 'roos', 'rougher', 'salesperson', 'schumann', 'scolding', 'scones', 'sculptors', 'sedgwick', 'seeger', 'segal', 'sentinels', \"service's\", 'seton', 'shad', 'shadowed', 'shadowing', 'shiite', 'shiraz', 'shitload', 'shouldered', 'simmonds', 'skillfully', 'skylight', 'skyrim', 'snacking', 'sneaked', 'snip', 'sombre', \"sotheby's\", 'sou', 'spas', 'spector', 'spi', 'spokes', 'spool', 'sprouting', 'spurt', 'sputtering', 'ssa', 'stahl', 'stencil', 'stoker', 'strays', 'stressors', 'strictest', 'subjectivity', 'subliminal', 'substantiated', 'sunil', 'superstitions', 'suri', 'surrogates', 'symphonic', 'taekwondo', 'tagalog', 'taka', 'teak', 'teary', 'teases', 'teething', 'toowoomba', 'tortures', 'tps', 'transducer', 'tryna', 'tuba', 'turnip', 'tween', 'twofold', \"un's\", 'uncontested', 'uncovers', 'underwriters', 'uprooted', 'upstart', 'ure', 'urea', 'uso', 'v4', 'veritas', 'vicksburg', 'villainous', 'voluminous', 'vv', 'walkways', 'watanabe', 'weathers', 'weeding', 'widens', \"will's\", 'winfield', 'winkler', \"wolf's\", 'wonky', 'xavi', 'xfinity', 'yoshi', 'zebras', 'zhejiang', 'φ', '😆', '8m', 'a8', 'a9', 'abed', 'absolve', 'acapulco', 'adair', 'adieu', 'agonist', 'aground', 'airfare', 'alli', 'alternator', 'antiviral', 'arousing', 'ashcroft', 'aspired', 'asuka', \"atlanta's\", 'austro', 'azhar', 'b.sc', 'b5', 'badlands', 'bari', 'baronet', \"batman's\", 'battlestar', 'bdo', 'bearish', 'bebop', \"beginner's\", 'bela', 'belting', 'bendigo', 'bilal', 'bilbo', 'bitumen', 'blythe', 'bobbie', 'boland', 'borges', 'braden', 'buss', 'butterfield', 'buzzard', 'bygone', 'cannibals', 'capers', 'carbine', 'carelessness', 'cbo', 'cdn', 'cech', 'cedars', 'certifying', 'cesc', 'chattering', 'chaz', 'chongqing', 'chucked', 'chuckling', 'commensurate', 'compressors', 'confounding', 'contaminate', 'copley', 'corgi', 'corsair', 'cortes', 'counterfeiting', 'couriers', \"craig's\", 'cranking', 'cranks', 'crenshaw', 'crescendo', 'cuss', 'dalek', 'dauphin', \"death's\", 'deepak', 'deformity', 'delevingne', 'dents', 'deviated', 'dibs', 'dickerson', 'dinghy', 'dipper', 'dipshit', 'discourages', 'disobey', 'disseminating', 'disturbs', 'diverge', 'dominoes', 'doughty', 'downpour', 'drifter', 'droids', 'dundas', 'durand', 'dusky', 'dystrophy', 'eastside', \"elizabeth's\", 'eloquence', 'elvira', 'enhancer', 'enquirer', 'enslave', 'epitaph', 'etat', 'exclusions', 'excrement', 'expedient', 'fac', 'fallow', 'fanart', 'fen', 'fermi', 'fiddler', 'flagging', 'foal', 'foreclosed', 'forlorn', 'foucault', 'fragmentary', 'freetown', 'furlongs', 'gab', 'gambino', 'gateways', 'gaudy', 'gauss', 'gawd', 'gazed', 'ginsberg', 'girlie', 'gobble', 'godspeed', 'grandparent', 'grays', 'greeley', 'grout', 'grumman', 'gush', 'haddock', 'halogen', 'harald', 'harpoon', 'hartmann', 'haydn', 'hazmat', 'heros', 'highlighter', 'hirst', 'hom', 'homeopathic', 'homogenous', 'hors', 'hv', 'hydrology', 'hypoxia', 'iba', 'ibis', 'ibrahimovic', 'idealist', 'ifa', 'ih', 'incarnations', 'incited', 'incubated', 'indecisive', 'indefensible', 'indivisible', 'industrialist', 'ineffectual', 'inextricably', 'inflows', 'ingest', 'inhibitions', 'innermost', 'insecticides', 'insoluble', 'instrumentals', 'insulate', 'interconnection', 'introverted', 'invokes', 'isobel', 'issn', 'jah', 'jewell', 'jian', 'jitters', \"johnny's\", \"jones's\", 'kaine', 'katana', 'kendal', 'kessel', 'keyhole', 'kickers', 'kiosks', 'knighted', 'koenig', 'kota', 'kyu', 'lachlan', 'laredo', 'laughlin', 'lem', 'licensees', \"lloyd's\", 'loafers', 'lovato', 'lymphocytes', 'lynched', 'maa', 'magda', 'mahdi', 'manipulations', 'margarine', 'mashup', 'massed', 'mauled', 'mayflower', 'meeks', 'mekong', 'melania', 'melanin', 'messina', 'millard', 'minis', 'mists', 'mobster', 'montevideo', 'moulds', 'murmurs', 'musty', 'muttered', 'mysql', 'nbn', 'nbs', 'neilson', 'neuropathy', 'neurotransmitter', 'neutrals', 'nevis', 'newsnight', 'niners', 'noam', 'normalcy', 'notts', 'nourished', 'nourishing', 'obituaries', 'oceanographic', 'okada', 'orissa', 'ormond', 'outcasts', 'outlay', 'outliers', 'overblown', 'overestimate', 'oxy', 'oxytocin', 'pandit', \"pandora's\", 'partitioned', 'pathos', 'peacekeepers', 'ped', 'pellegrini', 'penetrates', 'peninsular', 'perrin', 'physicality', 'pickers', 'pid', 'pimple', 'platelets', 'poi', 'pomeroy', 'popeye', 'portraiture', \"post's\", 'potable', 'potsdam', 'pout', 'precepts', 'predominately', 'privatized', 'psy', 'psychoactive', 'puffing', 'punctual', 'punishes', 'quadrangle', 'quezon', 'quickness', 'quito', 'raceway', 'rafting', 'rainer', 'rajan', 'raves', 'reaffirm', 'rebellions', 'reentry', 'rephrase', \"restaurant's\", 'retrofit', 'reus', 'riker', \"river's\", 'robustness', 'rogan', 'roleplaying', 'roped', 'roseanne', 'rosso', 'rubens', 'rubies', 'résumé', 'sade', 'salespeople', 'salutes', 'satisfactorily', 'savanna', 'scifi', 'scriptural', 'sedans', 'seedy', 'seuss', 'shandong', 'shawnee', 'skylar', 'sla', 'sleet', 'slugger', 'snarky', 'snr', 'sona', 'soooooo', 'sorghum', 'souza', 'spacer', 'spacetime', 'spartacus', 'spasm', 'spearhead', 'specialise', 'spl', 'sprites', 'squeal', 'squish', 'steppe', 'stubbornness', 'stubs', 'stunner', 'subcutaneous', 'subservient', 'substantiate', 'subtitled', 'subtracting', 'succinctly', 'summarily', 'summarised', 'supplementing', 'suresh', \"suspect's\", 'swab', 'swarmed', 'swath', 'swordsman', 'synapses', 'tailors', 'tattered', 'technicality', 'tekken', 'terracotta', 'testicle', 'thickening', \"thing's\", 'thrush', 'thunderbirds', 'tillman', 'tinge', 'tinnitus', 'toed', 'toure', 'trample', 'tribesmen', 'tribulations', 'tropic', 'tux', 'uncomplicated', 'unconnected', 'underweight', 'undetectable', 'unis', 'unprovoked', 'unremarkable', 'untrustworthy', 'unwin', 'villarreal', 'vilnius', 'volition', 'wane', 'wellcome', 'westerns', 'whittle', 'wields', 'willian', 'withstood', 'wor', 'wretch', 'xinhua', 'yakima', 'yamato', 'yolks', 'π', '□', '6d', 'abetting', 'accolade', 'accommodates', 'addicting', 'addy', 'adoptions', 'adoring', 'aime', 'aimlessly', 'alfalfa', 'alleles', 'amphetamines', 'andrey', 'appellant', 'archetypes', 'ashanti', 'ashok', 'atelier', \"aunt's\", 'australasia', 'axed', 'b.j', 'baguette', 'baloch', 'barbers', \"bear's\", 'belichick', 'bioinformatics', 'bounties', 'breastfeed', 'brimstone', 'bristow', 'buhari', 'bunt', 'burly', \"butcher's\", 'carbonated', 'carburetor', 'carrey', 'caruso', 'catacombs', 'categorization', 'caving', 'celts', \"ceo's\", 'cessna', 'chara', 'cheetahs', 'chlamydia', 'chugging', 'classifies', 'cna', \"coach's\", 'cobbler', 'cognizant', 'collared', \"colorado's\", 'columnists', 'communes', 'conceit', 'concubine', 'conforms', 'confounded', 'conservatively', 'constrain', 'contraption', 'cookbooks', 'coolness', 'coughlin', 'covertly', 'covet', 'cpm', 'curbing', 'dales', 'dds', 'deacons', 'defenceless', 'depressions', 'dfw', 'diggs', 'dingy', 'disappearances', 'disengaged', 'disillusionment', 'dispatching', 'dolph', 'donahue', 'doodles', 'dougherty', 'driverless', 'droppings', 'drowsy', 'dunlap', 'duos', \"e's\", 'elaboration', 'ele', 'elwood', 'eminently', \"emma's\", 'emphasises', 'entre', 'eocene', 'epigenetic', 'equalled', 'eriksson', 'esprit', 'ess', 'ethnography', 'eunuch', 'exclaim', 'extort', 'falter', 'fanfiction', 'fantasize', 'feverish', 'fh', 'fibrillation', 'fissure', 'fizzy', 'flutes', \"football's\", 'forcible', 'frenzied', 'freudian', 'frightful', 'ftw', 'fumbling', \"fund's\", 'gat', 'geforce', 'genji', 'geopolitics', 'getter', 'glamorgan', 'gloriously', 'gourd', 'grander', 'grandfathers', 'grins', 'grocers', 'hadi', 'haider', 'haig', 'hallam', 'halter', 'hawker', 'hei', 'heisenberg', 'hijackers', 'historiography', 'hogarth', 'hollowed', 'houdini', 'hybridization', 'hyenas', \"i'ma\", 'ibadan', 'icebreaker', 'idling', 'idolatry', 'iis', 'illawarra', 'indelible', 'indochina', 'infantile', 'infuse', 'inglewood', 'inheriting', 'iniesta', 'insuring', 'interplanetary', 'inv', 'irreverent', 'isd', 'isthmus', 'itinerant', 'jacky', 'jags', 'jeddah', 'jello', 'jud', 'judson', 'juke', 'juneau', 'kana', 'katarina', 'kenji', 'kiel', 'kincaid', 'kino', 'knopf', 'l3', 'lakshmi', 'lanier', 'lazio', 'leniency', 'liber', 'lifeboats', 'lillard', 'lind', 'linens', 'lorenz', 'loudoun', 'lpg', 'luftwaffe', 'lurks', 'lymphatic', 'magdalena', 'mahler', 'malhotra', 'malleable', 'mannerisms', 'manta', 'marcellus', 'marek', 'marquess', 'matinee', \"matthew's\", 'maxx', 'mds', 'mediating', 'mercurial', 'micheal', 'microwaves', 'middling', 'millionth', 'mlas', 'mollie', 'mores', 'mpeg', 'multimillion', 'myung', 'nae', 'narrates', 'neg', \"nelson's\", 'nicaraguan', 'nim', 'noi', 'noooo', 'o_o', 'oni', 'outgrown', 'outpouring', 'overdone', 'overreact', 'parson', 'pele', 'pelham', 'perceiving', 'peregrine', 'peres', 'pers', 'personification', 'petitioners', 'pheromones', 'piecemeal', 'piglet', 'pilar', 'placeholder', \"plane's\", 'playmate', 'pliny', 'pnc', 'poetics', 'pogo', 'politicized', 'popsicle', 'predisposition', 'prefrontal', 'preservatives', 'presumptive', 'proactively', 'psychoanalytic', 'pto', 'purdy', 'puri', 'pérez', 'racy', 'radha', \"radio's\", 'raucous', 'receivable', 'reconciling', 'reconstituted', 'reincarnated', 'reinsurance', 'repress', 'resignations', 'resolutely', 'respectability', 'retainers', 'retrospectively', 'revolts', 'robocop', 'roleplay', 'rostov', 'rotted', 'rte', 'rusher', 'sanctum', 'scarface', 'scc', 'scooping', 'scrolled', 'seng', 'sensuality', 'seperate', 'sequoia', 'serpents', 'serrano', 'serrated', 'severing', 'shunt', 'smyrna', 'snes', 'solis', 'solver', 'southland', 'spaniel', 'ssn', 'stagger', \"stalin's\", 'stalingrad', 'statuses', 'steels', 'steely', 'stent', 'stiffer', \"studio's\", 'subtext', 'summa', 'sunflowers', 'supercharged', 'surety', 'susquehanna', 'swaziland', 'sweatpants', 'sweethearts', 'sylvie', 'syntactic', 'takahashi', 'talkie', 'tana', 'thang', 'theorized', \"thomas's\", 'thrusts', 'tiebreaker', 'tnf', 'torquay', 'totalitarianism', 'treatises', 'trimble', 'ubc', 'ugg', 'unassuming', 'undersecretary', 'unintelligible', 'unorganized', 'upholds', 'usmc', 'vegeta', 'verdi', 'verity', 'victimization', 'w000', 'weve', 'whiteside', 'whitmore', 'wicks', 'winking', 'withering', 'woodpecker', 'workstations', 'wrc', 'wtc', 'xin', 'xr', 'xvii', 'yip', 'youd', 'zigzag', 'zika', '☆', 'aah', 'abilene', 'abscess', 'absorbent', 'acorns', 'acrobatic', 'acuity', 'acura', 'adrien', 'aec', 'afrikaans', 'agate', 'airstrip', 'albanians', 'alkyl', 'alle', 'amassing', 'amo', 'ansel', 'antiquarian', 'antiseptic', 'arbitrage', 'archduke', 'aren', \"arizona's\", 'ascetic', 'aspires', 'aster', 'attains', 'attenuation', 'australasian', 'avila', 'avionics', 'azad', \"bailey's\", 'banshee', 'barbs', 'basingstoke', 'beastie', 'bedouin', 'beholden', 'beholder', 'benzema', 'blackrock', 'blogged', 'blushes', 'boas', 'bolivar', 'bookmarks', 'brahman', 'brahmin', 'brandeis', 'brentford', 'brinkley', 'brookes', 'bsp', 'bubblegum', 'bugatti', 'bungalows', 'burg', 'burp', 'buttoned', 'cano', 'canto', 'canvass', 'carolinas', 'cashback', 'castings', 'cathartic', 'catwoman', 'caucuses', 'cementing', 'centrifuge', 'cfp', 'chee', 'chestnuts', 'chávez', 'ciao', 'cinco', 'citywide', 'cliches', 'cocker', 'comanche', 'comatose', 'comforter', 'commissary', 'compilers', 'conclave', 'concoction', 'confers', 'conspire', 'consternation', 'corneal', 'cornet', 'cramming', 'crawler', 'cris', 'cruised', 'cuffed', 'cynic', 'daemon', 'dampen', 'dancehall', \"darwin's\", 'decommissioned', 'defensible', 'demolishing', 'dentures', 'descriptor', 'diehard', 'differentiates', 'dipole', 'discoloration', 'disinfectant', 'dissipation', 'distracts', 'divider', 'dji', 'downsides', 'dsl', 'dts', 'dynamism', 'e.t', 'ealing', 'earnhardt', 'effigy', 'ehrlich', 'eisenberg', 'encroaching', 'encyclopaedia', 'entomology', 'erred', 'estes', 'estrada', 'everyman', 'excepting', 'exclaims', 'exclusives', 'excommunicated', 'exterminated', 'extravagance', 'facetime', 'factually', 'faker', 'falconer', \"fan's\", 'figurehead', 'fina', 'fiscally', 'fjord', 'flowered', 'flume', 'flyover', 'focussing', 'foils', 'foy', 'freelancers', 'fretting', 'fuchs', 'gabriela', 'gales', 'gallbladder', 'gatherers', 'gauteng', 'gaya', 'geordie', 'germantown', 'gestational', 'gigabit', 'gillis', 'girdle', 'giselle', 'glut', 'godless', 'goldwater', 'grandsons', 'gripe', 'gruff', 'gurgaon', 'hahahahaha', 'haji', 'hark', 'harmonics', 'hatchery', 'haystack', 'hearthstone', 'hegel', 'heidegger', 'helga', 'helical', 'hemorrhagic', 'hibbert', 'holo', 'homies', 'hookah', 'hse', 'htm', 'humpback', 'hundredth', 'huntingdon', 'iglesias', 'igneous', 'imams', 'imperfection', 'implosion', 'incredulous', 'inherits', 'intensification', 'intercepts', 'interwoven', 'intrude', 'jeweler', 'jpmorgan', 'jumble', 'k9', 'kagan', 'kagawa', 'kala', 'kenyatta', 'kimmy', 'kodi', 'konami', 'kpmg', 'krause', 'krebs', 'kyrgyz', 'labors', 'latched', 'latimer', 'lengthen', 'lewandowski', 'lineages', 'liqueur', 'locksmith', 'locusts', 'lolly', 'londoners', 'lynette', 'lyrically', 'maidstone', 'maimed', 'maisie', 'mallard', 'mallorca', 'mandating', 'marchand', 'mariachi', 'mccallum', 'mcd', 'mcneill', 'medvedev', 'memorizing', 'merc', 'metabolite', 'metlife', 'mezzanine', 'mgmt', 'midlife', 'mired', 'missoula', 'mistletoe', 'mmo', 'mmr', 'modality', 'modifiers', 'moly', 'monetize', 'monolith', 'monticello', \"moody's\", 'mtb', 'mulan', 'mumps', 'mya', 'mystics', 'méxico', 'naturalists', 'needham', 'nesbitt', 'nils', 'nudist', 'nymphs', 'ochoa', 'oder', 'orgies', 'ortho', 'outlast', 'ozzie', 'pajama', 'panics', 'paratroopers', \"parliament's\", 'partitioning', 'pathogenesis', 'pavements', 'pawnee', 'payloads', 'penney', 'pero', 'phoning', 'plunkett', 'pompeo', 'pon', 'potash', 'predisposed', 'presentable', 'processions', 'pronouncements', 'protectionism', 'provokes', 'purports', 'quinlan', 'rab', 'radiocarbon', 'raunchy', 'raya', 'rebuked', 'reconstructions', 'redesignated', 'reeks', 'refuges', 'relaying', 'remarking', 'resetting', 'reshuffle', 'responder', 'retiree', 'rewatching', 'rho', 'rommel', 'roughness', 'rudi', 'saf', 'saiyan', 'sala', 'salter', 'salve', 'sanatorium', 'savoury', 'scaly', 'scamming', 'scold', 'seducing', 'senpai', 'sentimentality', 'shabaab', 'shaolin', 'shimon', 'shined', 'slo', 'smearing', 'smudge', 'sociedad', 'speckled', 'stallone', 'subsidised', 'subtype', 'subtypes', 'supplanted', 'surfboard', 'swatch', 'sweatshirts', 'switchboard', 'synthesizer', 'taboos', 'tahir', 'tbilisi', 'teflon', 'telecoms', 'tempers', 'tencent', 'terrorized', 'terrorizing', 'tet', 'thebes', 'tibetans', 'tierney', 'tierra', 'toenails', 'tonya', 'toothpick', 'topshop', 'touting', 'tradesmen', 'transporters', 'travolta', 'trifecta', 'trois', 'trs', 'trumped', 'twinkling', 'underserved', 'undertones', 'unfairness', 'unwieldy', 'urinate', 'urology', \"v's\", \"valley's\", 'vero', 'vertebral', \"veteran's\", 'vexed', 'vibrates', 'viennese', 'vignettes', 'vinson', 'vivienne', 'voc', 'vocalists', 'voids', 'wada', 'waitresses', 'warping', 'welbeck', 'westeros', 'whacked', 'whisperer', 'whitewash', 'whitewashed', 'widths', 'wingspan', 'winton', 'wiper', 'wipers', 'wristband', 'xxl', 'yarra', 'yeltsin', 'á', 'ε', 'θ', '🙏', '1gb', '1tb', '7m', 'abdication', 'adirondack', 'admittance', 'adolph', 'aggravate', 'aia', 'airbase', \"aircraft's\", 'alcohols', 'alpaca', 'alveolar', 'aly', 'ambivalence', 'amped', 'amphitheater', 'andrade', 'ansari', 'anthropogenic', 'appendages', 'appraisals', 'appraiser', 'arboretum', 'archivist', 'aretha', 'argent', \"argentina's\", 'arraignment', 'arsehole', 'arvind', 'asahi', 'asgard', 'astrologer', 'awd', \"ball's\", 'banknotes', 'beaker', 'belcher', 'belted', 'bereft', 'bezel', 'bhutto', 'bicentennial', 'biff', 'blackberries', \"blair's\", 'blameless', 'blasio', 'blindfold', 'bobcat', 'bock', 'booties', 'borno', 'bottlenecks', 'bravado', 'brokered', \"bruce's\", 'bruges', 'bucking', 'buffoon', 'bullseye', 'bumbling', 'byzantium', 'cagr', 'calderon', 'canaveral', 'candor', 'canines', 'capitalizing', 'carats', 'caretakers', 'cassava', 'cellulite', 'cervantes', 'changers', 'chaste', 'chucky', 'clamoring', \"clarke's\", 'cobbled', 'communicable', 'compatriot', 'computations', 'concorde', 'consuls', 'conti', 'convergent', 'copd', 'cordova', 'cosmological', 'cossack', 'courtois', 'cpd', 'craps', 'crazies', 'creaking', 'creatine', 'creatives', 'crick', \"crohn's\", 'cronin', 'crumbles', 'cypher', 'darnell', 'dazzled', 'decomposing', 'dekalb', 'demetrius', 'deploys', 'derision', 'dermal', 'destabilize', 'dfs', 'diameters', 'digimon', 'dollhouse', 'donned', 'dosages', 'dramatist', 'dressage', 'duc', 'dumont', 'dunks', 'dysentery', 'eas', 'ecologically', 'elaborating', 'emeralds', 'enumerated', 'executable', 'extradited', 'fait', 'fallin', 'faltered', 'farnsworth', 'fightin', 'filet', 'firmness', 'flannery', 'flipper', 'fml', 'fnc', 'follicle', 'foreclosures', 'frasier', 'frayed', 'frenchmen', 'furlong', 'genocidal', 'germination', 'geyser', 'gibbon', 'gilligan', 'gimp', 'glorifying', 'gonzo', 'goodie', 'gorges', 'graff', 'grainger', 'greaves', 'greening', 'greenleaf', 'greenwald', 'greenway', 'gresham', 'gretzky', 'grinders', 'griswold', 'grooms', 'grumble', 'guevara', 'hairspray', 'hani', 'hardback', \"harvey's\", 'healthful', 'hearse', 'helplessly', 'heralds', 'herbicide', 'homemaker', 'hotdog', 'hots', 'hpa', 'hrt', 'huggins', 'hunan', 'hunched', 'hyena', 'hypnotized', 'igniting', 'illuminates', 'immaturity', 'impeding', 'impostor', 'incensed', 'inclement', 'inferences', 'ingesting', 'intercepting', 'iridescent', 'janssen', 'jinping', 'jordi', 'judi', 'justifiably', 'k1', 'kannada', 'kata', 'kilowatt', 'knelt', 'kol', 'krystal', 'laborious', 'landfills', \"latter's\", 'laval', 'lavishly', 'lazar', 'legible', 'lingual', 'liquidate', 'livable', 'lobo', 'loftus', 'loomed', 'lovejoy', 'lowercase', 'lpga', 'lusty', 'macao', 'maddening', 'malnourished', 'mami', 'manassas', 'manna', \"manufacturer's\", \"maria's\", 'martine', 'martínez', 'massaging', 'materiel', 'mchenry', 'menlo', 'mennonite', 'messier', 'mgr', 'microcosm', 'miki', 'mille', 'milos', 'miscarriages', 'misdeeds', 'mishra', 'mixtapes', 'moaned', 'monrovia', 'moro', 'muhammed', 'multifaceted', 'multiplicity', 'n.h', 'nac', 'nagpur', 'nasir', 'naylor', \"nba's\", 'neurosurgeon', 'nist', 'niño', 'noe', 'norah', 'norbert', 'nullified', 'nutter', 'obsessively', 'occured', 'olde', 'ooze', 'orangutan', 'orbs', 'oregano', 'organics', 'orig', 'osmond', 'outdone', 'outplayed', 'outrageously', 'outro', 'p0000', 'pacino', 'palisades', \"palmer's\", 'paloma', 'pandey', 'paraphrasing', 'parliamentarian', 'partied', 'passable', 'pasteur', 'pasting', 'patted', 'pease', 'peels', 'peeve', 'pendants', 'perishable', 'persie', 'personas', 'perv', 'pfc', 'photojournalist', 'pinks', 'plunges', 'politburo', 'polystyrene', 'pontiff', 'portrayals', 'postulated', 'pows', 'preemptive', 'pretender', 'primers', 'proletarian', 'prolonging', 'prong', 'prosthesis', 'prosthetics', 'psc', 'puny', 'qf', 'quantico', 'quarrels', 'quilted', 'quilts', 'r.a', 'r8', 'radium', 'ramming', 'rancid', 'reassess', 'reb', 'recoverable', 'rectangles', 'rediscover', 'redistricting', 'ree', 'reissued', 'renner', 'reorganize', 'replayed', 'reservists', 'resonator', 'restlessness', 'retaliated', 'retirements', 'revives', 'revolted', \"robin's\", 'rojas', 'roms', 'royalist', 'rpgs', 'ryo', 's9', 'savile', 'sawed', 'sayers', 'schilling', 'screenwriting', 'sculpt', 'selectivity', 'shatters', 'shopkeepers', 'sicker', 'signified', 'simi', 'sita', 'sizzle', 'skated', 'sloop', 'smu', 'snoopy', 'sobbed', 'spooner', 'spotter', 'squint', 'statisticians', 'stenosis', 'strathclyde', 'stv', 'subsystems', 'suffocation', 'surpluses', 'surrenders', 'syndication', 'tailgating', 'tama', 'tapestries', 'teamsters', 'technologists', 'tenfold', 'terrify', \"terry's\", \"there're\", 'thrall', 'throng', 'tianjin', 'togetherness', 'tolerances', 'tongs', 'topographical', 'traceable', 'trieste', 'trite', 'tryouts', 'tues', 'tusks', 'tylenol', 'undamaged', 'unpacked', 'unrivalled', 'urgh', 'urinating', 'v000', 'verily', 'vga', 'vir', 'visualized', 'vitae', 'vocally', 'wadi', 'walkthrough', 'wallow', \"ward's\", 'washroom', 'weldon', 'whigs', 'widgets', 'wilkie', 'wily', 'winks', 'wol', 'womack', \"wood's\", 'workhouse', 'worshiping', 'wouldn', 'x5', 'xian', \"z's\", 'zum', 'zz', '✓', '🎶', '😬', '5ft', '6k', 'aam', 'abingdon', 'acetone', 'actuarial', 'adel', 'adventist', 'albemarle', 'alcatraz', \"allah's\", 'allot', 'amine', 'amma', 'anathema', 'angelique', 'anni', 'anz', 'appeasement', 'appropriating', 'artisanal', 'ascertained', \"asperger's\", 'auguste', 'aurelius', 'aureus', 'authorise', 'b6', 'bacchus', 'bantam', 'barked', 'barrack', \"baseball's\", 'batty', 'belive', 'bellow', 'belvedere', 'benefactors', 'betta', 'bhopal', 'bia', 'bitty', 'blurb', 'bonham', 'bonsai', 'boro', 'bosworth', 'boyish', 'bps', \"brian's\", 'bron', 'bronte', 'brownlow', 'buckwheat', 'bushel', 'busses', 'bute', 'buttercup', 'ca2', 'calibrate', 'callback', 'campsites', 'candlestick', 'capricious', 'carcinogenic', 'cartagena', 'cataracts', 'cation', 'caveats', 'cdu', 'cel', 'centaur', 'centipede', 'chested', 'chiffon', 'chirp', 'chloroform', 'chromatin', 'citibank', 'clays', 'clichés', 'clogs', 'coaxial', 'colluding', 'colman', 'commutes', 'completions', 'conch', 'concocted', 'conditioners', 'condon', 'confucian', 'conspirator', 'conveyance', 'coronado', 'corrie', 'corsica', 'cosgrove', 'cotter', 'cottonwood', 'cranberries', 'crankshaft', \"crew's\", 'cristo', 'crossbar', 'crème', 'cytokines', 'dawning', 'delicacies', 'demarcation', 'desai', 'desalination', 'desktops', 'determinations', 'dictatorships', 'digby', 'dildos', 'dimly', 'discernment', 'dislodge', 'dismembered', 'disrepair', 'dissertations', 'doings', 'doorman', 'drogba', 'duckworth', 'duets', 'dunfermline', 'eames', 'easement', 'ebitda', 'eis', 'eloise', 'emilie', 'emulated', 'emulating', 'endorphins', 'engrossed', 'entwined', 'eren', 'espinosa', 'euclidean', 'euler', 'evacuations', 'ewe', 'exponents', 'extraneous', 'exuberance', 'eyeglasses', 'falsehoods', 'familiarize', 'fap', 'fastening', 'fenwick', 'ferrous', 'feta', 'florian', 'forearms', 'foreboding', \"foster's\", 'frieze', 'gangnam', 'gatekeeper', \"generation's\", 'giacomo', 'glyn', 'golem', 'gossiping', 'gracias', 'grafting', 'granules', 'gridlock', 'guarantor', \"guard's\", 'gujarati', 'gy', 'hanlon', 'happend', 'hares', 'haywood', 'herbaceous', 'herodotus', 'hightower', 'hilliard', 'hinckley', 'hither', 'hol', 'holbrook', 'homeboy', 'honing', 'honky', 'honorably', 'horan', 'hoskins', 'hoyer', 'humber', 'hurriedly', 'hyping', 'idioms', 'iga', 'illusory', 'illustrators', 'ilo', 'iman', 'inadequacy', 'inadvertent', 'inaudible', 'incapacity', \"indiana's\", 'industrious', 'infects', 'inflating', 'ingress', 'insufferable', \"int'l\", 'interred', 'interrogations', 'intrusions', 'isometric', \"j's\", 'javi', 'jeeps', 'jett', 'jib', 'jinnah', 'journeyed', 'jute', 'kauffman', 'kejriwal', 'kel', 'kevlar', 'kkr', 'kristian', 'laissez', 'layoff', 'leica', 'leper', 'levee', 'lewin', 'lido', 'lise', 'loci', 'loos', 'lotteries', 'loudspeakers', 'lovett', 'lucerne', 'lurch', 'm0000', \"madrid's\", 'magnificence', 'majid', 'majored', 'malaysians', 'malfunctions', 'mamas', 'mangoes', 'manipur', 'margaritas', 'martens', \"mason's\", 'matchmaker', 'matlab', 'mattie', 'mayhew', 'mcphee', 'measly', 'megapixel', 'mellitus', 'meringue', \"miami's\", 'minstrel', 'modesto', 'monaghan', 'mondo', 'moronic', 'mouthing', \"movement's\", 'muddle', 'multidimensional', 'nabbed', 'nantes', 'narrate', 'nathalie', 'naturalism', 'navigated', 'neoclassical', 'neoliberalism', 'neutered', 'neve', 'neverland', 'newsworthy', 'nomura', 'normalizing', 'northerners', 'nts', 'oaxaca', 'obliterate', 'ocr', 'oeuvre', 'omnipresent', 'oneida', \"ontario's\", 'ordinator', \"organisation's\", 'osmosis', 'outcrops', 'overhang', 'oxley', 'p.e', 'paganism', 'pail', 'palatine', 'paleontology', 'parabolic', 'paradoxes', 'pare', 'parkour', 'parlance', 'permafrost', 'permutations', 'persecute', 'phat', 'pixies', 'plexus', 'politic', 'poncho', 'poolside', 'pornstars', 'preeminent', 'prefabricated', 'premiering', 'presbytery', 'preservative', 'presse', 'presser', 'prioritise', 'probs', 'propelling', 'propriety', 'provisionally', 'pythons', 'qbs', 'quartered', 'quigley', 'rainey', 'rapunzel', 'rattles', 'razed', 'recitals', 'reconstructing', 'rejuvenation', 'repatriated', 'reposted', 'resection', 'reseller', 'roald', 'robles', 'rockland', 'ruffle', 's00e00', 'saito', 'samar', 'sarcophagus', 'sardar', 'sarin', 'sartre', 'saud', 'scab', 'schenectady', 'schlesinger', 'scoot', 'scp', 'scratchy', 'scuffle', 'secede', 'seep', 'sensuous', 'shabbat', 'shakti', 'shanti', 'shaver', 'sherpa', 'showy', 'sideboard', 'silks', 'silliness', 'sills', 'sisi', 'skittles', 'skyler', 'skyrocket', 'smalling', 'sns', 'softest', 'sonora', 'sor', 'spate', 'spellings', 'splinters', 'squeezes', 'starks', 'stasi', 'stealthy', 'stereotyped', 'storybook', 'stowed', 'strobe', 'stryker', 'stylists', 'subduction', 'submersible', 'suburbia', 'sud', 'sulu', 'superlative', 'surmounted', 'swarovski', 'sylvan', 'symphonies', 't5', 'tabby', \"taiwan's\", 'tamils', 'tatar', 'tatars', 'technologist', 'templars', 'terrorize', 'thorium', 'throes', 'tiananmen', 'tilts', 'tion', 'tomboy', 'tonsils', 'transfusions', 'traumas', 'triassic', 'tricycle', 'trp', 'truro', 'umass', 'unaltered', 'unapologetic', 'unclassified', 'uncool', 'unfavourable', 'unloved', 'unmasked', 'unsightly', 'uptick', 'urchin', 'vandal', 'vhf', 'villanova', 'violators', 'vise', 'vj', 'walsall', 'wasn', 'watertight', 'wavering', 'wherefore', 'whoo', 'wildflowers', 'windward', 'wip', 'witcher', 'wok', 'woodcock', 'xiang', 'xtreme', 'yahya', 'yoy', 'z000', 'zag', 'zips', 'über', '♬', '💜', '6p', '8a', 'abstained', 'accretion', 'activator', 'aeroplanes', 'aerosmith', 'affirmations', 'afresh', 'ahs', 'allahabad', 'allotments', 'annular', 'appetizers', 'appleby', 'appraised', 'appreciable', 'aquila', 'arnaud', 'associative', 'asst', 'assuredly', 'atherosclerosis', 'auctioneers', 'augsburg', 'aural', 'automakers', 'bachmann', 'backroom', 'baited', 'banksy', 'bap', 'barracuda', 'bcc', 'beauchamp', \"beethoven's\", 'belarusian', 'benefitting', 'benevolence', 'bettering', 'bewitched', 'bil', 'blazes', 'blimp', 'bls', 'bo3', 'bodywork', 'bondholders', 'bookcase', 'boucher', 'bracken', 'bridle', 'bruv', \"buddy's\", 'buford', 'bullard', 'bullshitting', 'butterworth', 'c.i.a', 'cassini', 'castration', 'cathay', 'caudal', 'charing', 'cheeseburgers', 'chews', 'chiles', 'chillin', 'choruses', 'chowder', 'clary', 'clinching', 'cmd', 'cogs', 'collarbone', 'colonize', 'condolence', 'conjugated', 'conquerors', 'consents', 'constructively', 'cordoba', 'cov', 'crackle', 'crematorium', 'crests', 'croissant', 'crustaceans', 'cryin', 'cryogenic', 'curbs', 'dally', 'decoded', 'decontamination', 'defenceman', 'delle', 'delving', 'demonstrably', 'deniers', 'depositors', 'despises', 'devolve', 'devotes', 'dha', \"diana's\", 'diffuser', 'dispersing', 'disposals', \"dj's\", 'dominguez', 'dor', 'dpp', 'drucker', 'dupe', 'duster', 'eatery', 'electronica', 'elms', 'elongate', 'elude', 'embattled', \"employer's\", 'enamored', 'encephalitis', 'ender', 'endowments', 'entertainments', 'enthralled', 'escalates', 'eskimos', 'eso', 'esplanade', 'etch', 'eustace', 'evangelists', 'excavating', 'expelling', 'eyewear', 'fairgrounds', 'fallacies', 'farted', 'favoritism', 'fenders', 'fervently', 'feudalism', 'fireproof', 'flounder', 'foetus', 'forthright', 'frans', 'gaon', 'gaylord', 'geisha', 'gelato', 'gemstones', 'giza', 'glade', 'glassy', 'gleefully', 'glycogen', \"gm's\", 'godsend', 'gofundme', 'goodall', 'grasshoppers', 'groped', 'grubby', 'guan', 'gulch', 'gynecologist', 'hacienda', 'hairpin', 'halliday', \"hannah's\", 'hannover', 'harnesses', \"hart's\", 'haru', 'hatter', 'hausa', 'hawes', 'hazelnut', \"hbo's\", 'hendrick', 'hiker', 'hilbert', 'hj', 'homologous', 'horseshit', 'howls', 'hsc', 'hummer', 'hydrating', 'hyo', 'icp', 'ifc', 'iffy', 'immovable', 'impaled', 'inspectorate', 'interstitial', 'inverter', 'iona', 'irate', 'isu', 'iverson', \"jake's\", 'jeju', 'jezebel', 'jf', 'jizz', 'joliet', 'joshi', 'jugular', 'kean', 'kelli', 'kerrigan', 'kickstart', 'killian', 'kinsey', 'kirkwood', 'knockdown', 'konstantin', 'kor', 'krugman', 'ladd', 'lagoons', 'lapis', 'laramie', 'lessening', 'lethargic', 'lga', 'liberator', 'ligature', 'linkin', 'lipped', 'littering', 'livers', \"logan's\", 'longhorns', 'loony', 'loveliest', 'lse', 'lynchburg', 'maggot', 'mahesh', 'malek', 'malkin', 'mambo', 'mandala', 'mandolin', \"manhattan's\", 'margie', 'marinated', 'martinique', 'maryam', 'mbs', 'mcguinness', 'mcnulty', 'mediaeval', 'megaphone', 'megawatts', 'merci', 'milfs', 'militarism', 'millimetres', 'mim', 'misfortunes', 'mismatched', 'missus', 'miyazaki', 'moab', 'modernizing', 'moped', \"morrison's\", 'moser', 'mountaineers', 'msf', 'mugging', 'multiplex', 'musica', 'más', 'nang', 'nar', 'nickels', 'nicol', 'noelle', \"o'grady\", 'obstructions', 'odom', 'oktoberfest', 'oncologist', 'onside', 'opel', 'opiates', 'optimally', 'optionally', 'oscillating', 'outperformed', 'overlaid', 'overlapped', 'pamper', 'panacea', 'parc', 'parietal', 'parkes', 'patronizing', 'pauper', 'pedersen', 'peppered', 'pestilence', 'pews', 'pewter', 'philippa', 'philosophically', 'pineapples', 'pippin', 'pittsburg', 'plainfield', 'plenum', 'polygraph', 'popup', 'precipitate', 'principality', 'priori', \"professor's\", 'pronged', 'proofing', 'propping', 'protease', 'proust', 'punchline', 'purges', 'px', 'queenstown', 'quintana', 'r.i.p', 'radish', 'rashad', 'rds', 'receded', 'reciprocate', 'recklessness', 'regenerating', 'remaking', 'repetitions', \"republic's\", 'restock', 'restorations', 'retweets', 'reykjavik', 'rickie', 'roasts', 'rocha', 'rotunda', 'roundhouse', 'rowed', \"roy's\", 'rpi', 'rushmore', 'sanctioning', 'sativa', 'savour', 'sawing', 'scarab', 'schengen', 'scoff', 'scythe', 'searle', 'secretions', 'sedated', 'semper', 'sepia', 'severus', 'shaffer', 'shamans', 'shipley', 'shoveling', 'shs', 'silvers', 'sinaloa', 'sketchbook', 'skirting', 'slapstick', 'slinging', 'smythe', \"so's\", 'sourdough', 'spiking', 'spires', 'sprinters', 'sprouted', 'squirm', 'srt', 'staircases', 'stepdaughter', 'stm', 'stoney', 'strategists', 'stupendous', 'sunbathing', 'supercars', 'surrealism', 'surya', 'sys', 'tabitha', 'tabor', 'takashi', 'tarrant', 'tca', 'telepathic', 'telescopic', 'tellers', 'telstra', 'tenderly', 'termite', 'theron', 'thicke', 'thickens', 'thongs', 'thurs', 'tig', \"tiger's\", 'timetables', 'tortoises', 'transcriptional', 'transgenic', 'trimmer', 'trudy', 'twa', 'ucc', 'underscored', 'undiagnosed', 'unease', 'univision', 'unrequited', 'uptime', 'urinal', 'urls', 'usf', 'usurped', 'vagabond', 'vamos', 'vanuatu', 'varna', 'vaseline', 'vedas', 'vestiges', 'vipers', 'virtualization', 'visage', 'vk', 'warne', 'webcams', 'wechat', 'weeps', 'wel', 'wether', 'wham', 'wien', 'winked', 'woodville', 'woohoo', 'wook', 'writhing', 'wuhan', 'yardage', 'yg', 'yue', 'zeitung', 'zing', 'zumba', '2e', '3p', 'a.a', 'ablation', 'abo', 'accelerators', 'actuator', 'adkins', 'admirals', 'adrenalin', 'advertises', 'agribusiness', 'aguirre', 'aig', 'aja', 'aleksandr', 'algorithmic', 'alignments', 'alleviating', 'alsace', 'amass', 'amok', 'anatolia', 'androgen', 'angina', 'animating', 'anthologies', 'apolitical', 'apologist', 'appalachia', 'arcades', 'archeology', 'arian', 'asf', 'astrological', 'attaché', 'auger', 'ayala', 'babble', 'babs', 'baillie', 'balinese', 'bankruptcies', 'barman', 'barrows', 'baruch', \"bay's\", 'beachfront', 'beatrix', 'beckman', 'berlusconi', 'bic', 'blighted', 'blinks', 'bloodborne', 'borrowings', 'botha', 'bottas', 'bouncers', 'brea', 'buoys', 'c.c', 'cady', 'camouflaged', 'cardi', 'carrera', 'cartesian', 'catalogued', 'catastrophes', 'cerberus', 'chalkboard', 'chantal', 'chappelle', 'charlestown', 'cheerios', 'chica', 'childress', 'chorizo', 'chubb', 'cockney', 'collated', 'comically', 'commoners', 'compiles', 'conde', 'conjoined', 'conservationists', 'controversially', 'credo', 'crevices', 'cri', 'critter', 'csc', 'culminates', 'cytoplasm', 'dap', 'darpa', 'ddr', 'deadbeat', 'debauchery', 'decrepit', 'dejected', 'democratization', 'denison', 'dented', 'deprecating', 'derided', 'designates', 'despatched', 'dimples', 'dirtiest', 'djibouti', 'domenico', 'driest', 'dubbing', 'dubuque', 'durbin', 'dweller', 'dynastic', 'edouard', \"edward's\", 'eea', 'elan', 'elinor', 'elkins', 'elo', 'embarrassingly', 'embolism', 'enclose', \"engine's\", 'entree', 'enzymatic', 'eradicating', 'esmeralda', 'esophageal', 'essen', 'euston', 'f.b.i', 'figueroa', 'firs', 'flashlights', 'flaunting', 'flavoring', 'flirtatious', 'flue', 'formulae', 'frankfort', 'frescoes', 'fuckery', 'furness', 'futurama', 'fwd', 'gam', \"gandhi's\", 'gatherer', 'generative', 'gentleness', 'ghouls', 'globalist', 'gnarly', 'gnostic', 'grassley', 'greenbelt', 'grier', 'griggs', 'guadalajara', 'handicrafts', 'haphazard', \"harrison's\", 'haus', 'headliners', 'hempstead', 'hippos', 'hollande', 'huck', 'hyperion', 'hypersensitivity', 'inaccuracy', 'inadmissible', 'indecision', 'indomitable', 'infidel', 'inhabits', 'ini', 'inr', 'insemination', 'insinuating', 'inst', 'intelligible', 'intervenes', 'ionizing', 'irrevocably', 'islets', 'ivanov', 'j.m', 'jayden', 'jimbo', 'jocks', 'juba', 'judgemental', 'jurisdictional', 'k000', 'kama', 'kenosha', \"kentucky's\", 'kidnapper', 'kiran', 'knesset', 'krusty', 'krypton', 'kuan', 'kuo', 'lagrange', 'lapel', 'laverne', 'leaped', 'liao', 'lichen', 'liechtenstein', 'lindbergh', 'lino', 'litmus', 'llewellyn', 'longman', 'magellan', 'magnificently', 'magnify', 'malachi', 'marnie', 'marques', 'masha', 'matador', 'maxed', \"mccain's\", 'mcdougall', 'mcm', 'mda', 'meera', 'megatron', 'mehmet', 'mendel', 'meniscus', 'menthol', 'methodically', 'mightily', 'misjudged', 'miso', 'monotone', 'monstrosity', 'mordecai', 'moseley', 'mourns', 'mowed', 'mst', 'muskets', 'mutter', 'naismith', 'nationale', 'navigators', 'neb', \"netflix's\", 'nineveh', 'nostril', 'nothings', 'notting', 'numeral', 'oddity', 'odious', 'odo', 'offbeat', 'officio', 'omb', 'omens', 'operandi', 'opie', 'opportunist', 'orifice', 'ornamentation', 'overcoat', 'overreaction', 'overused', 'pag', 'pah', 'painkiller', 'panchayat', 'pansy', 'parading', 'parte', 'parti', 'pathologists', 'patter', 'peerage', 'peirce', 'peloton', 'permissive', 'phrased', 'pieced', 'pittman', 'placate', 'ploughed', 'polynomials', 'posited', 'postsecondary', 'powdery', 'ppe', 'pram', 'prescriptive', 'preying', 'psst', 'purifying', 'puritans', 'pushback', 'quads', 'radicalized', 'ragnar', 'ramesh', 'rampart', 'rapporteur', 'rav', 'rcs', 'reaped', 'recesses', 'redeemable', 'redistribute', 'redistributed', 'refraction', 'reinvented', 'rejections', 'rejuvenated', 'reloading', 'reminiscences', 'remittances', 'remus', 'renewals', 'renter', 'revels', 'revolvers', 'ringside', 'rinsed', 'riverbank', 'rockingham', 'rog', 'ronin', 'roofed', 'rouen', 'rourke', 'rousey', 'rowers', 'sab', 'safes', 'saif', 'salma', 'sarkozy', 'scoundrel', 'scouted', 'sdi', 'seamstress', 'sevastopol', 'shifty', 'showman', 'sibley', 'siobhan', 'slacking', 'slashes', 'slob', 'sneezes', 'snubbed', 'sojourn', 'sounders', 'soured', 'sousa', 'southernmost', 'spitzer', 'splatter', 'sputnik', 'squirting', 'stanhope', 'stipulate', 'stipulations', 'straddle', 'subbing', 'sumter', 'suzie', 'swatches', 'sweeten', 'swinger', 'talib', 'tallies', 'talons', 'tawny', 'tbd', 'tenured', 'terriers', 'thereon', 'throwaway', 'thunderous', \"tiffany's\", 'tigris', 'transcontinental', 'trims', 'trott', 'tui', 'tweezers', 'twerking', 'typographical', 'u00s', 'ubi', 'unbeknownst', 'unchained', 'unedited', 'unelected', 'unleashes', 'uplands', 'uppsala', 'upstanding', 'vallejo', 'vapors', 'verma', 'vertebra', 'viaduct', 'vino', 'voracious', 'warbler', 'wart', 'wasabi', 'waterworks', 'wettest', 'whammy', 'whedon', 'whines', 'whitechapel', 'wich', 'wilful', 'willa', \"wisconsin's\", 'wittgenstein', 'wolfsburg', 'wye', 'xia', 'yams', 'yorktown', 'yui', 'zeitgeist', 'на', '😄', \"aaron's\", 'abb', 'accentuate', 'adf', 'adipose', 'adjudication', 'adl', 'advices', 'affording', 'aggravation', 'aggregator', 'agua', 'ainsworth', 'airforce', 'ait', 'aldermen', 'alvarado', 'amazonian', 'aml', 'amorous', 'anabolic', 'andersson', 'anemic', 'anima', 'anointing', 'apologising', 'apostrophe', 'appellation', 'appendage', 'appendicitis', 'appropriateness', 'aquariums', 'artur', 'ary', \"ashley's\", \"assad's\", 'autumnal', 'awash', 'backstreet', 'bagley', 'balling', 'bandai', 'banerjee', 'banishment', 'baptised', 'basra', 'bate', 'bawling', 'bayard', 'bayonets', 'beastly', 'becket', 'beetroot', 'berkley', 'beto', \"billy's\", 'bim', 'birdies', 'blockbusters', 'bluffing', 'bonita', 'bonjour', 'boomed', 'boson', 'brainchild', 'brawn', 'bridegroom', 'buh', 'bulwark', 'butthurt', 'candidly', 'cappella', 'capsized', 'carne', 'cartman', 'cec', 'chapo', 'chatsworth', 'chauncey', 'chien', 'chippewa', 'christa', 'ciara', 'ciudad', 'conciliatory', 'condensate', 'condiments', 'conferring', 'convening', 'correspondingly', 'corrigan', 'crit', 'crouched', 'crusoe', 'crybaby', 'culpability', 'cyberpunk', 'deflecting', 'desegregation', 'deserters', 'deservedly', 'devalued', 'digress', 'dijon', 'dinesh', 'disappoints', 'discus', 'distinctively', 'diverged', \"division's\", 'dla', 'dnr', 'doa', 'dryers', 'dumbarton', 'eatin', 'ece', 'eduard', 'elaborately', 'elevates', 'empathize', 'encrypt', 'endocrinology', 'energetically', 'energize', 'enix', 'entertains', 'estimator', \"event's\", 'excellently', 'exerts', 'extrusion', 'facades', 'fagan', 'farnham', 'felling', 'fester', 'feuding', 'flexed', 'flywheel', 'foams', 'foregone', 'foreshadowed', 'foreshadowing', 'formosa', 'fortnightly', 'fourths', 'freshest', 'fringed', 'ftse', 'fulcrum', 'funnels', 'furman', 'gaiman', 'galbraith', 'gallic', 'geddes', 'ghosh', 'gilliam', 'gilroy', 'ginseng', 'gnomes', 'goodrich', 'goodwood', 'gophers', 'goths', 'grandest', \"greece's\", 'grimy', 'gsp', 'gung', 'gunter', 'h1n1', 'hadid', 'hanukkah', 'hardball', 'hargreaves', 'harriman', 'hatcher', 'headstone', 'heil', 'herbicides', 'heterogeneity', 'hibiscus', 'hillman', 'hin', 'hitchens', 'hob', 'hows', 'hwan', 'hyperactive', 'hysterectomy', 'iberia', 'icky', 'identically', 'immediacy', 'immunotherapy', 'improvising', 'inbreeding', 'incisive', 'inconspicuous', 'indebtedness', 'indentured', 'infiniti', 'inhabitant', 'inhospitable', 'inoperable', 'instigate', 'insufficiently', 'intercession', 'interferon', 'intersects', 'irrevocable', 'irritability', 'islet', 'israelite', 'ivoire', 'jaden', 'jaffe', 'janie', 'jefferies', \"jessica's\", 'johansen', 'jonathon', 'juris', 'kaduna', 'kcal', 'ker', 'keychain', 'khorasan', 'kojima', 'kraus', 'kravitz', 'krieger', 'laity', 'landlocked', 'latterly', 'leaner', 'legos', 'leukaemia', 'leyte', 'licensure', 'lighthouses', 'lingua', 'lipton', 'llamas', 'lts', \"lucy's\", 'luminaries', 'lz', 'm.j', 'makings', 'maldonado', 'maleficent', 'maniacs', 'manifolds', 'maradona', 'marrakech', 'mauro', 'mcfly', 'mckinsey', 'mcl', 'medea', 'mek', 'mesmerized', 'midge', 'milked', 'minotaur', 'misfit', 'miu', 'moana', 'moorish', 'morgana', 'mosquitos', 'mottled', 'moulton', 'mountaineer', 'mountainside', 'mov', \"mp's\", 'mucous', 'mulholland', 'murmuring', 'mvc', 'myer', 'mythos', 'naa', 'najib', 'nationalized', 'nca', 'neutrinos', 'nips', 'northside', 'nuevo', 'nus', 'nusra', 'obamas', 'obelisk', 'oddball', 'offload', \"ohio's\", 'osa', 'osteoarthritis', 'otago', 'outcrop', 'outlander', 'overestimated', 'overloading', 'overthrowing', 'oxfam', 'padua', 'pageants', 'paley', 'panning', 'pari', 'pariah', 'parka', 'parke', 'paton', 'peddle', 'peerless', 'pentium', 'permanence', 'permeable', 'personhood', 'pil', 'pillage', 'pistachio', 'planing', 'plebiscite', 'ploughing', 'poisson', 'polynesia', 'polyurethane', 'posit', 'poughkeepsie', 'precipice', 'presuming', 'protégé', 'puked', 'queued', 'quickie', 'rahim', 'raina', 'ralston', 'randi', 'ravages', 'ravenous', 'realy', 'rearranging', 'reclusive', 'reek', 'regenerated', 'regimens', 'reinhold', 'reinstall', 'rena', 'req', 'resold', 'rimmed', 'rind', 'riparian', 'risers', 'riverfront', 'rosebud', 'rosé', 'rtd', 'ruck', 'rumsfeld', 'runaways', 'salamander', 'santorum', 'sats', 'satya', 'scalpel', 'scraper', 'scribbled', 'scrutinize', 'seatbelts', 'sedate', \"senator's\", 'sfa', 'shallower', 'shaves', \"sheep's\", 'shou', 'shriek', 'simulates', 'singularly', 'sinkhole', 'skimpy', 'slavs', 'sloped', 'snore', 'solaris', 'sooners', 'sorceress', 'spaceflight', 'spe', 'spender', 'sphincter', 'spooks', \"sport's\", 'squires', 'stalinist', 'stank', 'sternum', 'stockbroker', 'stoppers', 'storytellers', 'strachan', 'strangulation', 'stratification', 'stratified', 'streaked', 'stretchy', \"subject's\", 'suckling', 'sucrose', 'suleiman', 'sundae', 'sundry', 'supercomputer', 'svetlana', 'swampy', 'synapse', 't6', 'tasking', 'tidings', 'toothache', 'tranquillity', 'transitive', 'trickling', 'trigonometry', 'trimmings', 'tupperware', 'tur', 'tutelage', 'twos', 'typhus', 'uhf', 'unaffiliated', 'unconscionable', 'underlines', 'unflattering', 'unrecognizable', 'uns', 'unscheduled', 'unstructured', 'vagrant', 'veracruz', 'viacom', 'vidya', 'vlog', 'voiceless', 'volga', 'volgograd', 'waka', 'walkout', 'wands', 'wearables', 'whosoever', 'willamette', 'wimpy', 'woodman', 'wordplay', \"work's\", 'worthing', '♡', '2x00', \"5'9\", '5b', '6b', 'aarp', 'abou', 'abstractions', 'acceptor', 'acrobatics', 'aerobics', 'afd', \"alabama's\", 'alertness', 'alleyway', 'amenity', 'angrier', 'antilles', 'arabella', 'arnhem', 'arno', 'ascribe', 'aso', \"athlete's\", 'athos', 'attenuated', 'atticus', 'atx', 'augusto', 'avenging', 'azerbaijani', 'backcountry', 'bandana', 'bangles', 'barbarism', 'bareback', 'battlefront', 'bbc2', 'bcci', 'beaters', \"bennett's\", 'berne', 'biddle', 'billet', 'binaries', 'blackmailing', 'blissfully', 'bloodied', \"bobby's\", 'boneless', 'borealis', 'brainless', 'breadcrumbs', 'breathable', 'bridged', 'brightening', 'bristle', 'buffaloes', 'bulkhead', 'bund', 'bur', 'burglaries', 'cacti', 'canaries', 'carded', 'carpool', 'cashew', 'cashiers', 'cavernous', 'ccm', \"cd's\", 'cece', 'chaff', 'changeable', 'chaperone', 'chlorophyll', 'chroma', 'claret', 'cloister', 'clothe', 'clutched', 'cochlear', 'coen', 'complainants', 'comps', 'concomitant', 'constipated', 'consults', 'consummated', 'contemplates', 'coppola', 'corby', 'creationism', 'credential', 'crump', 'crunches', 'cs:go', 'csp', 'cthulhu', 'ctv', \"cuba's\", 'curiosities', 'cymbals', 'côte', 'danforth', \"danny's\", 'darkening', 'darrow', 'debs', 'debunking', 'decompose', 'ded', 'deepens', 'deformities', 'denier', 'denounces', 'destabilizing', 'detaining', 'determinism', 'dieu', 'digesting', 'dimmed', 'dingo', 'disaffected', 'disheartened', 'dispossessed', 'dissecting', 'dma', 'domicile', 'dominions', \"don'ts\", 'donne', 'dreamland', 'dumbfounded', 'e5', 'ecc', 'effie', 'effing', 'egotistical', 'elgar', 'elmore', 'emirate', \"empire's\", 'encrusted', 'enticed', 'eph', 'erudite', 'estuaries', 'faintest', 'fasteners', \"fed's\", 'fervour', 'fiends', 'finders', 'flattening', 'flirts', 'foursome', 'franchising', 'francophone', 'froth', 'furlough', 'galatians', 'galicia', 'galleria', 'gambled', 'garnering', \"gentlemen's\", 'ghettos', 'gnawing', 'growths', 'gru', 'guile', 'gurley', 'hallo', 'hallows', 'hamiltonian', 'hangovers', 'havre', 'heartedly', 'heft', 'henrique', 'hibs', 'hideaway', 'hilarity', 'hiller', 'hillsides', 'holyrood', 'homeworld', 'homey', 'hortons', 'ils', 'imparted', 'impersonate', 'impropriety', 'inactivation', 'incompatibility', 'infact', 'instalments', 'intermediates', 'interment', 'introverts', 'irked', 'ivor', 'jardin', 'jbl', 'jemima', 'jenni', \"josh's\", 'json', 'junkyard', 'jurists', 'juxtaposed', 'kaufmann', 'kennels', 'keri', 'kingship', 'kinshasa', 'km2', 'kourtney', 'laa', 'lando', 'larissa', 'launceston', 'legitimize', 'leif', 'lifelike', 'lilian', 'lioness', 'lobos', 'locates', 'loin', 'loire', 'longterm', 'loveable', 'lovey', 'lowndes', 'lyin', 'maastricht', \"machine's\", 'machinist', 'mainz', 'mandible', 'manhole', 'margate', 'marginalised', 'marigold', 'marinade', 'marla', 'matted', 'mattis', 'mcarthur', 'mcclain', 'mccord', 'melancholic', 'merlot', 'methodists', 'metoo', 'michal', 'middlemen', 'mineralogy', 'minibus', 'misdemeanors', 'modifies', 'modulus', 'monarchies', 'monogamy', 'monotony', 'mopping', 'mormonism', 'mortally', 'moveable', 'multinationals', 'musculoskeletal', 'mut', 'myeloma', 'nast', 'natty', 'navies', 'neapolitan', 'nebulous', 'negated', 'neurotransmitters', 'newberry', \"newspaper's\", 'nilsson', 'no1', 'nok', 'nots', 'nozzles', 'nrg', 'nucleotides', 'nwa', 'oberlin', 'obscuring', 'occlusion', 'oliveira', 'opa', 'osgood', 'outlived', 'overdoses', \"owen's\", 'paralegal', 'pared', 'payrolls', 'peckham', \"peterson's\", 'petrov', 'pieter', 'pikes', 'pim', 'pining', 'pinoy', 'piranha', 'pix', 'pocketed', 'ponte', \"porter's\", 'posits', 'postmortem', 'postscript', 'prehistory', 'preterm', 'prismatic', 'prophesied', 'prototyping', 'prowl', 'psv', 'ptc', \"publisher's\", 'pugs', 'puja', 'punchy', 'purr', 'pussycat', 'quagmire', 'quaid', 'quash', 'r.j', 'rackets', 'radiates', 'rafe', 'rahm', 'railed', 'raindrops', 'rajesh', 'ransacked', 'readability', 'reba', 'recieve', 'recieved', 'reciprocated', 'redman', 'redox', 'reductive', 'refundable', 'reinvestment', 'remedied', 'renews', 'replaying', 'repose', 'reptilian', 'restful', 'retraining', 'rewrote', 'riccardo', 'ricochet', 'rifts', 'rishi', 'rona', \"room's\", 'rosh', 'rubric', 'savagely', 'scallop', 'scavengers', 'schoolmaster', 'schoolwork', 'scoffed', 'scoping', 'scoreline', 'searchers', 'seedling', 'setters', 'shaikh', 'shanty', 'shao', 'sharepoint', 'shat', 'sheba', 'sherri', 'shrew', 'shrimps', 'shush', 'signor', 'silencer', 'sind', 'singin', 'sited', 'slacker', 'sleight', 'smoldering', 'snowmobile', 'soapy', 'soloists', 'southgate', 'sovereigns', 'spaceships', 'spatially', \"speaker's\", 'spectroscopic', 'speedily', 'spidey', 'spiky', 'stilts', 'stoddard', 'stoning', 'stp', 'straddling', 'strikeout', 'styrofoam', 'subpoenaed', 'subprime', 'subtleties', 'succumbing', 'sulfuric', 'sunroof', 'suppresses', 'surabaya', 'surrealist', 'suspenseful', 'swartz', 't.i', 'tallinn', 'tanked', 'tattooing', 'tbi', 'tchaikovsky', 'tcm', 'teleportation', 'temperamental', 'teutonic', 'thakur', 'thiel', 'tock', 'tolerating', 'toning', 'traditionalist', 'trickier', 'tripartite', 'trujillo', 'tsai', 'twirling', 'udp', 'ultima', 'understudy', 'unguarded', 'unionized', 'unscientific', 'untamed', 'uo', 'upa', 'usn', 'utilisation', 'venn', 'vermilion', 'vesicles', 'vfx', 'victorians', 'visualizing', 'vivien', 'vor', 'vps', 'wafers', 'waver', 'weaning', 'webbing', 'wehrmacht', 'whoosh', 'winifred', 'winterfell', 'wmd', 'wooing', 'workloads', 'wracking', 'wring', 'xenophon', 'yar', 'ypres', 'zipped', 'zorro', 'è', 'özil', '▓', '😱', 'abduct', 'abolitionist', 'adama', 'adb', 'addie', 'aether', 'affluence', 'agave', \"airport's\", 'alexey', 'algebras', 'alhambra', 'amazons', 'amicus', 'amritsar', 'andaman', 'apothecary', 'applauds', 'apricots', \"art's\", 'asbury', 'ashleigh', 'attica', \"audience's\", 'authoring', 'ayer', 'backwoods', 'baddies', 'bagpipes', 'bainbridge', 'balsamic', 'bandcamp', 'barf', 'batten', 'beaks', 'beefy', 'benchmarking', 'benedictine', 'benitez', 'benning', 'berks', 'bernier', 'beseech', 'blackadder', 'blasters', 'bledsoe', 'boars', 'bodega', 'boing', 'bombard', 'bram', 'britannica', 'broads', 'brownlee', 'bru', 'buffon', \"butler's\", 'camcorder', 'canola', 'casillas', 'casters', 'castrated', 'cav', 'cava', 'cbp', 'cd4', \"centre's\", 'chapin', 'chipmunk', 'chronicling', 'chucking', 'chutney', 'claiborne', \"claire's\", 'cllr', 'cochin', 'coda', 'coders', 'coker', 'colluded', 'colonoscopy', 'commies', 'compaq', 'composting', 'conceiving', 'conciliation', 'concurred', 'conjugation', 'conklin', 'contreras', 'coombs', 'coos', 'corollary', 'couldn', 'counterbalance', 'courtiers', 'cringing', 'cui', 'culminate', 'customised', 'cuyahoga', 'cybercrime', 'cytochrome', 'czechoslovak', 'd.d', 'darien', 'defaced', 'deh', 'dendritic', 'deporting', 'desecration', 'destinies', 'devo', 'devos', 'didactic', 'diversifying', \"do's\", 'domestication', 'dominicans', 'dominick', 'donning', 'dorothea', 'drape', 'drax', 'drinkin', 'droplet', 'drunkard', 'dst', 'duds', 'dur', 'earp', 'electives', 'emphasising', 'enabler', 'endpoints', 'enforcers', 'engrossing', 'epistles', 'epithelium', 'ergonomics', \"eric's\", 'eugenie', 'eukaryotic', 'evaporates', 'evers', 'excitable', 'fanned', 'ferro', 'fes', 'fevers', 'flaring', 'flirtation', 'flor', 'fora', 'fords', 'foresters', 'formulaic', 'frisky', 'funnily', 'garrisons', 'genesee', 'gerrymandering', 'ghibli', \"giant's\", 'giulia', 'givers', 'glenda', 'glynn', 'gpl', 'gregorian', 'grisly', 'guesswork', 'gutting', 'gymnasts', 'haemorrhage', 'hairdressers', 'handpicked', 'handsets', 'harpercollins', 'hdl', \"head's\", 'hendry', 'herndon', 'hetero', 'hollows', 'homeostasis', 'homeschooling', 'huckleberry', 'hutt', 'iguana', 'impassable', 'impatiently', 'imprints', 'incinerator', 'inclinations', 'individualistic', 'init', 'innit', 'insolent', 'instituting', 'insulator', 'invert', 'invertebrate', 'ipv6', 'iridium', 'irrefutable', 'ivo', 'jacobi', 'jameis', 'jammer', 'jewry', 'jnr', 'jovial', \"jupiter's\", \"justin's\", 'kbs', 'kde', 'kenobi', 'keynesian', 'kidnappings', 'kippur', 'kitts', 'kohn', 'korn', 'kristy', 'l.p', 'laine', 'lasso', 'lattes', 'launder', \"laura's\", 'legislated', 'lemma', 'lexie', 'lian', 'lillie', 'loaders', 'lonsdale', 'lowkey', \"ma's\", 'mahi', \"maker's\", 'manatee', 'mansour', 'mcilroy', 'mdc', 'meehan', 'mesothelioma', 'mib', \"minnesota's\", 'mire', 'mlp', 'modulate', 'moisturizing', 'molybdenum', 'moncton', 'morecambe', 'motocross', 'motorcade', 'motorcyclist', 'moya', 'murakami', 'mussel', 'namaste', 'nanotubes', 'ncc', 'necessitates', 'neue', 'nihilism', 'nonchalant', 'noob', 'ntsb', 'nyx', 'obispo', 'oilfield', 'opportune', 'oppressor', 'orcas', 'orchestration', 'osi', 'oth', 'ouija', 'palmyra', 'panamanian', 'parapet', 'patterning', 'pejorative', 'penalize', 'penning', 'penrose', 'perseus', 'petitioning', 'pgs', 'pharaohs', 'phonograph', 'piggyback', 'pinochet', 'planetarium', 'poli', 'polis', 'porches', 'portico', 'postures', 'powerlifting', 'ppd', 'pravda', 'premarital', 'procreation', 'projective', 'proteus', 'pyramidal', 'qq', 'quarks', 'quashed', 'queried', 'quidditch', 'quivering', 'radeon', 'raff', 'rainforests', 'ramblings', 'ramparts', 'rasa', 'rascals', 'rebooted', 'receivership', 'redd', 'redstone', 'redux', \"reed's\", 'refills', 'replenished', 'replenishment', 'rhoda', 'riveted', 'rok', 'romantics', 'rosette', 'rouhani', 'rsi', 's.j', 'sacs', \"sainsbury's\", 'saluting', 'sanguine', 'sav', 'saxophonist', 'scone', 'scs', 'seeping', 'sein', 'seminoles', 'serendipity', 'shareholding', 'shatner', 'shem', 'shim', 'shona', 'sian', 'smallville', 'solano', 'sophomores', 'soya', 'splattered', 'spr', 'squander', 'ssp', 'stalkers', 'stans', 'steen', 'steeple', 'sth', 'stig', 'stillborn', 'sturgis', 'superintendents', 'suspenders', 'suu', 'swerved', 'syndicates', 'tajik', 'tamer', 'taunted', 'taverns', 'tba', 'teasers', \"ted's\", 'teenaged', 'thaddeus', 'thematically', 'timescale', 'toc', 'toke', 'toting', 'trademarked', 'trampling', 'tramways', 'transcended', 'twit', 'uaw', 'unconcerned', 'underbelly', 'underfunded', 'underperforming', 'undp', 'unlisted', 'unpredictability', 'uti', \"venezuela's\", 'ventricle', 'vichy', 'vieira', \"vietnam's\", 'vittorio', 'vulva', 'wahlberg', 'waistband', 'wap', 'warhammer', 'wayland', 'welker', 'whistled', 'wikimedia', 'winless', 'wipeout', 'wizardry', 'woollen', 'wooster', 'wyman', 'xrp', 'yamada', 'yuen', 'zanu', 'zonal', '2n', '7k', 'abatement', 'accentuated', 'acidification', 'acropolis', 'adaption', 'aer', 'agi', 'ahoy', 'aix', 'ako', 'allo', 'alston', 'alva', 'amiga', 'amplifying', 'anatoly', 'andrés', \"ann's\", 'anorexic', 'anthropomorphic', 'aprons', 'archiving', 'arif', 'armoury', 'aro', 'arraigned', 'artichoke', 'attendances', 'autonomic', 'avignon', 'awh', 'baboon', 'baca', 'backfield', 'bahadur', 'bakes', 'balled', 'bally', 'bandung', 'barnum', 'bba', 'bbc1', 'beaux', 'beeps', 'begotten', 'beleaguered', 'bennie', \"berlin's\", 'bicarbonate', 'bigg', 'biome', 'birthed', 'boarder', 'boardman', 'bollinger', 'boudoir', 'bough', 'bounding', 'bowery', 'browned', 'brunner', 'bse', 'capo', \"carl's\", 'casio', 'catalyzed', 'categorised', 'caterer', 'cay', 'celibate', 'chancel', 'chekhov', 'chiming', 'chivas', 'christendom', 'cmdr', 'cockburn', 'coltrane', 'commonality', 'congratulates', 'congratulation', 'congratulatory', 'conlon', 'conquers', 'contactless', 'continuance', 'cooney', 'cordless', 'costumed', 'countrywide', 'cre', 'creepers', 'crony', 'cru', 'cryptographic', 'csm', 'dabbled', 'daffodils', 'dalian', 'danbury', 'dartmoor', 'darwinism', 'deadwood', 'deceleration', 'defaulting', \"denmark's\", \"denny's\", 'detergents', 'deva', 'developmentally', 'dhl', 'dickheads', 'dicky', 'diffused', 'dint', 'dioceses', 'disagreeable', 'disapproving', 'disembodied', 'dishonored', 'dockyard', 'doctored', 'duffel', 'dumbo', 'e0000', 'ecole', 'efron', 'eindhoven', 'elektra', 'emaciated', 'emcee', 'endoscopy', 'envied', 'epps', 'ergonomic', 'especial', 'estradiol', 'exemplify', 'fanaticism', 'fattening', 'feller', 'fifi', 'fillets', 'fingernail', 'fireside', 'fis', 'fishman', 'fissures', 'fisted', 'flinging', 'floodplain', 'foodies', 'franchisees', 'freemasonry', 'fugue', 'funders', 'garber', 'gateshead', 'gelding', 'gerardo', \"gibson's\", 'gj', 'glandular', 'glaser', 'glean', 'gliders', 'glo', 'golding', 'gonzález', 'greenspan', 'growls', 'guerre', 'gutsy', 'hafiz', 'haim', 'handiwork', 'handjob', 'handlebars', 'hangouts', 'hastened', \"hawai'i\", 'hoff', 'holtz', 'homelands', 'homicidal', 'hovers', 'hurrying', 'hyacinth', 'hydroxy', 'ichi', 'ici', 'imitates', 'impersonator', 'ince', 'indi', 'inez', 'intergenerational', 'intricately', 'invigorating', 'inwardly', 'ise', 'italic', 'itll', 'jac', 'jarrod', 'javed', 'jenson', 'jfc', 'jie', 'jure', 'jürgen', \"kane's\", 'keira', 'khyber', 'kilkenny', \"killer's\", 'kimura', 'kochi', 'kroos', 'laban', 'laguardia', 'lallana', 'lanky', 'lar', 'lawrie', 'linebackers', 'loitering', 'lookalike', 'loveless', 'lurid', 'luzon', 'lviv', 'm.p', 'malays', 'marconi', 'marti', 'memoriam', 'merited', 'mesquite', 'metcalfe', 'microns', 'misnomer', 'mmorpg', 'mobilisation', 'mobsters', 'modulator', 'molest', 'monetization', 'morgantown', 'mountaintop', 'mournful', 'mrt', 'muh', 'mullah', 'mumbled', 'muscled', 'nagy', 'neeson', 'nettles', 'nicked', 'nodules', \"nurse's\", 'nuttall', 'nws', 'oba', 'obstinate', 'oddities', \"office's\", 'ontological', 'opined', 'optimisation', 'opts', 'oreos', 'orphanages', 'ospreys', 'outbuildings', 'overrule', 'ozark', 'pacify', 'pales', 'paraffin', 'pds', 'peculiarities', 'pere', 'periodontal', 'peruse', 'petulant', 'phenomenology', 'philology', \"photographer's\", 'pinus', 'piqued', 'pis', 'platitudes', 'pleated', 'pled', 'pnp', 'pointedly', 'pollinators', 'polygons', 'powerball', 'pretence', 'priyanka', 'progressions', 'psl', 'psychotherapist', 'pum', 'punctuality', 'purring', 'puttin', 'rashes', 'rath', 'reade', 'reals', 'rebuffed', 'recuperate', 'remi', 'renoir', 'retweet', 'revoking', 'rigidly', 'ripening', 'riskier', 'rivets', 'roblox', 'rollo', 'rots', 'ryanair', 'salina', 'salome', 'sandpaper', 'sandstorm', 'scepter', 'scorch', 'scribble', 'scurvy', 'searchlight', 'sentries', 'señor', 'sharpie', 'shayne', 'sheena', 'sheeting', 'shipwrecked', 'shudders', 'sickened', 'silverado', 'singaporeans', 'singly', 'sitters', 'skyrocketing', 'smc', 'softbank', 'sot', 'soweto', 'sported', 'spotlights', 'squealing', 'stallions', 'stannis', 'starcraft', 'stiletto', 'stipe', 'stockpiling', 'stooge', \"stranger's\", 'strep', 'stringing', 'subjugation', 'sunnis', \"superman's\", 'surrogacy', 'tamworth', 'tangential', 'teardrop', 'tera', 'theseus', 'thieving', 'toews', 'toga', 'toiletries', \"tommy's\", 'toolbar', \"tour's\", 'tpa', 'transference', 'transphobic', 'traverses', 'tribulation', 'trill', 'twisty', 'tye', 'unchanging', 'unfunded', 'universality', 'universidad', 'unmet', 'unsteady', 'untied', 'unturned', 'uplink', \"us's\", 'vaccinate', 'vax', 'veered', 'vestibule', 'vestry', 'vigo', 'vitaly', 'voluptuous', 'vx', 'w2', 'wagering', 'watchin', 'weasley', 'weevil', \"whatever's\", 'whirling', 'whitlock', 'windham', 'winehouse', 'wintry', 'worshipers', 'wycombe', 'xe', 'xing', 'yas', 'yow', 'zealots', 'zim', '🍆', '😜', '1v1', '6x', '7d', 'a.p', 'abubakar', 'acadia', 'acetyl', 'achievers', 'acrobat', 'actuators', 'afi', 'agora', \"airline's\", 'aldershot', 'algarve', 'allende', 'alumina', 'ambien', 'amicably', 'amiibo', 'amphibian', 'amputee', 'analogues', 'anchovies', 'anjali', \"annie's\", 'apu', 'ashtray', 'asics', 'askew', 'assoc', 'assyria', 'astana', 'athenians', 'attendee', 'authenticate', 'aviva', 'awoken', 'b0000', 'backline', 'backtrack', 'bada', 'baffle', 'baguio', 'balk', 'banquets', 'batavia', 'beckons', 'belles', 'bested', 'bicep', 'bioshock', 'bligh', 'bloating', 'bodybuilders', 'boulton', 'braintree', 'braised', 'breakups', 'brecht', 'brest', 'buckland', 'bulimia', \"bureau's\", 'burrowing', 'buyback', 'byes', 'c6', 'caltech', \"camp's\", 'campion', 'canter', 'cantilever', 'caressing', 'carpal', 'cdl', 'cem', 'cements', 'cfm', 'chalked', \"chan's\", 'cheetos', 'cine', \"cleveland's\", 'cloaks', 'cnt', 'coastguard', 'coasting', 'cobble', 'coc', 'colonisation', \"commander's\", 'conduits', 'conferencing', 'contaminating', 'convulsions', 'coopers', 'copernicus', 'cornbread', 'corso', 'corwin', 'costas', 'cqc', 'creamed', 'creeped', 'cronulla', 'crowbar', 'crowell', 'crudely', 'cuisines', 'cytoplasmic', 'd5', 'dca', 'deakin', 'dedicates', 'deleterious', 'delft', 'delineated', 'demeanour', 'depressants', 'desiree', 'detritus', 'dillard', 'dimple', 'disengagement', 'dishing', 'disintegrating', 'disown', 'disproved', 'distilleries', 'distilling', 'distorts', 'divinely', 'dorky', 'dormer', 'downplayed', 'driftwood', 'drivel', 'durga', 'dyslexic', 'dystopia', 'eateries', 'eda', 'effeminate', 'eldon', 'electrolysis', 'elses', 'embarks', 'emotionless', 'emphysema', 'endometriosis', 'entitles', 'eritrean', 'etta', 'euthanized', 'excision', 'exogenous', 'expandable', 'extractor', 'faerie', 'faulted', 'fel', 'fernández', 'ferrets', 'fet', 'fillies', 'fleshed', 'footballs', 'foresaw', 'foreskin', 'friendlier', 'futurist', 'fy0000', 'gabbana', 'gaffney', \"gaga's\", \"gang's\", 'ganja', 'genial', 'geophysics', 'gerd', 'gibb', 'givenchy', 'goalless', 'gogo', \"gold's\", 'gooch', 'gra', 'grafted', 'gti', 'gulliver', 'gunnery', 'gurion', 'hairdo', 'haitians', 'hala', 'hallucinating', 'hardie', 'harrell', 'headlong', \"helen's\", 'herrick', 'hesitating', 'heuristic', 'hick', 'hombre', 'homology', 'hopefuls', 'hopi', \"host's\", 'howes', 'humerus', 'hunky', \"hunt's\", 'hypertrophy', 'iceman', 'incestuous', 'iniquity', 'initiator', 'inman', 'innovating', 'interviewees', 'ironclad', 'jabbar', 'jacobsen', 'jalen', 'johnathan', 'joiner', \"jonathan's\", 'jordy', 'joão', 'kavanagh', 'kaz', 'kearns', 'keepin', 'kiddies', 'kilimanjaro', 'kirchner', 'kon', 'kristi', 'kwame', 'lactate', 'landers', 'lansdowne', 'lapped', 'lather', 'leaching', 'ledges', 'leed', 'linde', 'loathed', 'lovelace', 'luge', 'lumberjack', 'lunchbox', 'lye', 'madsen', 'mahmood', 'mahmud', 'manmade', 'marauders', 'mccaffrey', 'mci', 'meld', 'mended', 'mendelssohn', 'mettle', 'militancy', 'molars', 'monochromatic', 'motherly', 'moulin', 'munchies', 'muni', 'munson', 'nannies', 'narayan', 'navarre', 'nestlé', 'nhk', 'nhtsa', 'nightstand', 'noh', 'northernmost', 'notifies', 'npp', 'ntsc', 'nunavut', 'officiated', 'okey', 'optically', 'orgs', 'ouster', 'outdo', 'outlive', 'oxymoron', 'palmetto', 'pastels', 'patronize', 'paulina', 'pfa', 'phelan', 'phonological', 'pinkerton', 'pinkish', 'pissy', \"play's\", 'plundering', 'poa', 'polymorphism', 'pontoon', 'postoperative', 'powershell', 'prescribes', 'pretrial', 'primus', \"prisoner's\", 'probationary', 'professorship', 'promontory', 'proportioned', 'prozac', 'psychics', 'pushkin', 'pygmy', 'pym', 'quakes', 'quarrying', 'quin', \"r's\", 'r.r', 'rada', 'raines', 'ramones', 'raytheon', 'rearrangement', 'rearview', 'refocus', 'regains', \"regime's\", 'registries', 'relevancy', 'renegotiate', 'rensselaer', 'resurfacing', 'rik', 'riven', 'roan', 'rodrigues', 'rumi', 'rusting', 'rustle', 'sabina', 'saluted', 'sanborn', 'sarcoma', 'schooler', 'schweitzer', 'secretarial', 'secrete', 'senegalese', 'sik', 'skids', 'slytherin', 'smb', 'snarling', 'snatches', 'spillway', 'spiro', 'splintered', 'sriracha', 'stadia', 'standardize', 'stanzas', 'stetson', 'stigmatized', 'stormwater', 'strapless', 'stupor', 'subcontractor', 'summerslam', 'susanne', 'svp', 'swifts', 'swinton', 'sx', 'systolic', 'takeda', 'tanking', 'tanzanian', 'tarantula', 'tern', 'tetra', 'thinned', 'thot', 'tightrope', 'tink', 'toasty', \"tournament's\", 'towne', 'trailblazer', 'trainings', 'translocation', 'treasuries', 'trepidation', 'trumbull', 'turkmen', 'tutored', \"two's\", 'typified', 'unanticipated', 'unblock', 'unionism', 'unsavory', 'unselfish', 'unsound', 'unverified', 'unwashed', 'urination', 'utterance', 'valedictorian', 'verso', 'vibrational', 'vicariously', 'vila', 'vl', 'vms', 'voided', 'volumetric', 'vom', 'vroom', 'wagers', 'walther', 'wapo', 'waterbury', 'wav', 'wean', 'weezer', 'welling', 'wexford', 'whisked', 'wilfrid', 'wimp', 'wir', 'workhorse', 'wristbands', 'yachting', 'yeovil', 'yeung', 'zeroes', 'zooms', 'aaah', 'aang', 'abrahams', 'absorber', 'accenture', 'adjourn', 'airliners', 'aku', 'alabaster', 'allegro', 'allergens', 'allianz', 'anaesthesia', 'andros', 'approximations', 'aquifers', 'arching', 'arf', 'arrhythmia', 'arsed', 'backlinks', 'baddest', 'bahraini', 'bandaged', 'barak', 'barium', 'bauxite', 'befall', 'behead', 'bellied', 'beretta', 'bergeron', 'bestsellers', \"beyonce's\", 'biofuel', 'biometrics', 'bladed', 'blenheim', 'blindsided', 'bloodlines', 'blowback', \"boat's\", 'boathouse', 'bogut', 'bonfires', 'brickwork', 'britten', 'brooms', 'buchan', 'burnaby', 'calumet', 'cana', 'cardamom', 'cargill', 'carrion', 'casks', \"catherine's\", 'cellist', 'cham', 'chard', 'charmer', 'chewbacca', 'choctaw', 'chrissie', \"churchill's\", 'cif', 'clickbait', 'closings', 'cmt', 'cobwebs', 'cogent', 'collaborates', 'collages', 'colonels', 'comprehensible', 'compressing', 'condense', 'condescension', 'corkscrew', 'corporates', 'counsels', 'cour', 'creamer', 'creases', 'cribs', 'croissants', 'cse', 'curveball', 'custodians', 'cyan', 'd6', 'danica', \"dante's\", 'dbz', 'delves', 'derozan', 'deserter', 'dewar', 'dhawan', 'dictation', 'diction', 'dink', 'disbursement', 'disguising', 'dishonour', 'dissociative', 'diverging', 'dodds', 'dodson', \"don's\", 'dorn', 'dua', 'dunstan', 'durations', 'earpiece', 'edf', 'edwina', 'eee', 'elegy', 'elia', 'emf', 'encircling', 'ene', 'entitle', 'entomologist', 'ephesus', 'epidermis', 'epinephrine', 'erections', 'escalators', 'español', 'ethiopians', 'evacuees', 'evens', 'evs', 'faeces', 'faltering', 'femmes', 'fictions', 'finalizing', \"fisher's\", 'fiver', 'flabby', 'floodgates', 'floorboards', 'fluctuated', 'fluctuates', 'folic', 'fornication', 'fortuna', 'frailty', 'freiburg', 'fricking', 'frieda', 'friendliest', 'frowning', 'ful', 'futsal', 'gaggle', 'gauging', 'gazebo', 'geary', 'gees', 'germaine', 'girder', 'gmail.com', 'gol', 'golly', 'gonorrhea', 'gopal', 'gots', 'gouge', 'goulburn', 'greenock', 'gregarious', 'grenville', 'gretel', 'grosse', 'grunting', 'haden', 'halibut', 'halley', 'halloran', 'hama', 'hanford', \"hawaii's\", 'hein', 'hemispheres', 'herder', 'herefordshire', 'hillsboro', 'himachal', 'himalaya', 'histone', 'hmong', 'hocking', 'holi', 'holiest', 'holograms', 'holotype', 'hospitalised', \"hudson's\", 'hydrant', 'icao', 'ignites', \"ii's\", 'immortalized', 'immunodeficiency', 'incidences', 'inconveniences', 'incrementally', 'incubators', 'indiegogo', 'inefficiencies', 'infusions', 'injunctions', 'inlaid', \"institution's\", 'invents', 'jaundice', 'jayson', \"jeff's\", 'jeon', 'jewelers', 'jihadis', \"journal's\", 'joyfully', 'judeo', 'kap', 'kasper', 'kibbutz', 'kiefer', 'kilns', 'klm', 'knightley', 'kowalski', 'kya', 'larynx', 'lassie', 'laurens', 'lavigne', \"lawrence's\", \"lewis's\", 'lewiston', 'lifter', 'lightbulb', 'lithography', 'loathsome', 'lode', 'loggers', 'loins', \"madonna's\", 'magnitudes', 'maharaja', \"management's\", 'manipulates', 'martell', 'marwan', \"maryland's\", 'masterson', 'matriarch', 'mauve', 'mccaskill', 'mcclelland', 'mcdavid', 'mcewen', 'meir', 'mellor', 'mera', \"messi's\", 'microfilm', 'mitts', 'modems', 'modicum', \"monster's\", 'montagu', 'montclair', 'montréal', 'moreton', 'motorbikes', 'mouthwash', 'mowbray', 'mrc', 'mrsa', 'mss', 'mujahideen', 'multipliers', 'murat', \"nathan's\", 'nationalization', 'nauseating', 'neff', 'negan', 'nettle', 'newry', 'newtonian', 'normans', 'oakes', 'oldman', 'oli', 'olin', 'omits', 'omniscient', 'ona', 'opengl', 'oreal', 'oren', 'origination', 'ossetia', 'overdosed', 'overpopulation', 'overran', 'overshadow', \"p's\", 'pacer', 'pancras', 'paroled', 'partaking', 'parvati', 'patriarchs', 'paulsen', 'pavilions', 'pcm', 'peacocks', 'pedicure', 'pheromone', 'philistines', 'phish', 'placard', 'plutarch', 'polyps', 'postgame', 'postmodernism', 'pothole', 'potting', 'preconceptions', 'presides', 'primeval', 'procrastinate', 'promiscuity', 'provisioning', 'puddings', 'purplish', \"ra's\", 'rabbinic', 'rabin', 'rakes', 'ranching', 'raqqa', 'rationalization', 'ravel', 'reachable', 'reaffirms', 'reappears', 'reardon', 'rebelling', 'recede', 'reciprocating', 'reductase', 'reestablish', 'reintroduce', 'reintroduction', 'rekindle', 'relapsed', 'relented', 'reposition', 'reproduces', 'reverts', 'revulsion', 'rhs', 'richelieu', \"rico's\", 'rinsing', 'rly', \"rock'n'roll\", 'rosenstein', 'roxbury', 'rtl', 'rubicon', 'safeties', 'samaritans', 'sanctified', 'sandalwood', 'sandberg', 'sanding', 'savant', 'scape', 'schoolgirls', 'sco', 'scrawny', 'seabirds', 'sear', 'sequins', 'seri', 'shabab', 'shackled', 'shoreditch', 'slop', 'smothering', 'smp', 'solvency', 'sommer', \"sophie's\", 'spyware', 'stade', 'stamens', 'stepmom', 'stevenage', 'stewie', 'stockbridge', 'stocky', 'stoll', 'straus', 'strutting', 'subsidence', 'subtracted', 'sullen', 'sump', 'superconducting', 'supervises', 'swirls', 'symbiosis', 'sympathise', 'synchronize', 'taffy', 'tantalizing', 'taos', 'tarek', 'targaryen', 'taster', 'teacup', \"tech's\", 'technicalities', 'tectonics', 'teo', 'tepid', 'terrifies', 'testes', 'thatch', 'thawed', \"theatre's\", 'thicken', 'thornhill', 'throated', 'thumbnails', 'ticketmaster', 'tko', 'tmc', 'tmi', 'toa', 'tol', 'towson', 'tripe', 'trippin', 'tristram', 'trotted', 'troughs', 'tweeter', 'twinning', 'typewriters', 'unabated', 'unafraid', 'unambiguously', 'underpinnings', 'unearned', 'unenforceable', 'uninhabitable', 'unread', 'unsaturated', 'unsurpassed', 'urns', 'vadim', 'validates', 'valparaiso', \"vancouver's\", 'vats', 'vaulting', 'vcs', 'venerated', 'vere', 'waisted', 'waiving', 'waldron', 'wandsworth', 'waring', 'waxy', 'wests', 'whimper', 'whoopi', 'wiles', 'windermere', 'winkle', 'wistful', 'wizarding', 'wolfram', 'workaround', 'wpa', 'yeezus', 'yeezy', 'yeoman', \"you's\", 'yuk', 'yule', '1x00', '4chan', '5p', '8mm', '9a', '9m', 'abounds', 'accumulator', 'aerosols', 'airfields', 'airpods', 'ajit', \"alaska's\", 'allman', 'allude', 'amina', 'anas', 'anda', 'androgynous', 'animus', 'anion', 'antipathy', 'anubis', 'apd', 'archdeacon', 'arginine', 'armadillo', 'armband', 'arp', 'artefact', 'aslan', 'augustin', 'awning', 'awol', 'bacillus', 'balmy', 'bandmates', 'barbeque', 'bards', 'bayside', 'bento', 'berber', 'bicycling', 'binomial', 'blackie', 'blinders', 'bloodhound', 'booger', 'bowes', 'brandishing', 'bratislava', 'bridger', 'bromide', 'brookline', 'cabana', 'cadaver', 'caked', 'carnation', \"carson's\", 'censuses', 'centauri', 'chand', 'chesterton', 'chickpeas', 'chipset', 'chitty', 'choppers', \"christian's\", 'chromebook', 'chronicler', 'chub', 'chuffed', 'chutes', 'citric', 'clawing', 'cls', 'cobblestone', 'communique', 'compacted', 'complementing', 'condiment', 'confederations', 'conservationist', 'corroboration', 'cortana', 'cots', 'cowen', 'crim', 'cristian', 'croquet', 'crosshairs', \"cruz's\", 'crystallized', 'cska', 'cuddled', 'cuppa', 'curzon', 'césar', 'd0', 'dancefloor', 'dancin', 'degenerated', 'degrades', 'delectable', 'demotion', 'denizens', 'derailment', 'descriptors', 'dif', 'discoverer', 'dislodged', 'dmca', 'doubters', 'dragoons', 'dreadfully', 'dredged', 'duarte', 'durst', 'duvall', 'echelons', 'eec', 'elation', 'elly', 'elucidate', 'emitters', 'engraver', 'enlarging', 'envisage', 'eon', 'etcetera', 'evictions', 'excavator', 'exclusionary', 'excommunication', 'fads', 'fafsa', 'fairing', 'farnborough', 'fatwa', 'fawkes', \"fisherman's\", 'flamingos', 'flippers', 'flog', 'flogged', 'fluorine', 'flushes', \"flynn's\", 'forehand', 'fortescue', \"founder's\", 'foursquare', 'fuego', 'gcses', 'gillard', 'giroux', 'givens', 'gleeson', 'glencoe', 'glimpsed', 'glyph', 'gob', 'gohan', 'gollum', 'gordy', 'gotti', 'grammatically', 'gramophone', 'gratefully', 'grindr', 'gtr', 'gumbo', 'gwynedd', 'hadrian', 'halliwell', 'hansel', 'hardman', 'harrier', 'harshest', 'hartlepool', 'haymarket', 'heeded', 'helmand', 'herrmann', 'heyward', 'hibernate', 'hipaa', 'holborn', 'hollering', 'hollingsworth', 'hollyoaks', 'homeownership', 'homeward', 'hotdogs', 'hounded', 'iac', 'ibd', 'icann', 'igg', 'imitations', 'immanuel', 'impediments', 'implode', 'inane', 'industrialisation', 'ineptitude', 'inshore', 'instigating', 'instituto', 'intelligentsia', 'intensities', 'interagency', 'interconnect', 'interrelated', 'interviewee', 'irritant', 'ite', 'itis', 'j.a', 'jacqui', 'jak', 'jalan', 'jardine', 'jelena', 'jetpack', 'joao', 'jquery', 'juicing', 'jurist', 'kelowna', 'kenton', 'khamenei', 'kickbacks', 'kickin', 'kik', 'kisser', 'kwang', \"kyle's\", 'kyushu', 'labia', 'lakeshore', 'lakota', \"land's\", 'lawnmower', 'lazer', 'leaved', 'leeks', 'leibniz', 'leninist', 'lennie', 'leonidas', 'lik', 'litecoin', 'livia', 'longfellow', 'lop', 'lupita', \"lynch's\", 'lysine', 'm.c', 'm9', 'machiavelli', 'maier', 'majorly', 'malian', 'manicured', 'manolo', 'marais', 'marbella', 'mariam', 'marquise', 'mastectomy', 'maybelline', 'mcrae', 'mears', 'medellin', 'meiji', 'meteoric', 'midair', 'militaries', 'militiamen', 'milli', 'miscommunication', 'mohr', 'molester', 'monomer', 'moreland', 'moynihan', 'muff', 'muffler', 'multitudes', 'narrowest', 'necessitating', 'neckline', 'neuroscientist', 'neutralizing', 'ney', 'niels', 'nightmarish', 'nitty', 'noc', 'noire', 'northfield', 'northwards', 'nudged', 'obliquely', 'operationally', 'ophthalmologist', 'outermost', 'overheat', 'overlords', 'overthink', 'overzealous', 'ovid', 'pala', 'palgrave', 'paola', 'paperbacks', 'passcode', 'pbr', 'peasantry', 'persisting', 'photocopy', \"pig's\", 'pitman', 'plying', 'pmo', \"police's\", \"pop's\", 'porosity', 'pouting', \"powell's\", 'prefixes', 'prejudicial', 'preliminaries', 'preponderance', 'presbyterians', 'preyed', 'probiotics', 'procrastinating', \"property's\", 'prot', 'protege', 'pulsar', 'putrid', 'pylons', \"quinn's\", 'racquet', 'ramped', 'ransomware', 'rapped', 'rawalpindi', 'rayner', 'rda', 'reactivated', 'recessions', 'redfern', 'regalia', 'remaster', 'repainted', 'reposting', 'reproducible', 'retrial', 'ricciardo', 'rippling', 'ris', 'ritualistic', 'rko', 'roethlisberger', 'rogen', 'rolfe', 'rollback', 'rorschach', 'rosenfeld', 'rota', 'royally', 'rube', \"rubik's\", 'rucker', 'rusk', 'saggy', 'salvadoran', 'sanitizer', 'scanlon', 'schematics', 'schreiber', 'scoliosis', 'seiko', 'separatism', 'septa', 'serfs', 'shacks', 'shari', 'shibuya', 'shockwave', 'showrooms', 'shuttered', 'silurian', 'singling', 'sinning', 'skeet', 'skrillex', 'slouch', 'snapdragon', 'sneer', 'sola', 'somaliland', 'somalis', 'sorcerers', 'sorensen', 'sorrowful', 'spewed', 'splat', 'spokesmen', 'stabilise', 'stopover', 'suga', 'technicolor', 'thwarting', 'tidbits', 'tightens', 'tintin', 'tous', 'touts', 'tracksuit', 'transduction', 'triads', 'trinket', 'triplet', 'trolleys', 'troublemaker', 'truely', 'trumpeter', 'trusses', 'tshirt', 'tufted', 'tumult', 'typhoons', 'umi', 'uninitiated', 'uninspired', 'unrestrained', 'unsanitary', 'untoward', 'uppermost', 'ushers', 'usman', 'usurp', \"utah's\", 'utero', 'utes', 'uu', 'vag', 'valeria', 'valverde', 'vasectomy', 'vd', 'verdant', 'vicarage', 'videotaped', 'vilified', 'w.h', 'w1', 'waistline', 'weatherman', 'wf', 'whopper', 'wiretapping', 'womans', 'woolen', 'worldnews', 'wringing', 'wristwatch', 'www.facebook.com', 'xeon', 'yangtze', 'yerevan', 'yonge', 'youssef', \"youtube's\", '☺️', '💀', '💖', '4u', '8x', 'aberrant', 'absinthe', 'absolved', 'abstaining', 'acetaminophen', 'adamantly', 'adder', 'administratively', 'advisories', 'adwords', 'affinities', 'agamemnon', 'ageless', 'agitators', 'agonists', 'ahab', 'airframe', 'akp', 'alegre', 'alessandra', 'algal', 'alisa', 'allay', 'anachronistic', 'anarcho', 'anatomically', 'ancelotti', 'andorra', 'annoyingly', 'answerable', \"april's\", 'apropos', 'archimedes', 'arran', 'asad', 'assembler', 'asymptotic', 'aviators', 'axelrod', 'ayesha', 'azul', 'bachchan', 'backfires', 'bailiffs', 'ballgame', \"barcelona's\", 'barricaded', 'barça', 'batmobile', 'bday', 'bedlam', 'beeping', 'beluga', \"bernie's\", 'beveridge', 'bhatt', 'bibliographic', 'biel', 'biopsies', 'blackest', 'blakely', 'bloodless', 'boateng', 'bookshelves', 'boreal', 'brackish', 'bream', 'brough', 'buckling', 'buries', 'burlap', 'byproducts', 'cackling', 'cadiz', 'caicos', 'calabria', 'capitalise', 'capstone', 'carpeting', 'carvalho', 'cassel', 'catalysis', 'cdm', 'cen', 'centralization', 'changeover', 'chins', 'chiseled', 'chromecast', 'chrono', 'cistern', 'citigroup', 'classifieds', 'cleverness', 'coagulation', 'coder', 'coldly', 'colloquially', 'congruent', 'contributory', 'convective', 'counterintuitive', 'coursing', 'crowdsourcing', 'crucify', 'cryptocurrencies', 'csiro', 'cuticle', 'cyberbullying', 'dalrymple', 'darwinian', 'dateline', 'dauntless', 'davids', 'degas', 'denning', \"denver's\", 'depleting', 'despatch', 'devotions', 'dialectic', \"diego's\", 'dietitian', 'differentials', 'dijk', 'dinka', 'dismissals', 'disobeyed', 'disobeying', 'disorientation', 'dispositions', 'diurnal', 'divisible', 'domineering', 'dominos', 'downes', 'dredd', 'dunking', 'dura', 'dwarfed', 'dwyane', 'e.r', 'electrics', 'emancipated', 'embellishment', 'emblazoned', 'encodes', 'environmentalism', 'equalization', 'erupting', 'etchings', 'ethno', 'eto', 'eugenia', 'exclaiming', 'exposé', 'fabulously', 'faithless', 'falsetto', 'feliz', 'festering', 'fibonacci', \"finland's\", 'firecracker', 'firecrackers', 'flabbergasted', 'flanker', 'flathead', 'forges', 'fortran', 'frontrunner', 'frowns', 'frs', 'frustrates', 'fuchsia', 'fukuoka', 'g6', 'gant', \"gary's\", 'geraldo', 'geschichte', \"ghana's\", 'ghazi', 'giancarlo', 'gillies', 'glittery', 'globular', 'glutathione', 'glyphosate', 'goddam', 'gow', 'grandmas', \"grandpa's\", 'gro', 'groaned', \"groom's\", 'guildhall', 'haldane', 'hanuman', \"harvard's\", 'haulage', 'headland', 'headstrong', 'hedgehogs', 'hefner', 'heinemann', 'herbivores', 'hildebrand', 'hn', 'holcomb', 'hollander', 'holley', 'hooligan', 'horizonte', 'howland', 'huffman', 'humongous', 'hunchback', 'hydrothermal', 'hydroxyl', 'hyperspace', 'hypo', 'ibid', 'ife', 'igf', 'impurity', 'inactivated', 'inalienable', 'incisions', 'incongruous', 'indio', 'indonesians', 'infographics', 'informations', 'inge', 'innkeeper', 'insufficiency', 'interdependence', 'interleukin', 'intifada', 'intracranial', 'intruding', 'irreducible', 'iwo', 'jiangsu', 'jiggle', 'jingles', 'jumbled', 'keeler', 'keita', 'kell', 'kellie', 'ketones', 'kitsch', 'klamath', 'kleenex', 'knick', 'kubo', 'labours', 'lakeview', 'lazily', 'leadoff', 'lebowski', 'leger', 'leprechaun', 'lethargy', 'lettered', 'lic', 'liddell', 'lifeblood', 'lilo', 'lindley', 'linguistically', 'litt', 'littoral', 'lowes', 'lua', 'lumbering', 'm.sc', 'macular', 'madhouse', 'madigan', 'maelstrom', 'mahan', 'makati', 'maligned', 'marchers', 'marianna', 'mariota', 'marylebone', 'mazes', 'mcavoy', 'meander', 'menon', 'mercier', 'meshes', 'mhc', 'microscopes', 'mideast', 'midseason', 'miku', 'milkshakes', 'mimosa', 'minty', 'misbehaving', 'misusing', 'moldy', 'moll', 'molloy', \"mommy's\", 'monahan', 'monorail', 'moraine', 'morehouse', 'morpheus', 'morphing', 'mothership', 'munchkin', 'museo', 'musharraf', 'nach', 'nanking', 'nationalised', 'navas', 'nicklaus', 'noida', 'nonviolence', 'noo', 'npd', 'nueva', 'nwo', 'oboe', 'ochre', 'ogle', 'oligarch', 'onesie', 'oot', 'oppo', 'opulence', 'orang', 'oshkosh', 'overeating', 'overheads', 'overlays', 'overreacted', 'oxidase', 'paget', 'paleozoic', 'pali', 'palpitations', 'pancho', 'pancreatitis', 'pandemonium', 'parlors', 'patronising', 'pattaya', 'payoffs', 'peacemaker', 'penske', 'permeates', 'perpetuates', 'personable', 'personalize', 'perturbed', 'phenotypes', 'philanthropists', 'phoenician', 'phoney', 'pickens', 'platypus', 'ple', 'plows', 'polanski', 'pollutant', 'polypropylene', 'prankster', 'prentiss', 'priestley', 'profitably', 'proliferate', 'propagandist', 'publically', 'publix', 'punting', 'pyre', 'quibble', 'quinton', 'raison', 'ralf', 'ramón', 'rasheed', 'ravishing', 'readout', 'reapply', 'recidivism', 'recollect', \"reid's\", 'reis', 'reiterates', 'relievers', 'reo', 'repeatable', 'replicates', \"report's\", 'requisition', 'resettled', 'resistances', 'resp', 'restarts', 'retrace', 'reusing', 'rfa', 'ridin', 'rivet', 'roa', 'roadhouse', \"roger's\", \"romney's\", 'romulus', 'roughing', 'rrp', 'ruffles', 'ruinous', 'sadat', 'saintly', 'saks', 'scalability', 'schindler', 'scuttle', \"secretary's\", 'seein', 'seeley', 'selkirk', 'seltzer', \"senate's\", 'shakur', 'sharjah', 'sherwin', 'skippy', 'skyward', 'slings', 'sobre', 'solihull', 'solomons', 'speedo', 'spinster', 'spliced', 'sprinted', 'spud', 'squalor', 'stabilisation', 'startle', 'staunchly', 'steadfastly', 'straying', 'streaking', 'stubby', 'subjugated', 'subplot', 'subsidizing', 'subterfuge', \"sullivan's\", 'sunnyvale', 'supercharger', 'superfast', 'supersport', 'surfactants', 'surreptitiously', 'symonds', 'tablecloth', 'tacitly', 'tailing', 'tailings', 'tami', 'tapper', 'tardy', 'tassel', 'thicket', 'threefold', 'thruster', 'ths', 'tidying', 'tinned', 'toasting', 'torchwood', 'torrens', 'townhouses', 'transcribe', 'trapeze', 'triangulation', 'trifling', 'tsm', 'twirl', 'unconsciousness', 'unconvincing', 'uncooked', 'undaunted', 'underlining', 'underpinned', 'undeserved', 'unearth', 'unsaid', 'unsurprising', 'uppers', 'urquhart', 'uta', 'uttering', 'vardy', 'velvety', 'vim', 'wagga', 'walid', 'wallabies', \"wallace's\", 'waukesha', 'webcomic', 'wheelie', 'wildflower', 'winemaker', 'wiretap', 'wirral', 'woeful', 'wolfson', 'wouldve', 'wsu', 'wvu', 'xhosa', 'xps', 'yada', 'yardstick', 'zh', 'zhen', '💩', '1g', 'a.g', 'abate', 'abra', 'accesses', 'adenosine', 'adios', 'adjuster', 'adsense', 'affaires', 'aftertaste', 'airtel', 'ald', 'alleviated', 'amadeus', 'ambiance', 'analgesic', 'angkor', 'anh', 'antonin', 'apec', 'approximated', 'arlo', \"armstrong's\", \"arnold's\", 'ascends', 'aspirants', 'assisi', 'atwater', 'authentically', 'automaton', 'avalanches', 'axl', 'baboons', 'backflip', 'bade', 'baluchistan', 'baptize', 'batgirl', 'bathrobe', 'bef', 'beresford', 'berliner', 'biathlon', 'bir', 'blocs', 'bmp', 'bodyweight', 'bolo', 'bookie', 'bookmakers', 'bothersome', 'bou', 'bowe', 'brained', 'brantley', 'bsd', 'bundling', 'burleigh', 'busby', 'caching', 'calamities', 'campgrounds', 'canfield', 'cantina', 'carnivore', 'casement', 'catalans', 'cataloging', 'catnip', 'causative', 'cda', 'cdp', 'cesspool', 'chalky', 'chipmunks', 'churned', 'clio', 'collaboratively', 'commissar', 'conformed', 'congestive', 'consulates', 'corfu', 'corrupts', 'cupola', 'dabble', 'daesh', 'darting', 'dass', 'debunk', 'decays', 'decking', 'decrypt', 'deerfield', 'defectors', 'degenerates', 'depositions', 'despondent', 'despot', 'detachments', 'dialectical', 'digestible', 'disassembled', 'disembark', 'disgusts', 'dishonorable', 'disraeli', 'dogging', 'dopey', 'dubrovnik', 'ducky', \"duncan's\", 'dutt', 'easel', 'eastwards', 'ecs', 'edmondson', 'eek', 'eldorado', 'eliminations', 'ellipse', 'elysium', 'encoder', 'enormity', 'eons', 'espouse', 'exemplar', 'extender', 'extramarital', 'fandango', 'farber', 'farc', 'farina', 'fearlessly', 'fete', 'feynman', 'fiorentina', 'firewalls', 'fmri', 'foi', 'foie', 'foles', 'formalism', 'fortuitous', 'framingham', 'franchisee', 'franky', 'fredrik', 'freestanding', 'frenetic', 'fridges', 'frolic', 'funneled', 'fussing', 'gaff', 'galleys', 'ganesha', 'gangrene', 'gatekeepers', 'gilgamesh', 'gillingham', 'gini', 'glides', 'glosses', 'gluttony', 'goalkeeping', 'goaltending', 'goatee', 'gordo', 'gottfried', 'graceland', 'granddad', 'greyhounds', 'grieved', 'grist', 'grope', 'gto', 'guardsmen', 'gutenberg', 'gx', 'hadron', 'hammerhead', 'hampers', 'hangman', 'harvick', 'haughty', 'headmistress', 'headteacher', 'heavyweights', 'hela', 'hervey', 'hobbits', 'hogging', 'hoisting', 'horseradish', 'hotshot', 'householders', 'hus', 'hyland', 'hypoglycemia', 'hypothyroidism', 'ihs', 'immeasurably', 'imprecise', 'indigent', 'ingham', 'ings', 'inlay', 'intramural', 'invulnerable', 'irreconcilable', 'j.s', 'j.w', 'janitors', 'jawbone', 'jittery', 'joyner', 'judicious', 'kaka', 'kegs', 'kerri', 'kesha', 'khanna', 'kickass', 'kickback', 'kinsman', 'kirin', 'kowloon', 'krauss', 'kristine', 'kuroda', 'kyi', \"labor's\", 'laboured', \"lanka's\", 'laudable', 'lbc', 'ldp', 'lessens', 'lessing', 'león', 'liberalisation', 'liftoff', 'lightfoot', 'linnaeus', 'liszt', 'logarithmic', 'loudness', 'lowery', 'ltte', 'lucasfilm', 'luxor', 'macroeconomics', 'majlis', 'majorca', 'manchin', 'mandi', 'mannheim', 'manors', 'mantras', 'marist', 'marysville', 'mathers', 'mchale', 'mclachlan', 'mec', 'megawatt', 'meri', 'mesozoic', 'metroid', 'midlothian', 'militarized', 'misinterpretation', 'mobbed', 'mobilised', 'moneys', 'moorland', 'morristown', \"mourinho's\", 'naively', 'nappies', 'narcissus', 'nau', \"neighbour's\", 'neurodegenerative', 'neva', 'nightwing', 'nitrates', 'nlrb', 'northumbria', 'nouvelle', 'npa', 'npcs', 'obv', 'occipital', 'ophthalmic', 'ordinating', 'ostentatious', 'osteopathic', 'osx', 'oversize', 'padlock', 'palau', 'paltrow', 'panini', 'paras', 'pasco', 'patina', 'pauly', 'pcos', 'perf', 'permeated', 'perspiration', 'phenotypic', 'philippians', 'pina', 'pirelli', 'plagiarized', 'plasmid', 'playthrough', 'pleaser', 'pliocene', 'plummeting', 'poach', 'polices', 'policyholders', 'pontifical', 'postcolonial', 'precluded', 'prez', \"price's\", 'prosecco', 'prostrate', 'pubes', 'publicised', 'pushover', 'pythagoras', 'quicksand', 'quilting', 'r0000', 'raincoat', 'raine', 'randal', 'rasputin', 'ratcliffe', 'reconnected', 'reconsidering', 'redeveloped', 'refreshingly', 'refrigerate', 'refutes', 'reichstag', 'reiss', 'relativism', 'renata', 'renato', 'renditions', 'repelling', 'representational', 'republicanism', 'restaurateur', 'ribeiro', 'rickety', 'ricotta', 'riddick', 'ridership', 'rina', 'rox', 'rps', 'rsl', 'ruger', 'sacra', 'saddens', 'salinger', 'sappy', 'sark', 'sasquatch', \"saturn's\", 'saucers', 'saviors', 'scofield', 'semite', 'separations', 'sepulchre', 'sfo', 'shallots', 'shifters', 'shill', 'shins', 'shorted', 'sich', \"singh's\", 'sipped', 'siting', 'sixpence', 'sjw', 'skank', 'skateboards', 'skinhead', 'slats', 'sligo', 'sneezed', 'snorkel', 'solenoid', 'songbird', 'sorties', 'spaulding', 'speer', 'spinoza', 'splendidly', 'sprawled', 'spyder', 'squaw', 'stabilised', 'starz', 'staunton', 'stiller', 'storehouse', 'stormont', 'straighter', 'striptease', 'suki', 'sumerian', 'supersede', 'sustainably', 'svt', 'swimsuits', 'swooped', 'synergistic', 'tanganyika', 'tantric', 'taoist', 'tats', 'taz', 'tbc', 'telegrams', 'telekom', \"television's\", 'thais', 'thar', 'theatrics', 'theodor', 'thermally', 'throb', 'tht', 'ticketed', 'timon', 'tipperary', 'toda', 'tormenting', 'touche', 'tov', 'toyed', 'trachea', 'transitory', 'transparently', 'treasonous', 'tribalism', 'trig', 'truckload', 'tss', 'tua', 'tyneside', 'tyrol', 'unattached', 'underlie', 'underlies', 'unger', 'unmanageable', 'unmoved', 'unt', 'uplifted', 'upshot', 'upsurge', 'uribe', 'valery', 'vasco', 'vcu', 'virginian', 'vivacious', 'vowing', 'voyeur', 'warlike', 'warmup', 'watercolors', 'watermelons', 'watersheds', 'weaned', 'wid', 'willi', 'winnebago', 'wisp', 'wold', 'woolworths', 'xena', 'xerxes', 'xue', 'yearling', 'zahra', 'zamora', 'zapata', 'zeiss', 'zhong', 'zimmermann', 'а', '4e', \"abbott's\", 'abductions', 'ably', 'abortive', 'acr', \"afghanistan's\", 'agitating', 'aikido', 'aileen', 'akshay', 'alcoa', 'alkaloids', 'allahu', 'alm', 'alternated', 'amato', 'anagram', 'apaches', 'apologises', 'apostate', \"arabia's\", 'archway', 'arcy', 'ariane', 'artfully', 'artistes', 'asada', 'ashwin', 'axon', 'azam', 'azores', 'backpackers', 'bahn', 'ballooning', 'baptismal', 'basses', 'bauman', 'bca', 'beauregard', 'bede', 'beeswax', 'bentham', 'benthic', 'berated', 'bernal', 'bhd', 'bight', 'bilge', 'biohazard', 'bischoff', 'bissau', 'blouses', 'bonne', 'bozeman', 'breaststroke', 'breeches', 'bronzes', 'buttress', 'c.k', 'cabling', 'camber', 'canelo', \"capital's\", 'cartography', 'cataclysmic', 'catharsis', 'cerebellum', \"chancellor's\", 'chau', 'chesney', 'chiral', 'choy', 'civilisations', 'codec', 'cohabitation', 'collapsible', 'conga', 'conjures', 'consumables', 'contractually', 'contravention', 'copier', 'corden', 'corticosteroids', 'courtyards', 'coyne', 'creamery', 'critiquing', 'crunchyroll', 'ctc', 'cytokine', 'daffy', 'dany', 'danzig', 'darko', 'defrauded', 'depose', 'deprecated', 'dic', 'dicey', 'dimmer', 'disconnecting', 'disinfection', 'disobedient', 'distantly', 'divestment', 'divya', 'dizzying', 'donbass', 'downtrodden', 'drowsiness', 'dulce', 'dumpling', 'dupree', 'dutifully', 'dysplasia', 'déjà', 'ecologist', 'edicts', 'eeoc', 'effluent', 'egress', 'eights', 'embodying', 'encapsulates', 'encephalopathy', 'endangerment', 'enrol', 'evangeline', 'eventuality', 'evermore', 'evolutions', 'excretion', 'exegesis', 'exhibitor', 'exhumed', 'expunged', 'extrajudicial', 'extrapolate', 'f0.0', 'fal', 'faring', 'fingertip', 'finnegan', 'flavorful', \"floyd's\", 'forecasted', 'freemasons', 'ftl', 'fts', \"future's\", 'führer', 'galena', 'gamecocks', 'georgians', 'ggg', 'ghee', 'girolamo', 'glyphs', 'gor', 'gott', 'gouging', 'gpus', 'grammer', 'gravitation', 'griff', 'grr', 'gyllenhaal', 'gyn', 'halen', 'harmonize', 'haskins', 'haworth', 'hazzard', 'hcg', 'headwaters', 'hennessey', 'herbarium', 'hewn', 'hinata', 'honeysuckle', 'hoppers', 'hoshi', 'houseboat', 'houthi', 'houthis', \"human's\", 'hypothalamus', 'iea', 'ila', 'imaged', 'immobilized', 'imparting', 'imperium', 'indenture', 'inhumans', 'inimitable', 'instilling', \"international's\", 'inversions', 'iom', 'iplayer', 'jada', 'jealously', 'jervis', 'jetta', 'jogger', 'jumpy', 'justinian', 'kampf', 'kandi', 'karlsruhe', 'kenmore', 'keogh', 'kierkegaard', 'kildare', 'kingman', 'knockouts', 'kroner', 'lacerations', 'lacs', 'ladybug', 'latif', 'lauer', 'layover', 'leathers', 'leveson', 'lichfield', 'liens', 'littlest', 'loath', 'longhorn', 'loopy', 'lun', 'm7', 'maeve', 'magdalen', 'maidan', 'mair', 'mang', 'manifestly', 'manmohan', 'masa', 'matcha', 'matchbox', 'mathilde', 'mdr', 'mercia', 'mercies', 'mervyn', 'metamorphic', 'methuen', 'mews', 'minimums', 'modded', 'mongoose', 'monza', 'motility', 'moz', 'mucosa', 'munroe', 'mused', \"napoleon's\", 'nashua', 'natalya', 'naysayers', 'netizens', 'neuromuscular', 'nme', 'noblemen', 'nobu', \"nolan's\", 'nome', \"north's\", 'northridge', 'nta', 'nunez', 'obeys', 'obsolescence', 'obstetrician', 'occ', 'oceanside', 'ogilvy', 'ordinal', \"oscar's\", 'outgrow', 'outsmart', 'overcooked', 'overrides', 'overstate', 'oxnard', 'parables', 'particulates', 'pashtun', \"pat's\", 'pcbs', 'penile', 'perfusion', 'pessimist', 'physiotherapist', 'piecing', 'placards', 'plaguing', 'plantain', 'podcasting', 'poms', 'porky', 'poser', 'ppt', 'preschoolers', \"priest's\", 'pronounces', 'pullin', 'pyeongchang', 'pylon', 'quantifying', 'quip', 'radishes', 'rayburn', 'recife', 'recyclable', 'redirecting', 'reenactment', 'refit', 'reiterating', 'rejuvenate', 'relaunched', 'renard', 'renderings', 'renton', 'repaying', 'rereading', 'resellers', 'respirator', 'resplendent', 'restated', 'revitalized', 'rhythmically', 'rigour', \"riley's\", 'romani', 'roomy', 'rowena', 'rsc', 'rtc', 'rti', 'rulebook', 'salvia', 'saps', 'scm', 'seaton', 'seduces', 'seeps', 'segregate', 'seminaries', 'sfc', 'shaftesbury', 'shhhh', 'signer', 'signet', 'silicate', 'singlet', 'sirs', 'skewer', 'sloths', 'slugging', 'snares', 'société', 'soldered', 'spammers', 'spastic', 'specks', 'spina', 'squall', 'sst', 'stabilizers', \"staff's\", 'starlet', 'stayin', 'steinbeck', 'stinson', 'stockpiles', 'stoners', 'stranding', 'strangeness', 'stratum', 'strenuously', 'strove', 'surmise', 'susana', 'swindle', 'swirled', 'swordfish', 'swot', 'takings', 'talkers', 'tcs', 'tegan', 'tempore', 'tentacle', 'terse', 'thackeray', 'thales', 'thawing', 'thermonuclear', 'thinnest', 'thrace', 'timeliness', 'tincture', 'tio', 'tivoli', 'tmp', 'tombstones', 'tonto', 'tooting', 'topps', 'tora', 'torments', 'traitorous', 'transact', 'trawler', 'triumphantly', 'trustworthiness', 'tsx', 'tuan', 'tuc', 'tunbridge', 'turkic', 'turnips', 'tuskegee', \"uber's\", 'ultras', 'unadulterated', 'unbelievers', 'undeclared', 'undercurrent', 'undergrowth', 'underpin', 'unseemly', 'unsympathetic', 'unyielding', 'upheavals', 'urbanized', 'usages', 'vacuuming', 'vergara', 'vers', 'vesuvius', 'videography', 'viejo', 'wale', 'wallowing', 'wavered', 'wench', 'westin', 'wexler', 'wheres', \"whoever's\", 'wiggles', 'wilberforce', 'wilfully', 'wirelessly', \"witch's\", 'woking', 'woodhead', 'worsens', 'xxii', 'yeshiva', 'zany', 'zedd', 'zeno', 'zucker', 'º', '▬', '🙃', '0s', '5e', '6c', 'aau', 'abalone', 'abdicate', 'accosted', 'adjournment', 'admonished', 'affable', 'aficionados', 'aggressors', 'airbrush', 'airsoft', 'alarmingly', 'algonquin', 'alon', 'alopecia', 'alzheimer', 'ander', 'anja', 'annika', 'apocryphal', 'arguable', 'arianna', 'aru', 'asghar', 'ashworth', 'assembles', 'avowed', 'b.b', 'bahama', 'baldness', 'bamford', 'bathhouse', 'bayonne', 'beekeeping', 'beltran', 'bennington', 'berk', 'bide', 'biotic', 'bisexuality', 'bismuth', 'bitters', 'biweekly', 'bizarrely', 'blacker', 'blemishes', 'bloomed', 'bloomer', 'bmo', 'boleyn', 'bolshoi', 'boulevards', \"bp's\", 'brags', 'brainwash', 'breadwinner', 'bridgend', 'bridgestone', 'bulbous', 'bunbury', 'butternut', 'butting', 'c.e', 'c7', 'cambria', 'capa', 'capillaries', 'carcinogens', 'cardiomyopathy', 'caregiving', 'carpeted', 'casas', 'cea', 'cerro', 'chaka', 'charly', 'chastised', 'cie', 'cin', 'circuses', 'clank', 'classifier', 'cliques', 'clp', 'combinatorial', 'compensates', 'condé', 'constitutive', 'coolly', 'copping', 'cormier', 'cornering', 'coronal', 'counterweight', 'coupler', 'courtesan', 'cristobal', 'cuck', 'curable', 'curative', 'cushy', 'cysteine', 'dalmatian', 'danilo', 'darin', 'darkroom', \"davis's\", 'decentralised', 'deciphering', 'defibrillator', \"designer's\", 'desirability', 'deuterium', 'dietz', 'diluting', 'diplo', 'disconnection', 'disenchanted', 'distillers', 'dodgeball', 'dodges', \"donald's\", 'downwind', 'drago', 'dri', 'dropouts', 'duckling', 'dunked', 'eac', 'ectopic', 'educates', 'elbert', 'elmira', 'endoscopic', 'engulf', 'enrollees', 'enrollments', 'enthralling', 'epping', 'equaled', 'equivalency', 'erc', 'essayist', 'excavate', 'exceptionalism', 'exchangers', 'excreted', 'fallback', 'faris', 'faroe', 'farsi', 'fess', 'feu', 'fib', 'fico', 'filename', 'finsbury', 'firebird', 'flings', 'foreheads', 'forgeries', 'forsythe', 'fossilized', 'fournier', 'franca', 'franchised', 'fraudsters', \"freddy's\", 'fromm', 'fsc', 'fte', 'gaffe', 'gallatin', 'gard', 'gargantuan', 'gavel', 'geometries', 'ghosted', 'glens', 'glitz', 'goalies', 'godhead', 'godlike', 'goofing', 'goverment', 'goya', 'grates', 'gravestone', 'gridiron', 'grohl', 'grp', 'grupo', 'haggis', 'hainan', 'hamad', 'hangings', 'headdress', 'heli', 'hemmed', 'hgh', 'higuain', 'hoarder', 'hoarse', 'holyoke', 'homebrew', 'homebuyers', 'hoppy', 'howells', 'hts', 'hydrographic', 'iago', 'icebergs', \"iceland's\", 'illegality', 'imperious', 'implored', 'indore', 'industrialised', 'infanticide', 'infestations', 'ingraham', 'injectors', 'injects', 'ino', 'inoculation', 'inordinate', 'inquires', 'insensitivity', 'insincere', 'instigator', 'insubordination', 'intercity', 'iras', 'isc', 'isotopic', 'iver', 'ivey', 'jal', 'jeopardizing', 'joakim', 'joggers', 'joh', 'johnstown', 'josep', \"junior's\", \"k's\", 'karel', 'kebabs', 'khomeini', 'klinger', 'koalas', 'kodiak', 'kook', 'kronos', 'kunming', 'ladle', 'launchpad', 'laundered', 'laundromat', 'lavinia', 'lavrov', 'laxative', 'laxatives', 'leeward', 'lentil', 'lepage', 'lewisham', 'liaisons', 'lifeguards', 'lionsgate', 'liston', 'litters', 'lma', 'loca', 'lolo', 'lusaka', 'lustful', 'lustrous', 'macintyre', 'macroscopic', 'mahindra', \"maine's\", 'malden', 'malmö', 'marbled', 'margery', 'marten', 'materia', 'maxime', 'mbeki', 'mccollum', 'mcconaughey', 'mcmurray', 'meaner', 'medway', 'meetups', 'mensa', 'mignon', 'millicent', 'milt', 'mlg', 'moda', 'modric', 'moores', 'morsi', 'morten', 'mosby', 'mosh', 'mosses', \"mozart's\", \"mueller's\", 'mumbles', 'nabil', 'nationalisation', 'ncs', 'ndtv', 'newscast', 'nex', 'nfs', 'nicu', 'nighter', 'nir', 'nonverbal', 'nui', 'oakville', 'observatories', 'ooc', 'orchestrate', 'ordovician', 'otaku', 'ovechkin', 'overprotective', 'p.d', 'panache', 'panelist', 'paracetamol', 'paralyzing', 'parkin', 'parthenon', 'participle', 'pastimes', 'pathetically', 'pathophysiology', 'pauli', 'pdfs', 'pedantic', 'peered', 'pegging', 'peo', 'perthshire', 'perturbation', 'pha', 'phage', 'phallic', 'phobias', 'phonology', 'pickings', 'pima', 'pimping', 'pino', 'plateaus', 'pml', 'pocketbook', 'polymeric', \"portugal's\", 'ppr', 'precludes', 'prescient', 'pro00', 'procurator', 'prophesy', 'prouder', 'ps1', 'puffin', 'pumas', 'punts', 'purebred', 'purists', 'putney', 'qaida', 'rafferty', 'rar', 'ratepayers', 'recep', 'redline', 'rednecks', 'reefer', 'refilled', 'refrigerant', 'remarry', 'resiliency', 'retorted', 'revivals', 'revving', 'rhone', 'rhp', 'ridding', 'riddler', 'riordan', 'ripon', 'rit', 'rizal', 'rockabilly', 'rodin', 'roshan', 'salivary', 'saloons', 'sandford', 'sandor', 'sanitarium', 'sardine', 'sauerkraut', 'saville', 'sawn', 'scheer', 'schoolboys', 'scotts', 'seafloor', 'sedimentation', 'sequestered', 'sharpton', 'shavings', 'shek', 'shing', 'shirk', 'shitless', 'shoves', 'shrieks', 'shriver', 'skewers', 'slav', 'sleepwalking', 'slinky', 'slipknot', 'smirking', 'snd', 'snorkeling', 'snuggled', 'soames', 'softens', 'solon', 'speedster', 'spellbound', 'spiel', 'splint', 'spunk', 'squinting', 'squirming', 'statham', 'stc', 'stepan', 'stethoscope', 'stoops', 'strident', 'superstore', 'sutcliffe', 'svg', 'swank', 'swerving', 'swipes', 'syfy', 'syriac', 't.s', 'tacks', 'takumi', 'tans', 'techcrunch', 'tendering', 'tenses', 'thay', 'thicc', 'thinkpad', \"thor's\", 'tilbury', 'tilda', 'toasts', 'tobey', \"tolkien's\", 'tolling', 'tomi', 'torts', 'tradeoff', \"train's\", 'trapp', 'treadwell', 'tritium', 'tsn', 'tsu', 'tubby', 'tubers', 'tutti', 'twill', 'twinks', 'uavs', 'ubiquity', 'udall', 'unaccountable', 'unaffordable', 'underfoot', 'undrafted', 'unevenly', 'ung', 'unknowable', 'unreachable', 'unsealed', 'upc', 'upswing', 'urbanisation', 'uxbridge', 'valdes', 'varun', 'vastness', 'veganism', 'velasquez', 'verdun', 'vickie', \"village's\", 'vincennes', 'vogt', 'vou', 'waddell', 'wags', 'waikiki', 'waistcoat', 'wald', 'wankers', 'warburg', 'weeknd', 'wheelbarrow', 'whipple', 'wic', 'wrangling', 'yara', 'yawns', 'yellen', 'yost', 'yousef', 'yuna', 'zn', 'ø', '▪', '🤤', '1p', '8x00', 'abacus', 'abbotsford', 'abkhazia', 'abolitionists', 'absorbers', 'acct', 'acetic', 'aed', 'affidavits', 'afr', 'agape', 'agh', 'ailes', 'aimless', 'akhtar', 'alasdair', 'aldous', 'aldrin', 'aliexpress', 'allegiances', 'allstate', 'alo', 'altho', 'ambrosia', 'americano', 'amitabh', 'amoral', 'anise', 'ansar', 'aragorn', 'argonne', 'argumentation', 'asphyxiation', 'assessors', 'astaire', 'attn', 'auden', \"austria's\", 'avs', 'babyface', 'backstroke', 'baits', 'balsam', 'balzac', 'barbecues', 'barbell', 'barbican', 'baskin', 'bastions', 'bellator', 'benzodiazepines', 'bilingualism', 'biodiesel', 'blogosphere', 'bmt', 'bobble', 'bobsleigh', 'bohr', 'bola', 'boniface', 'boxy', 'boynton', 'brahmins', 'breakwater', 'breckenridge', 'broiler', 'brookhaven', 'buckner', 'buoyed', 'bushnell', 'bypasses', 'caliper', 'canopies', \"card's\", 'cargoes', 'caron', 'carted', 'cazorla', 'cbr', 'celluloid', 'chae', 'chantilly', \"chen's\", 'chimed', 'cilia', 'cinch', 'cirrus', 'clarksville', 'clatter', 'clench', 'clos', 'closeted', 'coinbase', 'colic', 'collectable', 'combats', 'commonsense', 'conceals', 'cond', 'confirmations', 'confound', 'conjugal', 'contouring', 'conyers', 'cornwallis', 'corr', 'couplings', 'courageously', 'covalent', 'crackhead', 'crawfish', 'crispr', 'cruciate', 'cudi', 'cufflinks', 'cussing', 'dandruff', 'darmstadt', \"dawson's\", 'deductive', 'defile', 'defiled', 'dela', 'deletions', 'delved', 'depeche', 'deplete', 'deteriorates', 'devalue', 'devel', 'dido', 'dingle', 'diphtheria', 'disconnects', 'dispelled', 'dispensers', 'disturbingly', 'dob', 'doer', 'doorknob', 'doormat', 'downsize', 'dpr', 'dragoon', 'dsa', 'dwelt', \"eagle's\", 'easygoing', 'eben', 'elway', 'envisioning', 'envisions', 'epcot', 'epidermal', 'erratically', 'esperanza', 'essences', 'etna', 'etruscan', 'excusing', 'extraordinaire', 'facials', 'fallujah', 'farcical', 'fattest', 'fawning', 'featherweight', 'feigned', 'feinberg', 'ferraris', 'fetishes', 'filip', 'filippo', 'fiske', 'flasks', 'folate', 'folkestone', 'forthwith', 'frampton', 'frankfurter', 'fre', 'frets', 'frome', 'fulani', 'gassing', 'gautam', 'gbs', 'geri', 'gestalt', 'gfs', 'gigabyte', 'gilda', 'gipsy', 'giulio', 'glint', 'gloating', 'gnc', 'goad', 'goddamnit', 'grammars', 'greenlight', 'greig', 'greyish', 'grog', 'groupie', 'gruden', 'guardia', 'h.e', 'haggle', 'halcyon', 'halos', 'handicaps', 'handicraft', 'harshness', 'hashim', 'hea', 'headscarf', 'headshots', 'heaping', 'heartbeats', 'hed', 'hedwig', 'heine', 'helios', 'hilo', 'hons', \"hope's\", 'hotbed', 'hotness', 'hoya', \"hungary's\", \"ian's\", 'ifrs', 'immunoglobulin', 'imperatives', 'incinerated', 'indented', 'inking', 'insolence', 'instigation', 'irresponsibility', 'islamism', 'j2', 'jacinto', 'jafar', 'jamboree', 'jeanie', 'jeeves', 'jeopardized', \"jesus's\", 'jeweller', 'jima', 'jorgensen', 'juilliard', 'jumpin', 'kao', \"kardashian's\", 'karp', 'kasey', 'kass', 'katerina', 'kemal', 'kigali', 'kyra', 'l4', \"la's\", 'lanyard', 'leavitt', \"lebron's\", 'leesburg', \"left's\", 'letdown', 'lewinsky', 'libretto', 'lidar', 'lipoprotein', 'lod', 'lopes', 'lotions', 'lox', 'luckier', 'lundy', 'lycra', 'macclesfield', 'machina', 'maddow', 'madmen', 'mahon', 'malignancy', 'mamie', 'mandel', \"margaret's\", 'marginalization', 'marshy', 'masai', 'massing', 'matriculation', 'mcclintock', 'mclennan', 'mecklenburg', 'medallions', 'meister', 'mercifully', 'mersey', 'mev', \"michelle's\", 'microbiome', 'midgets', 'mindsets', \"ministry's\", 'minutiae', 'misrepresent', 'misrepresenting', 'mitra', 'miyagi', 'mmmmm', 'mongrel', 'morin', \"moscow's\", 'mrp', \"mtv's\", 'mulling', 'mundy', 'munn', 'musgrave', 'n.m', 'n3', 'nairn', 'nak', \"nancy's\", 'nanoscale', 'napolitano', 'neely', 'neha', 'neiman', 'ner', 'nibbling', 'nisha', 'nita', 'no2', 'nob', 'nother', 'nuys', 'o.c', 'oas', 'oberon', 'objectors', 'octagonal', 'ofcom', 'oldie', 'operable', 'organises', 'orgasmic', 'oui', 'outclassed', 'overflows', 'overhear', 'oyo', 'pacifism', 'padma', 'pampering', 'paralyze', 'parra', 'pascoe', 'pasquale', 'pelts', 'perennials', 'perp', 'perugia', 'pham', 'phu', 'pillsbury', 'pineda', 'pinewood', 'pio', 'pjs', 'platters', 'policymaking', 'porting', 'postnatal', 'powertrain', 'predefined', 'preferentially', 'prelate', 'premonition', 'presets', 'pretenders', 'primitives', 'propagandists', 'proportionality', 'proportionately', 'provident', 'pubescent', 'pyro', \"q's\", 'qingdao', 'quantifiable', 'r.i', 'raffaele', 'rajah', 'ramallah', 'randwick', 'rata', 'ravenna', 'rcd', 'reaffirming', 'recaps', 'recharging', 'reconsideration', 'recur', 'recursion', 'redheads', 'redirects', 'redundancies', 'registrars', 'rehman', 'rejoiced', 'religiosity', 'relished', 'reportage', \"reporter's\", 'resents', 'resets', 'reviled', 'ricks', 'rifled', 'riva', 'robison', 'roebuck', 'rossetti', 'rotator', 'rta', 'rubbers', 'sadist', 'sais', 'salamanca', 'salas', 'samara', 'sanaa', 'sault', 'sbi', 'scheduler', 'schott', 'screamer', 'scrumptious', 'sectioned', 'sendai', 'shackleton', 'shakedown', 'shamefully', 'shams', 'shariah', 'shimmy', 'shoestring', 'shucks', 'sired', 'sitka', 'sleaze', 'smg', 'smithers', 'smoothest', 'snags', 'snark', 'spartanburg', 'speculates', 'sperry', 'spurned', 'squamous', 'stagnated', 'staphylococcus', 'stator', 'steelhead', 'stewed', 'stews', 'stockman', 'stoppages', 'straights', 'stravinsky', 'stuntman', 'stylistically', 'subjectively', 'subpar', 'subsumed', 'suffixes', 'sunbeam', 'swanky', 'swaths', 'symbolizing', 'synchrotron', 'synthase', 'teixeira', 'tendulkar', 'teton', 'thereabouts', 'thermos', 'thrasher', 'timo', 'tine', 'tinsel', 'toppling', 'tortuous', 'toughen', 'trawl', 'triglycerides', 'triumphal', \"trust's\", 'tuk', 'tulsi', 'typology', 'tywin', 'ultralight', 'uncooperative', 'underappreciated', 'undisciplined', 'uninjured', 'unlv', 'unobstructed', 'unobtrusive', 'unwitting', 'upholstered', 'upturned', 'usl', 'vandenberg', 'vaporized', 'variances', 'vaz', 'vela', 'vignette', \"visitor's\", 'vulgarity', 'wakanda', 'wanderlust', 'wardrobes', 'waterside', 'wattage', 'waxes', \"webster's\", 'wedgwood', 'weightless', 'wheelhouse', 'whiteley', 'whitworth', 'williamstown', 'withstanding', \"wizard's\", 'yucca', 'zaha', 'zappa', 'zx', 'μg', '○', '✅', '💪', '😈', '😒', '1million', '5km', '7b', 'abhor', 'abreu', 'absentia', 'accursed', 'adaptor', 'adj', 'aegon', 'aeon', 'aest', 'afterglow', 'aghast', 'agitate', 'ags', 'aight', 'alban', \"alberta's\", 'alderson', 'alls', 'amador', 'amoeba', 'andalusia', 'annuals', 'anselm', 'antimatter', 'apologetics', 'append', 'appraisers', 'arie', 'arnett', 'aspirational', 'asr', 'atmos', 'australis', \"authority's\", 'automaker', 'autonomously', 'auxiliaries', 'awp', 'ayrton', 'azur', 'backpacker', 'baidu', 'baka', 'banbury', 'bani', 'bankstown', 'bared', 'bariatric', 'basu', 'baywatch', 'bcg', 'bedbugs', 'bedded', 'bedridden', 'berners', 'bild', \"billboard's\", 'binance', 'birding', 'bleh', 'blige', 'blushed', 'bms', 'bombarding', 'borgia', 'boulogne', \"bowie's\", 'brecon', 'broadcasted', 'bronzer', 'bukhari', 'burnet', \"burton's\", 'buts', 'bx', 'caen', 'caldera', 'calvinist', 'capitan', 'carpe', 'carrollton', \"casey's\", 'cataclysm', 'catapulted', 'cavani', 'cdma', 'censured', 'centrepiece', 'chairing', 'chaise', 'chakras', 'characterise', 'chautauqua', 'chiba', 'childers', \"chloe's\", 'choc', 'choco', 'chronograph', 'chul', 'clairvoyant', 'clarita', 'clarks', 'clc', 'coldness', 'coleslaw', 'collard', \"columbia's\", 'commercialized', 'committal', 'communicators', 'conceptualized', 'condensing', 'condoned', 'connaught', 'conniving', 'contemptuous', 'corroded', 'corvallis', 'cosmetology', 'cotswolds', 'counterintelligence', 'countertop', 'courtier', 'crag', 'cranium', 'crystallization', 'csl', 'cultivar', 'curtiss', 'dachshund', 'dagenham', 'damm', 'dampened', 'dastardly', 'dawns', 'deadpan', \"dealer's\", 'decibels', 'decried', 'deeming', 'delinquents', 'delorean', 'desecrated', 'deserting', 'detonating', 'detours', 'dewy', 'dilly', 'dimitrov', 'dings', 'dionysus', 'discontinuous', 'docklands', 'dolomite', 'dominatrix', 'dou', 'dov', 'doze', 'dreamcast', 'dwi', 'düsseldorf', 'eamon', 'eckhart', 'eichmann', 'elaborates', 'elongation', 'embiid', 'emmerdale', 'enlists', 'enthused', 'erases', 'escapism', 'euripides', 'exasperation', 'excelling', 'exoskeleton', 'expropriation', 'extinguishers', 'extruded', 'falafel', 'fallacious', 'falstaff', 'famines', 'fanboys', 'fasted', 'fastidious', 'fealty', 'federalists', 'fibroblasts', 'fido', 'filial', 'fingerprinting', 'fisting', 'flaccid', 'flagpole', 'flamethrower', 'florists', 'fogg', 'footpaths', 'forays', \"franchise's\", \"franco's\", 'freda', 'freelancing', 'freeland', 'freezers', 'fut', 'fv', 'gameday', 'garnished', 'gastronomy', 'gauls', 'gazprom', 'generalised', 'generics', 'genteel', 'geographers', 'geotechnical', 'gesturing', 'ghani', 'glenwood', 'glib', 'glorification', 'goshen', 'govan', 'grands', 'gratuity', 'grayling', 'groningen', 'growled', 'gt3', 'gumball', 'haggling', 'hairdressing', 'handshakes', 'hardens', 'hardwoods', 'harker', 'harkness', 'harv', 'haye', 'hcv', 'headstones', 'heartbreaker', 'hemorrhoids', 'henshaw', 'herbalife', 'herders', 'hertford', 'hiphop', 'histamine', 'hitchhiking', 'hobbyists', 'holocene', 'hoosier', 'hrm', 'hsa', 'hst', 'humanely', 'hustled', 'huw', 'hynes', 'hyphen', \"id's\", 'ides', 'igloo', 'imessage', 'impregnable', 'impressionism', 'incredibles', 'indecency', 'indentation', 'inebriated', 'inexorably', 'insipid', 'intercollegiate', 'interdependent', 'itineraries', 'jamaicans', 'jessup', 'jewellers', 'jiffy', 'jor', 'jpl', 'jpn', 'kamara', 'kanpur', 'karting', 'karzai', 'keir', 'kemper', 'kenwood', 'ketone', 'kf', 'kiko', 'kimber', 'kingsbury', 'knackered', 'komodo', 'ktm', 'kunis', 'lagi', 'lah', 'lancers', 'lapland', \"lauren's\", 'leaded', 'lhasa', 'lhc', 'lightroom', \"lily's\", 'lingard', 'livy', 'loaning', 'lofts', 'loi', 'lomond', 'lorena', 'lossless', 'lucan', 'lugs', 'lyceum', 'machinists', 'macrae', 'madera', 'madoff', 'maim', 'mamba', 'mammography', 'manchu', 'maneuverability', 'mangroves', \"mankind's\", 'maples', 'marg', 'marooned', 'martians', 'mcallen', 'mcelroy', 'medias', 'meena', 'merrier', 'mesmerising', 'mfs', 'milliken', 'mistrial', 'miyamoto', 'moffett', 'moh', \"monica's\", 'montero', 'moorings', 'moretti', 'mortgaged', 'mossy', 'murad', 'muslin', 'myopic', 'nabi', 'nagel', 'naka', 'nape', 'natively', \"nato's\", 'naturals', 'nco', 'neel', 'nehemiah', 'nematodes', 'netscape', 'nida', 'nikkei', 'nipped', 'noncommercial', 'nondescript', 'norad', 'notables', 'objectification', 'officiate', 'ohms', 'ope', 'optimised', 'oracles', 'orbitals', 'origen', 'ornamented', 'oso', 'ots', 'outbid', 'outgrowth', 'outhouse', 'outlawing', 'overhanging', 'overreach', 'p.r', 'pacifier', 'pander', 'paralleled', 'pasts', 'patrician', 'pederson', 'pediatricians', 'peeked', \"pennsylvania's\", 'perfumed', 'permutation', 'phan', 'phenol', \"philadelphia's\", 'phytoplankton', 'pirlo', \"plan's\", 'plantar', \"plato's\", 'pliable', 'polemic', 'ponderosa', 'poppin', 'positron', 'praia', 'prewar', \"principal's\", 'prodding', 'prognostic', 'proviso', 'prunes', 'pubg', 'puffer', 'purport', 'quarts', 'quattro', 'ques', 'queueing', 'quint', 'radicalization', 'radiologist', 'ragnarok', 'rashford', 'raspy', 'receivables', 'recites', 'recuperation', \"red's\", 'rediscovering', 'redshirt', 'referential', 'refinements', 'reflectors', 'regrowth', 'reimagined', 'reinvention', 'reit', 'relinquishing', 'renunciation', 'reparation', 'repute', 'retardant', 'reunites', 'revamping', 'reversals', 'rez', 'rhiannon', 'ricketts', 'ripen', 'romaine', 'roseville', \"ross's\", 'rounders', 'rucksack', 'rvs', 's.d', 's.l', 'sacrilege', 'sadr', 'safekeeping', 'sahel', 'sallie', 'samaria', 'schoolyard', 'screenwriters', 'scruples', 'seafront', 'sedatives', 'seguin', 'selfishly', 'serif', 'serine', 'sexualized', 'shaheen', 'shallows', 'shawshank', 'shortfalls', 'showrunner', 'sickest', 'simcoe', 'sincerest', 'sistine', 'snazzy', 'snider', 'snipes', 'sorbet', 'soriano', 'specialities', 'spiny', 'spm', 'spreader', 'squarepants', 'ssb', \"stanley's\", 'steepest', 'straightaway', 'strainer', 'sturt', 'subsides', 'subverted', 'sudoku', 'suis', 'surefire', 'surmised', 'swabs', 'sweetwater', 'symantec', 'tacitus', 'tambourine', 'tangy', 'tarik', 'tch', 'tensed', 'tft', 'throttling', 'tics', 'tilapia', 'timbre', 'tiptoe', 'tithes', 'tongued', 'tonkin', 'toppers', 'torrid', 'traumatised', 'trawling', \"tree's\", 'trestle', 'troublemakers', 'tsunamis', 'tuber', 'tugged', 'ulcerative', 'unabridged', 'unbearably', 'underwriter', 'undeserving', 'unfunny', 'unkempt', 'unmitigated', 'unneeded', 'unsc', 'upmarket', 'upriver', 'uric', 'utley', 'utterances', 'venezuelans', 'virat', 'vit', 'vladivostok', 'vole', 'volker', 'vuelta', \"wagner's\", 'wallaby', 'warfarin', 'warplanes', 'warzone', 'welds', 'westphalia', 'whorls', \"widow's\", 'wilders', 'wildwood', 'wilkerson', 'winder', 'wintering', 'workaholic', 'worthiness', 'wrt', 'yeager', 'yore', 'zedong', 'zeit', 'ö', '3h', '4x00', 'aamir', 'abdi', 'aberrations', 'addon', 'aeg', 'aerials', 'affix', 'afoul', 'ahmadinejad', 'airlock', 'alcatel', 'alicante', 'allergen', 'alleviation', 'alphabets', 'amara', 'ambrosio', 'analogs', 'anchorman', 'angolan', 'aphids', 'appendices', 'applesauce', 'aqsa', 'aromas', 'assuage', 'asthmatic', 'autopsies', 'awed', 'bachman', 'bailouts', 'ballets', 'balmoral', 'bana', 'barreled', 'battlegrounds', 'bazooka', 'beatle', 'beckoning', 'beckwith', 'beebe', 'belfort', 'bewilderment', 'beyer', 'bighorn', 'biloxi', 'biomarker', 'bitchin', 'bitrate', 'bittorrent', 'blankly', 'bletchley', 'blyth', 'bogotá', 'boho', 'bombastic', \"bond's\", 'braved', 'brienne', 'brocade', 'brt', 'btu', \"buddha's\", 'bulldozers', 'bunks', 'butchering', 'cameroonian', 'capacitive', 'capaldi', 'carapace', 'carew', \"castle's\", 'cecile', 'cecily', \"cell's\", \"century's\", 'chancellors', 'changi', 'chapelle', 'charlatan', 'chatterjee', 'checkbook', 'chhattisgarh', \"chile's\", 'chillies', 'chim', 'chomping', 'christen', 'christiane', 'chucks', 'circulates', 'cityscape', 'clang', 'clergymen', 'closeup', 'clowning', 'cmp', 'coalesce', 'coldwater', 'competently', 'compresses', 'concacaf', 'conman', 'conning', 'constricted', 'contrarian', 'coped', 'cordially', 'cormac', 'corned', 'cornice', 'cornwell', 'corporeal', 'cowering', 'creeds', 'crepes', 'crispin', 'criticises', 'croats', 'crosswalk', \"crow's\", 'crud', 'curation', 'curley', 'cushman', 'cybernetic', 'cygnus', 'cyndi', 'cyrillic', \"d'souza\", 'dampening', 'darned', 'decaf', 'decapitation', 'deciphered', 'declarative', 'dede', 'demonstrable', 'demonstrative', 'despairing', 'deviates', \"device's\", 'digi', 'dillinger', 'dinky', 'disapproves', 'discontinuation', 'disliking', 'dismemberment', 'djing', 'dlr', 'dmx', 'dobby', 'doon', 'dorman', 'downplaying', \"doyle's\", 'drawstring', 'drunkenly', 'dumbbell', 'dutiful', 'earhart', 'earplugs', 'earshot', 'ecw', 'edn', 'efi', 'eke', 'electorates', 'elitism', 'elven', 'emigrant', 'enders', 'engender', 'entente', 'enveloping', 'escherichia', 'etudes', 'excavators', 'exhausts', 'exxonmobil', 'factional', 'fahey', 'felice', 'fermenting', 'fibromyalgia', 'fiftieth', \"fire's\", 'flacco', 'flatbed', 'fms', 'foals', 'footbridge', 'forceps', 'forecasters', 'fos', 'frothy', 'fucken', 'fujitsu', 'fume', 'gallium', 'gantry', 'gargoyle', 'gaslight', 'gastro', 'gastroenterology', 'gcs', 'generalist', 'georgi', 'germinate', 'gershwin', 'ghg', 'girardi', 'gitmo', 'glades', 'glebe', 'glowed', \"goat's\", 'godard', 'goh', 'gramps', 'granddaughters', 'grannies', 'gremlin', 'grrr', 'grudgingly', 'gryffindor', 'guadeloupe', 'gws', 'h.p', 'haddad', 'hallett', 'harbored', 'harmonized', 'headroom', 'hedley', 'henan', 'heparin', 'herded', 'hernando', 'hgtv', 'hikaru', 'hilal', 'hillel', 'hodgkin', 'hodor', \"holland's\", 'homily', 'hor', 'hornby', 'humana', 'hummingbirds', 'humpty', 'hustlers', 'i1', 'ibanez', 'icbm', 'ideation', 'iff', 'impeccably', 'impulsively', 'index.php', 'inedible', 'inequities', 'infinitesimal', 'informers', 'integrals', 'ipods', 'isolationist', 'iucn', 'j1', 'jailhouse', 'jeanine', 'jeannette', 'jellies', 'jetblue', 'jubilant', 'kain', 'kamen', 'karat', \"karen's\", 'karmic', 'keefe', 'keener', 'keepsake', 'kerber', 'kilpatrick', 'kobo', \"kohl's\", 'kono', 'krill', 'krispy', 'krug', 'kruse', 'laceration', 'laplace', \"leonard's\", 'libor', 'lightened', 'liposuction', 'literatures', 'liven', 'lombardo', 'longo', 'loudon', 'lowdown', 'loy', 'ltr', 'lubricated', 'lucca', 'luk', 'lul', 'lyricism', 'madi', 'mages', 'maghreb', 'mahjong', 'maja', 'malabar', 'malala', 'mammary', 'maximized', 'meer', 'menendez', 'menopausal', 'mers', 'metered', 'mfg', 'mfw', 'michonne', \"mickey's\", 'microbe', 'midline', 'millstone', 'mimicry', \"mission's\", 'mitre', 'moonlit', 'morningstar', 'morphs', 'mortis', 'mote', 'moyer', 'multiracial', 'munoz', 'murchison', 'musashi', 'mutate', 'myeloid', 'naik', 'naira', 'nand', 'neglects', 'nep', 'nervosa', 'newsom', 'nez', 'nickelback', 'nimrod', 'njpw', 'nooooo', 'novelties', 'novi', 'nubian', 'nutt', 'oakwood', 'oblast', 'oeuvres', 'offhand', 'okra', 'olney', 'omelet', 'oozes', 'opi', 'optometry', 'orchestrating', 'orwellian', 'oscillators', 'otp', 'outtakes', 'pacifica', 'paella', 'pager', 'panicky', 'papier', 'parasol', 'parenthesis', 'parser', 'partick', 'pattison', \"pc's\", 'peachtree', 'peele', 'pensive', 'performative', 'permeate', 'persevered', 'petticoat', 'pheasants', 'phenom', 'photosynthetic', 'pinging', 'pinion', 'pinter', 'pivots', 'plenipotentiary', 'plotters', 'pocono', \"poet's\", 'pons', 'poppers', 'posses', 'precondition', 'preconditions', 'premierships', 'preppy', 'pretensions', 'priebus', \"pro's\", 'professing', 'prospector', 'psychos', 'purvis', 'qian', 'qual', 'quantitatively', 'radiative', 'rambler', 'rance', 'rattan', 'reactivate', 'reapers', 'reassembled', 'rebalance', 'rebooting', 'recreates', 'refuting', 'regress', 'reintegration', 'rejoining', 'renegotiation', 'repositioning', 'reshaped', 'resurface', 'retails', 'retinue', 'rickey', 'rnas', 'roberson', 'rockaway', 'rockhampton', 'romanesque', 'roubles', 'rumba', 's.e', 'saatchi', \"sally's\", 'salvaging', 'sandi', 'saree', 'satirist', 'schrader', 'screenplays', 'segundo', 'sga', 'shaka', 'sharpshooter', 'shiner', \"shop's\", 'shrugging', 'shrunken', 'sidetracked', 'silesia', 'singlehandedly', 'skiff', 'skittish', 'skopje', 'skynet', 'slattery', 'sleuth', 'slocum', 'sluice', 'smokeless', 'solidity', 'sorrento', 'speciation', 'splatoon', 'sportsnet', 'squaring', 'squeamish', \"stark's\", 'stockade', 'stoicism', 'stoughton', 'straddles', 'strasburg', 'strontium', 'sturm', 'sunbury', 'superfund', 'supposition', 'suprised', 'svu', 'synchronised', 'tabasco', 'tagore', 'tantra', 'tarsus', 'tasker', 'teatro', 'theorizing', 'thermoplastic', 'thessaloniki', 'thickly', 'thro', 'timbuktu', 'timeshare', 'tino', 'tinto', 'tipper', 'titanfall', \"todd's\", 'toiling', 'toothbrushes', 'townshend', 'trailhead', 'transvestite', 'trask', 'trodden', 'tsang', 'tucks', 'turismo', 'tussle', 'twp', 'typist', 'tyr', 'uhhhh', 'uhuru', 'unaided', 'unbecoming', 'universalist', 'unmistakably', 'unrealized', 'unworkable', 'uppercut', 'uproot', 'usenet', 'valiantly', 'verandah', 'vermeer', 'villeneuve', 'virology', 'vivek', 'voir', 'voor', 'vulgaris', 'wastage', 'waterline', 'waxman', 'weariness', 'weblog', 'whalers', 'wheelbase', 'wholeness', 'williston', 'wilmer', 'win00', 'wingate', 'woolley', 'woot', 'wrest', 'yannick', 'zillion', 'zona', 'zte', 'zynga', '🇺🇸', '🎃', '😋', '🤗', '1e', '2f', '3x00', 'aar', 'acceptability', 'aceh', 'adjudged', 'adriano', 'ahaha', 'airbender', 'aire', 'alb', 'alcove', 'alger', 'alrighty', 'amira', 'ane', 'anesthesiologist', 'annualized', 'arcana', 'architecturally', 'archive.org', 'ase', 'asimov', 'aspirant', 'assertiveness', 'assyrians', 'astride', 'astrophysicist', 'asx', 'ateneo', 'auerbach', 'aut', 'autocracy', 'autosomal', 'awwww', 'balloting', 'bandar', 'baratheon', 'basset', 'baynes', 'beaton', 'bestiality', 'biracial', \"bitcoin's\", 'bixby', 'ble', 'blk', \"blue's\", 'bluray', 'blurs', 'blurted', 'bodice', 'bogdan', 'bozo', 'brac', 'brainy', 'braithwaite', 'bren', 'broach', 'broadbent', 'bromance', 'butane', 'bynum', 'cabbie', 'calcite', 'callan', 'candied', 'cantons', 'carbondale', 'castiel', 'celta', 'centrality', 'chamomile', 'childbearing', 'chippy', 'chives', \"chris's\", 'chua', 'citroen', 'clamor', 'classless', 'clink', 'cloaking', 'coastlines', 'coelho', 'cognate', 'coking', 'colombians', 'configuring', 'conifers', 'connoisseurs', 'consoling', 'contaminant', 'contrition', 'converges', 'correlating', 'cosa', 'counterclockwise', 'crevice', 'crewman', 'crockery', 'croke', 'crusts', 'cums', 'cusack', 'cushioned', 'cvd', 'dais', 'dalhousie', 'defector', 'deferring', 'degeneracy', 'delphine', 'demoralized', 'denali', 'devastate', 'diesels', 'dimming', 'disciplining', 'disloyalty', 'divested', 'dll', 'dmz', 'doers', 'dollop', 'donatello', 'dongle', 'donohue', 'dosed', 'doused', 'drapery', 'drawdown', 'dreadlocks', 'dreadnought', 'dregs', 'driveways', \"earl's\", 'edgerton', 'elissa', 'emptive', 'enablers', 'engendered', 'engined', 'entranced', 'escapades', 'escarpment', 'esperanto', 'eval', 'expedia', 'expos', 'extrinsic', 'fabrizio', 'facie', 'falcone', 'fantasizing', 'farid', 'farthing', 'fascinates', 'favs', 'feigning', 'fells', 'fenty', 'fett', 'fie', 'finality', 'flatbush', 'foldable', 'forebears', 'forestall', 'furthered', 'garlands', 'gatehouse', 'generalizing', 'gentlemanly', 'gesellschaft', 'gillett', 'giordano', 'gloat', 'glossed', 'glycerin', 'gog', 'goldeneye', 'goldilocks', 'goldmine', 'goodfellas', 'gorgon', 'gorillaz', \"grace's\", 'grayish', 'griezmann', 'gris', 'gros', 'groupies', 'gurl', 'gymnastic', 'h.g', 'h4', 'hahahah', 'handcuff', 'harbin', 'hardwired', 'harland', 'harpsichord', \"harris's\", 'hashish', 'hawaiians', 'hematology', 'hernández', 'heroically', 'highgate', 'hindenburg', 'hinkley', 'histogram', 'hmo', 'hokey', 'husain', 'hutu', 'hydrochloric', 'hydrochloride', 'iata', 'ibsen', 'iep', 'ies', 'impolite', 'inbetween', 'infringements', 'insomniac', 'installers', 'interlock', 'interventionist', 'ionian', 'ionized', 'irrelevance', 'italiano', 'itemized', 'ivanovic', 'jabba', 'javanese', 'jawline', 'jaylen', 'jell', 'jit', 'joann', 'kaiju', 'kaminsky', 'kanan', 'karts', 'kerouac', 'kilgore', 'kitt', 'koji', 'kyoko', 'lacroix', \"lake's\", 'langton', 'languishing', 'lauryn', 'laymen', 'layne', 'leandro', 'leathery', 'leclerc', 'libertarianism', 'lisle', 'lll', 'loam', 'lodi', 'lollipops', 'luger', 'lunges', 'lys', 'lytton', 'machu', \"maggie's\", 'maidenhead', 'malagasy', 'malfoy', 'malin', 'mammy', \"manning's\", 'manuela', 'marlo', 'marshalls', 'masque', 'masseuse', 'masson', 'matti', 'maulana', 'mayes', 'mcauliffe', 'mello', 'meltzer', 'mendocino', 'messer', 'meteorologists', 'metronome', 'metzger', 'mh000', 'mha', 'midrange', 'militaristic', 'mimicked', 'minimising', 'minnow', 'mirth', 'mitosis', 'mnemonic', 'mobilise', 'mofo', 'moonstone', 'morel', 'morey', 'moria', 'morningside', 'mothering', 'motorcyclists', 'natsu', 'naz', 'ndc', \"ned's\", 'neet', 'negotiates', 'nimbus', 'nog', 'notations', 'noyes', 'obscures', 'odis', 'ogilvie', 'oomph', 'ostracized', 'overvalued', 'overwork', 'pacman', 'paintbrush', 'passaic', 'patil', 'pcie', 'persecutions', 'pestering', 'pilkington', 'pivoting', 'pizzagate', 'plausibly', 'plebs', 'plucky', 'pocock', 'preposition', 'pretenses', 'privatised', 'proclamations', \"product's\", 'prohibitively', 'prost', 'proximate', 'puller', 'punctures', 'py', 'quadrupled', 'queasy', 'quiche', 'quips', 'qureshi', 'radley', 'rainstorm', 'rangel', 'rapprochement', 'rayleigh', 'reappearance', 'recompense', 'recuperating', 'redesigning', 'redlands', 'redraw', 'redrawn', 'refutation', 'remiss', 'remittance', 'renfrewshire', 'repudiated', 'resuscitate', 'reticent', 'reverie', 'revisionism', 'rewrites', 'rheumatism', 'rickman', 'rightwing', 'roused', 'ruble', 'ryerson', 'safeguarded', 'sakurai', 'santorini', 'sasaki', 'saya', 'schaeffer', 'schweinsteiger', 'scintillating', 'scribbling', 'scuttled', 'sectoral', \"see's\", 'selflessness', 'seong', 'sharapova', 'sharps', 'shauna', 'shimano', 'shinto', 'shrooms', 'shuddering', 'silken', 'slayers', 'slippage', 'slowness', 'slurred', 'smattering', 'snarl', 'snuggling', 'solvers', 'sook', 'sorbonne', \"soul's\", 'spawns', 'spongy', 'spx', 'sterilize', 'stewardess', 'stockholder', 'storefronts', 'storyboard', 'stragglers', 'stratigraphy', 'striding', 'strom', 'stunting', 'surcharges', 'surest', 'suriname', 'swe', 'sweety', 'taiga', 'tangier', 'tapioca', 'taskforce', 'telemedicine', 'tendrils', 'teng', 'texarkana', 'tfc', 'thani', 'thickest', \"three's\", 'ticklish', 'timestamp', 'tivo', 'tolerates', 'tomo', 'tradesman', 'traditionalists', 'trappers', 'tulle', 'turtleneck', 'tutsi', 'twats', 'uab', 'ugc', 'ula', 'ulm', 'umberto', 'unconvinced', 'underclass', 'underhill', 'undertone', 'undressing', 'unpopularity', 'unquestionable', 'unreadable', 'unwinding', 'urchins', 'ursa', 'vanquish', 'variegated', 'vedanta', 'vehement', 'vel', 'velma', 'videotapes', \"viewer's\", 'vikas', 'vinaigrette', 'walkman', 'wallop', \"walter's\", 'wcs', 'wea', 'weeknight', 'weenie', 'whet', 'whitehaven', 'wile', 'wilmot', 'wim', 'witten', 'wobbling', 'wowed', 'wps', \"wwe's\", 'xoxo', 'yamaguchi', 'yesteryear', 'ziggler', 'zipping', 'ã', '▶', '😫', '🚨', '🤷\\u200d♂️', 'aced', \"act's\", 'advantaged', 'afm', 'agarwal', 'agl', 'airspeed', 'ake', 'albus', 'allocates', 'alphas', 'altoona', 'amplifies', 'amply', 'anglophone', 'annealing', 'annexing', 'antecedents', 'antiretroviral', 'antithetical', 'antler', 'aoa', 'aoi', \"app's\", 'applegate', 'apprenticed', 'arb', 'aris', 'arma', 'arn', 'aromatherapy', 'arranger', 'asb', 'aspirated', 'atchison', 'atr', 'attestation', 'aways', 'aylesbury', 'ayurveda', 'babar', 'baptisms', \"bar's\", 'baraka', 'barbary', 'baudelaire', 'bb00', 'beached', 'beavis', 'beefing', 'belittling', 'bellini', 'bevel', 'birdsong', 'bizarro', 'blatt', 'blesses', 'blockaded', 'bly', 'bodhi', 'bookmaker', 'bradman', 'brava', 'brawling', 'breakouts', 'brezhnev', 'brin', 'brogan', 'bunyan', 'businesspeople', 'buzzword', 'cabbages', 'cacophony', 'caligula', 'capitalistic', 'caresses', 'carlsen', 'carnations', 'carruthers', 'carswell', 'cartoonists', 'castaway', 'catharine', 'cavanaugh', 'ccg', 'cenotaph', 'chafing', \"chairman's\", 'chambered', 'chibi', 'chibok', 'chink', 'chl', 'cip', 'circumscribed', 'cking', 'clack', 'clicker', 'collation', \"colombia's\", 'comings', 'commandeered', 'commemorations', 'commentating', \"competition's\", 'comprehending', 'confidentially', 'confining', 'confucianism', 'connectedness', 'conscripts', 'conservator', 'cooperates', 'cooperatively', 'copperfield', 'cou', 'counseled', 'covey', 'crewmen', 'crimp', 'cruces', 'cryo', 'curbed', 'customarily', 'dagestan', 'dartford', 'ddd', 'deactivation', 'debby', 'deductibles', 'deflate', 'demonize', 'dena', 'denunciation', 'dft', 'diazepam', 'discrediting', 'dished', 'dismount', 'diuretic', 'dnb', 'domini', 'doppelganger', 'dpa', 'drawbridge', 'drivin', 'drudge', 'drugging', 'duquesne', 'dwindle', 'décor', 'eckert', \"eddie's\", 'edp', 'effector', 'ellery', 'encapsulation', 'enchantress', 'encircle', 'env', 'eoin', \"epa's\", 'epistemological', 'erdoğan', 'etiology', 'evangelion', 'exonerate', 'expediency', 'exudes', 'eyesore', 'faceoff', 'facile', 'facilitators', 'fatherless', 'featherstone', 'feely', 'fertilize', \"field's\", 'fiennes', 'fittingly', 'flossing', 'fluted', 'fogarty', 'foreshore', 'foyle', 'français', \"fred's\", 'frederik', 'frightens', 'fruiting', 'fuk', 'gangbang', 'gascoigne', 'gasses', 'gawain', 'gazes', 'geneticist', 'genotypes', 'gert', 'gilly', 'gizmo', 'glycine', 'godot', 'goop', 'gorsuch', 'gregson', \"griffin's\", 'grimace', 'groggy', 'grt', 'guano', 'guava', 'guinean', 'gwinnett', 'gwyn', 'gwynn', 'hab', 'habsburg', 'haller', 'halliburton', 'halstead', 'hammocks', 'hamstrings', 'handbooks', 'hanzo', 'harford', 'haslam', 'hematoma', 'hew', 'hhh', 'hideo', 'histology', 'hitching', 'homewood', 'homogeneity', 'hoss', 'hossein', 'hotties', 'hoyle', 'huerta', 'huma', 'humanists', 'humbert', 'hummel', 'huntress', 'husks', 'ichigo', 'icrc', 'idiopathic', 'ige', 'ij', 'illini', 'immigrate', 'imparts', 'implacable', 'implicating', 'imprisoning', 'inclusiveness', 'indemnify', 'indiscretion', 'indulgences', 'infirm', 'inga', 'intermodal', 'intraday', 'ishikawa', 'itd', 'iwc', 'jackals', 'jaclyn', 'jailer', 'jamaat', \"jefferson's\", 'jharkhand', \"jin's\", 'joists', \"joke's\", \"jon's\", 'k.c', 'kanto', \"kanye's\", 'karabakh', 'keiko', \"keith's\", 'kenner', 'kennett', 'kerb', 'kiara', 'kidnaps', 'klingons', 'knott', 'kondo', 'kot', 'kwok', 'lacing', 'laidlaw', 'lambo', 'lanham', 'latches', 'ldr', 'lengthwise', \"lennon's\", 'lenore', 'leopoldo', 'linoleum', 'listeria', 'lockett', 'longview', 'lutherans', 'luxemburg', 'lyre', 'm.i.a', 'maas', 'maasai', 'magnanimous', 'magus', 'mammoths', 'manchurian', 'maniacal', 'manish', \"marie's\", 'marshawn', 'martel', 'materialist', 'matsumoto', 'maximizes', \"mccarthy's\", 'mccarty', 'mccauley', 'medica', 'meeker', 'metabolized', 'mewtwo', 'mfc', 'mickelson', 'micrograms', 'micronesia', 'mie', 'mikes', 'miniscule', 'ministering', 'miramar', 'miri', 'miro', 'miscalculation', 'misdirection', 'mlc', 'moc', 'modernised', 'modulating', 'monger', 'montpelier', \"montreal's\", 'mookie', 'morrell', 'mua', 'multicolored', 'multifamily', 'musing', 'mystified', 'narc', \"nat'l\", 'natchez', 'natwest', 'naya', 'necromancer', 'neh', 'neurobiology', \"newman's\", 'nics', 'nitride', 'noa', 'nobodies', 'norepinephrine', 'notional', 'nsaids', 'nuff', 'nuffield', 'obliging', 'observances', 'obverse', 'ocala', 'offing', 'offstage', 'oka', 'oooo', 'outkast', 'overlying', 'overridden', 'overruns', 'pacts', 'palatial', 'pappas', 'parley', 'parris', 'paucity', 'pauls', 'pavlov', 'peculiarly', 'peddler', 'pelagic', 'peppa', 'pepsico', 'persecuting', 'persephone', 'phds', 'phenomenally', \"philosopher's\", 'phonics', 'phs', 'physiologically', 'pilgrimages', 'pithy', 'pittance', 'placental', 'plastering', 'plex', 'plop', \"poe's\", 'portobello', 'prancing', 'preclinical', 'primark', 'prisms', 'prowling', 'puccini', 'pujols', 'pulleys', 'pullover', 'pye', 'r.c', 'rafi', 'rapp', 'rarities', 'raster', 'rau', 'razak', 'reassessment', 'recharged', 'reconfigured', 'reeled', 'registrant', 'rehabilitating', 'reimer', 'rekindled', 'renouncing', 'repaint', 'reprocessing', 'repulsion', 'resistive', 'resurgent', 'rfp', \"rihanna's\", 'rika', 'rma', \"rob's\", \"romania's\", \"ronaldo's\", 'ronson', \"roosevelt's\", 'rosita', 'rothman', 'roxas', 'rubbery', \"ruby's\", \"ruth's\", 'sagas', 'salamanders', 'sameer', 'sandia', 'sashimi', 'sauber', 'sayed', 'scalding', 'sceptre', 'schmitz', 'scoundrels', 'scrambles', 'seacrest', 'seasonings', 'seditious', 'segway', 'selangor', 'senor', 'serviceman', 'seti', 'sfr', 'shinjuku', 'shopify', 'shorting', 'shortsighted', 'shunning', 'silverstein', 'simona', 'sinker', 'skyfall', 'slates', 'smartass', 'snodgrass', 'sono', 'sophocles', 'soren', 'sortie', 'sotomayor', 'standish', 'starburst', 'statist', 'statuette', 'steppes', \"steven's\", 'storeroom', 'strumming', 'sua', 'subban', 'sucky', 'suiting', 'supersedes', 'swamy', 'swig', 'takeovers', 'tangles', 'tash', 'tass', 'taxidermy', 'taylors', 'tenner', 'texaco', 'thankless', 'thorin', 'thos', 'throwers', 'tightest', 'tillerson', 'tisdale', 'titian', 'todos', 'toiled', 'tomes', 'toots', 'trainor', 'triceps', 'tropez', 'tsui', 'ttp', 'tts', 'unapologetically', 'unappealing', 'uncivilized', 'underwritten', 'undoubted', 'unpatriotic', 'unrepentant', 'unsee', 'untidy', 'ural', 'useable', 'ushering', 'vassar', 'veep', 'velodrome', 'vevo', 'viewable', 'visionaries', 'vitals', 'waaaay', \"warrior's\", 'washable', 'washy', 'waterproofing', 'watters', 'waveguide', 'weaponized', 'wearers', 'weill', 'welders', 'werk', 'wetness', 'wheelers', 'wierd', 'wiggling', 'wilfried', 'wince', 'winemaking', 'wn', 'wnt', 'womanizer', 'woodbine', 'wreaking', 'wrecker', 'wrenches', 'xa', 'yulia', 'zayed', 'zealander', 'zuckerman', '͜', '4x000', '8b', '9k', 'aachen', 'abn', 'abrasions', 'acetylcholine', 'aco', 'actives', 'adherent', 'adulation', 'adverbs', 'aforesaid', 'afridi', 'agr', 'ahmadi', 'airlifted', \"alan's\", 'aleksandar', \"ambassador's\", 'amines', 'amniotic', 'amulets', 'amusements', 'antecedent', 'antiwar', 'aphasia', 'aphrodisiac', 'apm', 'aristotelian', 'arsenals', 'arteta', 'astley', 'astrophysical', 'asunder', 'aum', 'automating', 'ayy', 'b.v', 'backstabbing', 'backstop', 'bauhaus', \"bee's\", 'begets', \"belgium's\", 'bernanke', 'bevin', 'bharti', 'bibliographies', 'bimonthly', 'binocular', 'bioethics', 'birdy', 'birkenhead', 'birkin', 'biter', 'blatter', 'bldg', 'bloat', 'boden', 'boers', 'bolus', 'botanists', 'breakin', 'bretton', 'breyer', 'brightens', 'briskly', 'bruiser', 'brunel', 'brutes', 'bubonic', 'buggers', 'bulger', 'burgos', 'burj', 'bursa', 'bushels', 'busta', 'bylaw', 'c9', 'cabello', 'cached', 'caddie', 'caplan', 'carrillo', \"carroll's\", \"castro's\", 'caterers', 'cations', 'cellophane', 'cept', 'cera', 'chaining', 'channelled', 'chiara', 'chiron', 'choker', 'chrysalis', 'chums', 'cialis', 'clamour', 'clarice', 'claudette', 'clenching', 'clumsily', 'cmv', 'codename', 'cofounder', 'collectives', 'colonizing', 'compressive', 'condoning', 'convalescent', 'costal', 'couscous', 'crassus', 'cristal', 'critiqued', 'croker', 'crompton', 'crone', 'crystallography', 'cupping', 'dabbling', 'dabs', 'dampers', 'dayz', 'decoys', 'decry', 'deferral', 'delisted', 'desc', 'desoto', 'deviantart', 'dirtbag', 'dirtier', 'disavow', 'discordant', 'dismounted', 'distrustful', 'dmg', \"doll's\", 'downy', 'dragonball', 'dru', 'dsi', 'dualism', 'duplicating', 'durante', 'dwp', 'e.j', 'eazy', 'ecr', 'egon', 'elegans', 'embittered', 'emissaries', 'encyclopedias', 'endangers', 'enugu', 'epithets', 'esse', 'estimations', 'eunuchs', \"eve's\", 'evidentiary', 'ewen', 'exalt', 'executors', 'exoplanets', 'fairground', 'fairytales', 'fancier', 'fatherly', 'faultless', 'feedstock', 'fending', 'fistula', 'fjords', 'flemming', 'foxtrot', 'frith', 'frizzy', \"gabriel's\", 'garbled', 'garfunkel', 'gaskets', 'geert', 'generale', \"get's\", 'ginn', 'gla', 'godin', 'gpo', 'grimshaw', 'gronk', 'gsw', 'gulfstream', 'gyu', 'h.s', 'hachette', 'hadoop', 'hallucinogenic', 'halve', 'hamer', 'handfuls', 'harlot', 'harpers', 'headbutt', 'heathcote', 'hebei', 'hecht', 'heckler', 'heifer', \"henderson's\", 'hendrickson', 'hezekiah', 'hmas', 'hoards', 'holger', \"homer's\", 'hoosiers', 'hsi', 'hued', 'humbug', 'hydrological', 'i.v', 'icf', 'icm', 'imc', 'ime', 'impetuous', 'inadequately', 'inconvenienced', 'indignity', 'indisputably', 'indoctrinated', 'inflorescence', 'infowars', 'injectable', 'inky', 'inlets', 'innsbruck', 'interactivity', 'interdiction', 'intros', 'isl', 'jarred', 'jasmin', 'jaunt', 'jawaharlal', \"job's\", 'jointed', \"joker's\", 'joong', 'jutting', 'kawaii', 'kayaks', 'keeley', 'keisha', \"kerry's\", 'khans', 'kindergartens', 'kneels', 'knits', 'kph', 'kyo', 'ladbrokes', \"lane's\", 'laszlo', 'laud', 'leavin', 'legation', 'leh', 'letterhead', 'levis', 'levity', 'lichtenstein', 'lidl', 'likud', 'limped', 'liquors', 'loh', 'lombardy', 'lorentz', 'louse', 'lsat', 'lucha', 'luciana', 'lucked', 'lugo', 'luhansk', 'maarten', 'mab', 'magick', 'malayan', 'malfeasance', 'mandeville', 'markey', 'markle', 'martinis', 'massaged', 'massif', 'mattingly', 'mccracken', 'mechanistic', 'meijer', 'mementos', 'mercado', 'mezzo', 'mightiest', 'mii', 'millenium', 'millimetre', 'minnows', 'mino', 'misappropriation', 'mishandling', 'misinterpret', 'misstep', 'mitsui', 'mmc', 'moguls', 'mohamad', 'montauk', 'moorhead', 'morello', 'motherfuckin', 'mowers', 'multichannel', 'mummified', 'musik', 'nacl', 'nagano', 'narcissists', 'narrators', 'natura', 'nawab', 'nct', 'nederland', 'neu', 'newington', 'newness', 'newsreader', 'nipping', 'nona', 'nontraditional', 'nori', \"o'brien's\", 'octavian', 'oddest', 'olmsted', 'olympiad', 'optimise', 'oration', 'ordinates', 'orrin', 'ousting', 'overseers', 'oxidizing', 'paneling', 'panelled', 'pangs', 'pape', 'paribas', 'paschal', 'passivity', 'paterno', 'pcl', 'pec', 'peeks', 'percussive', 'perdue', 'phosphatase', 'pickets', 'piezoelectric', 'piglets', 'pinches', 'pir', 'pittsfield', 'plessis', 'plies', 'plinth', 'plos', 'pmc', 'polishes', 'polypeptide', 'postulate', 'presidio', 'priors', 'probiotic', 'productively', 'propylene', 'prosaic', 'proscribed', 'prosecutorial', 'pyrotechnics', 'qos', 'quacks', 'quandary', 'quietest', 'quipped', 'rabat', 'radisson', 'rajya', 'rationalism', 'rears', 'rebut', 'reclassified', 'reconnecting', 'redondo', 'refiners', 'reheat', 'reinhard', 'reinhart', 'reinvest', 'remorseful', 'renée', 'repackaged', 'repented', 'reprogramming', 'restocking', 'reticence', 'reversion', \"rey's\", 'rhinestone', 'riemann', 'rittenhouse', 'roundabouts', 'rspca', 'rubinstein', 'rutter', 's.i', 'saipan', 'saladin', 'saleem', 'sandown', 'sapphires', 'saran', 'scrip', 'scruff', 'scurrying', 'seafaring', 'sepp', 'sexiness', 'señora', 'shania', 'shaquille', 'sheaf', 'shipwrecks', \"shooter's\", 'siesta', 'sikkim', 'sinhalese', 'skoda', 'slp', 'sniffer', 'snobs', \"snyder's\", 'socialise', 'sociopathic', 'sociopaths', 'sof', 'speedometer', 'splints', 'spoofing', \"squad's\", 'squalid', 'staves', 'stillman', 'stockwell', 'stringed', 'strollers', 'strolls', 'styx', 'submerge', 'subordination', 'summarise', 'sunnah', 'surfactant', 'surry', 'survivability', 'sweltering', 'swooping', 'sz', 'tahrir', 'tannins', 'tanto', 'tarn', 'tater', 'taxicab', 'tdp', 'tedx', 'telluride', 'telus', 'tenements', 'thanet', 'themself', 'theyve', 'thule', 'thunk', 'tiber', 'tigger', 'tints', 'tokugawa', 'tonk', 'trevelyan', 'ttt', 'tupelo', 'ulta', 'unabashed', 'unencumbered', 'unfilled', 'unionization', 'unjustifiable', 'unnaturally', 'uttarakhand', 'uwu', 'vann', 'vazquez', 'vegetarianism', 'verstappen', 'vey', 'vicarious', 'villainy', 'virtuosity', 'virulence', 'vishal', 'vix', 'vizier', 'vries', 'waa', 'wali', 'walkable', 'walling', 'warmers', 'westbury', 'whimsy', 'whitcomb', 'wicca', 'willett', 'wilted', 'winging', 'wolfpack', 'worf', 'workpiece', 'wormwood', 'wrangle', 'x0000', 'x6', 'youngblood', 'yucatan', 'zander', 'zeller', 'zhi', 'zircon', 'zora', '✨', '2v2', '3e', \"6'2\", \"6'4\", 'aaaa', 'abated', 'abernathy', 'accrediting', 'aci', 'acoustical', 'advil', 'afflictions', 'afterall', 'aggregating', 'agitator', 'albedo', 'alcott', 'alisha', 'allyson', 'alun', 'alway', 'amateurish', 'anaphylaxis', 'ando', 'angelus', 'angora', 'anyplace', 'aos', 'appetizing', 'applicator', \"arby's\", 'arsonist', 'artichokes', 'ashlee', 'aslam', 'asmr', 'asquith', 'assemblages', 'augmenting', 'axons', 'babbitt', \"bach's\", 'ballin', \"baltimore's\", 'banc', 'barnacles', 'bast', 'beekeepers', 'benteke', 'berta', 'bests', 'beulah', 'biafra', 'biologic', 'bjj', 'blackfish', 'bleacher', 'blizzards', 'bloodiest', 'bloodshot', 'bnb', 'boku', 'bolognese', 'bolstering', 'brawls', 'bronchial', 'brownstone', 'buffered', 'burgoyne', 'burka', 'butterscotch', 'byung', 'caballero', 'caboose', 'caesarean', 'cair', 'calcareous', 'callus', 'cally', 'capella', 'capote', 'carmarthenshire', 'carotene', 'carpark', 'cartoonish', 'cassell', 'cesarean', 'chaim', 'chalets', \"champion's\", 'characterizations', 'cherub', 'chiswick', 'chula', 'clearinghouse', 'cleve', 'coaxed', 'colloidal', 'colville', 'commited', 'conceptualize', 'concurrency', 'confidante', 'conifer', 'consumable', 'convener', 'coogan', 'corker', 'corroborating', 'corsa', 'cours', 'courtenay', 'courtly', 'cupertino', 'cutlass', 'cutouts', 'cvt', 'cybernetics', 'cymbal', 'dabbing', 'dachau', 'dalits', 'darjeeling', 'daydreams', 'deccan', 'decriminalization', 'dejan', 'delmar', 'demar', 'demarcus', \"demon's\", 'demoralizing', 'denigrate', 'dennison', 'derrida', 'despatches', 'detonator', \"developer's\", 'devereux', 'diametrically', 'dian', 'dirac', 'dissing', 'disuse', 'dmt', 'donal', 'dore', 'dorks', 'douse', 'downgrading', 'dozing', 'dramatized', 'drinkable', 'drooping', 'ecologists', 'edin', 'edson', 'elam', 'eller', 'embarassing', 'embellishments', 'emg', 'emigrating', 'empathic', 'energizing', 'engl', 'enumeration', 'epo', 'epson', 'esme', 'evocation', 'excepted', 'existentialism', 'exterminator', 'extinguishing', 'extradite', 'extrapolated', 'extricate', 'falsifying', 'farmville', 'faro', 'fassbender', 'fastener', 'fatale', 'fedor', 'fibula', 'fidget', 'filesystem', 'flexion', 'flippant', 'floater', 'fondue', 'forerunners', 'fretted', 'fuelling', 'g.m', 'gallardo', 'galt', 'galvin', 'ganglia', 'ganglion', 'gare', 'geeta', 'geographies', 'geospatial', 'geranium', 'geun', 'ghanaians', 'gilberto', 'gingerly', 'glared', 'glick', 'goalposts', 'godaddy', 'goer', 'goldsmiths', 'gowdy', 'gpm', 'gratified', 'groucho', 'grouchy', 'grownup', 'guaranty', \"guardian's\", 'gusty', 'h.m', 'haber', 'hagar', 'hagerstown', 'harmonizing', 'heaviness', 'hedonism', 'heirlooms', 'hereof', 'heretofore', 'hillsdale', 'hopewell', 'horoscopes', 'hospitalizations', 'hov', 'hs2', \"huntington's\", 'i.t', 'i8', 'ichiro', 'immemorial', 'inequity', 'ines', 'inflected', 'infotainment', 'ingalls', 'ingersoll', 'inna', 'insinuate', 'inspects', 'interludes', 'iodide', 'irishmen', 'iva', 'ivana', 'iwatch', 'jacobite', 'jeffers', \"jesse's\", 'jindal', 'jodhpur', 'johnsons', 'johor', 'jolene', \"joyce's\", 'juana', 'juiced', 'jumpstart', 'kabuki', 'karol', \"kellogg's\", 'kennedys', 'kindling', 'knell', 'koehler', 'kroll', 'laboring', 'ladakh', 'lannisters', 'laparoscopic', 'laurier', 'leer', 'legume', 'lemurs', 'linesman', 'lipa', 'ljubljana', 'locum', 'logie', \"long's\", 'lpc', 'lum', 'lunged', 'madder', 'mailboxes', 'malign', 'maliki', 'maltreatment', 'mandrake', \"mao's\", 'marburg', 'marinate', 'marque', 'martín', \"marx's\", 'mashable', 'maurer', 'mcghee', 'mcloughlin', 'mcnabb', 'mcveigh', 'meltdowns', 'memorization', 'mems', 'merida', 'merthyr', 'mh00', 'middlebury', 'millisecond', 'misdirected', 'missteps', 'mockingjay', 'moiety', 'moline', \"molly's\", 'montreux', 'montserrat', 'mornington', 'morsel', 'mq', 'mucho', 'mugshot', 'mukesh', 'muncie', 'mundi', 'murillo', 'murthy', 'mythbusters', 'n.b', 'nabokov', 'naia', 'naperville', 'nary', 'nasi', 'nasr', 'nastiest', 'nei', 'newburgh', 'newsflash', 'nilly', 'nlp', 'nocturne', 'nongovernmental', 'nooks', 'nostra', 'nudging', 'oems', 'oma', 'ombre', \"operator's\", 'optimizations', 'oran', 'ors', 'osc', 'oxycodone', 'pacheco', \"page's\", 'paleolithic', 'paraphrased', 'parisians', 'passageways', 'passersby', 'patrolman', 'peacekeeper', 'peake', 'penzance', 'perlman', 'perot', 'pert', 'petco', 'petraeus', 'picchu', 'pillaging', \"plaintiff's\", 'platoons', 'playmates', 'pma', 'pollsters', 'populists', \"portland's\", 'practises', 'prat', 'pratchett', 'predate', 'predominate', 'prelims', 'presumes', 'principalities', 'printout', 'prodded', 'profiler', 'proofread', 'prophylactic', 'prophylaxis', 'pseudomonas', 'psh', 'ptv', 'pullout', 'puppeteer', 'purist', 'purposed', 'radiography', 'rajput', \"raven's\", 'raúl', 'readied', 'recherche', 'reiki', 'reimbursements', 'reopens', 'repairman', 'rescuer', 'resurrecting', 'revolutionizing', 'rialto', 'ridgeway', 'ringleader', 'riverview', \"road's\", 'rococo', 'rodolfo', 'rong', 'rottweiler', 'rq', 'ruhr', 'rukh', 'rumblings', 'runescape', 's.r', 'sandbags', 'sandeep', 'sapporo', 'sauer', 'scalping', 'scantily', 'scarlets', 'schmid', 'scsi', 'scurry', 'sebastien', 'secessionist', 'sedona', 'semites', 'sepals', 'serengeti', 'serialized', 'shader', 'shakin', 'shaper', 'sharkey', 'shaykh', 'sheamus', 'shekhar', 'sidestep', 'sieges', 'sinbad', 'slaw', 'smirked', 'smokescreen', 'snide', 'snohomish', 'snowballs', 'societe', 'solider', 'sov', 'sowed', 'sows', 'sprocket', 'squabble', 'squabbling', 'squeaking', 'sra', 'stapled', 'starbuck', 'starkey', 'startin', 'statins', 'steeplechase', 'steffen', 'sternly', 'stopwatch', 'stranglehold', 'stratospheric', 'streetwear', 'subcultures', 'subfamily', 'succulents', 'sulphate', 'superposition', 'suprise', 'sylvain', 'sympathizer', 'symposia', 'synchro', 'tachycardia', 'tactful', 'tafe', 'takeshi', 'tamarind', 'tapers', 'tarte', 'teared', 'telco', 'tete', 'theism', 'theocracy', 'theoretic', 'thun', 'tilley', 'tobi', 'toenail', 'toh', 'toussaint', 'tpc', 'tracers', 'trafficker', 'transducers', 'transfiguration', 'transphobia', 'trellis', 'tropicana', 'truthfulness', 'tryptophan', 'twd', 'typescript', 'tyrannosaurus', 'ulf', 'ullman', 'unblocked', 'undersized', 'understaffed', 'unexplainable', 'unflinching', 'uninhibited', \"universe's\", 'unmodified', 'unpretentious', 'unprocessed', 'unseat', 'urbanism', 'uriel', 'usurper', 'vagaries', 'vamps', 'vermouth', 'verna', 'vespa', 'vesta', \"victor's\", 'videographer', 'viewfinder', 'vonnegut', 'w.e', 'waikato', 'wanking', 'watchdogs', 'watchmaker', 'wawrinka', 'whe', 'whitefish', 'whittington', 'whoring', 'wiccan', 'wishy', 'wojciech', 'workbench', 'worksheets', 'wriggle', 'wrs', 'yama', 'yardley', 'yat', 'yearns', \"yemen's\", 'yoyo', 'yumi', 'zoë', 'état', '3t', '3x3', '4h', 'aaliyah', 'aarhus', 'abdicated', 'abm', 'acceded', 'accruing', 'acquit', 'adjuvant', 'admixture', 'adopter', 'afa', 'aftershock', 'agence', 'airshow', 'albumin', 'algernon', 'aline', 'amaya', 'ambiguities', 'amirite', 'amuses', 'anchovy', 'anguished', 'antagonize', 'antalya', 'anthracite', 'appa', 'apparitions', \"applebee's\", 'appt', 'ariadne', 'arjuna', 'artifice', 'aryans', 'ashburn', 'asides', 'aspergillus', 'assistive', 'audibly', 'ayurvedic', 'baldy', 'balthazar', 'bartley', 'batons', 'batshit', 'beardsley', \"beck's\", 'begining', 'beni', 'betcha', 'bidet', 'bingley', 'biophysics', 'biscayne', 'blacksmiths', 'blobs', 'bluster', 'boc', 'bodes', 'bodie', 'bookworm', 'bowyer', 'braga', 'bratton', 'brut', 'bruyne', 'bsn', 'buell', 'bung', 'bungie', \"burke's\", 'burqa', 'bursary', 'butted', 'c.a', 'cae', 'caffeinated', 'calvinism', 'cannery', 'canvassed', 'capra', 'captioning', 'carcinogen', \"carey's\", 'carters', 'cased', 'catamaran', 'cates', 'catheters', 'caucasians', 'cavill', 'cdna', 'ceding', 'celled', 'changeling', 'chargeable', 'chastain', 'chatroom', 'cheadle', 'checkin', 'checklists', 'cheri', 'chieftains', 'chil', 'choreographers', 'christo', 'clasped', \"clerk's\", 'clo', 'cmb', 'coauthor', 'cocos', 'colson', 'comming', 'constantin', 'cookware', 'cooperstown', 'copacabana', 'cordell', 'corduroy', 'corky', 'corleone', 'coroners', 'corsets', 'cortland', 'counterculture', 'crandall', 'criminalize', 'crocheted', 'crummy', 'crusading', 'curating', 'curries', 'customizing', 'cyrano', 'dandenong', 'daniele', 'darla', 'darted', 'datacenter', 'decryption', 'degrasse', 'dembele', 'demean', 'deming', 'dempster', 'depaul', 'deterring', 'detoxification', 'deutschen', 'diatribe', 'dinar', 'dionne', 'diplomatically', 'disassemble', 'discards', 'discontinuing', 'disparage', 'disqualifying', 'ditty', 'dockers', 'dogfight', 'dordrecht', 'downers', 'downfield', 'downsized', 'dramatists', 'droll', 'drudgery', 'drupal', 'ducats', 'dulwich', 'dumbasses', 'durian', 'díaz', 'e6', \"edinburgh's\", 'edl', 'edvard', 'egerton', 'electrocution', 'elkhart', 'emoluments', 'endometrial', \"energy's\", 'enright', 'erg', 'eucharistic', 'eusebius', 'excised', 'executioners', 'exhortation', 'exoplanet', 'exteriors', 'f8', 'fader', 'fallopian', \"federation's\", 'feign', 'fermanagh', 'fistful', 'fj', 'flamed', 'flatulence', 'flavia', 'flowchart', 'foetal', 'forgetfulness', 'fou', 'freshers', \"freud's\", 'fujian', 'gaithersburg', 'garish', 'gba', 'gdi', 'geodetic', 'gian', 'gib', 'gilding', 'globalism', 'gluing', 'googly', 'gorham', 'greenbrier', 'gremlins', 'gringo', 'gunslinger', 'haan', 'hampering', 'hansard', 'harps', 'hashing', 'hayman', 'hayne', 'headspace', 'healthily', 'hedonistic', 'hegemonic', 'hehehe', 'hellboy', 'hemming', 'hesitates', 'hina', 'histological', 'hoaxes', 'hobbled', 'hodder', 'hooch', 'hsiao', 'hysterics', 'ibf', 'incas', 'incriminate', 'infill', 'inflame', 'injurious', 'integrator', 'interminable', 'interrogator', 'inthe', 'irks', 'irrigate', 'itty', 'januzaj', 'jigs', 'jinn', 'jura', 'kanawha', 'keratin', 'keurig', \"key's\", 'kidder', 'kinases', 'koichi', 'kom', 'kooky', \"lab's\", 'lances', 'lansbury', 'larue', 'lauda', 'laureates', 'leaker', 'ledgers', 'leery', 'legislating', 'lepers', 'lessee', 'lethbridge', 'lettres', 'levees', \"li's\", 'lif', 'lobed', 'lodger', 'loew', 'lolol', 'lora', 'loveland', 'lubricating', 'lumley', 'magnetized', 'manon', 'marcella', \"mario's\", 'marple', 'massie', 'mastiff', 'mcewan', 'mcp', 'mediates', 'megadeth', 'mehr', 'melodious', 'microfinance', 'middleware', 'midori', 'midshipman', 'miffed', 'miho', 'minna', 'minot', 'mismanaged', 'mistral', 'mockingly', \"monkey's\", 'mook', 'morbidly', 'moresby', 'mucking', 'mudd', 'murano', 'muskegon', 'mvps', 'naan', 'naivety', 'nama', 'nanda', 'nastiness', 'nazarene', 'nem', 'newcomb', 'newsstand', \"nhl's\", 'nibbles', 'nonchalantly', 'normals', 'northwood', 'novartis', 'novgorod', 'nya', 'occasioned', 'occupier', 'odette', 'oki', \"oklahoma's\", 'omo', 'onetime', 'onondaga', 'orthography', 'ould', 'ovate', 'overflowed', 'overtakes', 'p.i', 'pageantry', 'parallelism', 'pba', 'peasy', 'pecans', 'penitent', 'pentagram', 'pettigrew', 'phe', 'philistine', 'phlegm', 'photonic', 'pianists', 'picketing', 'pka', 'poacher', 'poco', 'pomeranian', 'poon', 'possessor', 'precept', 'precipitous', 'previewed', 'prioritization', 'profiteering', 'proofreading', 'prospectors', 'prosser', 'prude', 'purifier', 'qiu', 'quartets', 'queers', 'quenching', 'r6', 'racecar', 'radioed', 'raglan', 'ramone', 'rampaging', 'randomised', 'rapier', 'ravage', 'readjust', 'realizations', 'reams', 'redirection', \"reese's\", 'reinvested', 'repeaters', 'reputedly', 'residencies', 'ridiculing', 'rifling', \"right's\", 'riverbed', 'robespierre', \"ron's\", 'rood', 'roundly', 'roz', 'rummaging', 'ryde', 'sacramental', 'sainsbury', 'sanctimonious', 'sardonic', 'sate', 'scabs', 'schafer', 'scunthorpe', 'sda', 'sdr', 'seabrook', 'sequencer', 'shittiest', 'shultz', 'siddiqui', 'sieg', 'siem', 'signers', 'sinead', 'singed', \"skin's\", 'sle', 'sledding', 'snowboarders', 'snowdon', 'soaks', 'socialising', 'solidifying', 'solvable', 'sonatas', 'sone', 'sororities', 'sorrel', 'southwards', 'spanner', 'speakeasy', 'specialisation', 'spenser', 'spiritualism', 'srinivasan', 'sry', 'staccato', 'staid', 'steadman', 'steyn', 'stilettos', 'stormtrooper', 'strang', 'stubhub', 'subatomic', 'subclasses', 'subscribes', 'suharto', 'sulking', 'sunnyside', 'tallulah', 'tannehill', 'tastings', 'tatters', 'tayyip', 'tenderloin', 'thoroughfares', 'thunders', 'thymus', 'tidewater', 'timberland', 'tomcat', 'tomkins', 'tornados', 'tramps', 'transcribing', 'transcriptions', 'ttl', 'uml', 'unappreciated', 'uncaring', 'uncharacteristic', 'uncommonly', 'undercooked', 'unplayable', 'usefully', 'uts', 'vagueness', 'valerian', 'vexing', 'virginians', 'vivaldi', 'vivi', 'vocab', 'voicemails', 'wac', 'waddle', \"wade's\", 'waded', 'watchable', 'wayyy', 'wherewithal', 'whined', 'wirth', 'wombat', 'woolsey', 'workweek', \"yang's\", 'yanking', 'yearned', 'zain', 'zooey', 'zuko', '♥️', '😐', '2l', '7c', 'aaaah', 'abominations', 'absenteeism', 'acrylics', 'adventuring', 'aew', 'aficionado', 'ajar', 'albury', 'alene', 'allegra', 'anguilla', 'anjou', 'annalise', 'anova', 'antipsychotic', 'apl', 'apogee', 'aquatics', 'arora', 'arrayed', 'articulates', 'ashy', 'auc', 'backboard', 'bancorp', 'bandstand', 'banyan', 'bara', 'barnyard', 'basf', 'batt', 'bau', 'bazar', 'bbm', 'bcm', 'beaulieu', 'begrudge', 'belatedly', 'benadryl', 'bernd', 'biggar', 'bioavailability', 'biogas', 'biosciences', 'bisexuals', 'bishopric', 'blackhawk', 'blacking', 'blimey', 'blitzer', 'bolting', 'bookish', 'bookshops', 'bosphorus', 'brainiac', 'brasilia', 'brevard', 'brioche', 'brutish', 'buddhas', 'bui', 'bukit', 'buller', 'bushing', 'busily', 'butlers', 'byline', 'calamari', 'cami', 'cannabinoids', 'captor', 'carlotta', \"carpenter's\", \"carr's\", 'carsten', 'cashman', 'caterina', 'caw', 'cci', 'ceaseless', 'charli', 'charmingly', 'childhoods', 'chinchilla', 'chrysanthemum', 'cobham', 'codenamed', 'cognitively', 'coining', 'collette', 'coms', 'concertos', 'concubines', 'conflagration', 'congenial', 'consoled', 'constriction', 'cookers', 'coppers', 'corks', 'coutts', 'coverup', \"cox's\", 'creampie', 'credibly', 'cringed', 'crozier', 'crunched', 'cso', 'csv', 'csx', 'cumulus', 'cytotoxic', 'daedalus', 'dcc', 'debussy', 'decathlon', 'deflections', 'defrauding', 'depressant', 'derangement', 'derp', 'despotic', 'devito', 'disallow', 'discriminates', 'disgustingly', 'disulfide', 'dnp', 'doctorates', 'doghouse', 'dottie', 'doubleheader', 'drakes', 'drg', 'drivetrain', 'dropper', 'druze', 'dvorak', 'dysphoria', 'eclipsing', 'educations', 'einar', 'elks', 'emin', 'employability', 'enchant', \"engineer's\", 'engle', 'entanglements', 'equalize', 'esau', 'eschew', 'etude', 'exhaled', 'expanses', 'expansionist', 'expressionism', 'externalities', 'extractive', 'extrovert', 'fabius', 'faints', 'fata', 'feeney', 'fendi', 'fics', 'figment', \"finn's\", 'firmament', 'fleck', 'flipside', 'floodwaters', 'floundering', 'fondant', 'foolhardy', 'fortaleza', 'fossa', 'fredo', 'freeware', 'furrow', 'gaffer', 'gaiety', 'galleon', 'gama', 'garnier', 'gauguin', 'geico', 'geist', 'generically', 'genitive', 'geoscience', 'girders', 'giveth', 'glenelg', 'globalized', 'glycerol', 'glycoprotein', 'godolphin', 'gooding', 'granary', 'graveyards', 'gravitas', 'greenback', \"greg's\", 'grenfell', 'grieves', 'grimly', 'grooved', 'grosses', 'grownups', 'gutless', 'hak', 'hanes', 'harrods', 'hayashi', 'haywire', 'heaney', 'hendrik', 'heredity', 'hermosa', 'hibernating', 'highbury', 'hing', \"ho's\", 'hobbyist', 'hocus', 'hollins', 'horvath', 'hosea', 'hsien', 'hymen', 'ices', 'idgaf', 'impairs', 'inaccurately', 'inadequacies', 'inaugurate', 'inching', 'inexhaustible', 'inexorable', 'inferring', 'infinitive', 'ingots', 'inoculated', 'inoue', 'instinctual', 'intangibles', 'intersected', \"iowa's\", 'irena', 'irfan', 'irregularity', 'irv', 'isco', \"islam's\", 'issac', 'j.h', 'janeway', 'jaye', 'jepsen', 'jessi', 'jogged', 'juli', 'kamloops', 'kandy', 'kaoru', 'kazuo', 'kempton', \"ken's\", 'kenilworth', 'khun', 'knead', 'kno', 'kop', 'landmines', 'laney', 'lanza', \"larry's\", 'latinas', 'latour', 'lav', 'leapfrog', 'lemur', 'leyton', 'lieut', 'liken', 'linker', 'lismore', 'littlefield', 'loons', 'lovemaking', 'lovren', 'lugging', 'lululemon', 'lumens', 'lurked', 'magnetically', 'magnetite', 'malcom', 'malfunctioned', 'malo', 'mance', 'maneuvered', 'mappings', 'marauder', 'maribor', 'marksmanship', 'masood', 'masterfully', 'maurizio', 'mawr', 'maximising', 'mcenroe', 'mcmurdo', 'meath', 'merv', 'metalcore', 'metastases', 'meu', 'militarization', 'minimization', 'missa', 'mitchel', 'mitral', \"monk's\", 'montmartre', 'morata', 'moribund', 'mortensen', 'mose', 'muda', 'mulatto', 'multicast', 'mumbo', 'musicianship', 'napster', 'narco', 'nci', 'needlework', 'nematode', 'neurosis', 'nevins', 'newhouse', 'newlywed', 'nicolson', 'nicosia', 'nominative', 'nono', 'northland', 'nougat', \"novel's\", 'npt', 'nss', 'nullification', 'numeracy', 'nuptial', 'oban', 'obligate', 'obstetric', 'octaves', 'odeon', 'okanagan', 'oldfield', 'olsson', 'oppressing', \"order's\", 'outerwear', 'outflows', 'overdoing', 'overhauling', 'overwhelms', 'ows', 'oxon', 'pacification', 'palme', 'palos', 'paradis', 'parlay', 'penalised', 'peony', 'perceptible', 'perches', 'perinatal', 'permanente', 'personalization', 'persson', 'perusing', 'pester', 'petey', 'phonetics', 'piet', 'pika', \"pittsburgh's\", 'plodding', 'pluralistic', 'pocus', 'poetical', 'poltergeist', 'ponders', 'poops', 'potro', 'pounced', 'powerplant', 'preorders', 'printmaking', \"producer's\", 'promissory', 'pruned', 'publ', 'pushers', 'pyke', 'pythagorean', 'qualitatively', 'quant', 'quinnipiac', 'ragtime', \"rat's\", 'rawlins', 'rba', 'reassures', 'rebar', 'recliner', 'reconfigure', 'recreations', 'redemptive', 'redevelop', 'redwoods', 'refuelling', 'refurbish', 'reimagining', 'remodelling', 'remoteness', 'resonances', 'resonating', 'retold', 'retry', 'rhesus', 'rickard', 'ricoh', 'ridgway', 'riesling', 'rikki', 'rosenbaum', 'royalists', 'rudyard', \"s'mores\", 'sacco', 'sadism', 'sagar', 'saki', 'salicylic', 'sandringham', 'sanitized', 'sarandon', 'saturate', 'schatz', 'scipio', 'scrupulous', 'seagate', 'sealer', 'sectarianism', 'semicircular', 'sez', 'shana', 'shashi', 'sheri', 'shootin', 'shortcoming', 'showmanship', 'sids', 'sifted', 'skydive', 'sleds', 'smock', 'smudged', 'sna', 'sniffs', 'snuffed', 'soca', 'socratic', 'solute', 'sombrero', 'sommers', \"south's\", 'southerner', 'southpaw', 'specializations', 'sprayer', 'squirts', 'stags', 'stansted', 'staph', 'starchy', 'statuary', 'stereoscopic', 'stil', 'stoneware', 'stover', 'subreddit', 'suffused', \"surgeon's\", 'svalbard', 'symbiote', 'symons', 'synthesizing', 'systematics', 't0000', 'tactician', 'tah', 'tasers', 'tassels', 'tavistock', 'tdi', 'testaments', 'theon', 'theyll', 'thicknesses', 'thins', 'tiago', 'tidbit', 'tik', 'tobe', 'toma', 'torpedoed', 'torturous', 'torus', 'toth', 'touristy', 'transceiver', 'transcending', 'transmutation', \"traveler's\", 'ttip', 'turntables', 'twitchy', 'tyrrell', 'ufa', 'uhd', 'ultimo', 'unassisted', 'undercutting', 'undergarments', 'undertale', 'unranked', 'unsatisfying', 'unsophisticated', 'unspoiled', \"up's\", 'uriah', 'usm', 'v0.0.0', 'vaca', 'veneto', 'verifies', 'vermillion', 'vh', 'vibrators', 'vinod', 'vitriolic', 'voight', 'volleys', 'wahoo', 'watercraft', 'waterlogged', 'whacking', 'whalen', 'whiteman', 'winemakers', 'wiretaps', 'wisteria', 'wordless', 'wyeth', 'wyo', 'yalta', 'yazidi', 'yiu', 'youngs', 'yp', 'yuh', 'zillow', \"zimbabwe's\", 'zippers', 'zoya', 'ángel', '😃', '1l', '5mm', '8d', 'abetted', 'abit', 'abstracting', 'acb', 'actuated', 'addled', 'adil', 'aeneas', 'afs', 'aftershave', 'aiko', 'airdrop', 'akram', 'alarmist', 'althea', 'amari', 'ameliorate', 'americanism', 'anak', 'anderlecht', 'anemone', 'angell', 'antifreeze', 'arco', 'artem', 'artis', 'asinine', 'astrologers', 'authorising', 'autocad', 'babysitters', 'backyards', 'bails', 'bamba', 'bankrupted', 'barksdale', 'barrios', 'baumann', 'bawdy', 'beaut', 'becuase', 'befriending', 'begum', \"beijing's\", 'belfry', 'beloit', 'bemused', 'berating', 'berkowitz', \"betty's\", 'bgs', 'bhagat', 'bianco', 'bicker', 'bicyclists', 'blackbeard', 'blitzkrieg', 'boozer', 'bossing', 'brabham', \"bradley's\", 'bramble', 'bremer', 'bric', 'brics', 'bruni', \"bryan's\", 'bsb', 'burnished', 'bursaries', 'butchery', 'c.b', 'c.m', 'cala', 'calloway', 'candlesticks', 'carbonyl', 'cardenas', 'cardigans', 'catty', 'cavalli', 'ccl', 'cfd', 'charlize', 'chewie', 'chittagong', 'cinque', 'claustrophobia', 'cleaved', 'coleraine', 'computationally', 'concurrence', 'conscripted', 'conspiratorial', \"consumer's\", 'cookin', 'cornucopia', 'corvettes', 'cotswold', 'covariance', 'cowper', 'crabb', 'creepiest', 'crustacean', 'ctf', 'cuny', 'curia', \"curry's\", 'curtailing', 'cybermen', 'cyborgs', \"da's\", 'daffodil', 'dangled', 'darrin', 'debriefing', 'debutant', 'decorators', 'delineate', 'demure', 'depresses', 'descendents', 'detested', 'dethroned', 'dionysius', 'disavowed', 'discerned', 'disembarked', 'disinterest', 'dissented', 'dissuaded', 'dogwood', 'domiciled', 'dornan', 'dripped', 'dustbin', 'dutchess', 'edgewood', 'eevee', 'efe', 'eisner', 'electrophoresis', 'eliciting', 'elicits', 'ello', 'embalming', 'embezzled', 'encyclopedic', 'enos', 'entrees', 'epistemic', 'epub', 'españa', 'estrangement', 'ethnology', \"eto'o\", 'evaporating', 'extenuating', \"facility's\", 'fallible', 'fandoms', 'farhan', 'fars', 'fenner', 'fides', 'filigree', 'fincher', 'firings', 'fissile', 'flagg', 'flaunts', 'fleischer', 'forking', 'française', 'freefall', 'frigging', 'fujifilm', 'furtherance', 'futon', 'gabor', 'gabriele', 'gangland', 'gating', 'gauthier', 'gaynor', 'geffen', 'geographer', 'georgette', 'gerda', 'gippsland', 'gisele', 'giuliano', 'glabrous', 'globo', 'gloved', 'gnaw', 'godson', 'grahame', 'grasse', 'gravelly', 'grazia', 'grenadines', 'grizzled', 'grosser', 'guetta', 'gusting', 'gwendolyn', 'haaretz', 'hagrid', 'halfpenny', 'hammam', 'harlequins', 'harmoniously', 'hasta', 'hayat', 'hazrat', 'headlamps', 'heartening', 'hebdo', 'hedged', 'hemi', 'hemmings', 'henny', 'hermetic', 'hessian', 'hic', 'hijacker', 'hippopotamus', 'hod', \"holder's\", 'holla', 'homophobe', \"honda's\", 'honeybees', 'honorees', 'hoopla', 'hora', 'hornsby', 'hrw', 'huffpost', 'hulme', 'humps', 'hurtling', 'hyperinflation', 'icj', 'identifications', 'ideologues', 'idiosyncrasies', 'imelda', 'immigrating', 'imperialists', 'imploded', 'incantation', 'infielder', 'infrastructural', 'inhumanity', 'inigo', 'initialization', 'inoffensive', 'inscrutable', 'intercede', 'internals', 'internationalization', 'irrationally', 'irrepressible', 'isha', 'ishida', 'isr', 'ith', 'ivar', 'jalapeno', 'joinery', 'jove', 'kaboom', \"katie's\", 'kaylee', \"kenny's\", \"kent's\", 'keswick', 'kettles', 'kilburn', 'knitwear', 'knowledgable', 'kompany', 'koscielny', 'kundalini', \"l's\", 'lally', 'laporte', 'latching', 'laver', \"lebanon's\", 'lel', 'leninism', \"liam's\", 'lichens', \"light's\", 'lithograph', 'lockup', 'lope', 'lorain', 'loring', 'lotr', 'louboutin', 'lovebirds', 'lsc', 'lucent', 'ludacris', 'lyell', 'macomb', 'madurai', 'margherita', 'marl', 'marne', 'marveled', 'matias', 'maxillary', 'mccluskey', 'mcmullen', 'meiosis', 'mela', 'mensch', 'menzel', \"merkel's\", 'messin', 'metacritic', 'meted', 'mgs', 'miroslav', 'misadventures', 'misconstrued', 'miser', 'mises', 'misreading', 'mizzou', 'mln', 'mmp', 'mockup', 'modena', 'monogatari', 'montaigne', \"montana's\", 'moog', 'morison', 'moslem', 'mpaa', 'mpi', 'myopia', 'myrrh', 'naidu', 'nakedness', \"nash's\", 'nazir', 'negates', 'negros', 'neurologic', 'newsday', 'newsreel', 'nikos', 'nitrite', 'nominates', 'npl', 'nrs', 'obfuscation', 'ome', 'omi', 'osceola', 'ozawa', 'pallas', 'pappy', 'parsonage', 'pecs', 'peebles', 'pees', 'peeta', 'pelle', 'pentax', 'perfectionism', 'perforation', 'periodicity', 'personals', 'pettis', 'phenolic', 'phosphor', 'photonics', 'pierrot', 'pigtails', 'pistachios', 'piñata', 'platformer', 'plied', 'pll', 'ponta', 'pooper', 'poppa', 'porpoise', 'portmanteau', 'postural', 'ppa', 'prednisone', 'preordered', 'professes', \"prosecution's\", 'prototypical', 'pseudoscience', 'puritanical', 'pushups', 'pyrite', 'quadrants', 'quayle', 'quitter', 'qué', 'rafter', 'raisers', 'rationalist', 'rcc', 'redknapp', 'reedy', 'refreshes', 'refurbishing', 'registrants', 'relapsing', 'repudiation', 'reselling', 'retaken', 'retaking', 'revis', 'rhee', 'rheumatic', 'ridiculousness', 'rinks', 'roadkill', 'romana', 'rooks', \"rooney's\", 'roque', 'rostrum', 'rothstein', 'rua', \"runner's\", \"sa's\", 'sagebrush', 'saheb', 'sajid', 'sakho', 'sanctification', 'sandhurst', 'sandstones', 'sanfl', 'sau', 'savin', 'scalloped', 'scalps', 'schuylkill', 'scudder', 'sdp', 'seager', 'sealant', 'seeped', 'segue', 'sequin', 'sevenfold', 'sforza', 'shackle', 'shapely', 'shellac', 'shoelaces', 'shutdowns', 'sidi', 'sif', 'skirted', 'sleepiness', 'slurp', \"solomon's\", 'soothes', 'soundness', 'spammed', 'spca', 'spotters', 'springbok', 'springboks', 'squealed', 'srinivas', 'starkly', 'stealthily', 'stilted', 'stooped', 'stuyvesant', 'suds', 'sumitomo', 'sunburst', 'supplant', 'sura', 'sweatshop', 'synthetics', 'tada', 'taf', 'talkies', 'tamales', 'tastefully', 'tbe', 'technica', \"technology's\", 'teetering', 'telegraphed', 'timezone', 'tohoku', 'townsfolk', 'traci', 'trav', 'treasurers', 'trt', \"truck's\", 'tryst', 'tubal', 'tuft', 'turpentine', 'twang', 'typesetting', 'u.p', 'uas', 'ucs', 'udaipur', \"uganda's\", 'underpass', 'undeterred', 'unhappily', 'unoriginal', 'unpalatable', 'unwillingly', 'unwrap', 'unzipped', 'upwardly', 'usr', 'uwe', 'uyghur', 'v5', 'vanadium', 'varian', 'verdes', 'verlander', 'vernal', 'vibrato', 'viewings', 'waifu', 'waitrose', 'wakeup', 'walleye', 'wallingford', 'warnock', 'watchlist', 'wawa', 'westerner', 'whimpering', 'whisker', 'whorl', 'wickedly', 'wilhelmina', 'willey', \"williams's\", 'wordy', 'wove', 'wozniak', 'wraparound', 'xb1', 'yasser', 'yau', 'yesterdays', 'yul', 'z2', 'zainab', 'zenit', '🎵', '👉', '👍🏻', '🗿', '😛', '😞', '0f', '4p', 'abducting', 'abides', 'aboriginals', 'accelerometer', 'acrimonious', 'adelphi', 'adorning', 'adverb', 'afrika', 'agt', 'alc', 'algo', 'allardyce', 'almaty', 'amb', 'anarchic', 'arkady', 'arras', 'ashdown', 'ashoka', 'asta', 'attache', 'aurelia', 'avondale', 'b.p', 'backtracking', 'bahamian', 'bamako', 'bandy', 'barbosa', 'barnacle', 'barometric', 'barstow', 'bby', 'beamer', 'beguiling', 'bendy', 'benigno', 'berets', \"berry's\", 'bestie', 'bevy', 'bfi', 'bfs', 'bidirectional', 'biltmore', 'bioengineering', 'blanked', 'blowin', 'bmg', 'bogan', 'bpi', 'braveheart', 'breastfed', 'brodsky', 'brompton', 'bronzed', \"brooklyn's\", 'brunettes', 'bunched', 'bureaucracies', 'burney', 'burwell', 'bushings', 'buzzards', 'calipers', 'cantwell', 'carboxylic', 'carrasco', 'cataloguing', 'cathcart', 'causa', 'centimetre', 'certifies', 'cgt', 'chambre', 'chaparral', 'chivalrous', 'christiana', 'christos', 'ciel', 'clarifications', 'clasps', 'clouding', 'cmu', 'cobbles', 'cobras', 'combatting', 'communiqué', 'computerised', \"conference's\", 'confiscating', 'conformal', 'conformist', 'contemptible', 'contorted', \"cop's\", 'costanza', 'courant', 'cower', 'crackpot', 'crewed', 'crist', 'croat', 'crowther', 'crusted', 'cubby', \"culture's\", 'culvert', 'cumshot', 'cutscenes', 'céline', 'd.l', 'dalia', 'dav', 'daya', 'decibel', 'deconstructed', 'defensemen', 'dependability', 'deregulated', 'dereliction', 'diario', 'dikes', 'dimer', 'disables', 'disinfect', 'disregards', 'dissension', 'distributive', 'dlp', 'dominus', 'dotcom', 'dour', 'downie', 'dox', 'dozier', 'dragonflies', 'dumpsters', 'dundalk', \"duo's\", 'earthworms', 'echr', 'efficacious', 'eft', 'ehhh', 'ejaculate', 'elec', 'electromechanical', \"elephant's\", 'embellish', 'endeared', 'entrails', 'equalised', 'equalling', 'eri', 'eroticism', 'eshop', 'espinoza', 'exacerbating', 'exaggerates', 'exhilaration', 'exon', 'exotics', 'extensible', 'extrapolation', 'falsify', 'farris', 'faulting', 'fco', 'fea', 'febrile', 'fenn', 'fim', 'flail', 'flaked', 'foh', 'fomo', 'fondling', 'fpl', 'franciscans', 'freakish', 'fredrick', 'freeform', \"freeman's\", 'fronds', 'fyodor', 'gadsden', 'gainsborough', 'galvanised', 'gameboy', 'garbo', 'gbr', 'gere', 'gerson', 'gestured', 'geysers', 'giovanna', 'glazer', 'goalscoring', 'gogol', 'goldschmidt', 'goldwyn', 'gossips', 'grandstanding', 'graphing', 'greenhill', 'grissom', 'groton', 'guadalcanal', 'guardsman', 'gunship', 'guttural', 'gyroscope', 'gérard', 'hackathon', 'hammy', 'handedness', 'handkerchiefs', 'handley', 'hangars', \"hardy's\", 'hartwell', 'heartstrings', 'hellcat', 'hellhole', 'hellman', 'helmholtz', 'herat', 'hiddleston', 'hiit', 'hillcrest', 'hoare', 'hofmann', \"hogan's\", 'hoke', 'hokies', 'holdin', 'holier', 'holtby', 'holton', 'hoodoo', 'horsham', 'hrh', 'hubbell', 'hummels', 'hygienist', 'hypertext', 'idolized', 'ilan', 'illegible', 'immunities', 'immunological', 'impertinent']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Incorporating Word Freq"
      ],
      "metadata": {
        "id": "UIKdkzkLcsox"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from wordfreq import top_n_list\n",
        "\n",
        "# Get top 50,000 words\n",
        "print(\"Loading top 50,000 English words...\")\n",
        "top_50k = top_n_list('en', 50000)\n",
        "\n",
        "# Create a comprehensive list of animal names\n",
        "animals = [\n",
        "    # Mammals\n",
        "    'dog', 'cat', 'horse', 'cow', 'pig', 'sheep', 'goat', 'mouse', 'rat', 'rabbit',\n",
        "    'lion', 'tiger', 'bear', 'wolf', 'fox', 'deer', 'elephant', 'monkey', 'ape',\n",
        "    'whale', 'dolphin', 'seal', 'bat', 'hamster', 'guinea', 'gerbil', 'ferret',\n",
        "    'squirrel', 'chipmunk', 'beaver', 'otter', 'raccoon', 'skunk', 'badger',\n",
        "    'panda', 'koala', 'kangaroo', 'wallaby', 'opossum', 'platypus', 'echidna',\n",
        "    'giraffe', 'zebra', 'hippopotamus', 'rhinoceros', 'camel', 'llama', 'alpaca',\n",
        "    'moose', 'elk', 'reindeer', 'caribou', 'antelope', 'gazelle', 'buffalo', 'bison',\n",
        "    'yak', 'ox', 'bull', 'donkey', 'mule', 'pony', 'mare', 'stallion', 'foal',\n",
        "    'lamb', 'ram', 'ewe', 'kid', 'boar', 'sow', 'piglet', 'hog',\n",
        "    'leopard', 'cheetah', 'jaguar', 'panther', 'cougar', 'puma', 'lynx', 'bobcat',\n",
        "    'hyena', 'jackal', 'coyote', 'dingo', 'puppy', 'kitten', 'cub', 'pup',\n",
        "    'walrus', 'manatee', 'dugong', 'narwhal', 'porpoise', 'orca', 'vole', 'shrew',\n",
        "    'mole', 'hedgehog', 'porcupine', 'armadillo', 'anteater', 'sloth', 'pangolin',\n",
        "    'lemur', 'baboon', 'chimpanzee', 'gorilla', 'orangutan', 'gibbon', 'macaque',\n",
        "    'mandrill', 'marmoset', 'tamarin', 'capuchin', 'weasel', 'mink', 'ermine',\n",
        "    'mongoose', 'meerkat', 'civet', 'tapir', 'aardvark', 'warthog', 'wildebeest',\n",
        "\n",
        "    # Birds\n",
        "    'bird', 'eagle', 'hawk', 'falcon', 'owl', 'crow', 'raven', 'sparrow', 'robin',\n",
        "    'cardinal', 'bluejay', 'finch', 'canary', 'parakeet', 'parrot', 'cockatoo',\n",
        "    'macaw', 'budgie', 'dove', 'pigeon', 'duck', 'goose', 'swan', 'chicken',\n",
        "    'rooster', 'hen', 'chick', 'turkey', 'quail', 'pheasant', 'peacock', 'ostrich',\n",
        "    'emu', 'cassowary', 'kiwi', 'penguin', 'pelican', 'stork', 'crane', 'heron',\n",
        "    'egret', 'flamingo', 'albatross', 'seagull', 'gull', 'tern', 'puffin', 'toucan',\n",
        "    'woodpecker', 'hummingbird', 'kingfisher', 'swallow', 'martin', 'swift',\n",
        "    'nightingale', 'mockingbird', 'wren', 'thrush', 'blackbird', 'starling',\n",
        "    'magpie', 'rook', 'jackdaw', 'vulture', 'condor', 'buzzard', 'kite', 'harrier',\n",
        "    'osprey', 'kestrel', 'merlin', 'hobby', 'goshawk', 'sparrowhawk', 'peregrine',\n",
        "\n",
        "    # Reptiles\n",
        "    'snake', 'lizard', 'turtle', 'tortoise', 'crocodile', 'alligator', 'iguana',\n",
        "    'gecko', 'chameleon', 'python', 'cobra', 'viper', 'rattlesnake', 'boa',\n",
        "    'anaconda', 'mamba', 'adder', 'asp', 'monitor', 'skink', 'dragon', 'newt',\n",
        "    'salamander', 'axolotl', 'terrapin', 'caiman', 'gharial',\n",
        "\n",
        "    # Amphibians\n",
        "    'frog', 'toad', 'bullfrog', 'treefrog', 'tadpole',\n",
        "\n",
        "    # Fish\n",
        "    'fish', 'shark', 'whale', 'dolphin', 'salmon', 'trout', 'bass', 'perch', 'pike',\n",
        "    'carp', 'catfish', 'tuna', 'mackerel', 'sardine', 'herring', 'anchovy', 'cod',\n",
        "    'haddock', 'halibut', 'flounder', 'sole', 'plaice', 'ray', 'skate', 'eel',\n",
        "    'sturgeon', 'swordfish', 'marlin', 'sailfish', 'barracuda', 'piranha',\n",
        "    'goldfish', 'guppy', 'minnow', 'angelfish', 'clownfish', 'grouper', 'snapper',\n",
        "    'mahi', 'wahoo', 'tilapia', 'bream', 'mullet', 'pompano', 'tarpon', 'bonefish',\n",
        "\n",
        "    # Insects and Arachnids\n",
        "    'ant', 'bee', 'wasp', 'hornet', 'fly', 'mosquito', 'gnat', 'midge', 'beetle',\n",
        "    'ladybug', 'butterfly', 'moth', 'caterpillar', 'dragonfly', 'damselfly',\n",
        "    'grasshopper', 'cricket', 'locust', 'mantis', 'stick', 'termite', 'aphid',\n",
        "    'flea', 'louse', 'tick', 'mite', 'spider', 'tarantula', 'scorpion', 'centipede',\n",
        "    'millipede', 'worm', 'leech', 'slug', 'snail', 'cockroach', 'roach', 'earwig',\n",
        "    'silverfish', 'firefly', 'glowworm', 'maggot', 'grub', 'larva', 'pupa',\n",
        "\n",
        "    # Marine invertebrates\n",
        "    'octopus', 'squid', 'cuttlefish', 'jellyfish', 'starfish', 'urchin', 'anemone',\n",
        "    'coral', 'sponge', 'crab', 'lobster', 'shrimp', 'prawn', 'crayfish', 'krill',\n",
        "    'barnacle', 'mussel', 'clam', 'oyster', 'scallop', 'abalone', 'conch', 'whelk',\n",
        "    'limpet', 'periwinkle', 'nautilus', 'seahorse', 'stingray', 'manta',\n",
        "\n",
        "    # Other\n",
        "    'dinosaur', 'mammoth', 'mastodon', 'sabertooth', 'dodo'\n",
        "]\n",
        "\n",
        "# Convert to set for faster lookup\n",
        "animal_set = set(animals)\n",
        "top_50k_set = set(top_50k)\n",
        "\n",
        "# Find animals that appear in top 50k words\n",
        "animals_in_top_50k = []\n",
        "for animal in animals:\n",
        "    if animal in top_50k_set:\n",
        "        rank = top_50k.index(animal) + 1  # 1-based rank\n",
        "        animals_in_top_50k.append((animal, rank))\n",
        "\n",
        "# Sort by rank (most frequent first)\n",
        "animals_in_top_50k.sort(key=lambda x: x[1])\n",
        "\n",
        "# Display results\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(f\"Animals found in top 50,000 English words: {len(animals_in_top_50k)}\")\n",
        "print(f\"{'='*60}\\n\")\n",
        "\n",
        "print(f\"{'Animal':<20} {'Rank':<10} {'Frequency Rank Group'}\")\n",
        "print(f\"{'-'*20} {'-'*10} {'-'*25}\")\n",
        "\n",
        "for animal, rank in animals_in_top_50k:\n",
        "    # Categorize by frequency rank\n",
        "    if rank <= 1000:\n",
        "        group = \"Very Common (Top 1k)\"\n",
        "    elif rank <= 5000:\n",
        "        group = \"Common (Top 5k)\"\n",
        "    elif rank <= 10000:\n",
        "        group = \"Fairly Common (Top 10k)\"\n",
        "    elif rank <= 25000:\n",
        "        group = \"Less Common (Top 25k)\"\n",
        "    else:\n",
        "        group = \"Uncommon (25k-50k)\"\n",
        "\n",
        "    print(f\"{animal:<20} {rank:<10} {group}\")\n",
        "\n",
        "# Analysis by category\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"ANALYSIS BY FREQUENCY GROUP\")\n",
        "print(f\"{'='*60}\\n\")\n",
        "\n",
        "groups = {\n",
        "    \"Very Common (Top 1k)\": [],\n",
        "    \"Common (Top 5k)\": [],\n",
        "    \"Fairly Common (Top 10k)\": [],\n",
        "    \"Less Common (Top 25k)\": [],\n",
        "    \"Uncommon (25k-50k)\": []\n",
        "}\n",
        "\n",
        "for animal, rank in animals_in_top_50k:\n",
        "    if rank <= 1000:\n",
        "        groups[\"Very Common (Top 1k)\"].append(animal)\n",
        "    elif rank <= 5000:\n",
        "        groups[\"Common (Top 5k)\"].append(animal)\n",
        "    elif rank <= 10000:\n",
        "        groups[\"Fairly Common (Top 10k)\"].append(animal)\n",
        "    elif rank <= 25000:\n",
        "        groups[\"Less Common (Top 25k)\"].append(animal)\n",
        "    else:\n",
        "        groups[\"Uncommon (25k-50k)\"].append(animal)\n",
        "\n",
        "for group_name, group_animals in groups.items():\n",
        "    if group_animals:\n",
        "        print(f\"{group_name}: {len(group_animals)} animals\")\n",
        "        print(f\"  {', '.join(sorted(group_animals))}\")\n",
        "        print()\n",
        "\n",
        "# Find common animals NOT in top 50k\n",
        "print(f\"{'='*60}\")\n",
        "print(\"ANIMALS NOT IN TOP 50k WORDS\")\n",
        "print(f\"{'='*60}\\n\")\n",
        "\n",
        "missing_animals = [animal for animal in animals if animal not in top_50k_set]\n",
        "print(f\"Total missing: {len(missing_animals)}\")\n",
        "print(f\"\\nExamples of animals not in top 50k:\")\n",
        "# Show first 20 missing animals\n",
        "for i, animal in enumerate(sorted(missing_animals)[:20]):\n",
        "    print(f\"  - {animal}\")\n",
        "if len(missing_animals) > 20:\n",
        "    print(f\"  ... and {len(missing_animals) - 20} more\")\n",
        "\n",
        "# Fun statistics\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(f\"{'='*60}\\n\")\n",
        "\n",
        "# Find shortest and longest animal names in top 50k\n",
        "if animals_in_top_50k:\n",
        "    shortest = min(animals_in_top_50k, key=lambda x: len(x[0]))\n",
        "    longest = max(animals_in_top_50k, key=lambda x: len(x[0]))\n",
        "    most_common = animals_in_top_50k[0] if animals_in_top_50k else None\n",
        "\n",
        "    print(f\"Most common animal: '{most_common[0]}' (rank #{most_common[1]})\")\n",
        "    print(f\"Shortest animal name: '{shortest[0]}' ({len(shortest[0])} letters, rank #{shortest[1]})\")\n",
        "    print(f\"Longest animal name: '{longest[0]}' ({len(longest[0])} letters, rank #{longest[1]})\")\n",
        "\n",
        "    # Percentage of our animal list that made it\n",
        "    percentage = (len(animals_in_top_50k) / len(animals)) * 100\n",
        "    print(f\"\\nSuccess rate: {percentage:.1f}% of our animal list appears in top 50k words\")"
      ],
      "metadata": {
        "id": "lW1XkYx22__a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19f58081-1611-4850-b1b0-212435353cbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading top 50,000 English words...\n",
            "\n",
            "============================================================\n",
            "Animals found in top 50,000 English words: 294\n",
            "============================================================\n",
            "\n",
            "Animal               Rank       Frequency Rank Group\n",
            "-------------------- ---------- -------------------------\n",
            "dog                  826        Very Common (Top 1k)\n",
            "kid                  1107       Common (Top 5k)\n",
            "fish                 1339       Common (Top 5k)\n",
            "cat                  1713       Common (Top 5k)\n",
            "horse                1793       Common (Top 5k)\n",
            "stick                1802       Common (Top 5k)\n",
            "fly                  1827       Common (Top 5k)\n",
            "martin               1870       Common (Top 5k)\n",
            "bear                 1985       Common (Top 5k)\n",
            "ray                  2087       Common (Top 5k)\n",
            "fox                  2204       Common (Top 5k)\n",
            "bird                 2329       Common (Top 5k)\n",
            "chicken              2334       Common (Top 5k)\n",
            "turkey               2706       Common (Top 5k)\n",
            "dragon               3555       Common (Top 5k)\n",
            "cricket              3682       Common (Top 5k)\n",
            "monitor              3829       Common (Top 5k)\n",
            "wolf                 3995       Common (Top 5k)\n",
            "bull                 4005       Common (Top 5k)\n",
            "robin                4118       Common (Top 5k)\n",
            "mouse                4255       Common (Top 5k)\n",
            "bat                  4286       Common (Top 5k)\n",
            "seal                 4331       Common (Top 5k)\n",
            "tiger                4340       Common (Top 5k)\n",
            "sole                 4411       Common (Top 5k)\n",
            "bass                 4427       Common (Top 5k)\n",
            "lion                 4686       Common (Top 5k)\n",
            "spider               4715       Common (Top 5k)\n",
            "snake                4895       Common (Top 5k)\n",
            "duck                 5031       Fairly Common (Top 10k)\n",
            "ram                  5254       Fairly Common (Top 10k)\n",
            "sheep                5264       Fairly Common (Top 10k)\n",
            "rat                  5446       Fairly Common (Top 10k)\n",
            "swift                5635       Fairly Common (Top 10k)\n",
            "buffalo              5663       Fairly Common (Top 10k)\n",
            "cow                  5670       Fairly Common (Top 10k)\n",
            "pig                  5724       Fairly Common (Top 10k)\n",
            "eagle                5785       Fairly Common (Top 10k)\n",
            "deer                 5872       Fairly Common (Top 10k)\n",
            "shark                6098       Fairly Common (Top 10k)\n",
            "bee                  6114       Fairly Common (Top 10k)\n",
            "chick                6223       Fairly Common (Top 10k)\n",
            "elephant             6236       Fairly Common (Top 10k)\n",
            "monkey               6380       Fairly Common (Top 10k)\n",
            "guinea               6475       Fairly Common (Top 10k)\n",
            "rabbit               6609       Fairly Common (Top 10k)\n",
            "goat                 6913       Fairly Common (Top 10k)\n",
            "lamb                 6930       Fairly Common (Top 10k)\n",
            "salmon               7055       Fairly Common (Top 10k)\n",
            "puppy                7174       Fairly Common (Top 10k)\n",
            "whale                7410       Fairly Common (Top 10k)\n",
            "whale                7410       Fairly Common (Top 10k)\n",
            "hobby                7800       Fairly Common (Top 10k)\n",
            "butterfly            7891       Fairly Common (Top 10k)\n",
            "crane                8021       Fairly Common (Top 10k)\n",
            "turtle               8223       Fairly Common (Top 10k)\n",
            "cardinal             8253       Fairly Common (Top 10k)\n",
            "cod                  8399       Fairly Common (Top 10k)\n",
            "frog                 8426       Fairly Common (Top 10k)\n",
            "owl                  8703       Fairly Common (Top 10k)\n",
            "swallow              8731       Fairly Common (Top 10k)\n",
            "ant                  8754       Fairly Common (Top 10k)\n",
            "coral                8770       Fairly Common (Top 10k)\n",
            "goose                9048       Fairly Common (Top 10k)\n",
            "swan                 9108       Fairly Common (Top 10k)\n",
            "hawk                 9477       Fairly Common (Top 10k)\n",
            "pony                 9509       Fairly Common (Top 10k)\n",
            "crow                 9590       Fairly Common (Top 10k)\n",
            "tick                 9678       Fairly Common (Top 10k)\n",
            "raven                9805       Fairly Common (Top 10k)\n",
            "shrimp               9815       Fairly Common (Top 10k)\n",
            "penguin              9935       Fairly Common (Top 10k)\n",
            "python               9943       Fairly Common (Top 10k)\n",
            "trout                9974       Fairly Common (Top 10k)\n",
            "dinosaur             10037      Less Common (Top 25k)\n",
            "worm                 10156      Less Common (Top 25k)\n",
            "crab                 10185      Less Common (Top 25k)\n",
            "falcon               10545      Less Common (Top 25k)\n",
            "skate                10611      Less Common (Top 25k)\n",
            "squirrel             11471      Less Common (Top 25k)\n",
            "pike                 11580      Less Common (Top 25k)\n",
            "dolphin              11686      Less Common (Top 25k)\n",
            "dolphin              11686      Less Common (Top 25k)\n",
            "dove                 11687      Less Common (Top 25k)\n",
            "mole                 11745      Less Common (Top 25k)\n",
            "snail                11796      Less Common (Top 25k)\n",
            "lobster              12093      Less Common (Top 25k)\n",
            "panda                12118      Less Common (Top 25k)\n",
            "panther              12119      Less Common (Top 25k)\n",
            "camel                12197      Less Common (Top 25k)\n",
            "kitten               12264      Less Common (Top 25k)\n",
            "pup                  12305      Less Common (Top 25k)\n",
            "tuna                 12345      Less Common (Top 25k)\n",
            "lizard               12459      Less Common (Top 25k)\n",
            "donkey               12581      Less Common (Top 25k)\n",
            "gorilla              12613      Less Common (Top 25k)\n",
            "beaver               12733      Less Common (Top 25k)\n",
            "moose                12809      Less Common (Top 25k)\n",
            "mosquito             12810      Less Common (Top 25k)\n",
            "pigeon               12829      Less Common (Top 25k)\n",
            "mare                 13015      Less Common (Top 25k)\n",
            "leopard              13186      Less Common (Top 25k)\n",
            "sponge               13246      Less Common (Top 25k)\n",
            "hog                  13532      Less Common (Top 25k)\n",
            "hen                  13733      Less Common (Top 25k)\n",
            "finch                13917      Less Common (Top 25k)\n",
            "kite                 13945      Less Common (Top 25k)\n",
            "oyster               14181      Less Common (Top 25k)\n",
            "beetle               14277      Less Common (Top 25k)\n",
            "cobra                14721      Less Common (Top 25k)\n",
            "jaguar               14780      Less Common (Top 25k)\n",
            "kangaroo             14977      Less Common (Top 25k)\n",
            "moth                 15005      Less Common (Top 25k)\n",
            "crocodile            15139      Less Common (Top 25k)\n",
            "cub                  15140      Less Common (Top 25k)\n",
            "elk                  15157      Less Common (Top 25k)\n",
            "parrot               15240      Less Common (Top 25k)\n",
            "ape                  15334      Less Common (Top 25k)\n",
            "badger               15342      Less Common (Top 25k)\n",
            "herring              15423      Less Common (Top 25k)\n",
            "sparrow              15512      Less Common (Top 25k)\n",
            "ox                   15672      Less Common (Top 25k)\n",
            "octopus              15872      Less Common (Top 25k)\n",
            "canary               16189      Less Common (Top 25k)\n",
            "mule                 16279      Less Common (Top 25k)\n",
            "peacock              16298      Less Common (Top 25k)\n",
            "roach                16332      Less Common (Top 25k)\n",
            "squid                16356      Less Common (Top 25k)\n",
            "flea                 16711      Less Common (Top 25k)\n",
            "merlin               16749      Less Common (Top 25k)\n",
            "mammoth              17180      Less Common (Top 25k)\n",
            "zebra                17279      Less Common (Top 25k)\n",
            "caterpillar          17563      Less Common (Top 25k)\n",
            "cougar               17580      Less Common (Top 25k)\n",
            "sow                  17722      Less Common (Top 25k)\n",
            "otter                17917      Less Common (Top 25k)\n",
            "scorpion             17953      Less Common (Top 25k)\n",
            "coyote               18051      Less Common (Top 25k)\n",
            "catfish              18266      Less Common (Top 25k)\n",
            "wasp                 18459      Less Common (Top 25k)\n",
            "sturgeon             18706      Less Common (Top 25k)\n",
            "toad                 18717      Less Common (Top 25k)\n",
            "kiwi                 18870      Less Common (Top 25k)\n",
            "alligator            19009      Less Common (Top 25k)\n",
            "giraffe              19096      Less Common (Top 25k)\n",
            "reindeer             19186      Less Common (Top 25k)\n",
            "hamster              19356      Less Common (Top 25k)\n",
            "rooster              19441      Less Common (Top 25k)\n",
            "slug                 19465      Less Common (Top 25k)\n",
            "viper                19500      Less Common (Top 25k)\n",
            "boar                 19537      Less Common (Top 25k)\n",
            "nightingale          19918      Less Common (Top 25k)\n",
            "perch                19934      Less Common (Top 25k)\n",
            "goldfish             20126      Less Common (Top 25k)\n",
            "raccoon              20470      Less Common (Top 25k)\n",
            "bison                20570      Less Common (Top 25k)\n",
            "tortoise             20798      Less Common (Top 25k)\n",
            "hedgehog             20950      Less Common (Top 25k)\n",
            "jellyfish            20972      Less Common (Top 25k)\n",
            "stallion             21369      Less Common (Top 25k)\n",
            "eel                  21505      Less Common (Top 25k)\n",
            "newt                 21593      Less Common (Top 25k)\n",
            "clam                 21750      Less Common (Top 25k)\n",
            "puma                 21907      Less Common (Top 25k)\n",
            "cheetah              22322      Less Common (Top 25k)\n",
            "weasel               22861      Less Common (Top 25k)\n",
            "boa                  22904      Less Common (Top 25k)\n",
            "carp                 22920      Less Common (Top 25k)\n",
            "vulture              23151      Less Common (Top 25k)\n",
            "leech                23327      Less Common (Top 25k)\n",
            "cockroach            23494      Less Common (Top 25k)\n",
            "hornet               23863      Less Common (Top 25k)\n",
            "mink                 23904      Less Common (Top 25k)\n",
            "firefly              24447      Less Common (Top 25k)\n",
            "quail                24560      Less Common (Top 25k)\n",
            "grub                 24772      Less Common (Top 25k)\n",
            "yak                  24962      Less Common (Top 25k)\n",
            "mantis               25131      Uncommon (25k-50k)\n",
            "chameleon            25317      Uncommon (25k-50k)\n",
            "rook                 25558      Uncommon (25k-50k)\n",
            "skunk                25578      Uncommon (25k-50k)\n",
            "sloth                25579      Uncommon (25k-50k)\n",
            "heron                25783      Uncommon (25k-50k)\n",
            "wren                 25979      Uncommon (25k-50k)\n",
            "antelope             26002      Uncommon (25k-50k)\n",
            "mackerel             26154      Uncommon (25k-50k)\n",
            "mite                 26169      Uncommon (25k-50k)\n",
            "pelican              26549      Uncommon (25k-50k)\n",
            "flamingo             26794      Uncommon (25k-50k)\n",
            "lynx                 26871      Uncommon (25k-50k)\n",
            "asp                  27056      Uncommon (25k-50k)\n",
            "emu                  27135      Uncommon (25k-50k)\n",
            "ostrich              27236      Uncommon (25k-50k)\n",
            "koala                27532      Uncommon (25k-50k)\n",
            "dragonfly            27816      Uncommon (25k-50k)\n",
            "grasshopper          27858      Uncommon (25k-50k)\n",
            "pheasant             27961      Uncommon (25k-50k)\n",
            "starling             28031      Uncommon (25k-50k)\n",
            "seagull              28358      Uncommon (25k-50k)\n",
            "ferret               28546      Uncommon (25k-50k)\n",
            "marlin               28616      Uncommon (25k-50k)\n",
            "gull                 28938      Uncommon (25k-50k)\n",
            "locust               28979      Uncommon (25k-50k)\n",
            "snapper              29092      Uncommon (25k-50k)\n",
            "starfish             29103      Uncommon (25k-50k)\n",
            "larva                29341      Uncommon (25k-50k)\n",
            "mockingbird          29749      Uncommon (25k-50k)\n",
            "walrus               29886      Uncommon (25k-50k)\n",
            "anaconda             29908      Uncommon (25k-50k)\n",
            "caribou              29953      Uncommon (25k-50k)\n",
            "mullet               30147      Uncommon (25k-50k)\n",
            "chimpanzee           30362      Uncommon (25k-50k)\n",
            "condor               30375      Uncommon (25k-50k)\n",
            "hummingbird          30452      Uncommon (25k-50k)\n",
            "llama                30868      Uncommon (25k-50k)\n",
            "orca                 31683      Uncommon (25k-50k)\n",
            "stingray             31778      Uncommon (25k-50k)\n",
            "blackbird            32295      Uncommon (25k-50k)\n",
            "gecko                32410      Uncommon (25k-50k)\n",
            "albatross            32669      Uncommon (25k-50k)\n",
            "magpie               32907      Uncommon (25k-50k)\n",
            "osprey               33353      Uncommon (25k-50k)\n",
            "dodo                 33624      Uncommon (25k-50k)\n",
            "porcupine            33797      Uncommon (25k-50k)\n",
            "stork                33860      Uncommon (25k-50k)\n",
            "gazelle              34075      Uncommon (25k-50k)\n",
            "jackal               34133      Uncommon (25k-50k)\n",
            "kingfisher           34148      Uncommon (25k-50k)\n",
            "nautilus             34203      Uncommon (25k-50k)\n",
            "prawn                34231      Uncommon (25k-50k)\n",
            "rattlesnake          34251      Uncommon (25k-50k)\n",
            "crayfish             34845      Uncommon (25k-50k)\n",
            "rhinoceros           35048      Uncommon (25k-50k)\n",
            "buzzard              35642      Uncommon (25k-50k)\n",
            "foal                 35721      Uncommon (25k-50k)\n",
            "haddock              35745      Uncommon (25k-50k)\n",
            "thrush               35985      Uncommon (25k-50k)\n",
            "manta                36238      Uncommon (25k-50k)\n",
            "peregrine            36276      Uncommon (25k-50k)\n",
            "piglet               36283      Uncommon (25k-50k)\n",
            "woodpecker           36399      Uncommon (25k-50k)\n",
            "alpaca               36856      Uncommon (25k-50k)\n",
            "bobcat               36895      Uncommon (25k-50k)\n",
            "gibbon               36997      Uncommon (25k-50k)\n",
            "hyena                37035      Uncommon (25k-50k)\n",
            "orangutan            37126      Uncommon (25k-50k)\n",
            "centipede            37375      Uncommon (25k-50k)\n",
            "conch                37390      Uncommon (25k-50k)\n",
            "ewe                  37448      Uncommon (25k-50k)\n",
            "urchin               37756      Uncommon (25k-50k)\n",
            "barracuda            37817      Uncommon (25k-50k)\n",
            "flounder             37931      Uncommon (25k-50k)\n",
            "maggot               38029      Uncommon (25k-50k)\n",
            "termite              38200      Uncommon (25k-50k)\n",
            "midge                38967      Uncommon (25k-50k)\n",
            "salamander           39072      Uncommon (25k-50k)\n",
            "dingo                39292      Uncommon (25k-50k)\n",
            "piranha              39482      Uncommon (25k-50k)\n",
            "scallop              39543      Uncommon (25k-50k)\n",
            "shrew                39560      Uncommon (25k-50k)\n",
            "chipmunk             39732      Uncommon (25k-50k)\n",
            "iguana               39853      Uncommon (25k-50k)\n",
            "mahi                 39904      Uncommon (25k-50k)\n",
            "manatee              39906      Uncommon (25k-50k)\n",
            "mussel               39926      Uncommon (25k-50k)\n",
            "baboon               40131      Uncommon (25k-50k)\n",
            "tarantula            40922      Uncommon (25k-50k)\n",
            "tern                 40923      Uncommon (25k-50k)\n",
            "halibut              41163      Uncommon (25k-50k)\n",
            "armadillo            41512      Uncommon (25k-50k)\n",
            "harrier              41663      Uncommon (25k-50k)\n",
            "adder                41977      Uncommon (25k-50k)\n",
            "bream                42037      Uncommon (25k-50k)\n",
            "platypus             42340      Uncommon (25k-50k)\n",
            "ladybug              43232      Uncommon (25k-50k)\n",
            "mongoose             43266      Uncommon (25k-50k)\n",
            "swordfish            43403      Uncommon (25k-50k)\n",
            "abalone              43490      Uncommon (25k-50k)\n",
            "puffin               43862      Uncommon (25k-50k)\n",
            "sardine              43899      Uncommon (25k-50k)\n",
            "mamba                44919      Uncommon (25k-50k)\n",
            "tilapia              45123      Uncommon (25k-50k)\n",
            "vole                 45158      Uncommon (25k-50k)\n",
            "wallaby              45162      Uncommon (25k-50k)\n",
            "krill                45475      Uncommon (25k-50k)\n",
            "minnow               46069      Uncommon (25k-50k)\n",
            "louse                47167      Uncommon (25k-50k)\n",
            "anchovy              48057      Uncommon (25k-50k)\n",
            "lemur                48861      Uncommon (25k-50k)\n",
            "wahoo                49140      Uncommon (25k-50k)\n",
            "anemone              49187      Uncommon (25k-50k)\n",
            "hippopotamus         49394      Uncommon (25k-50k)\n",
            "porpoise             49562      Uncommon (25k-50k)\n",
            "barnacle             49777      Uncommon (25k-50k)\n",
            "\n",
            "============================================================\n",
            "ANALYSIS BY FREQUENCY GROUP\n",
            "============================================================\n",
            "\n",
            "Very Common (Top 1k): 1 animals\n",
            "  dog\n",
            "\n",
            "Common (Top 5k): 28 animals\n",
            "  bass, bat, bear, bird, bull, cat, chicken, cricket, dragon, fish, fly, fox, horse, kid, lion, martin, monitor, mouse, ray, robin, seal, snake, sole, spider, stick, tiger, turkey, wolf\n",
            "\n",
            "Fairly Common (Top 10k): 45 animals\n",
            "  ant, bee, buffalo, butterfly, cardinal, chick, cod, coral, cow, crane, crow, deer, duck, eagle, elephant, frog, goat, goose, guinea, hawk, hobby, lamb, monkey, owl, penguin, pig, pony, puppy, python, rabbit, ram, rat, raven, salmon, shark, sheep, shrimp, swallow, swan, swift, tick, trout, turtle, whale, whale\n",
            "\n",
            "Less Common (Top 25k): 103 animals\n",
            "  alligator, ape, badger, beaver, beetle, bison, boa, boar, camel, canary, carp, caterpillar, catfish, cheetah, clam, cobra, cockroach, cougar, coyote, crab, crocodile, cub, dinosaur, dolphin, dolphin, donkey, dove, eel, elk, falcon, finch, firefly, flea, giraffe, goldfish, gorilla, grub, hamster, hedgehog, hen, herring, hog, hornet, jaguar, jellyfish, kangaroo, kite, kitten, kiwi, leech, leopard, lizard, lobster, mammoth, mare, merlin, mink, mole, moose, mosquito, moth, mule, newt, nightingale, octopus, otter, ox, oyster, panda, panther, parrot, peacock, perch, pigeon, pike, puma, pup, quail, raccoon, reindeer, roach, rooster, scorpion, skate, slug, snail, sow, sparrow, sponge, squid, squirrel, stallion, sturgeon, toad, tortoise, tuna, viper, vulture, wasp, weasel, worm, yak, zebra\n",
            "\n",
            "Uncommon (25k-50k): 117 animals\n",
            "  abalone, adder, albatross, alpaca, anaconda, anchovy, anemone, antelope, armadillo, asp, baboon, barnacle, barracuda, blackbird, bobcat, bream, buzzard, caribou, centipede, chameleon, chimpanzee, chipmunk, conch, condor, crayfish, dingo, dodo, dragonfly, emu, ewe, ferret, flamingo, flounder, foal, gazelle, gecko, gibbon, grasshopper, gull, haddock, halibut, harrier, heron, hippopotamus, hummingbird, hyena, iguana, jackal, kingfisher, koala, krill, ladybug, larva, lemur, llama, locust, louse, lynx, mackerel, maggot, magpie, mahi, mamba, manatee, manta, mantis, marlin, midge, minnow, mite, mockingbird, mongoose, mullet, mussel, nautilus, orangutan, orca, osprey, ostrich, pelican, peregrine, pheasant, piglet, piranha, platypus, porcupine, porpoise, prawn, puffin, rattlesnake, rhinoceros, rook, salamander, sardine, scallop, seagull, shrew, skunk, sloth, snapper, starfish, starling, stingray, stork, swordfish, tarantula, termite, tern, thrush, tilapia, urchin, vole, wahoo, wallaby, walrus, woodpecker, wren\n",
            "\n",
            "============================================================\n",
            "ANIMALS NOT IN TOP 50k WORDS\n",
            "============================================================\n",
            "\n",
            "Total missing: 63\n",
            "\n",
            "Examples of animals not in top 50k:\n",
            "  - aardvark\n",
            "  - angelfish\n",
            "  - anteater\n",
            "  - aphid\n",
            "  - axolotl\n",
            "  - bluejay\n",
            "  - bonefish\n",
            "  - budgie\n",
            "  - bullfrog\n",
            "  - caiman\n",
            "  - capuchin\n",
            "  - cassowary\n",
            "  - civet\n",
            "  - clownfish\n",
            "  - cockatoo\n",
            "  - cuttlefish\n",
            "  - damselfly\n",
            "  - dugong\n",
            "  - earwig\n",
            "  - echidna\n",
            "  ... and 43 more\n",
            "\n",
            "============================================================\n",
            "============================================================\n",
            "\n",
            "Most common animal: 'dog' (rank #826)\n",
            "Shortest animal name: 'ox' (2 letters, rank #15672)\n",
            "Longest animal name: 'hippopotamus' (12 letters, rank #49394)\n",
            "\n",
            "Success rate: 82.4% of our animal list appears in top 50k words\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uD3sRW2m6b1t",
        "outputId": "cd18fb0f-060e-4647-b072-6af073f73757"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ID,Item,clean_ID\n",
            "PD00020,lion,20\n",
            "PD00020,tiger,20\n",
            "PD00020,sheep,20\n",
            "PD00020,dog,20\n",
            "PD00020,cat,20\n",
            " .....\n",
            " PD01715,wolf,1715\n",
            "PD01715,dog,1715\n",
            "PD01715,horse,1715\n",
            "PD01715,turkey,1715\n",
            "PD01715,chicken,1715\n",
            "\n",
            "ID,alpha_NET_mean,status,visit,norm_SN_l,norm_SN_r,norm_LC_l,norm_LC_r,norm_SN_avg,norm_LC_avg,clean_ID\n",
            "PD00020,0.005821693,PD,MRI01,1.14817625,1.158620797,1.044436934,1.016706475,1.153398524,1.030571705,20\n",
            "PD00048,0.002184409,PD,MRI01,1.098492193,1.109323313,1.085092243,0.965901336,1.103907753,1.02549679,48\n",
            "PD00146,0.005128224,PD,MRI01,1.12043934,1.125366723,1.041352235,1.026072416,1.122903032,1.033712326,146\n",
            "PD00215,0.010895761,PD,MRI01,1.124369462,1.147340095,1.107812477,1.04618484,1.135gma854779,1.076998659,215\n",
            "PD00267,0.008189669,PD,MRI01,1.125531069,1.140897908,0.967051224,1.016658103,1.133214489,0.991854664,267\n",
            " .....\n",
            " PD01603,0.002877681,PD,MRI01,1.119341671,1.142670798,1.074238211,1.046278134,1.131006235,1.060258173,1603\n",
            "PD01623,0.013388923,PD,PD01623MRI01,1.110364728,1.101435699,1.073174459,0.997847314,1.105900214,1.035510887,1623\n",
            "PD01660,0.009658789,PD,MRI01,1.146810392,1.142374341,1.043183894,1.000483297,1.144592367,1.021833596,1660\n",
            "PD01667,0.004057877,PD,MRI01,1.14080379,1.130201021,1.059124791,1.0327146,1.135502406,1.045919696,1667\n",
            "PD01715,0.00505598,PD,MRI01,1.100505544,1.118382993,1.047199874,1.012294835,1.109444269,1.029747355,1715\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Load the data\n",
        "data_str = '''ID,Item\n",
        "PD00020,\"Lion,Tiger,Sheep,Dog,Cat,Camel,Monkey,Chimpanzee,Buffalo,Hyena,Dog,Cat,Elephant,Hyena,Dog,Cat,Mouse,Bird,Camel,Dragon\"\n",
        "PD00048,\"Lion,Hare,Elephant,Rhinoceros,Monkey,Giraffe,Cow,Elk,Fish,Horse,Tiger,Leopard,Jaguar\"\n",
        "PD00119,\"Lion,Tiger,Duck,Goose,Deer,Horse,Zebra,Elephant,Bird,Giraffe,Hippo,Crocodile,Elephant,Sheep,Goat,Ewe,Duck\"\n",
        "PD00146,\"Dog,Pig,Chicken,Partridge,Swallow,Squirrel,Rabbit,Horse,Hare,Calf,Bull,Cow,Lion,Tiger,Monkey,Giraffe,Elephant,Snake,Frog,Shark,Whale,Dolphin\"\n",
        "PD00215,\"Donkey,Horse,Cow,Ox,Elephant,Llama,Cat,Dog,Mouse,Tiger,Lion,Leopard,Cheetah,Hyena,Bear,Goat,Partridge,Hare,Manatee,Turtle,Iguana,Frog,Toad\"\n",
        "PD00219,\"Monkey,Lion,Tiger,Horse,Cat,Dog,Snake,Wolf,Coyote,Horse,Cow,Camel,Scorpion\"\n",
        "PD00267,\"Cat,Dog,Lion,Beaver,Jaguar,Elephant,Gazelle,Bear,Fox,Horse,Ox,Calf,Giraffe\"\n",
        "PD00457,\"rhinoceros,fox,tiger,hippopotamus,tiger,lion,leopard,gazelle,dog,cat,horse,cow,sheep,horse,lion,gazelle,turkey\"\n",
        "PD00458,\"Dog,Cat,Hamster,Tiger,Fox,Lion,Rhinoceros,Wolf,Partridge,Coyote,Eagle,Pigeon,Parrot,Crocodile,Whale,Dolphin,Marmot\"\n",
        "PD00471,\"Cat,Dog,Horse,Cow,Calf,Lion,Pig,Monkey,Rhinoceros,Zebra,Elephant,Antelope,Fish,Panther,Camel,Lion,Hare,Crocodile,Rabbit,Mouse,Butterfly,Monkey\"\n",
        "PD00472,\"Cat,dog,duck,Fish,Lark,Horse,pig,snake,crocodile,lion,Gazelle,Zebra,Elephant,Wolf,Fox,Panther,jaguar,Chimpanzee,Panda,Hen,Rooster\"\n",
        "PD00576,\"Wolf,Horse,Camel,Cat,Dog,Tiger,Leopard,Lion,Elephant,Antelope,Caterpillar,Ostrich,Wasp,Ant,Fish,Shark,Crow,Trout,Salmon,Frog,Swallow,Spider,Panther\"\n",
        "PD00583,\"Dog,Cat,Goat,Wolf,Fox,Hippopotamus,Elephant,Rooster,Hen,Turkey,Rabbit,Parrot,Crocodile,Butterfly,Grasshopper\"\n",
        "PD00647,\"Elephant,Tiger,Alligator,Monkey,Butterfly,Whale,Dog,Cat,Rat,Chimpanzee,Cow,Cat,Flea,bird,Insect,Fish\"\n",
        "PD00653,\"Cow,Cat,Bear,Horse,Pig,Dog,Wolf,Bird,Elk,Crocodile,Hippopotamus,Lion,Tiger,Bird,Snake,Pig,Cow,Chicken,Lamb\"\n",
        "PD00660,\"Dog,Cat,Rat,Crocodile,Lion,Tiger,Horse,Cow,Fish,Bird,Hen,Giraffe,Hippopotamus,Chimpanzee,Goat,Fox\"\n",
        "PD00666,\"Cat,Goat,Mouse,Weasel,Cow,Bizon,Horse,Lion,Panther,Elephant,Gazelle,Orangutan,Cat,Eagle,Marmot,Moray eel,Snake,Whale,Shark\"\n",
        "PD00757,\"Dog,Cat,Lion,Tiger,Fox,Snake,Spider,Elephant,Sheep\"\n",
        "PD00786,\"Cat,Dog,Monkey,Hen,Rooster,Pig,Horse,Cow,Calf,Lamb,Sheep,Ox,Chicken,Duck\"\n",
        "PD00849,\"Lion,Hare,Wolf,Fox,Cat,Dog,Tiger,Elephant,Rhinoceros,Ostrich,Zebra,Pheasant,Giraffe,Leopard,Tiger,Cougar\"\n",
        "PD00869,\"Cow,Calf,Horse,Lion,Hippopotamus,Rhinoceros,Monkey,Hen,Rabbit,Pheasant,Parrot,Gazelle,Giraffe,Lion,Marmot,dog,Donkey,Cheetah,Swan,Duck,Mule\"\n",
        "PD00955,\"Dog,Cat,Rat,Mole,Lion,Tiger,Giraffe,Hyena,Leopard,Lynx,Fox,Ram,Horse\"\n",
        "PD00959,\"Tiger,Lion,Hen,Rhino,Hippo,Llama,Giraffe,Goat,Sheep\"\n",
        "PD00999,\"Lion,Tiger,Elephant,Rhinoceros,Crocodile,Coyote,Duck,Camel,Wolf,Hare,Lynx,Turtle,Horse,Cat,Dog,Snake,Panther,Whale,Dolphin\"\n",
        "PD01003,\"Ostrich,Bison,Goat,Zebra,Dog,Cat,Cow,Pig,Hare,Lion,Tiger,Donkey,Monkey,Dog,Vulture,Turtle,Rhinoceros,Whale\"\n",
        "PD01126,\"Dog,Cat,Tiger,Elephant,Cow,Calf,Horse,Panda\"\n",
        "PD01133,\"Dog,Cat,Monkey,Mule,Eel,Tiger,Lion,Moose,Elk,Wolf,Fox,Marmot,Beaver,Gopher,Crow,Giraffe\"\n",
        "PD01145,\"Lion,Tiger,Bear,Wolf,Cat,Goat,Duck,Goose,Bull,Antelope\"\n",
        "PD01146,\"Lion,Cat,Dog,Cow,Sheep,Duck,Giraffe,Pig,Hare,Antelope,Zebra,Camel,Elephant,Rhinoceros,Dog,Donkey,Horse,Goat,Mouse\"\n",
        "PD01156,\"Reptile,Cow,Deer,Salamander,Bear,Fish,Cat,Mouse\"\n",
        "PD01160,\"Lion,Bear,Tiger,Fox,Rat,Cat,Dog,Horse,Monkey,Hippo,Wolf,Deer,Roe deer,Crocodile,Salamander,Reptile,Panda\"\n",
        "PD01161,\"Horse,Cow,Sheep,Ewe,Camel,Hippo,Elephant,Turkey,Cat,Otter,Rabbit,Hare,Tiger,Lion,Snake,Bee,Wasp,Mosquito,Wolf,Fox,Zebra,Coyote,Hen,Bird,Crow\"\n",
        "PD01199,\"Lion,Tiger,Duck,Goose,Roe Deer,Horse,Zebra,Elephant,Bird,Giraffe,Hippopotamus,Crocodile,Elephant,Sheep,Goat,Ewe,Duck\"\n",
        "PD01201,\"Cat,Dog,Elephant,Lion,Hippopotamus,Rhinoceros,Eagle,Zebra,Panther,Pigeon,Cow\"\n",
        "PD01223,\"Elephant,Lion,Crocodile,Caiman,Snake,Dog,Cat,Fish,Turtle,Skunk\"\n",
        "PD01225,\"Lion,Dog,Cat,Horse,Bird,Eagle,Donkey,Rabbit,Deer,Hare,Bird,Mouse,Rat,Snake,Bird,Camel,Dromedary,Alligator,Crocodile\"\n",
        "PD01237,\"Cat,Dog,Horse,Pig,Pig,Goose,Goat,Dromedary,Gazelle,Zebra,Bull,Swallow,Pigeon,Llama,Fox,Elephant,Marmot,Wildcat,Spider,Seagull,Mongoose,Penguin\"\n",
        "PD01247,\"Albatross,Whale,Bulldog,Poodle,Toad,Donkey,Monkey,Hippopotamus,Ram,Bull,Cat,Dog,Porcupine\"\n",
        "PD01270,\"Lion,Giraffe,Tiger,Panther,Pigeon,Monkey,Wolf,Dog,Cat,Mouse,Horse,Sheep,Camel,Leopard,Emu\"\n",
        "PD01282,\"Cow,Tiger,Lion,Horse,Dog,Cat,Mouse,Snake,Squirrel,Slug,Snail,Monkey,Giraffe,Elephant,Wolf,Fish,Bird\"\n",
        "PD01284,\"Lion,Tiger,Caribou,Owl,Shark,Fish,Monkey,Dog,Cat,Alligator,Crocodile,Pelican,Jaguar,Penguin,Cow,Pig,Rooster,Raccoon,Beaver\"\n",
        "PD01290,\"Dog,Cat,Rabbit,Lion,Lamb,Unicorn,Tiger,Elephant,Camel,Mole\"\n",
        "PD01306,\"Dog,Cat,Raccoon,Lion,Elephant,Giraffe,Leopard,Tiger,Eagle,Turtle,Horse,Wolf,Hare,Horse,Cow,Mule,Sheep,Llama,Donkey,Parrot,Crow,Finch\"\n",
        "PD01312,\"Dog,Cat,Horse,Goat,Sheep,Hen,Weasel,Hedgehog,Rabbit,Lion,Tiger,Monkey,Meerkat,Hippopotamus,Rhino,Zebra,Elephant,Panther,Jaguar,Chimpanzee,Gibbon,Fox,Raccoon,Rat,Elephant,Otter,Camel\"\n",
        "PD01319,\"Dog,Cat,Mouse,Rat,Lion,Elephant,Tiger,Giraffe,Zebra,Eagle,Deer,Wolf,Fox,Bear,Cow,Ox\"\n",
        "PD01369,\"Cat,Dog,Mouse,Rat,Snake,Caiman,Tiger,Giraffe,Fox,Crocodile,Lion,Elephant,Tiger,Deer,Crocodile,Dolphin,Otter,Whale,Dog,Swallow,Jaguar,Zebra,Mouse\"\n",
        "PD01377,\"Cat,Dog,Mosquito,Vulture,Cow,Bull,Dromedary,Goat,Parrot,Monkey,Leopard,Lion,Tiger,Zebra,Giraffe,Squirrel,Bird,Crocodile,Hen,Wolf,Rabbit\"\n",
        "PD01435,\"Rhinoceros,Dog,Mouse,Zebra,Raccoon,Wildcat,Kangaroo,Bear,Weasel,Skunk,Elephant,Monkey,Bull,Cow,Wolf,Wild boar,Fox\"\n",
        "PD01440,\"Horse,Fox,Dog,Deer,Eagle,Goat,Cat,Raccoon,Dromedary,Camel,Rhinoceros,Lion,Tiger,Whale,Dolphin,Elephant\"\n",
        "PD01457,\"Horse,Dog,Cat,Lion,Bird,Sheep,Giraffe,Whale,Hummingbird,Hippopotamus,Leopard,Deer,Panther\"\n",
        "PD01485,\"Horse,Cow,Hen,Pig,Parrot,Parakeet,Snake,Tiger,Lion,Crow,Sheep,Goat,Mare,Moose,Zebra,Pig,Squirrel\"\n",
        "PD01559,\"Dog,Cat,Perch,Golden eagle,Blackbird,Panther,Cow,Pig,Fox,Partridge,Gazelle,Hare,Jellyfish,Lizard,Tench,Fish,Shark,Cod\"\n",
        "PD01623,\"Dog,Cat,Hippopotamus,Giraffe,Lion,Zebra,Mammoth,Blue Whale,Dolphin,Humpback Whale,Whale,Eel,Tiger,Chimpanzee\"\n",
        "PD01660,\"Lion,Bear,Tiger,Fox,Dog,Cat,Rat,Mouse,Horse,Monkey,Hippopotamus,Ox,Deer,Roe Deer,Crocodile,Salamander,Turtle\"\n",
        "PD01667,\"Dog,Cat,Horse,Cow,Hen,Chick,Swan,Bird,Giraffe,Lion,Zebra,Gazelle,Monkey,Chimpanzee,Squirrel,Frog,Fish,Ox,Chicken\"\n",
        "PD01715,\"Donkey,Boa,Goat,Frog,Zebra,Hippopotamus,Elephant,Bird,Crocodile,Caiman,Fox,Wolf,Dog,Horse,Turkey,Chicken\"\n",
        "'''\n",
        "\n",
        "\n",
        "# Load the data into a DataFrame\n",
        "compressed_data = pd.read_csv(io.StringIO(data_str))\n",
        "\n",
        "# Compress the format\n",
        "# compressed_data = data.groupby('ID')['Item'].apply(lambda x: ','.join(x)).reset_index()\n",
        "# print(compressed_data.to_csv(index=False, header=False))\n",
        "\n",
        "data = compressed_data.set_index('ID')['Item'].str.split(',', expand=True).stack().reset_index(level=1, drop=True).reset_index(name='Item')\n",
        "\n",
        "# Preprocess the data\n",
        "data['Item'] = data['Item'].str.lower()\n",
        "data = data.dropna().reset_index(drop=True)\n",
        "\n",
        "# Load the MEG PSD and LC data\n",
        "meg_lc_data = pd.read_csv(io.StringIO('''\n",
        "PD00020,0.005821693,PD,MRI01,1.14817625,1.158620797,1.044436934,1.016706475,1.153398524,1.030571705\n",
        "PD00048,0.002184409,PD,MRI01,1.098492193,1.109323313,1.085092243,0.965901336,1.103907753,1.02549679\n",
        "PD00146,0.005128224,PD,MRI01,1.12043934,1.125366723,1.041352235,1.026072416,1.122903032,1.033712326\n",
        "PD00215,0.010895761,PD,MRI01,1.124369462,1.147340095,1.107812477,1.04618484,1.135854779,1.076998659\n",
        "PD00267,0.008189669,PD,MRI01,1.125531069,1.140897908,0.967051224,1.016658103,1.133214489,0.991854664\n",
        "PD00435,-0.000320732,PD,MRI01,1.151385681,1.157403175,1.077082602,1.04921465,1.154394428,1.063148626\n",
        "PD00457,0.012298484,PD,MRI01,1.135743887,1.15363705,1.026133289,1.00723257,1.144690469,1.01668293\n",
        "PD00458,0.005792042,wh,MRI01,1.109559367,1.097898078,1.002167845,0.990411005,1.103728723,0.996289425\n",
        "PD00471,0.01557979,PD,MRI01,1.108482202,1.119510385,1.059153313,1.005142551,1.113996294,1.032147932\n",
        "PD00472,0.002845305,PD,MRI01,1.131407474,1.124698698,1.012803178,1.006284571,1.128053086,1.009543875\n",
        "PD00576,0.006214223,PD,MRI01,1.13669321,1.101167369,1.010767356,0.980709959,1.11893029,0.995738658\n",
        "PD00583,0.011054202,PD,MRI01,1.167059597,1.192501535,1.048418201,1.03093474,1.179780566,1.039676471\n",
        "PD00647,0.012765069,PD,MRI01,1.17168617,1.173416059,1.048713887,0.996420128,1.172551115,1.022567008\n",
        "PD00653,0.002976496,PD,MRI01,1.121667314,1.125644883,1.057027218,1.022004836,1.123656099,1.039516027\n",
        "PD00666,0.007817361,PD,MRI01,1.150401596,1.147735054,1.086564272,1.024473415,1.149068325,1.055518844\n",
        "PD00760,0.006284154,PD,MRI01,1.120037021,1.123426753,1.092308416,1.082897655,1.121731887,1.087603036\n",
        "PD00782,0.01282925,PD,MRI01,1.145133712,1.131980666,1.054120151,0.94571262,1.138557189,0.999916386\n",
        "PD00786,0.009724077,PD,MRI01,1.157515977,1.177123247,1.061681281,1.071758478,1.167319612,1.06671988\n",
        "PD00849,0.003137561,PD,MRI01,1.135132788,1.119543415,1.035214935,1.00009055,1.127338102,1.017652743\n",
        "PD00869,0.004906212,PD,MRI01,1.179676691,1.162712019,1.052869954,1.059981673,1.171194355,1.056425814\n",
        "PD00955,0.004907711,PD,MRI01,1.099646414,1.093747264,1.067138195,1.012457489,1.096696839,1.039797842\n",
        "PD00959,0.005620251,PD,MRI01,1.178740804,1.18169224,1.047018303,1.017696666,1.180216522,1.032357485\n",
        "PD00979,0.011858656,PD,MRI01,1.13533415,1.145842553,1.042297677,1.031131331,1.140588352,1.036714504\n",
        "PD00999,0.007539312,PD,MRI01,1.121039703,1.114581886,1.019246549,1.047996081,1.117810795,1.033621315\n",
        "PD01003,0.000208535,PD,MRI01,1.158352227,1.166165487,1.053469281,1.027859965,1.162258857,1.040664623\n",
        "PD01126,0.009593198,PD,MRI01,1.150857865,1.161401845,1.040231225,0.936756654,1.156129855,0.98849394\n",
        "PD01133,0.010680812,PD,MRI01,1.140434901,1.136423638,1.067105935,1.01522526,1.13842927,1.041165598\n",
        "PD01145,0.013859908,PD,MRI01,1.113749657,1.12799097,1.04202595,1.037014288,1.120870314,1.039520119\n",
        "PD01146,0.00846295,PD,MRI01,1.135879429,1.145600225,1.062304091,0.971604258,1.140739827,1.016954175\n",
        "PD01156,0.006055495,PD,MRI01,1.141696067,1.156531656,1.032215543,1.007290441,1.149113862,1.019752992\n",
        "PD01160,0.003374795,PD,MRI01,1.171401262,1.164055444,1.100873266,1.079814085,1.167728353,1.090343676\n",
        "PD01161,0.00994361,PD,MRI01,1.140817652,1.13972807,1.029183705,1.017640502,1.140272861,1.023412104\n",
        "PD01185,0.001633098,PD,MRI01,1.108157836,1.104975331,1.065245537,1.0417037,1.106566584,1.053474619\n",
        "PD01201,0.007203862,PD,MRI01,1.133900891,1.109959963,1.077411846,1.000333387,1.121930427,1.038872617\n",
        "PD01223,0.014742915,PD,MRI01,1.155200022,1.150784689,0.928924197,0.939748166,1.152992356,0.934336182\n",
        "PD01224,0.003490251,PD,MRI01,1.172828108,1.181531226,1.028351815,1.010027707,1.177179667,1.019189761\n",
        "PD01225,0.006126801,PD,MRI01,1.15817036,1.167311582,1.045890234,1.024632098,1.162740971,1.035261166\n",
        "PD01237,0.006228002,PD,MRI01,1.161751577,1.170066857,1.096360359,1.025476607,1.165909217,1.060918483\n",
        "PD01247,0.010700682,PD,MRI01,1.164163271,1.133893525,1.052122159,1.036381196,1.149028398,1.044251678\n",
        "PD01270,0.008413686,PD,MRI01,1.17624789,1.17607616,1.009163279,1.038136711,1.176162025,1.023649995\n",
        "PD01284,0.005869985,PD,MRI01,1.13403638,1.109575977,1.034757911,0.974893225,1.121806179,1.004825568\n",
        "PD01290,0.003746161,PD,MRI01,1.146972445,1.134276733,1.025885657,1.021652488,1.140624589,1.023769073\n",
        "PD01299,0.005044514,PD,MRI01,1.128833448,1.133872573,1.065549182,1.031607535,1.131353011,1.048578359\n",
        "PD01306,0.001772092,PD,MRI01,1.171649957,1.164974907,1.100990317,1.034121272,1.168312432,1.067555795\n",
        "PD01312,0.011649313,PD,MRI01,1.168236111,1.171257251,1.09582418,1.065116397,1.169746681,1.080470289\n",
        "PD01319,0.011121281,PD,MRI01,1.117372555,1.10524261,1.070446072,0.961042878,1.111307583,1.015744475\n",
        "PD01369,0.003870708,PD,MRI01,1.18250833,1.166918143,1.103202899,1.016960361,1.174713237,1.06008163\n",
        "PD01377,0.02001576,PD,MRI01,1.146505788,1.134881191,1.050975683,1.024639126,1.14069349,1.037807405\n",
        "PD01485,0.010696665,PD,MRI01,1.155521698,1.183913381,1.035332854,1.043189044,1.16971754,1.039260949\n",
        "PD01494,-0.000360164,PD,MRI01,1.154294214,1.15183774,1.103154652,1.049245173,1.153065977,1.076199913\n",
        "PD01550,0.004904257,PD,MRI01,1.142321634,1.126710722,1.076955259,1.044531412,1.134516178,1.060743336\n",
        "PD01559,0.002176473,PD,MRI01,1.185234345,1.164503426,1.072554804,1.074433506,1.174868886,1.073494155\n",
        "PD01603,0.002877681,PD,MRI01,1.119341671,1.142670798,1.074238211,1.046278134,1.131006235,1.060258173\n",
        "PD01623,0.013388923,PD,PD01623MRI01,1.110364728,1.101435699,1.073174459,0.997847314,1.105900214,1.035510887\n",
        "PD01660,0.009658789,PD,MRI01,1.146810392,1.142374341,1.043183894,1.000483297,1.144592367,1.021833596\n",
        "PD01667,0.004057877,PD,MRI01,1.14080379,1.130201021,1.059124791,1.0327146,1.135502406,1.045919696\n",
        "PD01715,0.00505598,PD,MRI01,1.100505544,1.118382993,1.047199874,1.012294835,1.109444269,1.029747355\n",
        "'''), header=None, names=['ID','alpha_NET_mean','status','visit','norm_SN_l','norm_SN_r','norm_LC_l','norm_LC_r','norm_SN_avg','norm_LC_avg'])\n",
        "\n",
        "meg_lc_data = meg_lc_data[meg_lc_data['norm_SN_avg'].notna()]\n",
        "\n",
        "# Remove 'PD' and leading zeros\n",
        "clean_id = lambda x: str(int(x.replace('PD', '')))\n",
        "data['clean_ID'] = data['ID'].apply(clean_id)\n",
        "meg_lc_data['clean_ID'] = meg_lc_data['ID'].apply(clean_id)\n",
        "\n",
        "# Display the data\n",
        "print(data.head().to_csv(index=False),'.....\\n',data.tail().to_csv(index=False, header=False))\n",
        "print(meg_lc_data.head().to_csv(index=False), '.....\\n', meg_lc_data.tail().to_csv(index=False, header=False))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33yAvYgcoJQ_",
        "outputId": "038c50b5-f4f7-4e61-842b-f2d881df48b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          ID     Item clean_ID\n",
              "0    PD00020     lion       20\n",
              "1    PD00020    tiger       20\n",
              "2    PD00020    sheep       20\n",
              "3    PD00020      dog       20\n",
              "4    PD00020      cat       20\n",
              "..       ...      ...      ...\n",
              "932  PD01715     wolf     1715\n",
              "933  PD01715      dog     1715\n",
              "934  PD01715    horse     1715\n",
              "935  PD01715   turkey     1715\n",
              "936  PD01715  chicken     1715\n",
              "\n",
              "[937 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f735b87e-0e0d-478a-824a-036e21265539\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Item</th>\n",
              "      <th>clean_ID</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>PD00020</td>\n",
              "      <td>lion</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>PD00020</td>\n",
              "      <td>tiger</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>PD00020</td>\n",
              "      <td>sheep</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>PD00020</td>\n",
              "      <td>dog</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>PD00020</td>\n",
              "      <td>cat</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>932</th>\n",
              "      <td>PD01715</td>\n",
              "      <td>wolf</td>\n",
              "      <td>1715</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>933</th>\n",
              "      <td>PD01715</td>\n",
              "      <td>dog</td>\n",
              "      <td>1715</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>934</th>\n",
              "      <td>PD01715</td>\n",
              "      <td>horse</td>\n",
              "      <td>1715</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>935</th>\n",
              "      <td>PD01715</td>\n",
              "      <td>turkey</td>\n",
              "      <td>1715</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>936</th>\n",
              "      <td>PD01715</td>\n",
              "      <td>chicken</td>\n",
              "      <td>1715</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>937 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f735b87e-0e0d-478a-824a-036e21265539')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f735b87e-0e0d-478a-824a-036e21265539 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f735b87e-0e0d-478a-824a-036e21265539');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-fa6d658f-d700-4ab1-a8c0-55cca3fe8b44\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fa6d658f-d700-4ab1-a8c0-55cca3fe8b44')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-fa6d658f-d700-4ab1-a8c0-55cca3fe8b44 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_fd000502-db3c-4aa9-a430-316f623ea9b8\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('data')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_fd000502-db3c-4aa9-a430-316f623ea9b8 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('data');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 937,\n  \"fields\": [\n    {\n      \"column\": \"ID\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 56,\n        \"samples\": [\n          \"PD00020\",\n          \"PD00219\",\n          \"PD01201\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Item\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 150,\n        \"samples\": [\n          \"caterpillar\",\n          \"elk\",\n          \"bulldog\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"clean_ID\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 56,\n        \"samples\": [\n          \"20\",\n          \"219\",\n          \"1201\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "source": [
        "from google.colab import sheets\n",
        "sheet = sheets.InteractiveSheet(df=data)"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://docs.google.com/spreadsheets/d/1qNu1lt6rnKLvFrmJwocJxcufUtzL_HF9XfEDDpWWYco/edit#gid=0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x7e332faaa3d0>"
            ],
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"100%\"\n",
              "            height=\"600\"\n",
              "            src=\"https://docs.google.com/spreadsheets/d/1qNu1lt6rnKLvFrmJwocJxcufUtzL_HF9XfEDDpWWYco/edit?rm=embedded#gid=0\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "            \n",
              "        ></iframe>\n",
              "        "
            ]
          },
          "metadata": {}
        }
      ],
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zt6CgzCt6rnS",
        "outputId": "32d2f993-8e6d-48e1-be62-463a7dd5db68"
      }
    },
    {
      "source": [
        "from google.colab import sheets\n",
        "sheet = sheets.InteractiveSheet(df=data)"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://docs.google.com/spreadsheets/d/1CZRmJw5Q9yty3zFfYNTC4FFEVt1ixfZCO7xWr3JAqX8/edit#gid=0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x7e33420fb0d0>"
            ],
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"100%\"\n",
              "            height=\"600\"\n",
              "            src=\"https://docs.google.com/spreadsheets/d/1CZRmJw5Q9yty3zFfYNTC4FFEVt1ixfZCO7xWr3JAqX8/edit?rm=embedded#gid=0\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "            \n",
              "        ></iframe>\n",
              "        "
            ]
          },
          "metadata": {}
        }
      ],
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 639
        },
        "id": "OK4lWLPyp2W7",
        "outputId": "f10258a7-de13-4f3b-b1d8-ff38e6eda332"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from wordfreq import top_n_list\n",
        "import io\n",
        "\n",
        "# Load the data\n",
        "data_str = '''ID,Item\n",
        "PD00020,\"Lion,Tiger,Sheep,Dog,Cat,Camel,Monkey,Chimpanzee,Buffalo,Hyena,Dog,Cat,Elephant,Hyena,Dog,Cat,Mouse,Bird,Camel,Dragon\"\n",
        "PD00048,\"Lion,Hare,Elephant,Rhinoceros,Monkey,Giraffe,Cow,Elk,Fish,Horse,Tiger,Leopard,Jaguar\"\n",
        "PD00119,\"Lion,Tiger,Duck,Goose,Deer,Horse,Zebra,Elephant,Bird,Giraffe,Hippo,Crocodile,Elephant,Sheep,Goat,Ewe,Duck\"\n",
        "PD00146,\"Dog,Pig,Chicken,Partridge,Swallow,Squirrel,Rabbit,Horse,Hare,Calf,Bull,Cow,Lion,Tiger,Monkey,Giraffe,Elephant,Snake,Frog,Shark,Whale,Dolphin\"\n",
        "PD00215,\"Donkey,Horse,Cow,Ox,Elephant,Llama,Cat,Dog,Mouse,Tiger,Lion,Leopard,Cheetah,Hyena,Bear,Goat,Partridge,Hare,Manatee,Turtle,Iguana,Frog,Toad\"\n",
        "PD00219,\"Monkey,Lion,Tiger,Horse,Cat,Dog,Snake,Wolf,Coyote,Horse,Cow,Camel,Scorpion\"\n",
        "PD00267,\"Cat,Dog,Lion,Beaver,Jaguar,Elephant,Gazelle,Bear,Fox,Horse,Ox,Calf,Giraffe\"\n",
        "PD00457,\"rhinoceros,fox,tiger,hippopotamus,tiger,lion,leopard,gazelle,dog,cat,horse,cow,sheep,horse,lion,gazelle,turkey\"\n",
        "PD00458,\"Dog,Cat,Hamster,Tiger,Fox,Lion,Rhinoceros,Wolf,Partridge,Coyote,Eagle,Pigeon,Parrot,Crocodile,Whale,Dolphin,Marmot\"\n",
        "PD00471,\"Cat,Dog,Horse,Cow,Calf,Lion,Pig,Monkey,Rhinoceros,Zebra,Elephant,Antelope,Fish,Panther,Camel,Lion,Hare,Crocodile,Rabbit,Mouse,Butterfly,Monkey\"\n",
        "PD00472,\"Cat,dog,duck,Fish,Lark,Horse,pig,snake,crocodile,lion,Gazelle,Zebra,Elephant,Wolf,Fox,Panther,jaguar,Chimpanzee,Panda,Hen,Rooster\"\n",
        "PD00576,\"Wolf,Horse,Camel,Cat,Dog,Tiger,Leopard,Lion,Elephant,Antelope,Caterpillar,Ostrich,Wasp,Ant,Fish,Shark,Crow,Trout,Salmon,Frog,Swallow,Spider,Panther\"\n",
        "PD00583,\"Dog,Cat,Goat,Wolf,Fox,Hippopotamus,Elephant,Rooster,Hen,Turkey,Rabbit,Parrot,Crocodile,Butterfly,Grasshopper\"\n",
        "PD00647,\"Elephant,Tiger,Alligator,Monkey,Butterfly,Whale,Dog,Cat,Rat,Chimpanzee,Cow,Cat,Flea,bird,Insect,Fish\"\n",
        "PD00653,\"Cow,Cat,Bear,Horse,Pig,Dog,Wolf,Bird,Elk,Crocodile,Hippopotamus,Lion,Tiger,Bird,Snake,Pig,Cow,Chicken,Lamb\"\n",
        "PD00660,\"Dog,Cat,Rat,Crocodile,Lion,Tiger,Horse,Cow,Fish,Bird,Hen,Giraffe,Hippopotamus,Chimpanzee,Goat,Fox\"\n",
        "PD00666,\"Cat,Goat,Mouse,Weasel,Cow,Bizon,Horse,Lion,Panther,Elephant,Gazelle,Orangutan,Cat,Eagle,Marmot,Moray eel,Snake,Whale,Shark\"\n",
        "PD00757,\"Dog,Cat,Lion,Tiger,Fox,Snake,Spider,Elephant,Sheep\"\n",
        "PD00786,\"Cat,Dog,Monkey,Hen,Rooster,Pig,Horse,Cow,Calf,Lamb,Sheep,Ox,Chicken,Duck\"\n",
        "PD00849,\"Lion,Hare,Wolf,Fox,Cat,Dog,Tiger,Elephant,Rhinoceros,Ostrich,Zebra,Pheasant,Giraffe,Leopard,Tiger,Cougar\"\n",
        "PD00869,\"Cow,Calf,Horse,Lion,Hippopotamus,Rhinoceros,Monkey,Hen,Rabbit,Pheasant,Parrot,Gazelle,Giraffe,Lion,Marmot,dog,Donkey,Cheetah,Swan,Duck,Mule\"\n",
        "PD00955,\"Dog,Cat,Rat,Mole,Lion,Tiger,Giraffe,Hyena,Leopard,Lynx,Fox,Ram,Horse\"\n",
        "PD00959,\"Tiger,Lion,Hen,Rhino,Hippo,Llama,Giraffe,Goat,Sheep\"\n",
        "PD00999,\"Lion,Tiger,Elephant,Rhinoceros,Crocodile,Coyote,Duck,Camel,Wolf,Hare,Lynx,Turtle,Horse,Cat,Dog,Snake,Panther,Whale,Dolphin\"\n",
        "PD01003,\"Ostrich,Bison,Goat,Zebra,Dog,Cat,Cow,Pig,Hare,Lion,Tiger,Donkey,Monkey,Dog,Vulture,Turtle,Rhinoceros,Whale\"\n",
        "PD01126,\"Dog,Cat,Tiger,Elephant,Cow,Calf,Horse,Panda\"\n",
        "PD01133,\"Dog,Cat,Monkey,Mule,Eel,Tiger,Lion,Moose,Elk,Wolf,Fox,Marmot,Beaver,Gopher,Crow,Giraffe\"\n",
        "PD01145,\"Lion,Tiger,Bear,Wolf,Cat,Goat,Duck,Goose,Bull,Antelope\"\n",
        "PD01146,\"Lion,Cat,Dog,Cow,Sheep,Duck,Giraffe,Pig,Hare,Antelope,Zebra,Camel,Elephant,Rhinoceros,Dog,Donkey,Horse,Goat,Mouse\"\n",
        "PD01156,\"Reptile,Cow,Deer,Salamander,Bear,Fish,Cat,Mouse\"\n",
        "PD01160,\"Lion,Bear,Tiger,Fox,Rat,Cat,Dog,Horse,Monkey,Hippo,Wolf,Deer,Roe deer,Crocodile,Salamander,Reptile,Panda\"\n",
        "PD01161,\"Horse,Cow,Sheep,Ewe,Camel,Hippo,Elephant,Turkey,Cat,Otter,Rabbit,Hare,Tiger,Lion,Snake,Bee,Wasp,Mosquito,Wolf,Fox,Zebra,Coyote,Hen,Bird,Crow\"\n",
        "PD01199,\"Lion,Tiger,Duck,Goose,Roe Deer,Horse,Zebra,Elephant,Bird,Giraffe,Hippopotamus,Crocodile,Elephant,Sheep,Goat,Ewe,Duck\"\n",
        "PD01201,\"Cat,Dog,Elephant,Lion,Hippopotamus,Rhinoceros,Eagle,Zebra,Panther,Pigeon,Cow\"\n",
        "PD01223,\"Elephant,Lion,Crocodile,Caiman,Snake,Dog,Cat,Fish,Turtle,Skunk\"\n",
        "PD01225,\"Lion,Dog,Cat,Horse,Bird,Eagle,Donkey,Rabbit,Deer,Hare,Bird,Mouse,Rat,Snake,Bird,Camel,Dromedary,Alligator,Crocodile\"\n",
        "PD01237,\"Cat,Dog,Horse,Pig,Pig,Goose,Goat,Dromedary,Gazelle,Zebra,Bull,Swallow,Pigeon,Llama,Fox,Elephant,Marmot,Wildcat,Spider,Seagull,Mongoose,Penguin\"\n",
        "PD01247,\"Albatross,Whale,Bulldog,Poodle,Toad,Donkey,Monkey,Hippopotamus,Ram,Bull,Cat,Dog,Porcupine\"\n",
        "PD01270,\"Lion,Giraffe,Tiger,Panther,Pigeon,Monkey,Wolf,Dog,Cat,Mouse,Horse,Sheep,Camel,Leopard,Emu\"\n",
        "PD01282,\"Cow,Tiger,Lion,Horse,Dog,Cat,Mouse,Snake,Squirrel,Slug,Snail,Monkey,Giraffe,Elephant,Wolf,Fish,Bird\"\n",
        "PD01284,\"Lion,Tiger,Caribou,Owl,Shark,Fish,Monkey,Dog,Cat,Alligator,Crocodile,Pelican,Jaguar,Penguin,Cow,Pig,Rooster,Raccoon,Beaver\"\n",
        "PD01290,\"Dog,Cat,Rabbit,Lion,Lamb,Unicorn,Tiger,Elephant,Camel,Mole\"\n",
        "PD01306,\"Dog,Cat,Raccoon,Lion,Elephant,Giraffe,Leopard,Tiger,Eagle,Turtle,Horse,Wolf,Hare,Horse,Cow,Mule,Sheep,Llama,Donkey,Parrot,Crow,Finch\"\n",
        "PD01312,\"Dog,Cat,Horse,Goat,Sheep,Hen,Weasel,Hedgehog,Rabbit,Lion,Tiger,Monkey,Meerkat,Hippopotamus,Rhino,Zebra,Elephant,Panther,Jaguar,Chimpanzee,Gibbon,Fox,Raccoon,Rat,Elephant,Otter,Camel\"\n",
        "PD01319,\"Dog,Cat,Mouse,Rat,Lion,Elephant,Tiger,Giraffe,Zebra,Eagle,Deer,Wolf,Fox,Bear,Cow,Ox\"\n",
        "PD01369,\"Cat,Dog,Mouse,Rat,Snake,Caiman,Tiger,Giraffe,Fox,Crocodile,Lion,Elephant,Tiger,Deer,Crocodile,Dolphin,Otter,Whale,Dog,Swallow,Jaguar,Zebra,Mouse\"\n",
        "PD01377,\"Cat,Dog,Mosquito,Vulture,Cow,Bull,Dromedary,Goat,Parrot,Monkey,Leopard,Lion,Tiger,Zebra,Giraffe,Squirrel,Bird,Crocodile,Hen,Wolf,Rabbit\"\n",
        "PD01435,\"Rhinoceros,Dog,Mouse,Zebra,Raccoon,Wildcat,Kangaroo,Bear,Weasel,Skunk,Elephant,Monkey,Bull,Cow,Wolf,Wild boar,Fox\"\n",
        "PD01440,\"Horse,Fox,Dog,Deer,Eagle,Goat,Cat,Raccoon,Dromedary,Camel,Rhinoceros,Lion,Tiger,Whale,Dolphin,Elephant\"\n",
        "PD01457,\"Horse,Dog,Cat,Lion,Bird,Sheep,Giraffe,Whale,Hummingbird,Hippopotamus,Leopard,Deer,Panther\"\n",
        "PD01485,\"Horse,Cow,Hen,Pig,Parrot,Parakeet,Snake,Tiger,Lion,Crow,Sheep,Goat,Mare,Moose,Zebra,Pig,Squirrel\"\n",
        "PD01559,\"Dog,Cat,Perch,Golden eagle,Blackbird,Panther,Cow,Pig,Fox,Partridge,Gazelle,Hare,Jellyfish,Lizard,Tench,Fish,Shark,Cod\"\n",
        "PD01623,\"Dog,Cat,Hippopotamus,Giraffe,Lion,Zebra,Mammoth,Blue Whale,Dolphin,Humpback Whale,Whale,Eel,Tiger,Chimpanzee\"\n",
        "PD01660,\"Lion,Bear,Tiger,Fox,Dog,Cat,Rat,Mouse,Horse,Monkey,Hippopotamus,Ox,Deer,Roe Deer,Crocodile,Salamander,Turtle\"\n",
        "PD01667,\"Dog,Cat,Horse,Cow,Hen,Chick,Swan,Bird,Giraffe,Lion,Zebra,Gazelle,Monkey,Chimpanzee,Squirrel,Frog,Fish,Ox,Chicken\"\n",
        "PD01715,\"Donkey,Boa,Goat,Frog,Zebra,Hippopotamus,Elephant,Bird,Crocodile,Caiman,Fox,Wolf,Dog,Horse,Turkey,Chicken\"\n",
        "'''\n",
        "\n",
        "# Parse data\n",
        "compressed_data = pd.read_csv(io.StringIO(data_str))\n",
        "\n",
        "# Get top 50k words and create rank dictionary\n",
        "print(\"Loading top 50,000 English words...\")\n",
        "top_50k = top_n_list('en', 50000)\n",
        "rank_dict = {word: rank+1 for rank, word in enumerate(top_50k)}\n",
        "\n",
        "# Process each patient\n",
        "results = []\n",
        "\n",
        "for _, row in compressed_data.iterrows():\n",
        "    patient_id = row['ID']\n",
        "    animals = [animal.strip().lower() for animal in row['Item'].split(',')]\n",
        "\n",
        "    # Rank each animal\n",
        "    for animal in animals:\n",
        "        rank = rank_dict.get(animal, 0)  # 0 means not in top 50k\n",
        "        results.append({\n",
        "            'ID': patient_id,\n",
        "            'Animal': animal,\n",
        "            'Rank': rank,\n",
        "            'In_Top_50k': 'Yes' if rank > 0 else 'No'\n",
        "        })\n",
        "\n",
        "# Create DataFrame\n",
        "results_df = pd.DataFrame(results)\n",
        "\n",
        "# Sort by ID and then by Rank (most common words first)\n",
        "results_df = results_df.sort_values(['ID', 'Rank'])\n",
        "\n",
        "# Display results\n",
        "print(\"\\nAnimal Word Frequency Rankings by Patient:\")\n",
        "print(\"=\"*60)\n",
        "print(results_df.to_string(index=False))\n",
        "\n",
        "# Save to CSV\n",
        "results_df.to_csv('animal_rankings_by_patient.csv', index=False)\n",
        "print(f\"\\nResults saved to 'animal_rankings_by_patient.csv'\")\n",
        "\n",
        "# Summary by patient\n",
        "print(\"\\n\\nSummary by Patient:\")\n",
        "print(\"=\"*60)\n",
        "summary = results_df.groupby('ID').agg({\n",
        "    'Rank': ['count', lambda x: (x > 0).sum(), lambda x: x[x > 0].mean() if any(x > 0) else None]\n",
        "})\n",
        "summary.columns = ['Total_Animals', 'Animals_in_Top50k', 'Avg_Rank_in_Top50k']\n",
        "summary['Pct_in_Top50k'] = (summary['Animals_in_Top50k'] / summary['Total_Animals'] * 100).round(1)\n",
        "summary['Avg_Rank_in_Top50k'] = summary['Avg_Rank_in_Top50k'].round(0)\n",
        "\n",
        "print(summary.to_string())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "V5hYTYFU5Yrx",
        "outputId": "38c3a75c-34b6-4439-b17e-f0cb3857ea36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading top 50,000 English words...\n",
            "\n",
            "Animal Word Frequency Rankings by Patient:\n",
            "============================================================\n",
            "     ID         Animal  Rank In_Top_50k\n",
            "PD00020            dog   826        Yes\n",
            "PD00020            dog   826        Yes\n",
            "PD00020            dog   826        Yes\n",
            "PD00020            cat  1713        Yes\n",
            "PD00020            cat  1713        Yes\n",
            "PD00020            cat  1713        Yes\n",
            "PD00020           bird  2329        Yes\n",
            "PD00020         dragon  3555        Yes\n",
            "PD00020          mouse  4255        Yes\n",
            "PD00020          tiger  4340        Yes\n",
            "PD00020           lion  4686        Yes\n",
            "PD00020          sheep  5264        Yes\n",
            "PD00020        buffalo  5663        Yes\n",
            "PD00020       elephant  6236        Yes\n",
            "PD00020         monkey  6380        Yes\n",
            "PD00020          camel 12197        Yes\n",
            "PD00020          camel 12197        Yes\n",
            "PD00020     chimpanzee 30362        Yes\n",
            "PD00020          hyena 37035        Yes\n",
            "PD00020          hyena 37035        Yes\n",
            "PD00048           fish  1339        Yes\n",
            "PD00048          horse  1793        Yes\n",
            "PD00048          tiger  4340        Yes\n",
            "PD00048           lion  4686        Yes\n",
            "PD00048            cow  5670        Yes\n",
            "PD00048       elephant  6236        Yes\n",
            "PD00048         monkey  6380        Yes\n",
            "PD00048           hare 11895        Yes\n",
            "PD00048        leopard 13186        Yes\n",
            "PD00048         jaguar 14780        Yes\n",
            "PD00048            elk 15157        Yes\n",
            "PD00048        giraffe 19096        Yes\n",
            "PD00048     rhinoceros 35048        Yes\n",
            "PD00119          horse  1793        Yes\n",
            "PD00119           bird  2329        Yes\n",
            "PD00119          tiger  4340        Yes\n",
            "PD00119           lion  4686        Yes\n",
            "PD00119           duck  5031        Yes\n",
            "PD00119           duck  5031        Yes\n",
            "PD00119          sheep  5264        Yes\n",
            "PD00119           deer  5872        Yes\n",
            "PD00119       elephant  6236        Yes\n",
            "PD00119       elephant  6236        Yes\n",
            "PD00119           goat  6913        Yes\n",
            "PD00119          goose  9048        Yes\n",
            "PD00119      crocodile 15139        Yes\n",
            "PD00119          zebra 17279        Yes\n",
            "PD00119        giraffe 19096        Yes\n",
            "PD00119          hippo 24472        Yes\n",
            "PD00119            ewe 37448        Yes\n",
            "PD00146            dog   826        Yes\n",
            "PD00146          horse  1793        Yes\n",
            "PD00146        chicken  2334        Yes\n",
            "PD00146           bull  4005        Yes\n",
            "PD00146          tiger  4340        Yes\n",
            "PD00146           lion  4686        Yes\n",
            "PD00146          snake  4895        Yes\n",
            "PD00146            cow  5670        Yes\n",
            "PD00146            pig  5724        Yes\n",
            "PD00146          shark  6098        Yes\n",
            "PD00146       elephant  6236        Yes\n",
            "PD00146         monkey  6380        Yes\n",
            "PD00146         rabbit  6609        Yes\n",
            "PD00146          whale  7410        Yes\n",
            "PD00146           frog  8426        Yes\n",
            "PD00146        swallow  8731        Yes\n",
            "PD00146           calf 10996        Yes\n",
            "PD00146       squirrel 11471        Yes\n",
            "PD00146        dolphin 11686        Yes\n",
            "PD00146           hare 11895        Yes\n",
            "PD00146        giraffe 19096        Yes\n",
            "PD00146      partridge 22465        Yes\n",
            "PD00215            dog   826        Yes\n",
            "PD00215            cat  1713        Yes\n",
            "PD00215          horse  1793        Yes\n",
            "PD00215           bear  1985        Yes\n",
            "PD00215          mouse  4255        Yes\n",
            "PD00215          tiger  4340        Yes\n",
            "PD00215           lion  4686        Yes\n",
            "PD00215            cow  5670        Yes\n",
            "PD00215       elephant  6236        Yes\n",
            "PD00215           goat  6913        Yes\n",
            "PD00215         turtle  8223        Yes\n",
            "PD00215           frog  8426        Yes\n",
            "PD00215           hare 11895        Yes\n",
            "PD00215         donkey 12581        Yes\n",
            "PD00215        leopard 13186        Yes\n",
            "PD00215             ox 15672        Yes\n",
            "PD00215           toad 18717        Yes\n",
            "PD00215        cheetah 22322        Yes\n",
            "PD00215      partridge 22465        Yes\n",
            "PD00215          llama 30868        Yes\n",
            "PD00215          hyena 37035        Yes\n",
            "PD00215         iguana 39853        Yes\n",
            "PD00215        manatee 39906        Yes\n",
            "PD00219            dog   826        Yes\n",
            "PD00219            cat  1713        Yes\n",
            "PD00219          horse  1793        Yes\n",
            "PD00219          horse  1793        Yes\n",
            "PD00219           wolf  3995        Yes\n",
            "PD00219          tiger  4340        Yes\n",
            "PD00219           lion  4686        Yes\n",
            "PD00219          snake  4895        Yes\n",
            "PD00219            cow  5670        Yes\n",
            "PD00219         monkey  6380        Yes\n",
            "PD00219          camel 12197        Yes\n",
            "PD00219       scorpion 17953        Yes\n",
            "PD00219         coyote 18051        Yes\n",
            "PD00267            dog   826        Yes\n",
            "PD00267            cat  1713        Yes\n",
            "PD00267          horse  1793        Yes\n",
            "PD00267           bear  1985        Yes\n",
            "PD00267            fox  2204        Yes\n",
            "PD00267           lion  4686        Yes\n",
            "PD00267       elephant  6236        Yes\n",
            "PD00267           calf 10996        Yes\n",
            "PD00267         beaver 12733        Yes\n",
            "PD00267         jaguar 14780        Yes\n",
            "PD00267             ox 15672        Yes\n",
            "PD00267        giraffe 19096        Yes\n",
            "PD00267        gazelle 34075        Yes\n",
            "PD00457            dog   826        Yes\n",
            "PD00457            cat  1713        Yes\n",
            "PD00457          horse  1793        Yes\n",
            "PD00457          horse  1793        Yes\n",
            "PD00457            fox  2204        Yes\n",
            "PD00457         turkey  2706        Yes\n",
            "PD00457          tiger  4340        Yes\n",
            "PD00457          tiger  4340        Yes\n",
            "PD00457           lion  4686        Yes\n",
            "PD00457           lion  4686        Yes\n",
            "PD00457          sheep  5264        Yes\n",
            "PD00457            cow  5670        Yes\n",
            "PD00457        leopard 13186        Yes\n",
            "PD00457        gazelle 34075        Yes\n",
            "PD00457        gazelle 34075        Yes\n",
            "PD00457     rhinoceros 35048        Yes\n",
            "PD00457   hippopotamus 49394        Yes\n",
            "PD00458         marmot     0         No\n",
            "PD00458            dog   826        Yes\n",
            "PD00458            cat  1713        Yes\n",
            "PD00458            fox  2204        Yes\n",
            "PD00458           wolf  3995        Yes\n",
            "PD00458          tiger  4340        Yes\n",
            "PD00458           lion  4686        Yes\n",
            "PD00458          eagle  5785        Yes\n",
            "PD00458          whale  7410        Yes\n",
            "PD00458        dolphin 11686        Yes\n",
            "PD00458         pigeon 12829        Yes\n",
            "PD00458      crocodile 15139        Yes\n",
            "PD00458         parrot 15240        Yes\n",
            "PD00458         coyote 18051        Yes\n",
            "PD00458        hamster 19356        Yes\n",
            "PD00458      partridge 22465        Yes\n",
            "PD00458     rhinoceros 35048        Yes\n",
            "PD00471            dog   826        Yes\n",
            "PD00471           fish  1339        Yes\n",
            "PD00471            cat  1713        Yes\n",
            "PD00471          horse  1793        Yes\n",
            "PD00471          mouse  4255        Yes\n",
            "PD00471           lion  4686        Yes\n",
            "PD00471           lion  4686        Yes\n",
            "PD00471            cow  5670        Yes\n",
            "PD00471            pig  5724        Yes\n",
            "PD00471       elephant  6236        Yes\n",
            "PD00471         monkey  6380        Yes\n",
            "PD00471         monkey  6380        Yes\n",
            "PD00471         rabbit  6609        Yes\n",
            "PD00471      butterfly  7891        Yes\n",
            "PD00471           calf 10996        Yes\n",
            "PD00471           hare 11895        Yes\n",
            "PD00471        panther 12119        Yes\n",
            "PD00471          camel 12197        Yes\n",
            "PD00471      crocodile 15139        Yes\n",
            "PD00471          zebra 17279        Yes\n",
            "PD00471       antelope 26002        Yes\n",
            "PD00471     rhinoceros 35048        Yes\n",
            "PD00472            dog   826        Yes\n",
            "PD00472           fish  1339        Yes\n",
            "PD00472            cat  1713        Yes\n",
            "PD00472          horse  1793        Yes\n",
            "PD00472            fox  2204        Yes\n",
            "PD00472           wolf  3995        Yes\n",
            "PD00472           lion  4686        Yes\n",
            "PD00472          snake  4895        Yes\n",
            "PD00472           duck  5031        Yes\n",
            "PD00472            pig  5724        Yes\n",
            "PD00472       elephant  6236        Yes\n",
            "PD00472          panda 12118        Yes\n",
            "PD00472        panther 12119        Yes\n",
            "PD00472            hen 13733        Yes\n",
            "PD00472         jaguar 14780        Yes\n",
            "PD00472      crocodile 15139        Yes\n",
            "PD00472          zebra 17279        Yes\n",
            "PD00472        rooster 19441        Yes\n",
            "PD00472           lark 24221        Yes\n",
            "PD00472     chimpanzee 30362        Yes\n",
            "PD00472        gazelle 34075        Yes\n",
            "PD00576            dog   826        Yes\n",
            "PD00576           fish  1339        Yes\n",
            "PD00576            cat  1713        Yes\n",
            "PD00576          horse  1793        Yes\n",
            "PD00576           wolf  3995        Yes\n",
            "PD00576          tiger  4340        Yes\n",
            "PD00576           lion  4686        Yes\n",
            "PD00576         spider  4715        Yes\n",
            "PD00576          shark  6098        Yes\n",
            "PD00576       elephant  6236        Yes\n",
            "PD00576         salmon  7055        Yes\n",
            "PD00576           frog  8426        Yes\n",
            "PD00576        swallow  8731        Yes\n",
            "PD00576            ant  8754        Yes\n",
            "PD00576           crow  9590        Yes\n",
            "PD00576          trout  9974        Yes\n",
            "PD00576        panther 12119        Yes\n",
            "PD00576          camel 12197        Yes\n",
            "PD00576        leopard 13186        Yes\n",
            "PD00576    caterpillar 17563        Yes\n",
            "PD00576           wasp 18459        Yes\n",
            "PD00576       antelope 26002        Yes\n",
            "PD00576        ostrich 27236        Yes\n",
            "PD00583            dog   826        Yes\n",
            "PD00583            cat  1713        Yes\n",
            "PD00583            fox  2204        Yes\n",
            "PD00583         turkey  2706        Yes\n",
            "PD00583           wolf  3995        Yes\n",
            "PD00583       elephant  6236        Yes\n",
            "PD00583         rabbit  6609        Yes\n",
            "PD00583           goat  6913        Yes\n",
            "PD00583      butterfly  7891        Yes\n",
            "PD00583            hen 13733        Yes\n",
            "PD00583      crocodile 15139        Yes\n",
            "PD00583         parrot 15240        Yes\n",
            "PD00583        rooster 19441        Yes\n",
            "PD00583    grasshopper 27858        Yes\n",
            "PD00583   hippopotamus 49394        Yes\n",
            "PD00647            dog   826        Yes\n",
            "PD00647           fish  1339        Yes\n",
            "PD00647            cat  1713        Yes\n",
            "PD00647            cat  1713        Yes\n",
            "PD00647           bird  2329        Yes\n",
            "PD00647          tiger  4340        Yes\n",
            "PD00647            rat  5446        Yes\n",
            "PD00647            cow  5670        Yes\n",
            "PD00647       elephant  6236        Yes\n",
            "PD00647         monkey  6380        Yes\n",
            "PD00647          whale  7410        Yes\n",
            "PD00647      butterfly  7891        Yes\n",
            "PD00647         insect 10227        Yes\n",
            "PD00647           flea 16711        Yes\n",
            "PD00647      alligator 19009        Yes\n",
            "PD00647     chimpanzee 30362        Yes\n",
            "PD00653            dog   826        Yes\n",
            "PD00653            cat  1713        Yes\n",
            "PD00653          horse  1793        Yes\n",
            "PD00653           bear  1985        Yes\n",
            "PD00653           bird  2329        Yes\n",
            "PD00653           bird  2329        Yes\n",
            "PD00653        chicken  2334        Yes\n",
            "PD00653           wolf  3995        Yes\n",
            "PD00653          tiger  4340        Yes\n",
            "PD00653           lion  4686        Yes\n",
            "PD00653          snake  4895        Yes\n",
            "PD00653            cow  5670        Yes\n",
            "PD00653            cow  5670        Yes\n",
            "PD00653            pig  5724        Yes\n",
            "PD00653            pig  5724        Yes\n",
            "PD00653           lamb  6930        Yes\n",
            "PD00653      crocodile 15139        Yes\n",
            "PD00653            elk 15157        Yes\n",
            "PD00653   hippopotamus 49394        Yes\n",
            "PD00660            dog   826        Yes\n",
            "PD00660           fish  1339        Yes\n",
            "PD00660            cat  1713        Yes\n",
            "PD00660          horse  1793        Yes\n",
            "PD00660            fox  2204        Yes\n",
            "PD00660           bird  2329        Yes\n",
            "PD00660          tiger  4340        Yes\n",
            "PD00660           lion  4686        Yes\n",
            "PD00660            rat  5446        Yes\n",
            "PD00660            cow  5670        Yes\n",
            "PD00660           goat  6913        Yes\n",
            "PD00660            hen 13733        Yes\n",
            "PD00660      crocodile 15139        Yes\n",
            "PD00660        giraffe 19096        Yes\n",
            "PD00660     chimpanzee 30362        Yes\n",
            "PD00660   hippopotamus 49394        Yes\n",
            "PD00666          bizon     0         No\n",
            "PD00666         marmot     0         No\n",
            "PD00666      moray eel     0         No\n",
            "PD00666            cat  1713        Yes\n",
            "PD00666            cat  1713        Yes\n",
            "PD00666          horse  1793        Yes\n",
            "PD00666          mouse  4255        Yes\n",
            "PD00666           lion  4686        Yes\n",
            "PD00666          snake  4895        Yes\n",
            "PD00666            cow  5670        Yes\n",
            "PD00666          eagle  5785        Yes\n",
            "PD00666          shark  6098        Yes\n",
            "PD00666       elephant  6236        Yes\n",
            "PD00666           goat  6913        Yes\n",
            "PD00666          whale  7410        Yes\n",
            "PD00666        panther 12119        Yes\n",
            "PD00666         weasel 22861        Yes\n",
            "PD00666        gazelle 34075        Yes\n",
            "PD00666      orangutan 37126        Yes\n",
            "PD00757            dog   826        Yes\n",
            "PD00757            cat  1713        Yes\n",
            "PD00757            fox  2204        Yes\n",
            "PD00757          tiger  4340        Yes\n",
            "PD00757           lion  4686        Yes\n",
            "PD00757         spider  4715        Yes\n",
            "PD00757          snake  4895        Yes\n",
            "PD00757          sheep  5264        Yes\n",
            "PD00757       elephant  6236        Yes\n",
            "PD00786            dog   826        Yes\n",
            "PD00786            cat  1713        Yes\n",
            "PD00786          horse  1793        Yes\n",
            "PD00786        chicken  2334        Yes\n",
            "PD00786           duck  5031        Yes\n",
            "PD00786          sheep  5264        Yes\n",
            "PD00786            cow  5670        Yes\n",
            "PD00786            pig  5724        Yes\n",
            "PD00786         monkey  6380        Yes\n",
            "PD00786           lamb  6930        Yes\n",
            "PD00786           calf 10996        Yes\n",
            "PD00786            hen 13733        Yes\n",
            "PD00786             ox 15672        Yes\n",
            "PD00786        rooster 19441        Yes\n",
            "PD00849            dog   826        Yes\n",
            "PD00849            cat  1713        Yes\n",
            "PD00849            fox  2204        Yes\n",
            "PD00849           wolf  3995        Yes\n",
            "PD00849          tiger  4340        Yes\n",
            "PD00849          tiger  4340        Yes\n",
            "PD00849           lion  4686        Yes\n",
            "PD00849       elephant  6236        Yes\n",
            "PD00849           hare 11895        Yes\n",
            "PD00849        leopard 13186        Yes\n",
            "PD00849          zebra 17279        Yes\n",
            "PD00849         cougar 17580        Yes\n",
            "PD00849        giraffe 19096        Yes\n",
            "PD00849        ostrich 27236        Yes\n",
            "PD00849       pheasant 27961        Yes\n",
            "PD00849     rhinoceros 35048        Yes\n",
            "PD00869         marmot     0         No\n",
            "PD00869            dog   826        Yes\n",
            "PD00869          horse  1793        Yes\n",
            "PD00869           lion  4686        Yes\n",
            "PD00869           lion  4686        Yes\n",
            "PD00869           duck  5031        Yes\n",
            "PD00869            cow  5670        Yes\n",
            "PD00869         monkey  6380        Yes\n",
            "PD00869         rabbit  6609        Yes\n",
            "PD00869           swan  9108        Yes\n",
            "PD00869           calf 10996        Yes\n",
            "PD00869         donkey 12581        Yes\n",
            "PD00869            hen 13733        Yes\n",
            "PD00869         parrot 15240        Yes\n",
            "PD00869           mule 16279        Yes\n",
            "PD00869        giraffe 19096        Yes\n",
            "PD00869        cheetah 22322        Yes\n",
            "PD00869       pheasant 27961        Yes\n",
            "PD00869        gazelle 34075        Yes\n",
            "PD00869     rhinoceros 35048        Yes\n",
            "PD00869   hippopotamus 49394        Yes\n",
            "PD00955            dog   826        Yes\n",
            "PD00955            cat  1713        Yes\n",
            "PD00955          horse  1793        Yes\n",
            "PD00955            fox  2204        Yes\n",
            "PD00955          tiger  4340        Yes\n",
            "PD00955           lion  4686        Yes\n",
            "PD00955            ram  5254        Yes\n",
            "PD00955            rat  5446        Yes\n",
            "PD00955           mole 11745        Yes\n",
            "PD00955        leopard 13186        Yes\n",
            "PD00955        giraffe 19096        Yes\n",
            "PD00955           lynx 26871        Yes\n",
            "PD00955          hyena 37035        Yes\n",
            "PD00959          tiger  4340        Yes\n",
            "PD00959           lion  4686        Yes\n",
            "PD00959          sheep  5264        Yes\n",
            "PD00959           goat  6913        Yes\n",
            "PD00959          rhino 13593        Yes\n",
            "PD00959            hen 13733        Yes\n",
            "PD00959        giraffe 19096        Yes\n",
            "PD00959          hippo 24472        Yes\n",
            "PD00959          llama 30868        Yes\n",
            "PD00999            dog   826        Yes\n",
            "PD00999            cat  1713        Yes\n",
            "PD00999          horse  1793        Yes\n",
            "PD00999           wolf  3995        Yes\n",
            "PD00999          tiger  4340        Yes\n",
            "PD00999           lion  4686        Yes\n",
            "PD00999          snake  4895        Yes\n",
            "PD00999           duck  5031        Yes\n",
            "PD00999       elephant  6236        Yes\n",
            "PD00999          whale  7410        Yes\n",
            "PD00999         turtle  8223        Yes\n",
            "PD00999        dolphin 11686        Yes\n",
            "PD00999           hare 11895        Yes\n",
            "PD00999        panther 12119        Yes\n",
            "PD00999          camel 12197        Yes\n",
            "PD00999      crocodile 15139        Yes\n",
            "PD00999         coyote 18051        Yes\n",
            "PD00999           lynx 26871        Yes\n",
            "PD00999     rhinoceros 35048        Yes\n",
            "PD01003            dog   826        Yes\n",
            "PD01003            dog   826        Yes\n",
            "PD01003            cat  1713        Yes\n",
            "PD01003          tiger  4340        Yes\n",
            "PD01003           lion  4686        Yes\n",
            "PD01003            cow  5670        Yes\n",
            "PD01003            pig  5724        Yes\n",
            "PD01003         monkey  6380        Yes\n",
            "PD01003           goat  6913        Yes\n",
            "PD01003          whale  7410        Yes\n",
            "PD01003         turtle  8223        Yes\n",
            "PD01003           hare 11895        Yes\n",
            "PD01003         donkey 12581        Yes\n",
            "PD01003          zebra 17279        Yes\n",
            "PD01003          bison 20570        Yes\n",
            "PD01003        vulture 23151        Yes\n",
            "PD01003        ostrich 27236        Yes\n",
            "PD01003     rhinoceros 35048        Yes\n",
            "PD01126            dog   826        Yes\n",
            "PD01126            cat  1713        Yes\n",
            "PD01126          horse  1793        Yes\n",
            "PD01126          tiger  4340        Yes\n",
            "PD01126            cow  5670        Yes\n",
            "PD01126       elephant  6236        Yes\n",
            "PD01126           calf 10996        Yes\n",
            "PD01126          panda 12118        Yes\n",
            "PD01133         marmot     0         No\n",
            "PD01133            dog   826        Yes\n",
            "PD01133            cat  1713        Yes\n",
            "PD01133            fox  2204        Yes\n",
            "PD01133           wolf  3995        Yes\n",
            "PD01133          tiger  4340        Yes\n",
            "PD01133           lion  4686        Yes\n",
            "PD01133         monkey  6380        Yes\n",
            "PD01133           crow  9590        Yes\n",
            "PD01133         beaver 12733        Yes\n",
            "PD01133          moose 12809        Yes\n",
            "PD01133            elk 15157        Yes\n",
            "PD01133           mule 16279        Yes\n",
            "PD01133        giraffe 19096        Yes\n",
            "PD01133            eel 21505        Yes\n",
            "PD01133         gopher 34083        Yes\n",
            "PD01145            cat  1713        Yes\n",
            "PD01145           bear  1985        Yes\n",
            "PD01145           wolf  3995        Yes\n",
            "PD01145           bull  4005        Yes\n",
            "PD01145          tiger  4340        Yes\n",
            "PD01145           lion  4686        Yes\n",
            "PD01145           duck  5031        Yes\n",
            "PD01145           goat  6913        Yes\n",
            "PD01145          goose  9048        Yes\n",
            "PD01145       antelope 26002        Yes\n",
            "PD01146            dog   826        Yes\n",
            "PD01146            dog   826        Yes\n",
            "PD01146            cat  1713        Yes\n",
            "PD01146          horse  1793        Yes\n",
            "PD01146          mouse  4255        Yes\n",
            "PD01146           lion  4686        Yes\n",
            "PD01146           duck  5031        Yes\n",
            "PD01146          sheep  5264        Yes\n",
            "PD01146            cow  5670        Yes\n",
            "PD01146            pig  5724        Yes\n",
            "PD01146       elephant  6236        Yes\n",
            "PD01146           goat  6913        Yes\n",
            "PD01146           hare 11895        Yes\n",
            "PD01146          camel 12197        Yes\n",
            "PD01146         donkey 12581        Yes\n",
            "PD01146          zebra 17279        Yes\n",
            "PD01146        giraffe 19096        Yes\n",
            "PD01146       antelope 26002        Yes\n",
            "PD01146     rhinoceros 35048        Yes\n",
            "PD01156           fish  1339        Yes\n",
            "PD01156            cat  1713        Yes\n",
            "PD01156           bear  1985        Yes\n",
            "PD01156          mouse  4255        Yes\n",
            "PD01156            cow  5670        Yes\n",
            "PD01156           deer  5872        Yes\n",
            "PD01156        reptile 21046        Yes\n",
            "PD01156     salamander 39072        Yes\n",
            "PD01160       roe deer     0         No\n",
            "PD01160            dog   826        Yes\n",
            "PD01160            cat  1713        Yes\n",
            "PD01160          horse  1793        Yes\n",
            "PD01160           bear  1985        Yes\n",
            "PD01160            fox  2204        Yes\n",
            "PD01160           wolf  3995        Yes\n",
            "PD01160          tiger  4340        Yes\n",
            "PD01160           lion  4686        Yes\n",
            "PD01160            rat  5446        Yes\n",
            "PD01160           deer  5872        Yes\n",
            "PD01160         monkey  6380        Yes\n",
            "PD01160          panda 12118        Yes\n",
            "PD01160      crocodile 15139        Yes\n",
            "PD01160        reptile 21046        Yes\n",
            "PD01160          hippo 24472        Yes\n",
            "PD01160     salamander 39072        Yes\n",
            "PD01161            cat  1713        Yes\n",
            "PD01161          horse  1793        Yes\n",
            "PD01161            fox  2204        Yes\n",
            "PD01161           bird  2329        Yes\n",
            "PD01161         turkey  2706        Yes\n",
            "PD01161           wolf  3995        Yes\n",
            "PD01161          tiger  4340        Yes\n",
            "PD01161           lion  4686        Yes\n",
            "PD01161          snake  4895        Yes\n",
            "PD01161          sheep  5264        Yes\n",
            "PD01161            cow  5670        Yes\n",
            "PD01161            bee  6114        Yes\n",
            "PD01161       elephant  6236        Yes\n",
            "PD01161         rabbit  6609        Yes\n",
            "PD01161           crow  9590        Yes\n",
            "PD01161           hare 11895        Yes\n",
            "PD01161          camel 12197        Yes\n",
            "PD01161       mosquito 12810        Yes\n",
            "PD01161            hen 13733        Yes\n",
            "PD01161          zebra 17279        Yes\n",
            "PD01161          otter 17917        Yes\n",
            "PD01161         coyote 18051        Yes\n",
            "PD01161           wasp 18459        Yes\n",
            "PD01161          hippo 24472        Yes\n",
            "PD01161            ewe 37448        Yes\n",
            "PD01199       roe deer     0         No\n",
            "PD01199          horse  1793        Yes\n",
            "PD01199           bird  2329        Yes\n",
            "PD01199          tiger  4340        Yes\n",
            "PD01199           lion  4686        Yes\n",
            "PD01199           duck  5031        Yes\n",
            "PD01199           duck  5031        Yes\n",
            "PD01199          sheep  5264        Yes\n",
            "PD01199       elephant  6236        Yes\n",
            "PD01199       elephant  6236        Yes\n",
            "PD01199           goat  6913        Yes\n",
            "PD01199          goose  9048        Yes\n",
            "PD01199      crocodile 15139        Yes\n",
            "PD01199          zebra 17279        Yes\n",
            "PD01199        giraffe 19096        Yes\n",
            "PD01199            ewe 37448        Yes\n",
            "PD01199   hippopotamus 49394        Yes\n",
            "PD01201            dog   826        Yes\n",
            "PD01201            cat  1713        Yes\n",
            "PD01201           lion  4686        Yes\n",
            "PD01201            cow  5670        Yes\n",
            "PD01201          eagle  5785        Yes\n",
            "PD01201       elephant  6236        Yes\n",
            "PD01201        panther 12119        Yes\n",
            "PD01201         pigeon 12829        Yes\n",
            "PD01201          zebra 17279        Yes\n",
            "PD01201     rhinoceros 35048        Yes\n",
            "PD01201   hippopotamus 49394        Yes\n",
            "PD01223         caiman     0         No\n",
            "PD01223            dog   826        Yes\n",
            "PD01223           fish  1339        Yes\n",
            "PD01223            cat  1713        Yes\n",
            "PD01223           lion  4686        Yes\n",
            "PD01223          snake  4895        Yes\n",
            "PD01223       elephant  6236        Yes\n",
            "PD01223         turtle  8223        Yes\n",
            "PD01223      crocodile 15139        Yes\n",
            "PD01223          skunk 25578        Yes\n",
            "PD01225      dromedary     0         No\n",
            "PD01225            dog   826        Yes\n",
            "PD01225            cat  1713        Yes\n",
            "PD01225          horse  1793        Yes\n",
            "PD01225           bird  2329        Yes\n",
            "PD01225           bird  2329        Yes\n",
            "PD01225           bird  2329        Yes\n",
            "PD01225          mouse  4255        Yes\n",
            "PD01225           lion  4686        Yes\n",
            "PD01225          snake  4895        Yes\n",
            "PD01225            rat  5446        Yes\n",
            "PD01225          eagle  5785        Yes\n",
            "PD01225           deer  5872        Yes\n",
            "PD01225         rabbit  6609        Yes\n",
            "PD01225           hare 11895        Yes\n",
            "PD01225          camel 12197        Yes\n",
            "PD01225         donkey 12581        Yes\n",
            "PD01225      crocodile 15139        Yes\n",
            "PD01225      alligator 19009        Yes\n",
            "PD01237      dromedary     0         No\n",
            "PD01237         marmot     0         No\n",
            "PD01237            dog   826        Yes\n",
            "PD01237            cat  1713        Yes\n",
            "PD01237          horse  1793        Yes\n",
            "PD01237            fox  2204        Yes\n",
            "PD01237           bull  4005        Yes\n",
            "PD01237         spider  4715        Yes\n",
            "PD01237            pig  5724        Yes\n",
            "PD01237            pig  5724        Yes\n",
            "PD01237       elephant  6236        Yes\n",
            "PD01237           goat  6913        Yes\n",
            "PD01237        swallow  8731        Yes\n",
            "PD01237          goose  9048        Yes\n",
            "PD01237        penguin  9935        Yes\n",
            "PD01237         pigeon 12829        Yes\n",
            "PD01237          zebra 17279        Yes\n",
            "PD01237        wildcat 27030        Yes\n",
            "PD01237        seagull 28358        Yes\n",
            "PD01237          llama 30868        Yes\n",
            "PD01237        gazelle 34075        Yes\n",
            "PD01237       mongoose 43266        Yes\n",
            "PD01247            dog   826        Yes\n",
            "PD01247            cat  1713        Yes\n",
            "PD01247           bull  4005        Yes\n",
            "PD01247            ram  5254        Yes\n",
            "PD01247         monkey  6380        Yes\n",
            "PD01247          whale  7410        Yes\n",
            "PD01247         donkey 12581        Yes\n",
            "PD01247        bulldog 17562        Yes\n",
            "PD01247           toad 18717        Yes\n",
            "PD01247         poodle 28333        Yes\n",
            "PD01247      albatross 32669        Yes\n",
            "PD01247      porcupine 33797        Yes\n",
            "PD01247   hippopotamus 49394        Yes\n",
            "PD01270            dog   826        Yes\n",
            "PD01270            cat  1713        Yes\n",
            "PD01270          horse  1793        Yes\n",
            "PD01270           wolf  3995        Yes\n",
            "PD01270          mouse  4255        Yes\n",
            "PD01270          tiger  4340        Yes\n",
            "PD01270           lion  4686        Yes\n",
            "PD01270          sheep  5264        Yes\n",
            "PD01270         monkey  6380        Yes\n",
            "PD01270        panther 12119        Yes\n",
            "PD01270          camel 12197        Yes\n",
            "PD01270         pigeon 12829        Yes\n",
            "PD01270        leopard 13186        Yes\n",
            "PD01270        giraffe 19096        Yes\n",
            "PD01270            emu 27135        Yes\n",
            "PD01282            dog   826        Yes\n",
            "PD01282           fish  1339        Yes\n",
            "PD01282            cat  1713        Yes\n",
            "PD01282          horse  1793        Yes\n",
            "PD01282           bird  2329        Yes\n",
            "PD01282           wolf  3995        Yes\n",
            "PD01282          mouse  4255        Yes\n",
            "PD01282          tiger  4340        Yes\n",
            "PD01282           lion  4686        Yes\n",
            "PD01282          snake  4895        Yes\n",
            "PD01282            cow  5670        Yes\n",
            "PD01282       elephant  6236        Yes\n",
            "PD01282         monkey  6380        Yes\n",
            "PD01282       squirrel 11471        Yes\n",
            "PD01282          snail 11796        Yes\n",
            "PD01282        giraffe 19096        Yes\n",
            "PD01282           slug 19465        Yes\n",
            "PD01284            dog   826        Yes\n",
            "PD01284           fish  1339        Yes\n",
            "PD01284            cat  1713        Yes\n",
            "PD01284          tiger  4340        Yes\n",
            "PD01284           lion  4686        Yes\n",
            "PD01284            cow  5670        Yes\n",
            "PD01284            pig  5724        Yes\n",
            "PD01284          shark  6098        Yes\n",
            "PD01284         monkey  6380        Yes\n",
            "PD01284            owl  8703        Yes\n",
            "PD01284        penguin  9935        Yes\n",
            "PD01284         beaver 12733        Yes\n",
            "PD01284         jaguar 14780        Yes\n",
            "PD01284      crocodile 15139        Yes\n",
            "PD01284      alligator 19009        Yes\n",
            "PD01284        rooster 19441        Yes\n",
            "PD01284        raccoon 20470        Yes\n",
            "PD01284        pelican 26549        Yes\n",
            "PD01284        caribou 29953        Yes\n",
            "PD01290            dog   826        Yes\n",
            "PD01290            cat  1713        Yes\n",
            "PD01290          tiger  4340        Yes\n",
            "PD01290           lion  4686        Yes\n",
            "PD01290       elephant  6236        Yes\n",
            "PD01290         rabbit  6609        Yes\n",
            "PD01290           lamb  6930        Yes\n",
            "PD01290           mole 11745        Yes\n",
            "PD01290          camel 12197        Yes\n",
            "PD01290        unicorn 14241        Yes\n",
            "PD01306            dog   826        Yes\n",
            "PD01306            cat  1713        Yes\n",
            "PD01306          horse  1793        Yes\n",
            "PD01306          horse  1793        Yes\n",
            "PD01306           wolf  3995        Yes\n",
            "PD01306          tiger  4340        Yes\n",
            "PD01306           lion  4686        Yes\n",
            "PD01306          sheep  5264        Yes\n",
            "PD01306            cow  5670        Yes\n",
            "PD01306          eagle  5785        Yes\n",
            "PD01306       elephant  6236        Yes\n",
            "PD01306         turtle  8223        Yes\n",
            "PD01306           crow  9590        Yes\n",
            "PD01306           hare 11895        Yes\n",
            "PD01306         donkey 12581        Yes\n",
            "PD01306        leopard 13186        Yes\n",
            "PD01306          finch 13917        Yes\n",
            "PD01306         parrot 15240        Yes\n",
            "PD01306           mule 16279        Yes\n",
            "PD01306        giraffe 19096        Yes\n",
            "PD01306        raccoon 20470        Yes\n",
            "PD01306          llama 30868        Yes\n",
            "PD01312        meerkat     0         No\n",
            "PD01312            dog   826        Yes\n",
            "PD01312            cat  1713        Yes\n",
            "PD01312          horse  1793        Yes\n",
            "PD01312            fox  2204        Yes\n",
            "PD01312          tiger  4340        Yes\n",
            "PD01312           lion  4686        Yes\n",
            "PD01312          sheep  5264        Yes\n",
            "PD01312            rat  5446        Yes\n",
            "PD01312       elephant  6236        Yes\n",
            "PD01312       elephant  6236        Yes\n",
            "PD01312         monkey  6380        Yes\n",
            "PD01312         rabbit  6609        Yes\n",
            "PD01312           goat  6913        Yes\n",
            "PD01312        panther 12119        Yes\n",
            "PD01312          camel 12197        Yes\n",
            "PD01312          rhino 13593        Yes\n",
            "PD01312            hen 13733        Yes\n",
            "PD01312         jaguar 14780        Yes\n",
            "PD01312          zebra 17279        Yes\n",
            "PD01312          otter 17917        Yes\n",
            "PD01312        raccoon 20470        Yes\n",
            "PD01312       hedgehog 20950        Yes\n",
            "PD01312         weasel 22861        Yes\n",
            "PD01312     chimpanzee 30362        Yes\n",
            "PD01312         gibbon 36997        Yes\n",
            "PD01312   hippopotamus 49394        Yes\n",
            "PD01319            dog   826        Yes\n",
            "PD01319            cat  1713        Yes\n",
            "PD01319           bear  1985        Yes\n",
            "PD01319            fox  2204        Yes\n",
            "PD01319           wolf  3995        Yes\n",
            "PD01319          mouse  4255        Yes\n",
            "PD01319          tiger  4340        Yes\n",
            "PD01319           lion  4686        Yes\n",
            "PD01319            rat  5446        Yes\n",
            "PD01319            cow  5670        Yes\n",
            "PD01319          eagle  5785        Yes\n",
            "PD01319           deer  5872        Yes\n",
            "PD01319       elephant  6236        Yes\n",
            "PD01319             ox 15672        Yes\n",
            "PD01319          zebra 17279        Yes\n",
            "PD01319        giraffe 19096        Yes\n",
            "PD01369         caiman     0         No\n",
            "PD01369            dog   826        Yes\n",
            "PD01369            dog   826        Yes\n",
            "PD01369            cat  1713        Yes\n",
            "PD01369            fox  2204        Yes\n",
            "PD01369          mouse  4255        Yes\n",
            "PD01369          mouse  4255        Yes\n",
            "PD01369          tiger  4340        Yes\n",
            "PD01369          tiger  4340        Yes\n",
            "PD01369           lion  4686        Yes\n",
            "PD01369          snake  4895        Yes\n",
            "PD01369            rat  5446        Yes\n",
            "PD01369           deer  5872        Yes\n",
            "PD01369       elephant  6236        Yes\n",
            "PD01369          whale  7410        Yes\n",
            "PD01369        swallow  8731        Yes\n",
            "PD01369        dolphin 11686        Yes\n",
            "PD01369         jaguar 14780        Yes\n",
            "PD01369      crocodile 15139        Yes\n",
            "PD01369      crocodile 15139        Yes\n",
            "PD01369          zebra 17279        Yes\n",
            "PD01369          otter 17917        Yes\n",
            "PD01369        giraffe 19096        Yes\n",
            "PD01377      dromedary     0         No\n",
            "PD01377            dog   826        Yes\n",
            "PD01377            cat  1713        Yes\n",
            "PD01377           bird  2329        Yes\n",
            "PD01377           wolf  3995        Yes\n",
            "PD01377           bull  4005        Yes\n",
            "PD01377          tiger  4340        Yes\n",
            "PD01377           lion  4686        Yes\n",
            "PD01377            cow  5670        Yes\n",
            "PD01377         monkey  6380        Yes\n",
            "PD01377         rabbit  6609        Yes\n",
            "PD01377           goat  6913        Yes\n",
            "PD01377       squirrel 11471        Yes\n",
            "PD01377       mosquito 12810        Yes\n",
            "PD01377        leopard 13186        Yes\n",
            "PD01377            hen 13733        Yes\n",
            "PD01377      crocodile 15139        Yes\n",
            "PD01377         parrot 15240        Yes\n",
            "PD01377          zebra 17279        Yes\n",
            "PD01377        giraffe 19096        Yes\n",
            "PD01377        vulture 23151        Yes\n",
            "PD01435      wild boar     0         No\n",
            "PD01435            dog   826        Yes\n",
            "PD01435           bear  1985        Yes\n",
            "PD01435            fox  2204        Yes\n",
            "PD01435           wolf  3995        Yes\n",
            "PD01435           bull  4005        Yes\n",
            "PD01435          mouse  4255        Yes\n",
            "PD01435            cow  5670        Yes\n",
            "PD01435       elephant  6236        Yes\n",
            "PD01435         monkey  6380        Yes\n",
            "PD01435       kangaroo 14977        Yes\n",
            "PD01435          zebra 17279        Yes\n",
            "PD01435        raccoon 20470        Yes\n",
            "PD01435         weasel 22861        Yes\n",
            "PD01435          skunk 25578        Yes\n",
            "PD01435        wildcat 27030        Yes\n",
            "PD01435     rhinoceros 35048        Yes\n",
            "PD01440      dromedary     0         No\n",
            "PD01440            dog   826        Yes\n",
            "PD01440            cat  1713        Yes\n",
            "PD01440          horse  1793        Yes\n",
            "PD01440            fox  2204        Yes\n",
            "PD01440          tiger  4340        Yes\n",
            "PD01440           lion  4686        Yes\n",
            "PD01440          eagle  5785        Yes\n",
            "PD01440           deer  5872        Yes\n",
            "PD01440       elephant  6236        Yes\n",
            "PD01440           goat  6913        Yes\n",
            "PD01440          whale  7410        Yes\n",
            "PD01440        dolphin 11686        Yes\n",
            "PD01440          camel 12197        Yes\n",
            "PD01440        raccoon 20470        Yes\n",
            "PD01440     rhinoceros 35048        Yes\n",
            "PD01457            dog   826        Yes\n",
            "PD01457            cat  1713        Yes\n",
            "PD01457          horse  1793        Yes\n",
            "PD01457           bird  2329        Yes\n",
            "PD01457           lion  4686        Yes\n",
            "PD01457          sheep  5264        Yes\n",
            "PD01457           deer  5872        Yes\n",
            "PD01457          whale  7410        Yes\n",
            "PD01457        panther 12119        Yes\n",
            "PD01457        leopard 13186        Yes\n",
            "PD01457        giraffe 19096        Yes\n",
            "PD01457    hummingbird 30452        Yes\n",
            "PD01457   hippopotamus 49394        Yes\n",
            "PD01485       parakeet     0         No\n",
            "PD01485          horse  1793        Yes\n",
            "PD01485          tiger  4340        Yes\n",
            "PD01485           lion  4686        Yes\n",
            "PD01485          snake  4895        Yes\n",
            "PD01485          sheep  5264        Yes\n",
            "PD01485            cow  5670        Yes\n",
            "PD01485            pig  5724        Yes\n",
            "PD01485            pig  5724        Yes\n",
            "PD01485           goat  6913        Yes\n",
            "PD01485           crow  9590        Yes\n",
            "PD01485       squirrel 11471        Yes\n",
            "PD01485          moose 12809        Yes\n",
            "PD01485           mare 13015        Yes\n",
            "PD01485            hen 13733        Yes\n",
            "PD01485         parrot 15240        Yes\n",
            "PD01485          zebra 17279        Yes\n",
            "PD01559   golden eagle     0         No\n",
            "PD01559          tench     0         No\n",
            "PD01559            dog   826        Yes\n",
            "PD01559           fish  1339        Yes\n",
            "PD01559            cat  1713        Yes\n",
            "PD01559            fox  2204        Yes\n",
            "PD01559            cow  5670        Yes\n",
            "PD01559            pig  5724        Yes\n",
            "PD01559          shark  6098        Yes\n",
            "PD01559            cod  8399        Yes\n",
            "PD01559           hare 11895        Yes\n",
            "PD01559        panther 12119        Yes\n",
            "PD01559         lizard 12459        Yes\n",
            "PD01559          perch 19934        Yes\n",
            "PD01559      jellyfish 20972        Yes\n",
            "PD01559      partridge 22465        Yes\n",
            "PD01559      blackbird 32295        Yes\n",
            "PD01559        gazelle 34075        Yes\n",
            "PD01623     blue whale     0         No\n",
            "PD01623 humpback whale     0         No\n",
            "PD01623            dog   826        Yes\n",
            "PD01623            cat  1713        Yes\n",
            "PD01623          tiger  4340        Yes\n",
            "PD01623           lion  4686        Yes\n",
            "PD01623          whale  7410        Yes\n",
            "PD01623        dolphin 11686        Yes\n",
            "PD01623        mammoth 17180        Yes\n",
            "PD01623          zebra 17279        Yes\n",
            "PD01623        giraffe 19096        Yes\n",
            "PD01623            eel 21505        Yes\n",
            "PD01623     chimpanzee 30362        Yes\n",
            "PD01623   hippopotamus 49394        Yes\n",
            "PD01660       roe deer     0         No\n",
            "PD01660            dog   826        Yes\n",
            "PD01660            cat  1713        Yes\n",
            "PD01660          horse  1793        Yes\n",
            "PD01660           bear  1985        Yes\n",
            "PD01660            fox  2204        Yes\n",
            "PD01660          mouse  4255        Yes\n",
            "PD01660          tiger  4340        Yes\n",
            "PD01660           lion  4686        Yes\n",
            "PD01660            rat  5446        Yes\n",
            "PD01660           deer  5872        Yes\n",
            "PD01660         monkey  6380        Yes\n",
            "PD01660         turtle  8223        Yes\n",
            "PD01660      crocodile 15139        Yes\n",
            "PD01660             ox 15672        Yes\n",
            "PD01660     salamander 39072        Yes\n",
            "PD01660   hippopotamus 49394        Yes\n",
            "PD01667            dog   826        Yes\n",
            "PD01667           fish  1339        Yes\n",
            "PD01667            cat  1713        Yes\n",
            "PD01667          horse  1793        Yes\n",
            "PD01667           bird  2329        Yes\n",
            "PD01667        chicken  2334        Yes\n",
            "PD01667           lion  4686        Yes\n",
            "PD01667            cow  5670        Yes\n",
            "PD01667          chick  6223        Yes\n",
            "PD01667         monkey  6380        Yes\n",
            "PD01667           frog  8426        Yes\n",
            "PD01667           swan  9108        Yes\n",
            "PD01667       squirrel 11471        Yes\n",
            "PD01667            hen 13733        Yes\n",
            "PD01667             ox 15672        Yes\n",
            "PD01667          zebra 17279        Yes\n",
            "PD01667        giraffe 19096        Yes\n",
            "PD01667     chimpanzee 30362        Yes\n",
            "PD01667        gazelle 34075        Yes\n",
            "PD01715         caiman     0         No\n",
            "PD01715            dog   826        Yes\n",
            "PD01715          horse  1793        Yes\n",
            "PD01715            fox  2204        Yes\n",
            "PD01715           bird  2329        Yes\n",
            "PD01715        chicken  2334        Yes\n",
            "PD01715         turkey  2706        Yes\n",
            "PD01715           wolf  3995        Yes\n",
            "PD01715       elephant  6236        Yes\n",
            "PD01715           goat  6913        Yes\n",
            "PD01715           frog  8426        Yes\n",
            "PD01715         donkey 12581        Yes\n",
            "PD01715      crocodile 15139        Yes\n",
            "PD01715          zebra 17279        Yes\n",
            "PD01715            boa 22904        Yes\n",
            "PD01715   hippopotamus 49394        Yes\n",
            "\n",
            "Results saved to 'animal_rankings_by_patient.csv'\n",
            "\n",
            "\n",
            "Summary by Patient:\n",
            "============================================================\n",
            "         Total_Animals  Animals_in_Top50k  Avg_Rank_in_Top50k  Pct_in_Top50k\n",
            "ID                                                                          \n",
            "PD00020             20                 20              8958.0          100.0\n",
            "PD00048             13                 13             10739.0          100.0\n",
            "PD00119             17                 17             10365.0          100.0\n",
            "PD00146             22                 22              7808.0          100.0\n",
            "PD00215             23                 23             13894.0          100.0\n",
            "PD00219             13                 13              6484.0          100.0\n",
            "PD00267             13                 13              9753.0          100.0\n",
            "PD00457             17                 17             12106.0          100.0\n",
            "PD00458             17                 16             11298.0           94.1\n",
            "PD00471             22                 22              9312.0          100.0\n",
            "PD00472             21                 21             11034.0          100.0\n",
            "PD00576             23                 23              9349.0          100.0\n",
            "PD00583             15                 15             11993.0          100.0\n",
            "PD00647             16                 16              7975.0          100.0\n",
            "PD00653             19                 19              7402.0          100.0\n",
            "PD00660             16                 16             10311.0          100.0\n",
            "PD00666             19                 16             10209.0           84.2\n",
            "PD00757              9                  9              3875.0          100.0\n",
            "PD00786             14                 14              7250.0          100.0\n",
            "PD00849             16                 16             12351.0          100.0\n",
            "PD00869             21                 20             15076.0           95.2\n",
            "PD00955             13                 13             10323.0          100.0\n",
            "PD00959              9                  9             13663.0          100.0\n",
            "PD00999             19                 19             10113.0          100.0\n",
            "PD01003             18                 18             11137.0          100.0\n",
            "PD01126              8                  8              5462.0          100.0\n",
            "PD01133             16                 15             11026.0           93.8\n",
            "PD01145             10                 10              6772.0          100.0\n",
            "PD01146             19                 19              9633.0          100.0\n",
            "PD01156              8                  8             10119.0          100.0\n",
            "PD01160             17                 16              9443.0           94.1\n",
            "PD01161             25                 25             10096.0          100.0\n",
            "PD01199             17                 16             12204.0           94.1\n",
            "PD01201             11                 11             13780.0          100.0\n",
            "PD01223             10                  9              7626.0           90.0\n",
            "PD01225             19                 18              6649.0           94.7\n",
            "PD01237             22                 20             13064.0           90.9\n",
            "PD01247             13                 13             16819.0          100.0\n",
            "PD01270             15                 15              8654.0          100.0\n",
            "PD01282             17                 17              6487.0          100.0\n",
            "PD01284             19                 19             11236.0          100.0\n",
            "PD01290             10                 10              6952.0          100.0\n",
            "PD01306             22                 22              9702.0          100.0\n",
            "PD01312             27                 26             13127.0           96.3\n",
            "PD01319             16                 16              6566.0          100.0\n",
            "PD01369             23                 22              8049.0           95.7\n",
            "PD01377             21                 20              9429.0           95.2\n",
            "PD01435             17                 16             12425.0           94.1\n",
            "PD01440             16                 15              8479.0           93.8\n",
            "PD01457             13                 13             11857.0          100.0\n",
            "PD01485             17                 16              8634.0           94.1\n",
            "PD01559             18                 16             12387.0           88.9\n",
            "PD01623             14                 12             15456.0           85.7\n",
            "PD01660             17                 16             10438.0           94.1\n",
            "PD01667             19                 19             10132.0          100.0\n",
            "PD01715             16                 15             10337.0           93.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from wordfreq import top_n_list\n",
        "import spacy\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "\n",
        "# Load spaCy model\n",
        "nlp = spacy.load(\"en_core_web_md\")\n",
        "\n",
        "# Get top 50k words for frequency ranking\n",
        "print(\"Loading top 50,000 English words...\")\n",
        "top_50k = top_n_list('en', 50000)\n",
        "rank_dict = {word: rank+1 for rank, word in enumerate(top_50k)}\n",
        "\n",
        "def get_word_rank(word):\n",
        "    \"\"\"Get frequency rank (1=most common, 50000=least common, 0=not in top 50k)\"\"\"\n",
        "    return rank_dict.get(word.lower(), 0)\n",
        "\n",
        "def get_word_frequency_score(word):\n",
        "    \"\"\"Convert rank to frequency score (higher score = more common)\"\"\"\n",
        "    rank = get_word_rank(word)\n",
        "    if rank == 0:\n",
        "        return 0  # Not in top 50k\n",
        "    else:\n",
        "        # Convert rank to score: most common (rank 1) = 1.0, least common (rank 50000) ≈ 0\n",
        "        return 1.0 - (rank / 50000)\n",
        "\n",
        "def cosine_similarity(vec1, vec2):\n",
        "    \"\"\"Calculate cosine similarity between two vectors\"\"\"\n",
        "    return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))\n",
        "\n",
        "def frequency_transition_score(word1, word2):\n",
        "    \"\"\"Calculate transition score based on frequency change\"\"\"\n",
        "    freq1 = get_word_frequency_score(word1)\n",
        "    freq2 = get_word_frequency_score(word2)\n",
        "    # Large negative values indicate transition from common to rare (exploration)\n",
        "    # Large positive values indicate transition from rare to common\n",
        "    return freq2 - freq1\n",
        "\n",
        "def combined_similarity_score(vec1, vec2, word1, word2, semantic_weight=0.7):\n",
        "    \"\"\"Combine semantic similarity with frequency transition\"\"\"\n",
        "    semantic_sim = cosine_similarity(vec1, vec2)\n",
        "    freq_trans = frequency_transition_score(word1, word2)\n",
        "\n",
        "    # Normalize frequency transition to [0, 1] range\n",
        "    # Map [-1, 1] to [0, 1] where negative transitions (common→rare) map to low values\n",
        "    freq_sim = (freq_trans + 1) / 2\n",
        "\n",
        "    # Combine scores\n",
        "    combined = semantic_weight * semantic_sim + (1 - semantic_weight) * freq_sim\n",
        "    return combined, semantic_sim, freq_trans\n",
        "\n",
        "def identify_phases_with_frequency(similarities, items, vectors, threshold,\n",
        "                                   use_combined=True, semantic_weight=0.7):\n",
        "    \"\"\"Identify phases using either semantic similarity alone or combined with frequency\"\"\"\n",
        "    if len(similarities) < 1:\n",
        "        return []\n",
        "\n",
        "    phases = []\n",
        "    combined_sims = []\n",
        "    freq_transitions = []\n",
        "\n",
        "    # Calculate combined similarities if requested\n",
        "    if use_combined:\n",
        "        for i in range(len(items) - 1):\n",
        "            combined, _, freq_trans = combined_similarity_score(\n",
        "                vectors[i], vectors[i+1], items[i], items[i+1], semantic_weight\n",
        "            )\n",
        "            combined_sims.append(combined)\n",
        "            freq_transitions.append(freq_trans)\n",
        "\n",
        "        # Use combined similarities for phase detection\n",
        "        sims_for_phases = combined_sims\n",
        "    else:\n",
        "        sims_for_phases = similarities\n",
        "        # Still calculate frequency transitions for analysis\n",
        "        for i in range(len(items) - 1):\n",
        "            freq_trans = frequency_transition_score(items[i], items[i+1])\n",
        "            freq_transitions.append(freq_trans)\n",
        "\n",
        "    # Identify phases\n",
        "    current_phase = \"Exploitation\" if sims_for_phases[0] > threshold else \"Exploration\"\n",
        "    phase_start = 0\n",
        "\n",
        "    for i in range(1, len(sims_for_phases)):\n",
        "        if (current_phase == \"Exploitation\" and sims_for_phases[i] <= threshold) or \\\n",
        "           (current_phase == \"Exploration\" and sims_for_phases[i] > threshold):\n",
        "\n",
        "            # Calculate phase statistics\n",
        "            phase_items = items[phase_start:i+1]\n",
        "            phase_ranks = [get_word_rank(item) for item in phase_items]\n",
        "            phase_freqs = [get_word_frequency_score(item) for item in phase_items]\n",
        "\n",
        "            phase = {\n",
        "                'type': current_phase,\n",
        "                'start': phase_start,\n",
        "                'end': i,\n",
        "                'items': phase_items,\n",
        "                'vectors': vectors[phase_start:i+1],\n",
        "                'similarities': similarities[phase_start:i],\n",
        "                'combined_similarities': combined_sims[phase_start:i] if use_combined else None,\n",
        "                'freq_transitions': freq_transitions[phase_start:i],\n",
        "                'ranks': phase_ranks,\n",
        "                'freq_scores': phase_freqs,\n",
        "                'avg_rank': np.mean([r for r in phase_ranks if r > 0]) if any(r > 0 for r in phase_ranks) else 0,\n",
        "                'avg_freq_score': np.mean(phase_freqs),\n",
        "                'freq_diversity': np.std(phase_freqs) if len(phase_freqs) > 1 else 0\n",
        "            }\n",
        "            phases.append(phase)\n",
        "\n",
        "            current_phase = \"Exploration\" if current_phase == \"Exploitation\" else \"Exploitation\"\n",
        "            phase_start = i\n",
        "\n",
        "    # Add final phase\n",
        "    phase_items = items[phase_start:]\n",
        "    phase_ranks = [get_word_rank(item) for item in phase_items]\n",
        "    phase_freqs = [get_word_frequency_score(item) for item in phase_items]\n",
        "\n",
        "    phase = {\n",
        "        'type': current_phase,\n",
        "        'start': phase_start,\n",
        "        'end': len(items) - 1,\n",
        "        'items': phase_items,\n",
        "        'vectors': vectors[phase_start:],\n",
        "        'similarities': similarities[phase_start:] if phase_start < len(similarities) else [],\n",
        "        'combined_similarities': combined_sims[phase_start:] if use_combined and phase_start < len(combined_sims) else None,\n",
        "        'freq_transitions': freq_transitions[phase_start:] if phase_start < len(freq_transitions) else [],\n",
        "        'ranks': phase_ranks,\n",
        "        'freq_scores': phase_freqs,\n",
        "        'avg_rank': np.mean([r for r in phase_ranks if r > 0]) if any(r > 0 for r in phase_ranks) else 0,\n",
        "        'avg_freq_score': np.mean(phase_freqs),\n",
        "        'freq_diversity': np.std(phase_freqs) if len(phase_freqs) > 1 else 0\n",
        "    }\n",
        "    phases.append(phase)\n",
        "\n",
        "    return phases\n",
        "\n",
        "def analyze_responses_with_frequency(participant_data, threshold, use_combined=True, semantic_weight=0.7):\n",
        "    \"\"\"Enhanced analysis including word frequency information\"\"\"\n",
        "    participant = participant_data['participant']\n",
        "    items = participant_data['items']\n",
        "    vectors = participant_data['vectors']\n",
        "    similarities = participant_data['similarities']\n",
        "\n",
        "    # Get word frequencies\n",
        "    word_ranks = [get_word_rank(item) for item in items]\n",
        "    word_freq_scores = [get_word_frequency_score(item) for item in items]\n",
        "\n",
        "    # Identify phases with frequency information\n",
        "    phases = identify_phases_with_frequency(\n",
        "        similarities, items, vectors, threshold, use_combined, semantic_weight\n",
        "    )\n",
        "\n",
        "    # Calculate enhanced metrics\n",
        "    exploitation_phases = [p for p in phases if p['type'] == \"Exploitation\"]\n",
        "    exploration_phases = [p for p in phases if p['type'] == \"Exploration\"]\n",
        "\n",
        "    # Phase size calculations\n",
        "    exploitation_phase_sizes = [p['end'] - p['start'] + 1 for p in exploitation_phases]\n",
        "    exploration_phase_sizes = [p['end'] - p['start'] + 1 for p in exploration_phases]\n",
        "\n",
        "    # Frequency-based metrics\n",
        "    exploitation_avg_freq = np.mean([p['avg_freq_score'] for p in exploitation_phases]) if exploitation_phases else 0\n",
        "    exploration_avg_freq = np.mean([p['avg_freq_score'] for p in exploration_phases]) if exploration_phases else 0\n",
        "\n",
        "    exploitation_freq_diversity = np.mean([p['freq_diversity'] for p in exploitation_phases]) if exploitation_phases else 0\n",
        "    exploration_freq_diversity = np.mean([p['freq_diversity'] for p in exploration_phases]) if exploration_phases else 0\n",
        "\n",
        "    # Calculate frequency transitions\n",
        "    freq_transitions = []\n",
        "    for i in range(len(items) - 1):\n",
        "        freq_transitions.append(frequency_transition_score(items[i], items[i+1]))\n",
        "\n",
        "    # Count exploration-like frequency transitions (common→rare)\n",
        "    exploration_transitions = sum(1 for ft in freq_transitions if ft < -0.1)\n",
        "    exploitation_transitions = sum(1 for ft in freq_transitions if ft > 0.1)\n",
        "\n",
        "    # Original metrics\n",
        "    num_switches = len(phases) - 1\n",
        "    exploitation_time = sum(exploitation_phase_sizes)\n",
        "    exploration_time = sum(exploration_phase_sizes)\n",
        "    total_time = exploitation_time + exploration_time\n",
        "\n",
        "    exploitation_percentage = (exploitation_time / total_time) * 100 if total_time > 0 else 0\n",
        "    exploration_percentage = (exploration_time / total_time) * 100 if total_time > 0 else 0\n",
        "\n",
        "    mean_phase_size = np.mean(exploitation_phase_sizes + exploration_phase_sizes) if phases else 0\n",
        "    ee_tradeoff = mean_phase_size / num_switches if num_switches > 0 else 0\n",
        "\n",
        "    return {\n",
        "        'participant': participant,\n",
        "        'items': items,\n",
        "        'phases': phases,\n",
        "        'avg_similarity': np.mean(similarities) if similarities else 0,\n",
        "        'avg_word_rank': np.mean([r for r in word_ranks if r > 0]) if any(r > 0 for r in word_ranks) else 0,\n",
        "        'avg_freq_score': np.mean(word_freq_scores),\n",
        "        'freq_score_std': np.std(word_freq_scores),\n",
        "        'pct_in_top50k': sum(1 for r in word_ranks if r > 0) / len(word_ranks) * 100 if word_ranks else 0,\n",
        "        'exploitation_time': exploitation_time,\n",
        "        'exploration_time': exploration_time,\n",
        "        'exploitation_percentage': exploitation_percentage,\n",
        "        'exploration_percentage': exploration_percentage,\n",
        "        'exploitation_avg_freq': exploitation_avg_freq,\n",
        "        'exploration_avg_freq': exploration_avg_freq,\n",
        "        'exploitation_freq_diversity': exploitation_freq_diversity,\n",
        "        'exploration_freq_diversity': exploration_freq_diversity,\n",
        "        'exploration_freq_transitions': exploration_transitions,\n",
        "        'exploitation_freq_transitions': exploitation_transitions,\n",
        "        'mean_phase_size': mean_phase_size,\n",
        "        'ee_tradeoff': ee_tradeoff,\n",
        "        'num_switches': num_switches\n",
        "    }\n",
        "\n",
        "# Example usage with your data\n",
        "def process_all_participants(data, meg_lc_data, use_combined=True, semantic_weight=0.7):\n",
        "    \"\"\"Process all participants with frequency-enhanced analysis\"\"\"\n",
        "\n",
        "    all_data = []\n",
        "    all_similarities = []\n",
        "\n",
        "    # Process each participant\n",
        "    for participant, group in data.groupby(['ID', 'clean_ID']):\n",
        "        items = group['Item'].tolist()\n",
        "\n",
        "        # Compute word vectors\n",
        "        docs = [nlp(item) for item in items if nlp(item).has_vector]\n",
        "        vectors = [doc.vector for doc in docs]\n",
        "\n",
        "        # Calculate similarities\n",
        "        similarities = [cosine_similarity(vectors[i], vectors[i+1]) for i in range(len(vectors) - 1)]\n",
        "        all_similarities.extend(similarities)\n",
        "\n",
        "        all_data.append({\n",
        "            'participant': participant[0],\n",
        "            'clean_ID': participant[1],\n",
        "            'items': items,\n",
        "            'vectors': vectors,\n",
        "            'similarities': similarities\n",
        "        })\n",
        "\n",
        "    # Calculate threshold\n",
        "    mean_similarity = np.mean(all_similarities)\n",
        "\n",
        "    # Analyze all participants\n",
        "    results = []\n",
        "    for participant_data in all_data:\n",
        "        analysis = analyze_responses_with_frequency(\n",
        "            participant_data, mean_similarity, use_combined, semantic_weight\n",
        "        )\n",
        "\n",
        "        # Create summary for dataframe\n",
        "        result = {\n",
        "            'ID': participant_data['participant'],\n",
        "            'clean_ID': participant_data['clean_ID'],\n",
        "            'num_items': len(participant_data['items']),\n",
        "            'avg_similarity': analysis['avg_similarity'],\n",
        "            'avg_word_rank': analysis['avg_word_rank'],\n",
        "            'avg_freq_score': analysis['avg_freq_score'],\n",
        "            'freq_score_std': analysis['freq_score_std'],\n",
        "            'pct_in_top50k': analysis['pct_in_top50k'],\n",
        "            'num_phases': len(analysis['phases']),\n",
        "            'num_switches': analysis['num_switches'],\n",
        "            'exploitation_time': analysis['exploitation_time'],\n",
        "            'exploration_time': analysis['exploration_time'],\n",
        "            'exploitation_percentage': analysis['exploitation_percentage'],\n",
        "            'exploration_percentage': analysis['exploration_percentage'],\n",
        "            'exploitation_avg_freq': analysis['exploitation_avg_freq'],\n",
        "            'exploration_avg_freq': analysis['exploration_avg_freq'],\n",
        "            'exploitation_freq_diversity': analysis['exploitation_freq_diversity'],\n",
        "            'exploration_freq_diversity': analysis['exploration_freq_diversity'],\n",
        "            'exploration_freq_transitions': analysis['exploration_freq_transitions'],\n",
        "            'exploitation_freq_transitions': analysis['exploitation_freq_transitions'],\n",
        "            'mean_phase_size': analysis['mean_phase_size'],\n",
        "            'ee_tradeoff': analysis['ee_tradeoff']\n",
        "        }\n",
        "        results.append(result)\n",
        "\n",
        "    results_df = pd.DataFrame(results)\n",
        "\n",
        "    # Merge with MEG data\n",
        "    merged_df = pd.merge(results_df, meg_lc_data[['ID', 'alpha_NET_mean', 'norm_SN_avg', 'norm_LC_avg']],\n",
        "                         on='ID', how='left')\n",
        "\n",
        "    return merged_df, all_data\n",
        "\n",
        "# Function to visualize phase analysis with frequency\n",
        "def visualize_participant_phases(participant_data, analysis, threshold):\n",
        "    \"\"\"Create visualization showing phases with frequency information\"\"\"\n",
        "\n",
        "    fig, axes = plt.subplots(3, 1, figsize=(12, 10))\n",
        "\n",
        "    items = participant_data['items']\n",
        "    similarities = participant_data['similarities']\n",
        "    phases = analysis['phases']\n",
        "\n",
        "    # Plot 1: Semantic similarity with phases\n",
        "    ax1 = axes[0]\n",
        "    x = range(len(similarities))\n",
        "    ax1.plot(x, similarities, 'b-', label='Semantic Similarity')\n",
        "    ax1.axhline(y=threshold, color='r', linestyle='--', label='Threshold')\n",
        "\n",
        "    # Color phases\n",
        "    for phase in phases:\n",
        "        color = 'lightgreen' if phase['type'] == 'Exploitation' else 'lightcoral'\n",
        "        ax1.axvspan(phase['start'], phase['end'], alpha=0.3, color=color)\n",
        "\n",
        "    ax1.set_ylabel('Semantic Similarity')\n",
        "    ax1.set_title(f\"Participant {participant_data['participant']} - Phase Analysis\")\n",
        "    ax1.legend()\n",
        "    ax1.grid(True, alpha=0.3)\n",
        "\n",
        "    # Plot 2: Word frequency scores\n",
        "    ax2 = axes[1]\n",
        "    freq_scores = [get_word_frequency_score(item) for item in items]\n",
        "    x_items = range(len(items))\n",
        "    bars = ax2.bar(x_items, freq_scores)\n",
        "\n",
        "    # Color bars by phase\n",
        "    for phase in phases:\n",
        "        color = 'green' if phase['type'] == 'Exploitation' else 'red'\n",
        "        for i in range(phase['start'], phase['end'] + 1):\n",
        "            if i < len(bars):\n",
        "                bars[i].set_color(color)\n",
        "                bars[i].set_alpha(0.7)\n",
        "\n",
        "    ax2.set_ylabel('Frequency Score')\n",
        "    ax2.set_xlabel('Word Position')\n",
        "    ax2.set_title('Word Frequency Scores by Phase')\n",
        "    ax2.grid(True, alpha=0.3)\n",
        "\n",
        "    # Plot 3: Frequency transitions\n",
        "    ax3 = axes[2]\n",
        "    if len(items) > 1:\n",
        "        freq_transitions = [frequency_transition_score(items[i], items[i+1])\n",
        "                           for i in range(len(items) - 1)]\n",
        "        x_trans = range(len(freq_transitions))\n",
        "        ax3.plot(x_trans, freq_transitions, 'g-', marker='o', markersize=4)\n",
        "        ax3.axhline(y=0, color='k', linestyle='-', alpha=0.5)\n",
        "        ax3.axhline(y=-0.1, color='r', linestyle='--', alpha=0.5, label='Exploration threshold')\n",
        "        ax3.axhline(y=0.1, color='b', linestyle='--', alpha=0.5, label='Exploitation threshold')\n",
        "\n",
        "        # Highlight strong transitions\n",
        "        for i, ft in enumerate(freq_transitions):\n",
        "            if ft < -0.1:  # Strong exploration transition\n",
        "                ax3.scatter(i, ft, color='red', s=100, zorder=5)\n",
        "            elif ft > 0.1:  # Strong exploitation transition\n",
        "                ax3.scatter(i, ft, color='blue', s=100, zorder=5)\n",
        "\n",
        "    ax3.set_ylabel('Frequency Transition Score')\n",
        "    ax3.set_xlabel('Transition Position')\n",
        "    ax3.set_title('Frequency Transitions (Common→Rare = negative)')\n",
        "    ax3.legend()\n",
        "    ax3.grid(True, alpha=0.3)\n",
        "\n",
        "    # Add word labels (optional, for first 20 words)\n",
        "    if len(items) <= 20:\n",
        "        ax2.set_xticks(x_items)\n",
        "        ax2.set_xticklabels(items, rotation=45, ha='right')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    return fig\n",
        "\n",
        "# Example: Compare semantic-only vs combined approach\n",
        "def compare_approaches(data, meg_lc_data):\n",
        "    \"\"\"Compare results using semantic-only vs combined semantic+frequency approach\"\"\"\n",
        "\n",
        "    print(\"Running semantic-only analysis...\")\n",
        "    results_semantic, _ = process_all_participants(data, meg_lc_data, use_combined=False)\n",
        "\n",
        "    print(\"Running combined analysis...\")\n",
        "    results_combined, all_data = process_all_participants(data, meg_lc_data, use_combined=True, semantic_weight=0.7)\n",
        "\n",
        "    # Compare key metrics\n",
        "    comparison = pd.DataFrame({\n",
        "        'ID': results_semantic['ID'],\n",
        "        'num_switches_semantic': results_semantic['num_switches'],\n",
        "        'num_switches_combined': results_combined['num_switches'],\n",
        "        'exploit_pct_semantic': results_semantic['exploitation_percentage'],\n",
        "        'exploit_pct_combined': results_combined['exploitation_percentage'],\n",
        "        'ee_tradeoff_semantic': results_semantic['ee_tradeoff'],\n",
        "        'ee_tradeoff_combined': results_combined['ee_tradeoff']\n",
        "    })\n",
        "\n",
        "    print(\"\\nApproach Comparison:\")\n",
        "    print(comparison.head(10))\n",
        "\n",
        "    # Correlation with MEG data\n",
        "    print(\"\\nCorrelations with Alpha Power:\")\n",
        "    # Further examine semantic only exploitation\n",
        "    print(f\"Semantic-only exploitation %: {stats.pearsonr(results_semantic['exploitation_percentage'], results_semantic['alpha_NET_mean'])[0]:.3f}\")\n",
        "    print(f\"Combined exploitation %: {stats.pearsonr(results_combined['exploitation_percentage'], results_combined['alpha_NET_mean'])[0]:.3f}\")\n",
        "\n",
        "    return results_semantic, results_combined, all_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        },
        "id": "3X4SDkkPTouW",
        "outputId": "68813c89-1e89-4aa9-d308-6797f06a9640"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'wordfreq'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2572139270.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mwordfreq\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtop_n_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAgglomerativeClustering\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'wordfreq'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LeoIkt5zLg3D"
      },
      "source": [
        "**Verbal fluency basic analysis - Identify phases**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ObnewO-p9IeK"
      },
      "outputs": [],
      "source": [
        "# semantic search dynamics analysis\n",
        "import numpy as np\n",
        "import spacy\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "import math\n",
        "\n",
        "# Load the spaCy model (make sure you have run the cell to download it, e.g., !python -m spacy download en_core_web_md)\n",
        "try:\n",
        "    nlp = spacy.load(\"en_core_web_md\")\n",
        "except:\n",
        "    print(\"Loading en_core_web_md failed. Please run '!python -m spacy download en_core_web_md' first.\")\n",
        "    nlp = None\n",
        "\n",
        "def cosine_similarity(vec1, vec2):\n",
        "    \"\"\"Calculate cosine similarity between two vectors.\"\"\"\n",
        "    # Ensure vectors are numpy arrays\n",
        "    vec1 = np.array(vec1)\n",
        "    vec2 = np.array(vec2)\n",
        "    dot_product = np.dot(vec1, vec2)\n",
        "    norm_a = np.linalg.norm(vec1)\n",
        "    norm_b = np.linalg.norm(vec2)\n",
        "    if norm_a == 0 or norm_b == 0:\n",
        "        return 0 # Or handle as an error/NaN if preferred\n",
        "    else:\n",
        "        return dot_product / (norm_a * norm_b)\n",
        "\n",
        "def identify_phases(similarities, threshold):\n",
        "    \"\"\"Identify exploitation and exploration phases based on a similarity threshold.\"\"\"\n",
        "    phases = []\n",
        "    current_phase = None\n",
        "    phase_start = 0\n",
        "\n",
        "    # Initial phase based on the first transition\n",
        "    if similarities and similarities[0] >= threshold:\n",
        "        current_phase = \"Exploitation\"\n",
        "    else:\n",
        "        current_phase = \"Exploration\"\n",
        "\n",
        "    for i in range(len(similarities)):\n",
        "        if similarities[i] >= threshold and current_phase == \"Exploration\":\n",
        "            # Transition from Exploration to Exploitation\n",
        "            phases.append((\"Exploration\", phase_start, i, None, None, None)) # Store phase without vectors/similarities here\n",
        "            current_phase = \"Exploitation\"\n",
        "            phase_start = i\n",
        "        elif similarities[i] < threshold and current_phase == \"Exploitation\":\n",
        "            # Transition from Exploitation to Exploration\n",
        "            phases.append((\"Exploitation\", phase_start, i, None, None, None)) # Store phase without vectors/similarities here\n",
        "            current_phase = \"Exploration\"\n",
        "            phase_start = i\n",
        "\n",
        "    # Add the last phase\n",
        "    if similarities: # Ensure there was at least one similarity to define a phase\n",
        "         phases.append((current_phase, phase_start, len(similarities), None, None, None)) # Store phase without vectors/similarities here\n",
        "\n",
        "    return phases # Return phases as (type, start, end, None, None, None) tuples\n",
        "\n",
        "def calculate_novelty(items, vectors):\n",
        "    \"\"\"Calculate novelty score for each item based on similarity to previous items.\"\"\"\n",
        "    novelty_scores = []\n",
        "    for i in range(len(vectors)):\n",
        "        if i == 0:\n",
        "            novelty_scores.append(1) # First item is considered novel\n",
        "        else:\n",
        "            # Calculate similarity to all previous vectors\n",
        "            previous_vectors = vectors[:i]\n",
        "            similarities_to_previous = [cosine_similarity(vectors[i], pv) for pv in previous_vectors]\n",
        "            avg_similarity_to_previous = np.mean(similarities_to_previous) if similarities_to_previous else 0\n",
        "            novelty = 1 - avg_similarity_to_previous # Higher novelty for lower similarity\n",
        "            novelty_scores.append(novelty)\n",
        "    return novelty_scores\n",
        "\n",
        "\n",
        "def analyze_responses(participant_data, global_mean_similarity):\n",
        "    \"\"\"Analyze a participant's responses.\"\"\"\n",
        "    items = participant_data['items']\n",
        "    vectors = participant_data['vectors']\n",
        "    similarities = participant_data['similarities'] # These are pairwise consecutive similarities\n",
        "\n",
        "    if not items or not vectors or len(vectors) < 2:\n",
        "        return {\n",
        "            'avg_similarity': 0,\n",
        "            'num_phases': 0,\n",
        "            'phases': [],\n",
        "            'exploitation_time': 0,\n",
        "            'exploration_time': 0,\n",
        "            'exploitation_percentage': 0,\n",
        "            'exploration_percentage': 0,\n",
        "            'exploration_phases_ratio': 0,\n",
        "            'exploitation_phases_ratio': 0,\n",
        "            'novelty_scores': [],\n",
        "            'ee_tradeoff': np.nan,\n",
        "            'num_clusters': 0,\n",
        "            'clusters': [],\n",
        "            'mean_phase_size': 0,\n",
        "            'exploitation_mean_phase_size': 0,\n",
        "            'exploration_mean_phase_size': 0,\n",
        "            # Add placeholders for proximity metrics if they were needed later\n",
        "            'intra_phase_similarities_exploitation': [],\n",
        "            'intra_phase_similarities_exploration': [],\n",
        "            'inter_phase_similarities_exploitation': [],\n",
        "            'inter_phase_similarities_exploration': [],\n",
        "            'intra_phase_mean_exploitation': np.nan,\n",
        "            'intra_phase_variance_exploitation': np.nan,\n",
        "            'intra_phase_mean_exploration': np.nan,\n",
        "            'intra_phase_variance_exploration': np.nan,\n",
        "            'inter_phase_mean_exploitation': np.nan,\n",
        "            'inter_phase_variance_exploitation': np.nan,\n",
        "            'inter_phase_mean_exploration': np.nan,\n",
        "            'inter_phase_variance_exploration': np.nan,\n",
        "             'phase_centroids_exploitation': [],\n",
        "            'phase_centroids_exploration': [],\n",
        "            'phase_centroids_norms_exploitation': [],\n",
        "            'phase_centroids_norms_exploration': [],\n",
        "        }\n",
        "\n",
        "    # Average similarity\n",
        "    avg_similarity = np.mean(similarities) if similarities else 0\n",
        "\n",
        "    # Identify phases based on global mean similarity as threshold\n",
        "    phases = identify_phases(similarities, global_mean_similarity)\n",
        "\n",
        "    # --- Debugging added ---\n",
        "    print(f\"\\nDebug: Participant {participant_data.get('participant', 'N/A')}\")\n",
        "    print(f\"Debug: Phases identified ({len(phases)}): {phases}\")\n",
        "    # Check elements of phases list\n",
        "    for i, phase_info in enumerate(phases):\n",
        "        print(f\"Debug: Phase {i} info (Type, Start, End): {phase_info[:3]}\")\n",
        "        # Check if the element is iterable and has the expected number of elements\n",
        "        if not isinstance(phase_info, (list, tuple)) or len(phase_info) != 6:\n",
        "             print(f\"Debug: Unexpected phase element format at index {i}: {phase_info}\")\n",
        "    # --- End Debugging ---\n",
        "\n",
        "\n",
        "    # Calculate phase durations and percentages\n",
        "    total_duration = len(items) -1 # Transitions\n",
        "    exploitation_time = 0\n",
        "    exploration_time = 0\n",
        "    exploitation_phases_count = 0\n",
        "    exploration_phases_count = 0\n",
        "\n",
        "    # Recalculate durations based on start and end indices from identify_phases\n",
        "    for phase_type, start, end, _, _, _ in phases:\n",
        "        duration = end - start\n",
        "        if phase_type == \"Exploitation\":\n",
        "            exploitation_time += duration\n",
        "            exploitation_phases_count += 1\n",
        "        else:\n",
        "            exploration_time += duration\n",
        "            exploration_phases_count += 1\n",
        "\n",
        "    exploitation_percentage = (exploitation_time / total_duration) * 100 if total_duration > 0 else 0\n",
        "    exploration_percentage = (exploration_time / total_duration) * 100 if total_duration > 0 else 0\n",
        "\n",
        "    exploration_phases_ratio = exploration_phases_count / len(phases) if len(phases) > 0 else 0\n",
        "    exploitation_phases_ratio = exploitation_phases_count / len(phases) if len(phases) > 0 else 0\n",
        "\n",
        "\n",
        "    # Calculate mean phase size (number of items in a phase, including the first item of the next phase for duration calculation)\n",
        "    phase_sizes = [end - start + 1 for _, start, end, _, _, _ in phases] # +1 to include the end item\n",
        "    mean_phase_size = np.mean(phase_sizes) if phase_sizes else 0\n",
        "\n",
        "    exploitation_phase_sizes = [end - start + 1 for phase_type, start, end, _, _, _ in phases if phase_type == \"Exploitation\"]\n",
        "    exploitation_mean_phase_size = np.mean(exploitation_phase_sizes) if exploitation_phase_sizes else 0\n",
        "\n",
        "    exploration_phase_sizes = [end - start + 1 for phase_type, start, end, _, _, _ in phases if phase_type == \"Exploration\"]\n",
        "    exploration_mean_phase_size = np.mean(exploration_phase_sizes) if exploration_phase_sizes else 0\n",
        "\n",
        "\n",
        "    # Calculate novelty scores\n",
        "    novelty_scores = calculate_novelty(items, vectors)\n",
        "\n",
        "    # Calculate E/E Trade-off (example: Novelty Ratio / Avg Similarity)\n",
        "    # Need to ensure novelty_ratio is calculated outside or pass it\n",
        "    novelty_ratio = sum(novelty_scores) / len(items) if items else 0\n",
        "    ee_tradeoff = novelty_ratio / avg_similarity if avg_similarity != 0 else np.nan # Avoid division by zero\n",
        "\n",
        "\n",
        "    # Cluster analysis (simple example: Agglomerative Clustering on item vectors)\n",
        "    # Using Agglomerative Clustering to find semantic clusters\n",
        "    # Choosing an arbitrary number of clusters (e.g., 5) or using a heuristic\n",
        "    # For simplicity, let's just count unique items for a very basic idea of exploration diversity\n",
        "    # A more proper clustering would involve applying a clustering algorithm and analyzing cluster properties\n",
        "\n",
        "    # Placeholder for cluster analysis - counting unique items as a proxy for semantic space covered\n",
        "    num_clusters = len(set(items))\n",
        "    clusters = list(set(items)) # List of unique items as clusters\n",
        "\n",
        "    # Placeholder for phase proximity calculations - these are expected to be calculated and merged separately\n",
        "    intra_phase_similarities_exploitation = []\n",
        "    intra_phase_similarities_exploration = []\n",
        "    inter_phase_similarities_exploitation = []\n",
        "    inter_phase_similarities_exploration = []\n",
        "    intra_phase_mean_exploitation = np.nan\n",
        "    intra_phase_variance_exploitation = np.nan\n",
        "    intra_phase_mean_exploration = np.nan\n",
        "    intra_phase_variance_exploration = np.nan\n",
        "    inter_phase_mean_exploitation = np.nan\n",
        "    inter_phase_variance_exploitation = np.nan\n",
        "    inter_phase_mean_exploration = np.nan\n",
        "    inter_phase_variance_exploration = np.nan\n",
        "    phase_centroids_exploitation = []\n",
        "    phase_centroids_exploration = []\n",
        "    phase_centroids_norms_exploitation = []\n",
        "    phase_centroids_norms_exploration = []\n",
        "\n",
        "\n",
        "    return {\n",
        "        'avg_similarity': avg_similarity,\n",
        "        'num_phases': len(phases),\n",
        "        'phases': phases, # Return phases as (type, start, end, None, None, None) tuples\n",
        "        'exploitation_time': exploitation_time,\n",
        "        'exploration_time': exploration_time,\n",
        "        'exploitation_percentage': exploitation_percentage,\n",
        "        'exploration_percentage': exploration_percentage,\n",
        "        'exploration_phases_ratio': exploration_phases_ratio,\n",
        "        'exploitation_phases_ratio': exploitation_phases_ratio,\n",
        "        'novelty_scores': novelty_scores,\n",
        "        'ee_tradeoff': ee_tradeoff,\n",
        "        'num_clusters': num_clusters,\n",
        "        'clusters': clusters,\n",
        "        'mean_phase_size': mean_phase_size,\n",
        "        'exploitation_mean_phase_size': exploitation_mean_phase_size,\n",
        "        'exploration_mean_phase_size': exploration_mean_phase_size,\n",
        "         # Include placeholders for phase proximity metrics in the return dictionary\n",
        "        'intra_phase_similarities_exploitation': intra_phase_similarities_exploitation,\n",
        "        'intra_phase_similarities_exploration': intra_phase_similarities_exploration,\n",
        "        'inter_phase_similarities_exploitation': inter_phase_similarities_exploitation,\n",
        "        'inter_phase_similarities_exploration': inter_phase_similarities_exploration,\n",
        "        'intra_phase_mean_exploitation': intra_phase_mean_exploitation,\n",
        "        'intra_phase_variance_exploitation': intra_phase_variance_exploitation,\n",
        "        'intra_phase_mean_exploration': intra_phase_mean_exploration,\n",
        "        'intra_phase_variance_exploration': intra_phase_variance_exploration,\n",
        "        'inter_phase_mean_exploitation': inter_phase_mean_exploitation,\n",
        "        'inter_phase_variance_exploitation': inter_phase_variance_exploitation,\n",
        "        'inter_phase_mean_exploration': inter_phase_mean_exploration,\n",
        "        'inter_phase_variance_exploration': inter_phase_variance_exploration,\n",
        "        'phase_centroids_exploitation': phase_centroids_exploitation,\n",
        "        'phase_centroids_exploration': phase_centroids_exploration,\n",
        "        'phase_centroids_norms_exploitation': phase_centroids_norms_exploitation,\n",
        "        'phase_centroids_norms_exploration': phase_centroids_norms_exploration,\n",
        "    }\n",
        "\n",
        "# Helper function to calculate cosine similarity (redundant with the one above, keeping for now)\n",
        "# def cosine_similarity_helper(vec1, vec2):\n",
        "#     dot_product = np.dot(vec1, vec2)\n",
        "#     norm_a = np.linalg.norm(vec1)\n",
        "#     norm_b = np.linalg.norm(vec2)\n",
        "#     if norm_a == 0 or norm_b == 0:\n",
        "#         return 0\n",
        "#     else:\n",
        "#         return dot_product / (norm_a * norm_b)\n",
        "\n",
        "\n",
        "# This function seems to be a re-implementation of some parts of analyze_responses\n",
        "# and calculate_intra_phase_similarities/calculate_inter_phase_similarities.\n",
        "# It might be intended to calculate phase proximity metrics separately.\n",
        "# Keeping it as is for now, but noting potential overlap.\n",
        "def calculate_phase_proximities(participant_data, phases):\n",
        "    \"\"\"\n",
        "    Calculate intra- and inter-phase similarities and phase centroid norms.\n",
        "    This function assumes phases returned from identify_phases contain\n",
        "    the items and vectors within each phase.\n",
        "\n",
        "    Args:\n",
        "        participant_data (dict): Dictionary containing participant's 'items', 'vectors', 'similarities'.\n",
        "        phases (list): List of tuples representing identified phases,\n",
        "                       where each tuple is (phase_type, start, end, items, vectors, similarities).\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary containing calculated proximity metrics.\n",
        "    \"\"\"\n",
        "    items = participant_data['items']\n",
        "    vectors = participant_data['vectors']\n",
        "    # Note: 'similarities' from participant_data are consecutive pairwise similarities.\n",
        "    # The 'sims' within the phase tuples might represent something else (e.g., intra-phase similarities).\n",
        "\n",
        "    # Re-calculate phases to ensure they include vectors/items/similarities for proximity calculation\n",
        "    # This is necessary because identify_phases above was modified to return None for these.\n",
        "    # A better approach would be to modify identify_phases or call this with full phase data if available.\n",
        "    # For now, let's re-construct phase data with actual content based on start/end indices.\n",
        "\n",
        "    reconstructed_phases = []\n",
        "    # Assuming the original 'phases' list from analyze_responses (before being simplified)\n",
        "    # had the structure (phase_type, start, end, items, vectors, similarities)\n",
        "    # We need the original phases list with content, which is not returned by the current analyze_responses.\n",
        "    # Let's assume for the purpose of fixing this function that we have access to the full original phases\n",
        "    # that include items, vectors, and similarities within each phase.\n",
        "    # Since analyze_responses now returns phases as (type, start, end, None, None, None),\n",
        "    # we cannot use that directly here.\n",
        "\n",
        "    # --- Placeholder/Assumption ---\n",
        "    # To make this function runnable *if* analyze_responses *did* return full phase data,\n",
        "    # we would iterate through those phases. However, with the current analyze_responses,\n",
        "    # the 'items', 'vectors', 'sims' within the phase tuples are None.\n",
        "    # This function cannot work correctly with the current output of analyze_responses.\n",
        "    # The error is likely stemming from cell oojCc1Qc4Px1 expecting results from this function\n",
        "    # or analyze_responses to contain proximity metrics, which they currently don't.\n",
        "    # The fix should focus on making analyze_responses return the necessary data or\n",
        "    # removing the code that expects it.\n",
        "\n",
        "    # Based on the traceback being in analyze_responses -> phase loop, the issue is likely there.\n",
        "    # Let's focus on fixing analyze_responses first. The calculate_phase_proximities function\n",
        "    # may be intended to run *after* analyze_responses but is not correctly integrated or used.\n",
        "\n",
        "    # Given the current error in analyze_responses during the phase unpacking,\n",
        "    # the issue is likely that the 'phases' list itself contains non-tuple elements,\n",
        "    # or tuples with fewer than 6 elements, or elements that are not iterable where tuples are expected.\n",
        "    # The debugging prints added to analyze_responses should clarify this.\n",
        "\n",
        "    # Leaving this function as is for now, assuming the fix in analyze_responses\n",
        "    # will reveal if this function is correctly called or needed.\n",
        "    pass # This function is currently not called or used in the main processing loop in oojCc1Qc4Px1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zydhCdV_sftW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21f953cd-72e5-4aa9-d097-451cab4b4ebb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EE Cross-Correlation Analysis Tool\n",
            "----------------------------------\n",
            "This script should be imported and used with your data.\n",
            "Example usage:\n",
            "  from ee_cross_correlation_analysis import run_comprehensive_ee_analysis\n",
            "  run_comprehensive_ee_analysis(results_df, merged_df_all)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy.stats import pearsonr, spearmanr\n",
        "import statsmodels.api as sm\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "\n",
        "def compute_ee_correlations(df, method='pearson', annot=True, cmap=\"coolwarm\", figsize=(12, 10)):\n",
        "    \"\"\"\n",
        "    Compute and visualize correlations between exploration-exploitation measures.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    df : pandas DataFrame\n",
        "        DataFrame containing EE measures\n",
        "    method : str\n",
        "        Correlation method ('pearson' or 'spearman')\n",
        "    annot : bool\n",
        "        Whether to annotate the heatmap with correlation values\n",
        "    cmap : str\n",
        "        Colormap for the heatmap\n",
        "    figsize : tuple\n",
        "        Figure size (width, height)\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    corr_df : pandas DataFrame\n",
        "        DataFrame with correlation values\n",
        "    \"\"\"\n",
        "    # Select EE-related columns\n",
        "    ee_columns = [\n",
        "        'exploitation_time', 'exploration_time',\n",
        "        'exploitation_percentage', 'exploration_percentage',\n",
        "        'exploitation_phases_ratio', 'exploration_phases_ratio',\n",
        "        'ee_tradeoff', 'mean_phase_size',\n",
        "        'exploitation_mean_phase_size', 'exploration_mean_phase_size',\n",
        "        'novelty_ratio', 'num_phases'\n",
        "    ]\n",
        "\n",
        "    # Filter out columns that don't exist in the dataframe\n",
        "    ee_columns = [col for col in ee_columns if col in df.columns]\n",
        "\n",
        "    # Compute correlation matrix\n",
        "    if method == 'pearson':\n",
        "        corr_matrix = df[ee_columns].corr(method='pearson')\n",
        "    else:\n",
        "        corr_matrix = df[ee_columns].corr(method='spearman')\n",
        "\n",
        "    # Visualize correlation matrix\n",
        "    plt.figure(figsize=figsize)\n",
        "    mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
        "    sns.heatmap(corr_matrix, mask=mask, annot=annot, fmt=\".2f\",\n",
        "                cmap=cmap, vmin=-1, vmax=1, square=True, linewidths=.5)\n",
        "    plt.title(f\"{method.capitalize()} Correlation Matrix of EE Measures\", fontsize=16)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    return corr_matrix\n",
        "\n",
        "def significant_correlations(df, method='pearson', alpha=0.05):\n",
        "    \"\"\"\n",
        "    Extract statistically significant correlations between EE measures.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    df : pandas DataFrame\n",
        "        DataFrame containing EE measures\n",
        "    method : str\n",
        "        Correlation method ('pearson' or 'spearman')\n",
        "    alpha : float\n",
        "        Significance level\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    sig_corrs : pandas DataFrame\n",
        "        DataFrame with significant correlations\n",
        "    \"\"\"\n",
        "    # Select EE-related columns\n",
        "    ee_columns = [\n",
        "        'exploitation_time', 'exploration_time',\n",
        "        'exploitation_percentage', 'exploration_percentage',\n",
        "        'exploitation_phases_ratio', 'exploration_phases_ratio',\n",
        "        'ee_tradeoff', 'mean_phase_size',\n",
        "        'exploitation_mean_phase_size', 'exploration_mean_phase_size',\n",
        "        'novelty_ratio', 'num_phases'\n",
        "    ]\n",
        "\n",
        "    # Filter out columns that don't exist in the dataframe\n",
        "    ee_columns = [col for col in ee_columns if col in df.columns]\n",
        "\n",
        "    # Create empty lists to store results\n",
        "    var1_list, var2_list, corr_list, p_list = [], [], [], []\n",
        "\n",
        "    # Calculate correlations for each pair of variables\n",
        "    for i, col1 in enumerate(ee_columns):\n",
        "        for j, col2 in enumerate(ee_columns):\n",
        "            if i < j:  # To avoid duplicates and self-correlations\n",
        "                if method == 'pearson':\n",
        "                    corr, p = pearsonr(df[col1].dropna(), df[col2].dropna())\n",
        "                else:\n",
        "                    corr, p = spearmanr(df[col1].dropna(), df[col2].dropna())\n",
        "\n",
        "                var1_list.append(col1)\n",
        "                var2_list.append(col2)\n",
        "                corr_list.append(corr)\n",
        "                p_list.append(p)\n",
        "\n",
        "    # Create results DataFrame\n",
        "    results = pd.DataFrame({\n",
        "        'Variable 1': var1_list,\n",
        "        'Variable 2': var2_list,\n",
        "        'Correlation': corr_list,\n",
        "        'p-value': p_list\n",
        "    })\n",
        "\n",
        "    # Filter for significant correlations\n",
        "    significant = results[results['p-value'] < alpha].sort_values(by='Correlation', ascending=False)\n",
        "\n",
        "    return significant\n",
        "\n",
        "def plot_ee_relationship(df, x_col, y_col, method='pearson'):\n",
        "    \"\"\"\n",
        "    Plot relationship between two EE measures with regression line.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    df : pandas DataFrame\n",
        "        DataFrame containing EE measures\n",
        "    x_col : str\n",
        "        Column name for x-axis\n",
        "    y_col : str\n",
        "        Column name for y-axis\n",
        "    method : str\n",
        "        Correlation method ('pearson' or 'spearman')\n",
        "    \"\"\"\n",
        "    # Check if columns exist\n",
        "    if x_col not in df.columns or y_col not in df.columns:\n",
        "        print(f\"Error: One or both columns not found in the DataFrame: {x_col}, {y_col}\")\n",
        "        return\n",
        "\n",
        "    # Calculate correlation coefficient and p-value\n",
        "    if method == 'pearson':\n",
        "        corr, p = pearsonr(df[x_col].dropna(), df[y_col].dropna())\n",
        "    else:\n",
        "        corr, p = spearmanr(df[x_col].dropna(), df[y_col].dropna())\n",
        "\n",
        "    # Create scatter plot\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.regplot(x=x_col, y=y_col, data=df, scatter_kws={'alpha':0.6})\n",
        "\n",
        "    # Add correlation annotation\n",
        "    sig_str = 'p < 0.05*' if p < 0.05 else 'p = {:.3f} (ns)'.format(p)\n",
        "    if p < 0.01:\n",
        "        sig_str = 'p < 0.01**'\n",
        "    if p < 0.001:\n",
        "        sig_str = 'p < 0.001***'\n",
        "\n",
        "    plt.title(f\"Relationship between {x_col} and {y_col}\", fontsize=15)\n",
        "    plt.annotate(f\"{method.capitalize()} r = {corr:.2f}, {sig_str}\",\n",
        "                 xy=(0.05, 0.95), xycoords='axes fraction', fontsize=12,\n",
        "                 bbox=dict(facecolor='white', alpha=0.5))\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Fit linear regression model\n",
        "    X = sm.add_constant(df[x_col].dropna())\n",
        "    model = sm.OLS(df[y_col].dropna(), X).fit()\n",
        "    print(f\"Regression results for {x_col} predicting {y_col}:\")\n",
        "    print(model.summary().tables[1])\n",
        "    print(\"\\n\")\n",
        "\n",
        "def plot_ee_distribution(df, cols=None):\n",
        "    \"\"\"\n",
        "    Plot distributions of EE measures.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    df : pandas DataFrame\n",
        "        DataFrame containing EE measures\n",
        "    cols : list or None\n",
        "        Specific columns to plot, if None plots all EE measures\n",
        "    \"\"\"\n",
        "    if cols is None:\n",
        "        cols = [\n",
        "            'exploitation_time', 'exploration_time',\n",
        "            'exploitation_percentage', 'exploration_percentage',\n",
        "            'exploitation_phases_ratio', 'exploration_phases_ratio',\n",
        "            'ee_tradeoff', 'mean_phase_size',\n",
        "            'exploitation_mean_phase_size', 'exploration_mean_phase_size'\n",
        "        ]\n",
        "\n",
        "    # Filter out columns that don't exist in the dataframe\n",
        "    cols = [col for col in cols if col in df.columns]\n",
        "\n",
        "    # Calculate number of rows for subplots\n",
        "    n_cols = 2\n",
        "    n_rows = (len(cols) + 1) // 2\n",
        "\n",
        "    # Create figure and subplots\n",
        "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(12, n_rows * 3))\n",
        "    axes = axes.flatten()\n",
        "\n",
        "    # Plot histograms for each measure\n",
        "    for i, col in enumerate(cols):\n",
        "        if i < len(axes):\n",
        "            sns.histplot(df[col].dropna(), kde=True, ax=axes[i])\n",
        "            axes[i].set_title(f\"Distribution of {col}\")\n",
        "            axes[i].set_xlabel(col)\n",
        "            axes[i].set_ylabel(\"Frequency\")\n",
        "\n",
        "    # Hide any unused subplots\n",
        "    for i in range(len(cols), len(axes)):\n",
        "        axes[i].set_visible(False)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def analyze_ee_measure_groups(df):\n",
        "    \"\"\"\n",
        "    Analyze correlations between different groups of EE measures.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    df : pandas DataFrame\n",
        "        DataFrame containing EE measures\n",
        "    \"\"\"\n",
        "    # Define groups of related measures\n",
        "    ee_measure_groups = {\n",
        "        'Time-based': ['exploitation_time', 'exploration_time'],\n",
        "        'Percentage-based': ['exploitation_percentage', 'exploration_percentage'],\n",
        "        'Phase-ratio': ['exploitation_phases_ratio', 'exploration_phases_ratio'],\n",
        "        'Phase-size': ['mean_phase_size', 'exploitation_mean_phase_size', 'exploration_mean_phase_size'],\n",
        "        'Trade-off': ['ee_tradeoff', 'novelty_ratio', 'num_phases']\n",
        "    }\n",
        "\n",
        "    # Filter to ensure all columns exist\n",
        "    for group, measures in ee_measure_groups.items():\n",
        "        ee_measure_groups[group] = [col for col in measures if col in df.columns]\n",
        "\n",
        "    # Get all EE measures\n",
        "    all_ee_measures = []\n",
        "    for measures in ee_measure_groups.values():\n",
        "        all_ee_measures.extend(measures)\n",
        "\n",
        "    all_ee_measures = list(set(all_ee_measures))  # Remove duplicates\n",
        "\n",
        "    # 1. Within-group correlations\n",
        "    print(\"Analyzing within-group correlations...\")\n",
        "    for group, measures in ee_measure_groups.items():\n",
        "        if len(measures) > 1:  # Only analyze groups with multiple measures\n",
        "            print(f\"\\nCorrelations within {group} measures:\")\n",
        "            group_corr = df[measures].corr()\n",
        "            print(group_corr)\n",
        "\n",
        "            # Visualize\n",
        "            plt.figure(figsize=(8, 6))\n",
        "            sns.heatmap(group_corr, annot=True, fmt=\".2f\", cmap=\"Blues\")\n",
        "            plt.title(f\"Correlations within {group} Measures\")\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "\n",
        "    # 2. Between-group correlations\n",
        "    print(\"\\nAnalyzing between-group correlations...\")\n",
        "    for i, (group1, measures1) in enumerate(ee_measure_groups.items()):\n",
        "        for j, (group2, measures2) in enumerate(ee_measure_groups.items()):\n",
        "            if i < j and measures1 and measures2:  # Compare each pair of groups once\n",
        "                print(f\"\\nCorrelations between {group1} and {group2} measures:\")\n",
        "\n",
        "                # Create correlation table\n",
        "                corr_table = pd.DataFrame(index=measures1, columns=measures2)\n",
        "                p_table = pd.DataFrame(index=measures1, columns=measures2)\n",
        "\n",
        "                for m1 in measures1:\n",
        "                    for m2 in measures2:\n",
        "                        corr, p = pearsonr(df[m1].dropna(), df[m2].dropna())\n",
        "                        corr_table.loc[m1, m2] = corr\n",
        "                        p_table.loc[m1, m2] = p\n",
        "\n",
        "                print(\"Correlation values:\")\n",
        "                print(corr_table)\n",
        "                print(\"\\nP-values:\")\n",
        "                print(p_table)\n",
        "\n",
        "                # Create heatmap with significance markers\n",
        "                plt.figure(figsize=(max(6, len(measures2) * 1.5), max(4, len(measures1) * 1.2)))\n",
        "                sns.heatmap(corr_table, annot=True, fmt=\".2f\", cmap=\"coolwarm\", vmin=-1, vmax=1)\n",
        "\n",
        "                # Add asterisks for significance\n",
        "                for i, idx in enumerate(corr_table.index):\n",
        "                    for j, col in enumerate(corr_table.columns):\n",
        "                        if p_table.loc[idx, col] < 0.05:\n",
        "                            plt.text(j + 0.5, i + 0.85, '*', ha='center', va='center')\n",
        "                        if p_table.loc[idx, col] < 0.01:\n",
        "                            plt.text(j + 0.5, i + 0.85, '**', ha='center', va='center')\n",
        "                        if p_table.loc[idx, col] < 0.001:\n",
        "                            plt.text(j + 0.5, i + 0.85, '***', ha='center', va='center')\n",
        "\n",
        "                plt.title(f\"Correlations: {group1} vs {group2}\")\n",
        "                plt.tight_layout()\n",
        "                plt.show()\n",
        "\n",
        "    # 3. PCA analysis to identify patterns across all EE measures\n",
        "    print(\"\\nPerforming PCA on all EE measures...\")\n",
        "\n",
        "    # Prepare data for PCA\n",
        "    ee_data = df[all_ee_measures].dropna()\n",
        "\n",
        "    if len(ee_data) >= 3:  # Need at least 3 samples for PCA\n",
        "        # Standardize the data\n",
        "        scaler = StandardScaler()\n",
        "        ee_scaled = scaler.fit_transform(ee_data)\n",
        "\n",
        "        # Apply PCA\n",
        "        pca = PCA()\n",
        "        pca_result = pca.fit_transform(ee_scaled)\n",
        "\n",
        "        # Explained variance\n",
        "        explained_variance = pca.explained_variance_ratio_\n",
        "        cumulative_variance = np.cumsum(explained_variance)\n",
        "\n",
        "        # Print explained variance\n",
        "        print(\"\\nPCA Explained Variance by Component:\")\n",
        "        for i, var in enumerate(explained_variance):\n",
        "            print(f\"PC{i+1}: {var:.4f} ({cumulative_variance[i]:.4f} cumulative)\")\n",
        "\n",
        "        # Plot explained variance\n",
        "        plt.figure(figsize=(10, 5))\n",
        "        plt.bar(range(1, len(explained_variance) + 1), explained_variance, alpha=0.7)\n",
        "        plt.plot(range(1, len(explained_variance) + 1), cumulative_variance, 'ro-')\n",
        "        plt.xlabel('Principal Component')\n",
        "        plt.ylabel('Explained Variance Ratio')\n",
        "        plt.title('Explained Variance by Principal Component')\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        # Get component loadings\n",
        "        loadings = pca.components_\n",
        "\n",
        "        # Create a DataFrame of loadings\n",
        "        loadings_df = pd.DataFrame(\n",
        "            loadings.T,\n",
        "            columns=[f'PC{i+1}' for i in range(loadings.shape[0])],\n",
        "            index=all_ee_measures\n",
        "        )\n",
        "\n",
        "        print(\"\\nPCA Component Loadings:\")\n",
        "        print(loadings_df)\n",
        "\n",
        "        # Visualize loadings for the first two components\n",
        "        plt.figure(figsize=(12, 8))\n",
        "        loadings_threshold = 0.2  # Minimum loading to show\n",
        "\n",
        "        # Create loading plot\n",
        "        for i, feature in enumerate(all_ee_measures):\n",
        "            plt.arrow(0, 0, loadings[0, i], loadings[1, i], head_width=0.05, head_length=0.05, fc='blue', ec='blue')\n",
        "            if np.abs(loadings[0, i]) > loadings_threshold or np.abs(loadings[1, i]) > loadings_threshold:\n",
        "                plt.text(loadings[0, i] * 1.15, loadings[1, i] * 1.15, feature, color='navy', ha='center', va='center')\n",
        "\n",
        "        plt.xlim(-1, 1)\n",
        "        plt.ylim(-1, 1)\n",
        "        plt.grid(True)\n",
        "        plt.axhline(y=0, color='k', linestyle='--', alpha=0.3)\n",
        "        plt.axvline(x=0, color='k', linestyle='--', alpha=0.3)\n",
        "        plt.xlabel(f'PC1 ({explained_variance[0]:.2%} variance explained)')\n",
        "        plt.ylabel(f'PC2 ({explained_variance[1]:.2%} variance explained)')\n",
        "        plt.title('PCA Loading Plot (PC1 vs PC2)')\n",
        "\n",
        "        # Add a circle\n",
        "        circle = plt.Circle((0, 0), 1, fill=False, color='gray', linestyle='--')\n",
        "        plt.gca().add_patch(circle)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        # Plot the first two principal components\n",
        "        plt.figure(figsize=(10, 8))\n",
        "        scatter = plt.scatter(pca_result[:, 0], pca_result[:, 1], alpha=0.7)\n",
        "\n",
        "        # Add participant labels for identification\n",
        "        if 'participant' in df.columns:\n",
        "            for i, txt in enumerate(df.loc[ee_data.index, 'participant']):\n",
        "                plt.annotate(txt, (pca_result[i, 0], pca_result[i, 1]), fontsize=8)\n",
        "\n",
        "        plt.xlabel(f'PC1 ({explained_variance[0]:.2%} variance explained)')\n",
        "        plt.ylabel(f'PC2 ({explained_variance[1]:.2%} variance explained)')\n",
        "        plt.title('PCA: Participants in EE Measure Space')\n",
        "        plt.grid(True)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "    else:\n",
        "        print(\"Not enough complete data points for PCA analysis\")\n",
        "\n",
        "def explore_merged_correlations(merged_df, meg_columns=None):\n",
        "    \"\"\"\n",
        "    Explore correlations between EE measures and MEG data.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    merged_df : pandas DataFrame\n",
        "        Merged DataFrame containing both EE measures and MEG data\n",
        "    meg_columns : list or None\n",
        "        List of MEG-related columns to include\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    corr_df : pandas DataFrame\n",
        "        DataFrame with correlation values between EE and MEG measures\n",
        "    \"\"\"\n",
        "    # EE columns\n",
        "    ee_columns = [\n",
        "        'exploitation_time', 'exploration_time',\n",
        "        'exploitation_percentage', 'exploration_percentage',\n",
        "        'exploitation_phases_ratio', 'exploration_phases_ratio',\n",
        "        'ee_tradeoff', 'mean_phase_size',\n",
        "        'exploitation_mean_phase_size', 'exploration_mean_phase_size',\n",
        "        'novelty_ratio', 'num_phases'\n",
        "    ]\n",
        "\n",
        "    # Filter out columns that don't exist in the dataframe\n",
        "    ee_columns = [col for col in ee_columns if col in merged_df.columns]\n",
        "\n",
        "    # If MEG columns are not specified, infer them (excluding EE columns and participant ID)\n",
        "    if meg_columns is None:\n",
        "        exclude_cols = ee_columns + ['participant', 'clean_ID', 'items', 'similarities',\n",
        "                                    'phases', 'novelty_scores', 'clusters']\n",
        "        exclude_cols = [col for col in exclude_cols if col in merged_df.columns]\n",
        "        meg_columns = [col for col in merged_df.columns if col not in exclude_cols and\n",
        "                      merged_df[col].dtype in [np.int64, np.float64]]\n",
        "\n",
        "    # Calculate correlations between EE and MEG data\n",
        "    correlation_results = []\n",
        "\n",
        "    for ee_col in ee_columns:\n",
        "        for meg_col in meg_columns:\n",
        "            # Skip if there's not enough data\n",
        "            if merged_df[ee_col].isnull().sum() > len(merged_df) * 0.5 or \\\n",
        "               merged_df[meg_col].isnull().sum() > len(merged_df) * 0.5:\n",
        "                continue\n",
        "\n",
        "            # Calculate correlation\n",
        "            valid_data = merged_df[[ee_col, meg_col]].dropna()\n",
        "            if len(valid_data) < 5:  # Skip if too few data points\n",
        "                continue\n",
        "\n",
        "            corr, p = pearsonr(valid_data[ee_col], valid_data[meg_col])\n",
        "\n",
        "            correlation_results.append({\n",
        "                'EE_Measure': ee_col,\n",
        "                'MEG_Measure': meg_col,\n",
        "                'Correlation': corr,\n",
        "                'p-value': p,\n",
        "                'Significant': p < 0.05\n",
        "            })\n",
        "\n",
        "    # Convert to DataFrame and sort\n",
        "    corr_df = pd.DataFrame(correlation_results)\n",
        "    if not corr_df.empty:\n",
        "        corr_df = corr_df.sort_values(by=['Significant', 'Correlation'], ascending=[False, False])\n",
        "\n",
        "    return corr_df\n",
        "\n",
        "def heatmap_ee_meg_correlations(merged_df, meg_columns=None, method='pearson',\n",
        "                               alpha=0.05, min_corr=0.3):\n",
        "    \"\"\"\n",
        "    Create a heatmap of correlations between EE measures and MEG data.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    merged_df : pandas DataFrame\n",
        "        Merged DataFrame containing both EE measures and MEG data\n",
        "    meg_columns : list or None\n",
        "        List of MEG-related columns to include\n",
        "    method : str\n",
        "        Correlation method ('pearson' or 'spearman')\n",
        "    alpha : float\n",
        "        Significance level\n",
        "    min_corr : float\n",
        "        Minimum correlation magnitude to display\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    ee_meg_corr : pandas DataFrame\n",
        "        Correlation matrix between EE and MEG measures\n",
        "    p_values : pandas DataFrame\n",
        "        P-values for the correlations\n",
        "    \"\"\"\n",
        "    # EE columns\n",
        "    ee_columns = [\n",
        "        'exploitation_time', 'exploration_time',\n",
        "        'exploitation_percentage', 'exploration_percentage',\n",
        "        'exploitation_phases_ratio', 'exploration_phases_ratio',\n",
        "        'ee_tradeoff', 'mean_phase_size',\n",
        "        'exploitation_mean_phase_size', 'exploration_mean_phase_size',\n",
        "        'novelty_ratio', 'num_phases'\n",
        "    ]\n",
        "\n",
        "    # Filter out columns that don't exist in the dataframe\n",
        "    ee_columns = [col for col in ee_columns if col in merged_df.columns]\n",
        "\n",
        "    # If MEG columns are not specified, infer them (excluding EE columns and participant ID)\n",
        "    if meg_columns is None:\n",
        "        exclude_cols = ee_columns + ['participant', 'clean_ID', 'items', 'similarities',\n",
        "                                    'phases', 'novelty_scores', 'clusters']\n",
        "        exclude_cols = [col for col in exclude_cols if col in merged_df.columns]\n",
        "        meg_columns = [col for col in merged_df.columns if col not in exclude_cols and\n",
        "                      merged_df[col].dtype in [np.int64, np.float64]]\n",
        "\n",
        "    # Limit to 10 MEG columns if there are too many\n",
        "    if len(meg_columns) > 10:\n",
        "        meg_columns = meg_columns[:10]\n",
        "        print(f\"Note: Limited to first 10 MEG columns due to large number.\")\n",
        "\n",
        "    # Calculate correlation matrix\n",
        "    corr_data = merged_df[ee_columns + meg_columns].dropna()\n",
        "\n",
        "    if method == 'pearson':\n",
        "        corr_matrix = corr_data.corr(method='pearson')\n",
        "    else:\n",
        "        corr_matrix = corr_data.corr(method='spearman')\n",
        "\n",
        "    # Get the subset of correlations between EE and MEG measures\n",
        "    ee_meg_corr = corr_matrix.loc[ee_columns, meg_columns]\n",
        "\n",
        "    # Calculate p-values for significance masking\n",
        "    p_values = pd.DataFrame(index=ee_columns, columns=meg_columns)\n",
        "    for ee_col in ee_columns:\n",
        "        for meg_col in meg_columns:\n",
        "            if method == 'pearson':\n",
        "                _, p = pearsonr(merged_df[ee_col].dropna(), merged_df[meg_col].dropna())\n",
        "            else:\n",
        "                _, p = spearmanr(merged_df[ee_col].dropna(), merged_df[meg_col].dropna())\n",
        "            p_values.loc[ee_col, meg_col] = p\n",
        "\n",
        "    # Create a mask for non-significant correlations\n",
        "    sig_mask = p_values > alpha\n",
        "\n",
        "    # Create a mask for correlations below the minimum threshold\n",
        "    corr_mask = (ee_meg_corr.abs() < min_corr)\n",
        "\n",
        "    # Combine masks\n",
        "    mask = sig_mask | corr_mask\n",
        "\n",
        "    # Plot heatmap\n",
        "    plt.figure(figsize=(max(10, len(meg_columns)), max(8, len(ee_columns))))\n",
        "    sns.heatmap(ee_meg_corr, annot=True, fmt=\".2f\", cmap=\"coolwarm\", vmin=-1, vmax=1,\n",
        "               mask=mask, linewidths=.5, cbar_kws={\"shrink\": .8})\n",
        "    plt.title(f\"Significant {method.capitalize()} Correlations between EE and MEG Measures\\n\" +\n",
        "             f\"(p < {alpha}, |r| > {min_corr})\", fontsize=16)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    return ee_meg_corr, p_values\n",
        "\n",
        "def run_comprehensive_ee_analysis(results_df, merged_df=None):\n",
        "    \"\"\"\n",
        "    Run a comprehensive analysis of EE measures and their correlations.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    results_df : pandas DataFrame\n",
        "        DataFrame containing EE measures\n",
        "    merged_df : pandas DataFrame or None\n",
        "        Optional merged DataFrame with MEG data\n",
        "    \"\"\"\n",
        "    print(\"Starting comprehensive analysis of EE measures...\\n\")\n",
        "\n",
        "    # 1. Basic correlation analysis\n",
        "    print(\"1. Basic correlation analysis\")\n",
        "    print(\"----------------------------\")\n",
        "    ee_corr_matrix = compute_ee_correlations(results_df, method='pearson')\n",
        "\n",
        "    # 2. Find significant correlations\n",
        "    print(\"\\n2. Significant correlations\")\n",
        "    print(\"---------------------------\")\n",
        "    sig_corrs = significant_correlations(results_df, method='pearson')\n",
        "    print(\"Significant correlations (p < 0.05):\")\n",
        "    print(sig_corrs)\n",
        "\n",
        "    # 3. Plot distributions\n",
        "    print(\"\\n3. Distributions of EE measures\")\n",
        "    print(\"------------------------------\")\n",
        "    key_ee_measures = [\n",
        "        'exploitation_percentage', 'exploration_percentage',\n",
        "        'exploitation_phases_ratio', 'exploration_phases_ratio',\n",
        "        'ee_tradeoff', 'novelty_ratio'\n",
        "    ]\n",
        "    key_ee_measures = [col for col in key_ee_measures if col in results_df.columns]\n",
        "    plot_ee_distribution(results_df, cols=key_ee_measures)\n",
        "\n",
        "    # 4. Relationship plots for top correlations\n",
        "    print(\"\\n4. Top correlation relationship plots\")\n",
        "    print(\"-----------------------------------\")\n",
        "    if not sig_corrs.empty:\n",
        "        top_corrs = sig_corrs.head(3)\n",
        "        for _, row in top_corrs.iterrows():\n",
        "            plot_ee_relationship(results_df, row['Variable 1'], row['Variable 2'])\n",
        "\n",
        "    # 5. Analyze EE measure groups\n",
        "    print(\"\\n5. EE measure group analysis\")\n",
        "    print(\"---------------------------\")\n",
        "    analyze_ee_measure_groups(results_df)\n",
        "\n",
        "    # 6. MEG correlations if available\n",
        "    if merged_df is not None and not merged_df.empty:\n",
        "        print(\"\\n6. Correlations with MEG data\")\n",
        "        print(\"----------------------------\")\n",
        "\n",
        "        # Find potential MEG columns\n",
        "        ee_columns = [\n",
        "            'exploitation_time', 'exploration_time',\n",
        "            'exploitation_percentage', 'exploration_percentage',\n",
        "            'exploitation_phases_ratio', 'exploration_phases_ratio',\n",
        "            'ee_tradeoff', 'mean_phase_size',\n",
        "            'exploitation_mean_phase_size', 'exploration_mean_phase_size',\n",
        "            'novelty_ratio', 'num_phases'\n",
        "        ]\n",
        "\n",
        "        exclude_cols = ee_columns + ['participant', 'clean_ID', 'items', 'similarities',\n",
        "                                    'phases', 'novelty_scores', 'clusters']\n",
        "        exclude_cols = [col for col in exclude_cols if col in merged_df.columns]\n",
        "\n",
        "        potential_meg_cols = [col for col in merged_df.columns\n",
        "                              if col not in exclude_cols\n",
        "                              and merged_df[col].dtype in [np.int64, np.float64]]\n",
        "\n",
        "        if potential_meg_cols:\n",
        "            print(f\"Found {len(potential_meg_cols)} potential MEG data columns\")\n",
        "\n",
        "            # Get correlations\n",
        "            ee_meg_corrs = explore_merged_correlations(merged_df, meg_columns=potential_meg_cols)\n",
        "\n",
        "            if not ee_meg_corrs.empty:\n",
        "                print(\"\\nTop 10 correlations between EE and MEG measures:\")\n",
        "                print(ee_meg_corrs.head(10))\n",
        "\n",
        "                # Create heatmap\n",
        "                meg_subset = potential_meg_cols[:10] if len(potential_meg_cols) > 10 else potential_meg_cols\n",
        "                heatmap_ee_meg_correlations(merged_df, meg_columns=meg_subset)\n",
        "        else:\n",
        "            print(\"No suitable MEG data columns found\")\n",
        "\n",
        "    print(\"\\nComprehensive EE analysis complete!\")\n",
        "\n",
        "# Example usage (uncomment and update with your actual dataframes):\n",
        "# run_comprehensive_ee_analysis(results_df, merged_df_all)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # This section runs when the script is executed directly\n",
        "    print(\"EE Cross-Correlation Analysis Tool\")\n",
        "    print(\"----------------------------------\")\n",
        "    print(\"This script should be imported and used with your data.\")\n",
        "    print(\"Example usage:\")\n",
        "    print(\"  from ee_cross_correlation_analysis import run_comprehensive_ee_analysis\")\n",
        "    print(\"  run_comprehensive_ee_analysis(results_df, merged_df_all)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g6l6nQnTB7I9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "37523fa4-2e91-42e9-ff34-8badd9fc502e"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'data' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4117970283.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[0;31m# Ensure 'data' is a DataFrame before grouping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m     \u001b[0;31m# Re-load data from compressed_data if it's not a DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Detected 'data' is not a DataFrame, attempting to reload from compressed_data.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "from matplotlib.ticker import MultipleLocator # Import MultipleLocator\n",
        "\n",
        "# Assuming spacy and cosine_similarity are already defined and available from previous cells\n",
        "\n",
        "\n",
        "# Function to calculate cosine similarity (Copied from oojCc1Qc4Px1)\n",
        "def cosine_similarity(vec1, vec2):\n",
        "    \"\"\"Calculate cosine similarity between two vectors.\"\"\"\n",
        "    # Add a check for zero vectors to prevent division by zero\n",
        "    norm_product = np.linalg.norm(vec1) * np.linalg.norm(vec2)\n",
        "    if norm_product == 0:\n",
        "        return 0\n",
        "    return np.dot(vec1, vec2) / norm_product\n",
        "\n",
        "# Function to calculate phase centroids (Copied from oojCc1Qc4Px1)\n",
        "def calculate_phase_centroids(phases):\n",
        "    exploitation_centroids = []\n",
        "    exploration_centroids = []\n",
        "    for idx, phase_info in enumerate(phases):\n",
        "        # Add a check to ensure phase_info has the expected structure\n",
        "        if not isinstance(phase_info, tuple) or len(phase_info) != 6:\n",
        "            # print(f\"Warning: Unexpected phase structure at index {idx}: {phase_info}. Skipping centroid calculation for this phase.\")\n",
        "            continue\n",
        "\n",
        "        # Access elements by position based on the structure (type, start, end, items, vectors, similarities)\n",
        "        phase_type, phase_start, phase_end, phase_items, phase_vectors, sims = phase_info\n",
        "\n",
        "        if phase_vectors is not None and len(phase_vectors) > 0:\n",
        "            centroid = np.mean(phase_vectors, axis=0)\n",
        "            if phase_type == \"Exploitation\":\n",
        "                exploitation_centroids.append((centroid, \", \".join(phase_items)))\n",
        "            else:\n",
        "                exploration_centroids.append((centroid, \", \".join(phase_items)))\n",
        "            # Print summary statistics for each centroid (optional, for debugging)\n",
        "            # centroid_norm = np.linalg.norm(centroid)\n",
        "            # print(f'Centroid {idx} ({phase_type}) \"{phase_items} sims={sims}\": Norm={centroid_norm}')\n",
        "        # else:\n",
        "            # print(f\"No vectors in phase {idx} ({phase_type}) to calculate centroid.\")\n",
        "    return exploitation_centroids, exploration_centroids\n",
        "\n",
        "# Function to calculate intra-phase similarities (Copied from oojCc1Qc4Px1)\n",
        "def calculate_intra_phase_similarities(phases):\n",
        "    \"\"\"Calculate pairwise cosine similarities within each phase.\"\"\"\n",
        "    intra_phase_similarities_exploitation = []\n",
        "    intra_phase_similarities_exploration = []\n",
        "\n",
        "    # Add print statement to inspect the phases data\n",
        "    # print(\"\\nDebugging: Inside calculate_intra_phase_similarities\")\n",
        "    # print(f\"Input phases: {phases}\")\n",
        "\n",
        "    for phase_idx, phase_info in enumerate(phases):\n",
        "        # Add a check to ensure phase_info has the expected structure\n",
        "        if not isinstance(phase_info, tuple) or len(phase_info) != 6:\n",
        "            # print(f\"Warning: Unexpected phase structure at index {phase_idx}: {phase_info}. Skipping intra-phase similarity calculation for this phase.\")\n",
        "            continue\n",
        "\n",
        "        # Access elements by position based on the structure (type, start, end, items, vectors, similarities)\n",
        "        phase_type, phase_start, phase_end, phase_items, phase_vectors, sims = phase_info\n",
        "\n",
        "        # Add a check for phase_vectors being None or empty\n",
        "        if phase_vectors is None or len(phase_vectors) <= 1:\n",
        "            # print(f\"Debugging: Not enough vectors in phase {phase_idx} ({phase_type}) to calculate intra-phase similarities.\")\n",
        "            continue\n",
        "\n",
        "        # Calculate pairwise similarities within the phase\n",
        "        phase_sims = [cosine_similarity(phase_vectors[i], phase_vectors[j])\n",
        "                      for i in range(len(phase_vectors))\n",
        "                      for j in range(i+1, len(phase_vectors))]\n",
        "        # print(f'phase_items={phase_items} phase={phase_type} phase_sims={sims}') # Debugging\n",
        "        if phase_type == \"Exploitation\":\n",
        "            intra_phase_similarities_exploitation.append((phase_sims, \", \".join(phase_items)))\n",
        "        else:\n",
        "            intra_phase_similarities_exploration.append((phase_sims, \", \".join(phase_items)))\n",
        "        # else:\n",
        "            # print(f\"Not enough items in phase {phase_idx} ({phase_type}) to calculate intra-phase similarities.\") # Debugging\n",
        "    return intra_phase_similarities_exploitation, intra_phase_similarities_exploration\n",
        "\n",
        "\n",
        "# Function to calculate inter-phase similarities (Copied from oojCc1Qc4Px1)\n",
        "def calculate_inter_phase_similarities(phase_centroids):\n",
        "    \"\"\"Calculate cosine similarities between consecutive phase centroids.\"\"\"\n",
        "    inter_phase_similarities = []\n",
        "    # Iterate through consecutive pairs of centroids\n",
        "    for i in range(len(phase_centroids) - 1):\n",
        "        # Check if both centroids have valid vectors\n",
        "        if phase_centroids[i] is not None and phase_centroids[i+1] is not None and phase_centroids[i][0] is not None and phase_centroids[i+1][0] is not None:\n",
        "            # Calculate similarity between centroid i and centroid i+1\n",
        "            sim = cosine_similarity(phase_centroids[i][0], phase_centroids[i+1][0])\n",
        "            inter_phase_similarities.append((sim, phase_centroids[i][1] + \" <=> \" + phase_centroids[i+1][1]))\n",
        "    return inter_phase_similarities\n",
        "\n",
        "\n",
        "# Main function to calculate phase proximities (Copied from oojCc1Qc4Px1)\n",
        "def calculate_phase_proximities(row):\n",
        "    \"\"\"\n",
        "    Calculate and return intra- and inter-phase proximity measures for a single participant.\n",
        "\n",
        "    Args:\n",
        "        row (pd.Series): A row from the results_df DataFrame containing\n",
        "                         'vectors', 'phases', and 'items'.\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary containing calculated proximity metrics.\n",
        "    \"\"\"\n",
        "    vectors = row['vectors']\n",
        "    phases = row['phases']\n",
        "    items = row['items']\n",
        "\n",
        "    # Calculate intra-phase similarities\n",
        "    intra_phase_similarities_exploitation, intra_phase_similarities_exploration = calculate_intra_phase_similarities(phases)\n",
        "\n",
        "    # Calculate phase centroids\n",
        "    exploitation_centroids, exploration_centroids = calculate_phase_centroids(phases)\n",
        "    all_centroids = []\n",
        "    # Reconstruct all_centroids in sequence order by looking up centroids by their items/names\n",
        "    # This requires iterating through the original phases list to get the order\n",
        "    all_phase_names = []\n",
        "    for phase_info in phases:\n",
        "        # Access elements by position based on the structure (type, start, end, items, vectors, similarities)\n",
        "        if isinstance(phase_info, tuple) and len(phase_info) == 6 and phase_info[3] is not None:\n",
        "            all_phase_names.append(\", \".join(phase_info[3]))\n",
        "\n",
        "\n",
        "    # Create a lookup dictionary for centroids by their item names\n",
        "    centroid_lookup = {}\n",
        "    for centroid_vector, centroid_name in exploitation_centroids:\n",
        "        centroid_lookup[centroid_name] = centroid_vector\n",
        "    for centroid_vector, centroid_name in exploration_centroids:\n",
        "        centroid_lookup[centroid_name] = centroid_vector\n",
        "\n",
        "    # Build all_centroids list in sequence order\n",
        "    for phase_name in all_phase_names:\n",
        "        if phase_name in centroid_lookup:\n",
        "            # Need to include the name in the all_centroids list structure for calculate_inter_phase_similarities\n",
        "            all_centroids.append((centroid_lookup[phase_name], phase_name))\n",
        "        # else:\n",
        "             # print(f\"Warning: Centroid for phase '{phase_name}' not found.\")\n",
        "\n",
        "\n",
        "    # Calculate inter-phase similarities between consecutive centroids\n",
        "    inter_phase_similarities_consecutive = calculate_inter_phase_similarities(all_centroids)\n",
        "\n",
        "\n",
        "    # Calculate norms for phase centroids\n",
        "    exploitation_centroids_norms = [np.linalg.norm(centroid) for centroid, name in exploitation_centroids if centroid is not None]\n",
        "    exploration_centroids_norms = [np.linalg.norm(centroid) for centroid, name in exploration_centroids if centroid is not None]\n",
        "\n",
        "\n",
        "    # Calculate mean and variance for intra- and inter-phase proximities\n",
        "    # Flatten the intra-phase similarities\n",
        "    flattened_intra_exploit_sims = [sim for sim_list, _ in intra_phase_similarities_exploitation for sim in sim_list]\n",
        "    flattened_intra_explore_sims = [sim for sim_list, _ in intra_phase_similarities_exploration for sim in sim_list]\n",
        "    flattened_inter_sims = [sim for sim, _ in inter_phase_similarities_consecutive] # Use consecutive inter-phase sims\n",
        "\n",
        "    # Calculate mean and variance (assuming equal weights for simplicity here)\n",
        "    intra_exploit_mean = np.mean(flattened_intra_exploit_sims) if flattened_intra_exploit_sims else np.nan\n",
        "    intra_exploit_variance = np.var(flattened_intra_exploit_sims) if flattened_intra_exploit_sims else np.nan\n",
        "\n",
        "    intra_explore_mean = np.mean(flattened_intra_explore_sims) if flattened_intra_explore_sims else np.nan\n",
        "    intra_explore_variance = np.var(flattened_intra_explore_sims) if flattened_intra_explore_sims else np.nan\n",
        "\n",
        "    inter_mean = np.mean(flattened_inter_sims) if flattened_inter_sims else np.nan\n",
        "    inter_variance = np.var(flattened_inter_sims) if flattened_inter_sims else np.nan\n",
        "\n",
        "\n",
        "    return {\n",
        "        # Phase Centroids\n",
        "        'phase_centroids_exploitation': exploitation_centroids,\n",
        "        'phase_centroids_exploration': exploration_centroids,\n",
        "        'phase_centroids_norms_exploitation': exploitation_centroids_norms,\n",
        "        'phase_centroids_norms_exploration': exploration_centroids_norms,\n",
        "        # Intra-Phase Similarities\n",
        "        'intra_phase_similarities_exploitation': intra_phase_similarities_exploitation,\n",
        "        'intra_phase_mean_exploitation': intra_exploit_mean,\n",
        "        'intra_phase_variance_exploitation': intra_exploit_variance,\n",
        "        'intra_phase_similarities_exploration': intra_phase_similarities_exploration,\n",
        "        'intra_phase_mean_exploration': intra_explore_mean,\n",
        "        'intra_phase_variance_exploration': intra_explore_variance,\n",
        "        # Inter-Phase Similarities (Consecutive)\n",
        "        'inter_phase_similarities_consecutive': inter_phase_similarities_consecutive,\n",
        "        'inter_phase_mean_consecutive': inter_mean,\n",
        "        'inter_phase_variance_consecutive': inter_variance\n",
        "    }\n",
        "\n",
        "# Processing all participants (This block should be in a cell that runs AFTER function definitions)\n",
        "all_data = []  # Structure to store ID, items, vectors, similarities\n",
        "all_similarities = []  # List to hold all similarities for global mean/std calculation\n",
        "\n",
        "# Ensure 'data' is a DataFrame before grouping\n",
        "if not isinstance(data, pd.DataFrame):\n",
        "    # Re-load data from compressed_data if it's not a DataFrame\n",
        "    print(\"Detected 'data' is not a DataFrame, attempting to reload from compressed_data.\")\n",
        "    try:\n",
        "        data = compressed_data.set_index('ID')['Item'].str.split(',', expand=True).stack().reset_index(level=1, drop=True).reset_index(name='Item')\n",
        "        data['Item'] = data['Item'].str.lower()\n",
        "        data = data.dropna().reset_index(drop=True)\n",
        "        data['clean_ID'] = data['ID'].apply(lambda x: str(int(str(x).replace('PD', '')))) # Ensure clean_ID is created\n",
        "        print(\"Reloaded 'data' successfully.\")\n",
        "    except Exception as e:\n",
        "        raise TypeError(f\"Could not reload 'data' from 'compressed_data': {e}. Please ensure 'compressed_data' is a valid DataFrame.\")\n",
        "\n",
        "\n",
        "for participant_id, group in data.groupby('ID'):\n",
        "# DEBUG - test first PD00020\n",
        "# participant, group = next(iter(data.groupby('ID')))\n",
        "# items = group['Item'].tolist()\n",
        "    items = group['Item'].tolist()\n",
        "\n",
        "    # Compute word vectors for each item\n",
        "    docs = [nlp(item) for item in items if nlp(item).has_vector]\n",
        "    vectors = [doc.vector for doc in docs]\n",
        "\n",
        "    # Filter items to only include those with valid vectors\n",
        "    valid_items = [doc.text for doc in docs]\n",
        "\n",
        "\n",
        "    # Calculate cosine similarities for consecutive items with valid vectors\n",
        "    similarities = [cosine_similarity(vectors[i], vectors[i+1]) for i in range(len(vectors) - 1)]\n",
        "\n",
        "    # Append similarities to the global list for mean/std calculation\n",
        "    all_similarities.extend(similarities)\n",
        "\n",
        "    # Store participant data\n",
        "    all_data.append({\n",
        "        'participant': participant_id,\n",
        "        'items': valid_items, # Use filtered items\n",
        "        'vectors': vectors,\n",
        "        'similarities': similarities,\n",
        "        'clean_ID': str(int(participant_id.replace('PD', ''))) # Ensure clean_ID is added here\n",
        "    })\n",
        "\n",
        "all_similarities = np.array(all_similarities)\n",
        "\n",
        "mean_similarity = np.mean(all_similarities) if len(all_similarities) > 0 else 0\n",
        "std_similarity = np.std(all_similarities) if len(all_similarities) > 0 else 0\n",
        "\n",
        "print(f\"Mean Similarity: {mean_similarity}\")\n",
        "print(f\"Standard Deviation of Similarity: {std_similarity}\")\n",
        "\n",
        "# Analyze all participants (This block should be in a cell that runs AFTER function definitions)\n",
        "results = []\n",
        "# TODO clean debugging code\n",
        "# all_data = [participant_data for participant_data in all_data if participant_data['participant'] == 'PD01156']\n",
        "for participant_data in all_data:\n",
        "    # try:\n",
        "        analysis = analyze_responses(participant_data, mean_similarity)\n",
        "\n",
        "        participant = participant_data['participant']\n",
        "        items = participant_data['items']\n",
        "        vectors = participant_data['vectors']\n",
        "        similarities = participant_data['similarities']\n",
        "\n",
        "        # Reconstruct phases with actual data for calculate_phase_proximities\n",
        "        phases_with_data = []\n",
        "        # Ensure the original phases list from analyze_responses has the correct structure before iterating\n",
        "        # The issue might be in the original identify_phases function if it's not consistent.\n",
        "        # Let's use the phases list directly from the analysis results and ensure it has the right format.\n",
        "        # Based on the traceback, the phases list seems to contain tuples of length 6, but with None values.\n",
        "        # The fix in the previous step updated analyze_responses to return tuples with data.\n",
        "        # Let's double-check how phases are generated in analyze_responses.\n",
        "        # Looking at analyze_responses in cell ObnewO-p9IeK, it calls identify_phases which *does* return\n",
        "        # (type, start, end, items, vectors, similarities) tuples.\n",
        "        # The issue might be how those are then processed or stored.\n",
        "        # Let's re-construct phases_with_data directly from the items, vectors, and analysis['phases'] indices.\n",
        "\n",
        "        # Use the phase boundaries from analysis['phases'] but get items and vectors from the participant_data\n",
        "        for phase_type, start, end, _, _, _ in analysis['phases']:\n",
        "             # Ensure end index is within bounds\n",
        "             end_index = min(end, len(items) - 1)\n",
        "\n",
        "             phase_items = items[start:end_index+1]\n",
        "             phase_vectors = vectors[start:end_index+1]\n",
        "             # Similarities are for transitions between items *within* the phase.\n",
        "             # The similarities list in participant_data is for transitions between consecutive items in the whole sequence.\n",
        "             # For intra-phase similarity, calculate pairwise within phase_vectors in calculate_intra_phase_similarities.\n",
        "             # For inter-phase similarity, this uses centroids.\n",
        "             # The `sims` in the phase tuple from `identify_phases` is not actually used in `calculate_intra_phase_similarities`.\n",
        "             # Let's pass the segment of the original similarities list corresponding to transitions *within* this phase.\n",
        "             phase_similarities_segment = similarities[start:end] if start < end else []\n",
        "\n",
        "             phases_with_data.append((phase_type, start, end_index, phase_items, phase_vectors, phase_similarities_segment))\n",
        "\n",
        "\n",
        "        results.append({\n",
        "            'participant': participant,\n",
        "            'num_items': len(items),\n",
        "            'items': items, # Keep items here\n",
        "            'vectors': vectors, # Include vectors here\n",
        "            'similarities': similarities, # Include similarities here\n",
        "            'avg_similarity': analysis['avg_similarity'],\n",
        "            'num_phases': len(analysis['phases']),\n",
        "            'phases': phases_with_data, # Use phases with actual data\n",
        "            'exploitation_time': analysis['exploitation_time'],\n",
        "            'exploration_time': analysis['exploration_time'],\n",
        "            'exploitation_percentage': analysis['exploitation_percentage'],\n",
        "            'exploration_percentage': analysis['exploration_percentage'],\n",
        "            'exploration_phases_ratio': analysis['exploration_phases_ratio'], # Ensure this key is present\n",
        "            'exploitation_phases_ratio': analysis['exploitation_phases_ratio'], # Ensure this key is present\n",
        "            'novelty_scores': analysis['novelty_scores'],\n",
        "            'novelty_ratio': sum(analysis['novelty_scores']) / len(items) if items else 0,\n",
        "            'mean_phase_size': analysis['mean_phase_size'],\n",
        "            'exploitation_mean_phase_size': analysis['exploitation_mean_phase_size'],\n",
        "            'exploration_mean_phase_size': analysis['exploration_mean_phase_size'],\n",
        "            'ee_tradeoff': analysis['ee_tradeoff'],\n",
        "            'num_clusters': analysis['num_clusters'],\n",
        "            'clusters': analysis['clusters'],\n",
        "\n",
        "            # Removed lines that were trying to access phase centroid and similarity data from 'analysis'\n",
        "            # as these are not calculated within the analyze_responses function in cell ObnewO-p9IeK.\n",
        "            # This data is calculated in calculate_phase_proximities in cell g6l6nQnTB7I9\n",
        "            # and merged in cell g6l6nQnTB7I9.\n",
        "\n",
        "        })\n",
        "    # except Exception as e:\n",
        "        # print(f\"Error processing participant {participant}: {str(e)}\")\n",
        "\n",
        "results_df = pd.DataFrame(results)\n",
        "# print(results_df)\n",
        "# Sort the DataFrame by participant IDs for consistent ordering\n",
        "results_df = results_df.sort_values('participant').reset_index(drop=True)\n",
        "\n",
        "\n",
        "# Ensure required columns exist in results_df for calculate_phase_proximities\n",
        "required_cols = ['vectors', 'phases', 'items', 'participant']\n",
        "for col in required_cols:\n",
        "    if col not in results_df.columns:\n",
        "        raise ValueError(f\"Required column '{col}' not found in results_df.\")\n",
        "\n",
        "# Apply the function to each row of the results_df\n",
        "phase_proximity_results = results_df.apply(\n",
        "    calculate_phase_proximities, # Pass the row directly\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "# Expand the resulting Series of dictionaries into a DataFrame\n",
        "proximity_df = pd.json_normalize(phase_proximity_results)\n",
        "\n",
        "# Merge the proximity results into results_df\n",
        "# Ensure 'participant' column is in both dataframes for merging\n",
        "if 'participant' not in results_df.columns:\n",
        "    # Assuming 'participant' can be derived from 'ID' or another column in results_df\n",
        "    # Add logic here to create 'participant' in results_df if it's missing\n",
        "    # For example, if 'ID' exists and is 'PDXXXXX':\n",
        "    if 'ID' in results_df.columns:\n",
        "        results_df['participant'] = results_df['ID']\n",
        "    else:\n",
        "        raise ValueError(\"Cannot merge proximity results: 'participant' or 'ID' column not found in results_df.\")\n",
        "\n",
        "\n",
        "# Perform the merge\n",
        "# Use a suffix for columns that might exist in both dataframes if needed\n",
        "results_df = pd.merge(results_df, proximity_df, on='participant', how='left', suffixes=('', '_proximity'))\n",
        "\n",
        "\n",
        "# Display the head of the updated results_df with new proximity columns\n",
        "print(\"\\nResults DataFrame with Phase Proximity Measures:\")\n",
        "display(results_df.head())\n",
        "\n",
        "\n",
        "# Now merged_df_all contains the phase proximity measures and can be used in cell wanJ0F_Jca-s\n",
        "# Combine intra- and inter-phase similarity lists by participant\n",
        "# Flattening the list of tuples to just a single list of similarities per participant\n",
        "# NOTE: These flattenings and related calculations below (like group means for flattened lists)\n",
        "# will now operate on empty lists/NaNs if phase proximity calculations haven't been run and merged yet.\n",
        "# The phase proximity calculations are handled separately in cell g6l6nQnTB7I9.\n",
        "# These columns are kept for compatibility with later cells, but their values will be NaN\n",
        "# until the results from g6l6nQnTB7I9 are merged into merged_df_all.\n",
        "\n",
        "results_df['flattened_intra_phase_similarities_exploitation'] = results_df.apply(\n",
        "    lambda row: [sim for sim_list, _ in row['intra_phase_similarities_exploitation'] for sim in sim_list] if 'intra_phase_similarities_exploitation' in row and row['intra_phase_similarities_exploitation'] is not None else [],\n",
        "    axis=1\n",
        ")\n",
        "# Using the correct merged column name for inter-phase similarities\n",
        "results_df['flattened_inter_phase_similarities_consecutive'] = results_df.apply(\n",
        "    lambda row: [sim for sim, _ in row['inter_phase_similarities_consecutive']] if 'inter_phase_similarities_consecutive' in row and row['inter_phase_similarities_consecutive'] is not None else [],\n",
        "    axis=1\n",
        ")\n",
        "results_df['flattened_intra_phase_similarities_exploration'] = results_df.apply(\n",
        "    lambda row: [sim for sim_list, _ in row['intra_phase_similarities_exploration'] for sim in sim_list] if 'intra_phase_similarities_exploration' in row and row['intra_phase_similarities_exploration'] is not None else [],\n",
        "    axis=1\n",
        ")\n",
        "# No flattened_inter_phase_similarities_exploration needed based on calculate_phase_proximities\n",
        "\n",
        "# Calculate mean and variance per phase for each participant (already done in calculate_phase_proximities, just confirming column names)\n",
        "# These columns should now be correctly populated after the merge with proximity_df\n",
        "# results_df['intra_phase_mean_exploitation'] = results_df['intra_phase_mean_exploitation_proximity'] # Not needed, already merged\n",
        "# results_df['intra_phase_variance_exploitation'] = results_df['intra_phase_variance_exploitation_proximity'] # Not needed, already merged\n",
        "# results_df['intra_phase_mean_exploration'] = results_df['intra_phase_mean_exploration_proximity'] # Not needed, already merged\n",
        "# results_df['intra_phase_variance_exploration'] = results_df['intra_phase_variance_exploration_proximity'] # Not needed, already merged\n",
        "# results_df['inter_phase_mean_consecutive'] = results_df['inter_phase_mean_consecutive'] # Not needed, already merged\n",
        "# results_df['inter_phase_variance_consecutive'] = results_df['inter_phase_variance_consecutive'] # Not needed, already merged\n",
        "\n",
        "\n",
        "# Calculate group-level exploitation/exploration ratio\n",
        "group_exploitation_time = results_df['exploitation_time'].mean()\n",
        "group_exploration_time = results_df['exploration_time'].mean()\n",
        "group_exploitation_percentage = results_df['exploitation_percentage'].mean()\n",
        "group_exploration_percentage = results_df['exploration_percentage'].mean()\n",
        "group_exploration_phases_ratio = results_df['exploration_phases_ratio'].mean()\n",
        "group_exploitation_phases_ratio = results_df['exploitation_phases_ratio'].mean()\n",
        "\n",
        "print(f\"\\nGroup-level Exploitation Times Ratio: {group_exploitation_time}\")\n",
        "print(f\"Group-level Exploration Times Ratio: {group_exploration_time}\")\n",
        "print(f\"Group-level Exploitation Percentage: {group_exploitation_percentage}\")\n",
        "print(f\"Group-level Exploration Percentage: {group_exploration_percentage}\")\n",
        "print(f\"Group-level Exploration Phases Ratio: {group_exploration_phases_ratio}\")\n",
        "print(f\"Group-level Exploitation Phases Ratio: {group_exploitation_phases_ratio}\")\n",
        "\n",
        "# Calculate correlations\n",
        "# Include the new proximity mean/variance columns in the correlation analysis\n",
        "numerical_columns = [\n",
        "    'num_items',\n",
        "    'avg_similarity',\n",
        "    'num_phases',\n",
        "    'exploitation_time',\n",
        "    'exploration_time',\n",
        "    'exploitation_percentage',\n",
        "    'exploration_percentage',\n",
        "    'exploration_phases_ratio',\n",
        "    'exploitation_phases_ratio',\n",
        "    'novelty_ratio',\n",
        "    'num_clusters',\n",
        "    'intra_phase_mean_exploitation_proximity', # Use the merged column name\n",
        "    'intra_phase_variance_exploitation_proximity', # Use the merged column name\n",
        "    'intra_phase_mean_exploration_proximity', # Use the merged column name\n",
        "    'intra_phase_variance_exploration_proximity', # Use the merged column name\n",
        "    'inter_phase_mean_consecutive', # Use the merged column name\n",
        "    'inter_phase_variance_consecutive', # Use the merged column name\n",
        "    'ee_tradeoff',\n",
        "    'mean_phase_size',\n",
        "    'exploitation_mean_phase_size',\n",
        "    'exploration_mean_phase_size',\n",
        "    'phase_centroids_norms_exploitation_proximity',\n",
        "    'phase_centroids_norms_exploration_proximity'\n",
        "    ]\n",
        "\n",
        "# Filter numerical columns to only include those present in results_df\n",
        "numerical_columns = [col for col in numerical_columns if col in results_df.columns]\n",
        "\n",
        "correlations = results_df[numerical_columns].corr()\n",
        "print(\"\\nCorrelations:\")\n",
        "print(correlations)\n",
        "\n",
        "\n",
        "# Define columns to exclude from merged_df_all, *keeping* 'items', 'similarities', and 'phases'\n",
        "# These columns are needed for plotting in cell 2FrqAiuyPvf6\n",
        "columns_to_exclude = [\n",
        "    #'vectors', # DO NOT EXCLUDE 'vectors'\n",
        "    #'items', # DO NOT EXCLUDE 'items'\n",
        "    'novelty_scores',\n",
        "    'clusters',\n",
        "    # The following columns are now in results_df with '_proximity' suffix, so they are handled by numerical_columns\n",
        "    # 'phase_centroids_exploitation',\n",
        "    # 'phase_centroids_exploration',\n",
        "    # 'phase_centroids_norms_exploitation',\n",
        "    # 'phase_centroids_norms_exploration',\n",
        "    # 'intra_phase_similarities_exploitation',\n",
        "    # 'intra_phase_similarities_exploration',\n",
        "    # 'inter_phase_similarities_consecutive',\n",
        "    'flattened_intra_phase_similarities_exploitation',\n",
        "    'flattened_inter_phase_similarities_consecutive',\n",
        "    'flattened_intra_phase_similarities_exploration',\n",
        "    #'similarities' # DO NOT EXCLUDE 'similarities'\n",
        "    #'phases' # DO NOT EXCLUDE 'phases'\n",
        "]\n",
        "\n",
        "# Remove 'PD' and leading zeros to create clean_ID for merging\n",
        "# Ensure clean_ID is created if it doesn't exist (should be from analyze_responses)\n",
        "if 'clean_ID' not in results_df.columns:\n",
        "    clean_id = lambda x: str(int(x.replace('PD', '')))\n",
        "    results_df['clean_ID'] = results_df['participant'].apply(clean_id)\n",
        "\n",
        "# Merge dataframes with MEG/LC data\n",
        "# Ensure meg_lc_data is a DataFrame before merging\n",
        "if not isinstance(meg_lc_data, pd.DataFrame):\n",
        "    print(\"MEG/LC data is not a DataFrame. Skipping merge.\")\n",
        "    # Explicitly keep 'items', 'similarities', and 'phases' when dropping\n",
        "    merged_df_all = results_df.drop(columns=[col for col in columns_to_exclude if col not in ['items', 'similarities', 'phases', 'vectors']], errors='ignore')\n",
        "else:\n",
        "     # Ensure clean_ID exists in meg_lc_data and is comparable\n",
        "    if 'clean_ID' not in meg_lc_data.columns:\n",
        "         # Attempt to create clean_ID if it doesn't exist\n",
        "         try:\n",
        "              # Assuming the first column in meg_lc_data is the ID column like 'PDXXXXX'\n",
        "              meg_lc_data['clean_ID'] = meg_lc_data.iloc[:, 0].apply(lambda x: str(int(str(x).replace('PD', ''))))\n",
        "              print(\"Created 'clean_ID' in meg_lc_data.\")\n",
        "         except Exception as e:\n",
        "              print(f\"Could not create 'clean_ID' in meg_lc_data from the first column: {e}. Skipping merge.\")\n",
        "              # Explicitly keep 'items', 'similarities', and 'phases' when dropping\n",
        "              merged_df_all = results_df.drop(columns=[col for col in columns_to_exclude if col not in ['items', 'similarities', 'phases', 'vectors']], errors='ignore')\n",
        "    else:\n",
        "        # Ensure 'clean_ID' types are consistent\n",
        "        results_df['clean_ID'] = results_df['clean_ID'].astype(str)\n",
        "        meg_lc_data['clean_ID'] = meg_lc_data['clean_ID'].astype(str)\n",
        "        # Explicitly keep 'items', 'similarities', and 'phases' when dropping from results_df\n",
        "        merged_df_all = pd.merge(results_df.drop(columns=[col for col in columns_to_exclude if col not in ['items', 'similarities', 'phases', 'vectors']], errors='ignore'),\n",
        "                                 meg_lc_data, on='clean_ID', how='left')\n",
        "        print(f\"Merged results with MEG/LC data for {len(merged_df_all)} participants.\")\n",
        "\n",
        "\n",
        "# Display head of the final merged DataFrame with selected columns\n",
        "print('\\nMerged DataFrame head with selected columns:')\n",
        "# Include 'age', 'norm_LC_avg', and 'alpha_NET_mean' in the columns to display if they exist\n",
        "display_cols = ['participant', 'clean_ID'] + [col for col in numerical_columns if col in merged_df_all.columns]\n",
        "if 'age' in merged_df_all.columns:\n",
        "    display_cols.append('age')\n",
        "if 'norm_LC_avg' in merged_df_all.columns:\n",
        "    display_cols.append('norm_LC_avg')\n",
        "if 'alpha_NET_mean' in merged_df_all.columns:\n",
        "    display_cols.append('alpha_NET_mean')\n",
        "if 'items' in merged_df_all.columns:\n",
        "    display_cols.append('items')\n",
        "if 'similarities' in merged_df_all.columns:\n",
        "     display_cols.append('similarities')\n",
        "if 'phases' in merged_df_all.columns:\n",
        "     display_cols.append('phases')\n",
        "if 'vectors' in merged_df_all.columns:\n",
        "     display_cols.append('vectors')\n",
        "\n",
        "# Ensure all display_cols are actually in merged_df_all's columns\n",
        "display_cols = [col for col in display_cols if col in merged_df_all.columns]\n",
        "\n",
        "display(merged_df_all[display_cols].head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2FrqAiuyPvf6"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import math\n",
        "\n",
        "\n",
        "def plot_similarity_all_participants_composite(merged_df_all, figsize=(24, 20)):\n",
        "    \"\"\"\n",
        "    Creates a composite grid of similarity bar plots for all participants.\n",
        "\n",
        "    Args:\n",
        "        merged_df_all (pd.DataFrame): The complete DataFrame containing all participants.\n",
        "        figsize (tuple): Size of the overall figure.\n",
        "    \"\"\"\n",
        "    participants = merged_df_all['participant'].unique()\n",
        "    num_participants = len(participants)\n",
        "\n",
        "    # Determine grid size (3 columns)\n",
        "    cols = 3\n",
        "    rows = math.ceil(num_participants / cols)\n",
        "\n",
        "    fig, axes = plt.subplots(rows, cols, figsize=figsize, constrained_layout=True)\n",
        "    axes = axes.flatten()  # Flatten to easily iterate\n",
        "\n",
        "    for idx, participant in enumerate(participants):\n",
        "        ax = axes[idx]\n",
        "        participant_row = merged_df_all.loc[merged_df_all['participant'] == participant].iloc[0]\n",
        "\n",
        "        items = participant_row['items']\n",
        "        similarities = participant_row['similarities']\n",
        "\n",
        "        # Check data consistency\n",
        "        if len(items) != len(similarities) + 1:\n",
        "            ax.text(0.5, 0.5, 'Data Mismatch', horizontalalignment='center', verticalalignment='center', fontsize=12, color='red')\n",
        "            ax.set_title(f\"{participant}\\nData Mismatch\", fontsize=10)\n",
        "            ax.axis('off')\n",
        "            continue\n",
        "\n",
        "        transitions = [f\"{items[i]} -> {items[i+1]}\" for i in range(len(similarities))]\n",
        "\n",
        "        df = pd.DataFrame({\n",
        "            'Transition': transitions,\n",
        "            'Similarity': similarities\n",
        "        })\n",
        "\n",
        "        # Removed palette since no hue is used. Alternatively, specify a single color.\n",
        "        sns.barplot(x='Similarity', y='Transition', data=df, color='skyblue', ax=ax)\n",
        "        ax.set_title(participant, fontsize=10)\n",
        "        ax.set_xlabel('Similarity Score', fontsize=8)\n",
        "        ax.set_ylabel('')\n",
        "        ax.tick_params(axis='x', labelsize=6)\n",
        "        ax.tick_params(axis='y', labelsize=6)\n",
        "\n",
        "        # Add average similarity line\n",
        "        avg_similarity = participant_row['avg_similarity']\n",
        "        ax.axvline(avg_similarity, color='red', linestyle='--', linewidth=0.5)\n",
        "        ax.legend(['Average Similarity'], fontsize=6)\n",
        "\n",
        "    # Hide any unused subplots\n",
        "    for i in range(idx + 1, len(axes)):\n",
        "        axes[i].axis('off')\n",
        "\n",
        "    plt.suptitle('Similarity Scores Across All Participants', fontsize=16)\n",
        "    plt.savefig(\"similarity_scores_all_participants_composite.svg\", format='svg', bbox_inches='tight', dpi=300)\n",
        "    plt.show()\n",
        "\n",
        "# Plot similarity heatmap for all participants\n",
        "# doesnt make any sense\n",
        "plot_similarity_all_participants_composite(merged_df_all)\n",
        "\n",
        "\n",
        "def plot_phase_transitions_all_participants_composite(merged_df_all, figsize=(24, 20)):\n",
        "    \"\"\"\n",
        "    Creates a composite grid of phase transitions plots for all participants using the old approach.\n",
        "\n",
        "    Args:\n",
        "        merged_df_all (pd.DataFrame): The complete DataFrame containing all participants.\n",
        "        figsize (tuple): Size of the overall figure.\n",
        "    \"\"\"\n",
        "    participants = merged_df_all['participant'].unique()\n",
        "    num_participants = len(participants)\n",
        "\n",
        "    # Determine grid size (3 columns)\n",
        "    cols = 3\n",
        "    rows = math.ceil(num_participants / cols)\n",
        "\n",
        "    fig, axes = plt.subplots(rows, cols, figsize=figsize, constrained_layout=True)\n",
        "    axes = axes.flatten()\n",
        "\n",
        "    phase_mapping = {'Exploration': 0, 'Exploitation': 1}\n",
        "    palette = {'Exploration': 'skyblue', 'Exploitation': 'salmon'}\n",
        "\n",
        "    for idx, participant in enumerate(participants):\n",
        "        ax = axes[idx]\n",
        "        participant_row = merged_df_all.loc[merged_df_all['participant'] == participant].iloc[0]\n",
        "\n",
        "        phases = participant_row['phases']\n",
        "\n",
        "        if not phases:\n",
        "            ax.text(0.5, 0.5, 'No Phase Data', horizontalalignment='center', verticalalignment='center', fontsize=12, color='gray')\n",
        "            ax.set_title(f\"{participant}\\nNo Phase Data\", fontsize=10)\n",
        "            ax.axis('off')\n",
        "            continue\n",
        "\n",
        "        # Prepare data for plotting using the old approach\n",
        "        phase_numbers = []\n",
        "        phase_types = []\n",
        "        # Correctly unpack 6 values from the phase tuple\n",
        "        for phase_type, start, end, items, vectors, sims in phases:\n",
        "            phase_numbers.append(start)\n",
        "            phase_types.append(phase_type)\n",
        "        # The end index in the phase tuple is inclusive, so the last point should be at the end index\n",
        "        phase_numbers.append(phases[-1][2])\n",
        "\n",
        "        phase_values = [phase_mapping.get(pt, 0) for pt in phase_types]\n",
        "        # Maintain the last phase value for the step plot's end point\n",
        "        phase_values.append(phase_values[-1])\n",
        "\n",
        "        # Step plot\n",
        "        ax.step(phase_numbers, phase_values, where='post', linewidth=2, color='purple')\n",
        "        ax.set_ylim(-0.1, 1.1)\n",
        "        ax.set_yticks([0, 1])\n",
        "        ax.set_yticklabels(['Exploration', 'Exploitation'])\n",
        "        ax.set_title(participant, fontsize=10)\n",
        "        ax.set_xlabel('Item Index', fontsize=8) # Changed label to Item Index for clarity\n",
        "        ax.set_ylabel('Phase Type', fontsize=8) # Added Phase Type label\n",
        "        ax.tick_params(axis='x', labelsize=6)\n",
        "        ax.tick_params(axis='y', labelsize=6)\n",
        "\n",
        "        # Set x-axis limits to match the number of items + 1 for the step plot\n",
        "        num_items = participant_row['num_items']\n",
        "        ax.set_xlim(-0.5, num_items - 0.5) # Adjusted x-limits to better fit item indices\n",
        "\n",
        "\n",
        "        # Annotate phase labels\n",
        "        for phase_type, start, end, items, vectors, sims in phases:\n",
        "            mid_point = (start + end) / 2\n",
        "            ax.text(mid_point, phase_mapping.get(phase_type, 0) + 0.05,\n",
        "                    phase_type, ha='center', va='bottom', fontsize=6, rotation=45)\n",
        "\n",
        "        # Optional: Add colored spans for phase types\n",
        "        for phase_type, start, end, items, vectors, sims in phases:\n",
        "            ax.axvspan(start - 0.5, end + 0.5, color=palette.get(phase_type, 'gray'), alpha=0.3) # Adjusted span limits\n",
        "\n",
        "\n",
        "    # Hide any unused subplots\n",
        "    for i in range(idx + 1, len(axes)):\n",
        "        axes[i].axis('off')\n",
        "\n",
        "    plt.suptitle('Phase Transitions Across All Participants', fontsize=16)\n",
        "    plt.savefig(\"phase_transitions_all_participants_composite.svg\", format='svg', bbox_inches='tight', dpi=500)\n",
        "    plt.show()\n",
        "\n",
        "# Plot phase transitions for all participants\n",
        "plot_phase_transitions_all_participants_composite(merged_df_all)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oojCc1Qc4Px1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98d530ae-d71e-420c-f039-3a147815d2e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Group-Level Exploitation and Exploration Ratios and Percentages:\n",
            "\n",
            "merged_df_all DataFrame is not available. Please run the preceding cell to generate it.\n"
          ]
        }
      ],
      "source": [
        "# Intra/Inter cluster analysis\n",
        "# TODO:\n",
        "# check weighted mean calculations\n",
        "####\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "# Assuming spacy and cosine_similarity are already defined and available\n",
        "\n",
        "# Function to calculate the weighted mean and variance for cosine similarities\n",
        "def weighted_mean_variance(values, weights):\n",
        "    if values and len(values) >= 1:\n",
        "      mean = np.average(values, weights=weights)\n",
        "      # Calculate weighted variance\n",
        "      variance = np.average((values - mean) ** 2, weights=weights)\n",
        "      return mean, variance\n",
        "    else:\n",
        "      return np.nan, np.nan\n",
        "\n",
        "\n",
        "# This cell is now primarily for group-level analysis and correlation after merged_df_all is created in g6l6nQnTB7I9\n",
        "\n",
        "# Calculate group-level exploitation/exploration ratio (This was moved to g6l6nQnTB7I9)\n",
        "# Calculate correlations (This was moved to g6l6nQnTB7I9)\n",
        "# Merge dataframes with MEG/LC data (This was moved to g6l6nQnTB7I9)\n",
        "\n",
        "# The following code uses merged_df_all which is now generated in cell g6l6nQnTB7I9\n",
        "\n",
        "print(\"\\nGroup-Level Exploitation and Exploration Ratios and Percentages:\")\n",
        "if 'merged_df_all' in locals() and isinstance(merged_df_all, pd.DataFrame):\n",
        "    # Calculate group-level exploitation/exploration ratio\n",
        "    group_exploitation_time = merged_df_all['exploitation_time'].mean()\n",
        "    group_exploration_time = merged_df_all['exploration_time'].mean()\n",
        "    group_exploitation_percentage = merged_df_all['exploitation_percentage'].mean()\n",
        "    group_exploration_percentage = merged_df_all['exploration_percentage'].mean()\n",
        "    # Ensure total time is not zero before calculating phases ratio\n",
        "    total_time_sum = merged_df_all['exploitation_time'].sum() + merged_df_all['exploration_time'].sum()\n",
        "    group_exploration_phases_ratio = merged_df_all['exploration_time'].mean() / (merged_df_all['exploitation_time'].mean() + merged_df_all['exploration_time'].mean()) if (merged_df_all['exploitation_time'].mean() + merged_df_all['exploration_time'].mean()) > 0 else np.nan\n",
        "    group_exploitation_phases_ratio = merged_df_all['exploitation_time'].mean() / (merged_df_all['exploitation_time'].mean() + merged_df_all['exploration_time'].mean()) if (merged_df_all['exploitation_time'].mean() + merged_df_all['exploration_time'].mean()) > 0 else np.nan\n",
        "\n",
        "\n",
        "    print(f\"Group-level Exploitation Times Ratio: {group_exploitation_time}\")\n",
        "    print(f\"Group-level Exploration Times Ratio: {group_exploration_time}\")\n",
        "    print(f\"Group-level Exploitation Percentage: {group_exploitation_percentage}\")\n",
        "    print(f\"Group-level Exploration Percentage: {group_exploration_percentage}\")\n",
        "    print(f\"Group-level Exploration Phases Ratio: {group_exploration_phases_ratio}\")\n",
        "    print(f\"Group-level Exploitation Phases Ratio: {group_exploitation_phases_ratio}\")\n",
        "\n",
        "    # Calculate correlations (using the numerical columns defined in g6l6nQnTB7I9)\n",
        "    # Need to redefine or import numerical_columns if not globally available\n",
        "    # Assuming numerical_columns includes the '_proximity' suffixed columns after the merge in g6l6nQnTB7I9\n",
        "    numerical_columns = [col for col in merged_df_all.columns if merged_df_all[col].dtype in [np.int64, np.float64] and col not in ['clean_ID', 'norm_SN_l', 'norm_SN_r', 'norm_LC_l', 'norm_LC_r', 'norm_SN_avg', 'norm_LC_avg']] # Example: exclude clinical data raw columns\n",
        "    numerical_columns.extend(['norm_SN_avg', 'norm_LC_avg', 'alpha_NET_mean', 'age']) # Add key clinical columns back\n",
        "\n",
        "    # Filter to ensure columns exist and are numeric after potential merge\n",
        "    numerical_columns = [col for col in numerical_columns if col in merged_df_all.columns and pd.api.types.is_numeric_dtype(merged_df_all[col])]\n",
        "\n",
        "\n",
        "    if numerical_columns:\n",
        "        correlations = merged_df_all[numerical_columns].corr()\n",
        "        print(\"\\nCorrelations (including proximity measures and clinical data):\")\n",
        "        display(correlations)\n",
        "    else:\n",
        "        print(\"\\nNo numerical columns available for correlation analysis.\")\n",
        "\n",
        "\n",
        "else:\n",
        "    print(\"\\nmerged_df_all DataFrame is not available. Please run the preceding cell to generate it.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a figure with 4 subplots (2x2 layout) analyzing semantic verbal fluency test results where participants named animals:\n",
        "# Subplot A (Top Left): \"Total vs. Unique Words by Subject\"\n",
        "# Type: Grouped bar chart\n",
        "# X-axis: Subject IDs (approximately 50 subjects)\n",
        "# Y-axis: \"Number of Animals Named\" (range 0-25)\n",
        "# Data: Two bars per subject:\n",
        "# Dark teal bars: Total words produced\n",
        "# Light teal bars: Unique words (non-repeated)\n",
        "# Note: Total is always ≥ Unique, showing repetition patterns\n",
        "# Subplot B (Top Right): \"Repetition Rate by Subject\"\n",
        "# Type: Bar chart with gradient coloring\n",
        "# X-axis: Subject IDs (sorted by repetition rate, descending)\n",
        "# Y-axis: \"Repetition Rate (repetitions/total words)\" (range 0-0.30)\n",
        "# Color: Gradient from dark brown/orange (high repetition) to light orange (low repetition)\n",
        "# Labels: Show top 3 subject IDs on bars (PD00020, PD00457, PD01369)\n",
        "# Data: Shows approximately 10 subjects with highest repetition rates\n",
        "# Subplot C (Bottom Left): \"Distribution of Total Words\"\n",
        "# Type: Histogram\n",
        "# X-axis: \"Number of Animals Named\" (bins: 5, 10, 15, 20, 25, 30, 35, 40)\n",
        "# Y-axis: \"Number of Participants\" (range 0-20)\n",
        "# Color: Pink/rose bars\n",
        "# Statistics: Add vertical dashed lines for:\n",
        "# Mean: 17.1 (red dashed line)\n",
        "# Median: 17.0 (red dashed line)\n",
        "# Distribution: Bell-shaped, centered around 15-20 words\n",
        "# Subplot D (Bottom Right): \"Most Common Animals\"\n",
        "# Type: Horizontal bar chart\n",
        "# X-axis: \"Number of Participants Naming Each Animal\" (range 0-50)\n",
        "# Y-axis: Animal names (top 10): Dog, Cat, Lion, Tiger, Horse, Elephant, Cow, Monkey, Fox, Giraffe\n",
        "# Color: Gradient from dark purple (most common) to yellow (less common)\n",
        "# Labels: Show percentage at the end of each bar (e.g., \"95.7%\", \"93.3%\", etc.)\n",
        "# Ordering: Descending by frequency\n",
        "# General Styling:\n",
        "# Use a clean, scientific style with gridlines\n",
        "# Font: Sans-serif, professional\n",
        "# Title each subplot with bold text\n",
        "# Ensure consistent spacing and alignment\n",
        "# Color schemes should be colorblind-friendly\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from matplotlib.patches import Rectangle\n",
        "\n",
        "# Assume 'data' DataFrame is already loaded with participant fluency data\n",
        "# It should have at least 'ID' and 'Item' columns.\n",
        "# Assume 'merged_df_all' DataFrame exists from previous analysis\n",
        "# It should contain calculated metrics like 'num_items', 'items', 'novelty_scores', etc.\n",
        "\n",
        "\n",
        "# 1. Prepare data for plots (keeping your data preparation code as is)\n",
        "# Data for Subplot A: Total vs. Unique Words by Subject\n",
        "\n",
        "subject_summary = merged_df_all.groupby('participant').agg(\n",
        "    total_words=('items', lambda x: len(x.iloc[0])),\n",
        "    unique_words=('items', lambda x: len(set(x.iloc[0])))\n",
        ").reset_index()\n",
        "\n",
        "# Data for Subplot B: Repetition Rate by Subject\n",
        "subject_summary['repetitions'] = subject_summary['total_words'] - subject_summary['unique_words']\n",
        "subject_summary['repetition_rate'] = subject_summary['repetitions'] / subject_summary['total_words']\n",
        "subject_summary_top_rep = subject_summary.sort_values('repetition_rate', ascending=False).head(10)\n",
        "\n",
        "# Data for Subplot C: Distribution of Total Words\n",
        "total_words_distribution = subject_summary['total_words']\n",
        "mean_total_words = total_words_distribution.mean()\n",
        "median_total_words = total_words_distribution.median()\n",
        "\n",
        "# Data for Subplot D: Most Common Animals\n",
        "all_animals = [item for sublist in merged_df_all['items'] for item in sublist]\n",
        "animal_counts = pd.Series(all_animals).value_counts().reset_index()\n",
        "animal_counts.columns = ['Animal', 'Count']\n",
        "# Fix: Calculate percentage based on number of unique participants\n",
        "n_participants = len(merged_df_all['participant'].unique())\n",
        "animal_counts['Percentage'] = (animal_counts['Count'] / n_participants) * 100\n",
        "animal_counts_top_10 = animal_counts.head(10)\n",
        "\n",
        "# 2. Create the figure with improved formatting\n",
        "plt.style.use('default')  # Use default style for clean appearance\n",
        "plt.rcParams['font.family'] = 'sans-serif'\n",
        "plt.rcParams['font.size'] = 10\n",
        "plt.rcParams['axes.titlesize'] = 14\n",
        "plt.rcParams['axes.labelsize'] = 11\n",
        "plt.rcParams['xtick.labelsize'] = 9\n",
        "plt.rcParams['ytick.labelsize'] = 9\n",
        "\n",
        "# Create figure with better spacing\n",
        "fig = plt.figure(figsize=(16, 12))\n",
        "gs = fig.add_gridspec(2, 2, hspace=0.3, wspace=0.3,\n",
        "                      left=0.06, right=0.94, top=0.93, bottom=0.05)\n",
        "\n",
        "# ========== Subplot A: Scatter Plot - Total vs. Unique Words ==========\n",
        "ax1 = fig.add_subplot(gs[0, 0])\n",
        "\n",
        "# ALTERNATIVE OPTION: Box plot comparison (uncomment to use instead)\n",
        "\"\"\"\n",
        "# Create box plot comparing distributions\n",
        "data_to_plot = [subject_summary['total_words'], subject_summary['unique_words']]\n",
        "bp = ax1.boxplot(data_to_plot, labels=['Total Words', 'Unique Words'],\n",
        "                  patch_artist=True, notch=True, showmeans=True)\n",
        "# Color the boxes\n",
        "colors = ['#663399', '#FF8C00']\n",
        "for patch, color in zip(bp['boxes'], colors):\n",
        "    patch.set_facecolor(color)\n",
        "    patch.set_alpha(0.7)\n",
        "ax1.set_title('A. Distribution of Total vs. Unique Words', pad=10)\n",
        "ax1.set_ylabel('Number of Animals Named')\n",
        "ax1.grid(True, alpha=0.3, axis='y')\n",
        "\"\"\"\n",
        "\n",
        "# CURRENT IMPLEMENTATION: Scatter plot showing relationship\n",
        "# Create scatter plot showing relationship between total and unique words\n",
        "scatter = ax1.scatter(subject_summary['total_words'],\n",
        "                      subject_summary['unique_words'],\n",
        "                      c=subject_summary['repetition_rate'],\n",
        "                      cmap='YlOrRd', s=100, alpha=0.7, edgecolors='black', linewidth=0.5)\n",
        "\n",
        "# Add diagonal reference line (where total = unique, i.e., no repetitions)\n",
        "max_val = subject_summary['total_words'].max()\n",
        "ax1.plot([0, max_val], [0, max_val], 'k--', alpha=0.3, label='No repetitions line')\n",
        "\n",
        "# Add colorbar for repetition rate\n",
        "cbar = plt.colorbar(scatter, ax=ax1)\n",
        "cbar.set_label('Repetition Rate', fontsize=10)\n",
        "\n",
        "# Highlight subjects with highest repetition rates\n",
        "top_rep = subject_summary.nlargest(3, 'repetition_rate')\n",
        "for idx, row in top_rep.iterrows():\n",
        "    ax1.annotate(row['participant'],\n",
        "                 (row['total_words'], row['unique_words']),\n",
        "                 xytext=(5, 5), textcoords='offset points',\n",
        "                 fontsize=8)\n",
        "\n",
        "ax1.set_title('A. Relationship Between Total and Unique Words', pad=10)\n",
        "ax1.set_xlabel('Total Words Named')\n",
        "ax1.set_ylabel('Unique Words Named')\n",
        "ax1.set_xlim(0, max_val + 2)\n",
        "ax1.set_ylim(0, max_val + 2)\n",
        "ax1.grid(True, alpha=0.3)\n",
        "ax1.set_axisbelow(True)\n",
        "\n",
        "# Add text box with summary statistics\n",
        "textstr = f'Mean repetition rate: {subject_summary[\"repetition_rate\"].mean():.2f}\\n'\n",
        "textstr += f'Subjects with repetitions: {(subject_summary[\"repetition_rate\"] > 0).sum()}/{len(subject_summary)}'\n",
        "props = dict(boxstyle='round', facecolor='white', edgecolor='gray', alpha=0.8)\n",
        "ax1.text(0.05, 0.95, textstr, transform=ax1.transAxes, fontsize=9,\n",
        "         verticalalignment='top', bbox=props)\n",
        "\n",
        "# ========== Subplot B: Repetition Rate by Subject (Top 10) ==========\n",
        "ax2 = fig.add_subplot(gs[0, 1])\n",
        "\n",
        "# Create color gradient\n",
        "colors = plt.cm.Oranges(np.linspace(0.4, 0.9, len(subject_summary_top_rep)))\n",
        "\n",
        "bars = ax2.bar(range(len(subject_summary_top_rep)),\n",
        "                subject_summary_top_rep['repetition_rate'],\n",
        "                color=colors, edgecolor='none')\n",
        "\n",
        "# Add labels for top 3 participants\n",
        "for i, (idx, row) in enumerate(subject_summary_top_rep.head(3).iterrows()):\n",
        "    ax2.text(i, row['repetition_rate'] + 0.005, row['participant'],\n",
        "             ha='center', va='bottom', fontsize=9)\n",
        "\n",
        "ax2.set_title('B. Repetition Rate by Subject (Top 10)', pad=10)\n",
        "ax2.set_xlabel('Subject ID (Sorted by Rate)')\n",
        "ax2.set_ylabel('Repetition Rate (repetitions/total words)')\n",
        "ax2.set_ylim(0, subject_summary_top_rep['repetition_rate'].max() * 1.15)\n",
        "ax2.grid(True, alpha=0.3, axis='y')\n",
        "ax2.set_axisbelow(True)\n",
        "ax2.set_xticks(range(len(subject_summary_top_rep)))\n",
        "ax2.set_xticklabels(subject_summary_top_rep['participant'], rotation=45, ha='right')\n",
        "\n",
        "# ========== Subplot C: Distribution of Total Words ==========\n",
        "ax3 = fig.add_subplot(gs[1, 0])\n",
        "\n",
        "# Create histogram with narrower bins (10 bars instead of many 5-unit bins)\n",
        "# First find the range and create 10 evenly spaced bins\n",
        "min_val = max(0, total_words_distribution.min() - 2)\n",
        "max_val = total_words_distribution.max() + 2\n",
        "bins = np.linspace(min_val, max_val, 11)  # 11 edges for 10 bins\n",
        "\n",
        "n, bins, patches = ax3.hist(total_words_distribution, bins=bins,\n",
        "                             color='#d7858b', edgecolor='white', linewidth=1.2)\n",
        "\n",
        "# Add mean and median lines\n",
        "ax3.axvline(mean_total_words, color='#d62728', linestyle='--',\n",
        "            linewidth=2, alpha=0.8, label=f'Mean: {mean_total_words:.1f}')\n",
        "ax3.axvline(median_total_words, color='#ff7f0e', linestyle='--',\n",
        "            linewidth=2, alpha=0.8, label=f'Median: {median_total_words:.1f}')\n",
        "\n",
        "ax3.set_title('C. Distribution of Total Words', pad=10)\n",
        "ax3.set_xlabel('Number of Animals Named')\n",
        "ax3.set_ylabel('Number of Participants')\n",
        "ax3.legend(loc='upper right', frameon=True, fancybox=False)\n",
        "ax3.grid(True, alpha=0.3, axis='y')\n",
        "ax3.set_axisbelow(True)\n",
        "ax3.set_xlim(min_val, max_val)  # Set x-axis limits to match the data range\n",
        "\n",
        "# ========== Subplot D: Most Common Animals (Top 10) ==========\n",
        "ax4 = fig.add_subplot(gs[1, 1])\n",
        "\n",
        "# Create color gradient\n",
        "colors = plt.cm.plasma(np.linspace(0, 0.7, len(animal_counts_top_10)))\n",
        "\n",
        "# Create horizontal bar chart\n",
        "y_pos = np.arange(len(animal_counts_top_10))\n",
        "bars = ax4.barh(y_pos, animal_counts_top_10['Count'], color=colors, edgecolor='none')\n",
        "\n",
        "# Add percentage labels\n",
        "for i, (idx, row) in enumerate(animal_counts_top_10.iterrows()):\n",
        "    ax4.text(row['Count'] + 1, i, f\"{row['Percentage']:.1f}%\",\n",
        "             va='center', ha='left', fontsize=9)\n",
        "\n",
        "ax4.set_yticks(y_pos)\n",
        "ax4.set_yticklabels(animal_counts_top_10['Animal'])\n",
        "ax4.invert_yaxis()  # Most common at top\n",
        "ax4.set_title('D. Most Common Animals (Top 10)', pad=10)\n",
        "ax4.set_xlabel('Number of Participants Naming Each Animal')\n",
        "ax4.set_ylabel('Animal Name')\n",
        "ax4.grid(True, alpha=0.3, axis='x')\n",
        "ax4.set_axisbelow(True)\n",
        "ax4.set_xlim(0, animal_counts_top_10['Count'].max() * 1.15)\n",
        "\n",
        "# Clean up all axes\n",
        "for ax in [ax1, ax2, ax3, ax4]:\n",
        "    ax.spines['top'].set_visible(False)\n",
        "    ax.spines['right'].set_visible(False)\n",
        "    ax.spines['left'].set_linewidth(0.5)\n",
        "    ax.spines['bottom'].set_linewidth(0.5)\n",
        "\n",
        "# Add main title\n",
        "\n",
        "# Save figure\n",
        "plt.savefig('semantic_fluency_analysis.png', dpi=900, bbox_inches='tight')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6HeQcdKrGKIc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cVrp47Q4ZZYM"
      },
      "source": [
        " descriptive summary of semantic verbal fluency data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bVWhCMrszqVa"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "\n",
        "# Assuming 'merged_df_all' is available from a previous cell\n",
        "# Assuming 'rank_dict' (word frequency dictionary) is also available\n",
        "\n",
        "\n",
        "def get_animal_ranks(df, rank_dict):\n",
        "    \"\"\"\n",
        "    Calculates the average rank of animals in a participant's list based on a rank dictionary.\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): DataFrame containing participant data with 'participant' and 'items' columns.\n",
        "        rank_dict (dict): Dictionary mapping animals to their rank (lower rank = more frequent).\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: DataFrame with participant, total animals, number of animals in rank_dict,\n",
        "                      average rank, and percentage of animals in rank_dict.\n",
        "    \"\"\"\n",
        "    results = []\n",
        "    for index, row in df.iterrows():\n",
        "        participant = row['participant']\n",
        "        items = row['items']\n",
        "\n",
        "        total_animals = len(items)\n",
        "        animals_in_rank_dict = []\n",
        "        ranks = []\n",
        "\n",
        "        for item in items:\n",
        "            # Use .get() with a default value (e.g., len(rank_dict) + 1 for out-of-vocabulary words)\n",
        "            # Or skip items not in the rank_dict depending on the desired analysis\n",
        "            rank = rank_dict.get(item, None) # Get rank, return None if not found\n",
        "            if rank is not None:\n",
        "                animals_in_rank_dict.append(item)\n",
        "                ranks.append(rank)\n",
        "\n",
        "        num_animals_in_rank_dict = len(animals_in_rank_dict)\n",
        "        # Calculate average rank only for animals found in the rank_dict\n",
        "        average_rank = np.mean(ranks) if ranks else np.nan # Use np.nan for participants with no words in rank_dict\n",
        "        percentage_in_rank_dict = (num_animals_in_rank_dict / total_animals) * 100 if total_animals > 0 else 0\n",
        "\n",
        "        results.append({\n",
        "            'participant': participant,\n",
        "            'Total_Animals': total_animals,\n",
        "            'Animals_in_Rank_Dict': num_animals_in_rank_dict,\n",
        "            'Avg_Rank_in_Rank_Dict': average_rank,\n",
        "            'Pct_in_Rank_Dict': percentage_in_rank_dict\n",
        "        })\n",
        "\n",
        "    return pd.DataFrame(results)\n",
        "\n",
        "\n",
        "# Assuming 'merged_df_all' is your DataFrame containing participant data\n",
        "# and 'rank_dict' is your dictionary of animal ranks\n",
        "\n",
        "# Check if merged_df_all and rank_dict are available\n",
        "if 'merged_df_all' not in locals() or not isinstance(merged_df_all, pd.DataFrame):\n",
        "    print(\"Error: 'merged_df_all' DataFrame not found or is not a DataFrame.\")\n",
        "elif 'rank_dict' not in locals() or not isinstance(rank_dict, dict):\n",
        "     print(\"Error: 'rank_dict' dictionary not found or is not a dictionary.\")\n",
        "else:\n",
        "    # Call the function directly on the DataFrame\n",
        "    animal_rank_summary = get_animal_ranks(merged_df_all, rank_dict)\n",
        "\n",
        "    # Display the results\n",
        "    print(\"Animal Rank Summary per Participant:\")\n",
        "    display(animal_rank_summary.head())\n",
        "\n",
        "\n",
        "    # You can now merge this summary back into merged_df_all if needed\n",
        "    # For example:\n",
        "    # merged_df_all = pd.merge(merged_df_all, animal_rank_summary, on='participant', how='left')\n",
        "    # print(\"\\nMerged DataFrame with Animal Rank Summary:\")\n",
        "    # display(merged_df_all.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dUl4HQthCLoH"
      },
      "source": [
        "t-SNE Projection of Word Vectors with Exploration and Exploitation Centroids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Z2OKruFXDil"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "def plot_word_vectors_with_phases(participant_data, scaling_factor=80):\n",
        "    \"\"\"\n",
        "    Plots word vectors and phase centroids projected onto a 2D plane with\n",
        "    sequence arrows, sequence numbers, cluster names, and similarity circles.\n",
        "\n",
        "    Parameters:J\n",
        "        - 'participant': str, participant identifier.\n",
        "        - 'items': list of str, unique animal names.\n",
        "        - 'vectors': list of list or np.array, word vectors.\n",
        "        - 'phase_centroids_exploitation': list of tuples (vector, 'cluster_name')\n",
        "        - 'phase_centroids_exploration': list of tuples (vector, 'cluster_name')\n",
        "        - 'intra_phase_mean_exploitation': float\n",
        "        - 'inter_phase_mean_exploitation': float\n",
        "        - 'intra_phase_variance_exploitation': float\n",
        "        - 'inter_phase_variance_exploitation': float\n",
        "        - 'intra_phase_mean_exploration': float\n",
        "        - 'inter_phase_mean_exploration': float\n",
        "        - 'intra_phase_variance_exploration': float\n",
        "        - 'inter_phase_variance_exploration': float\n",
        "        - 'word_chains': list of str, sequence of words (optional, ignored in this implementation)\n",
        "    - scaling_factor: float, factor to scale the circle radii based on similarity.\n",
        "    \"\"\"\n",
        "    # Extract participant info\n",
        "    # print(f'participant_data={participant_data}')\n",
        "    participant_id = participant_data.get('participant', 'Unknown')\n",
        "    items = participant_data.get('items', [])\n",
        "    vectors = participant_data.get('vectors', [])\n",
        "    centroids_exploitation = participant_data.get('phase_centroids_exploitation', [])\n",
        "    centroids_exploration = participant_data.get('phase_centroids_exploration', [])\n",
        "\n",
        "    # Validate 'items' and 'vectors'\n",
        "    if not items or not vectors or len(items) != len(vectors):\n",
        "        print(f\"Participant {participant_id}: 'items' and 'vectors' are missing or not aligned. Skipping plot.\")\n",
        "        return\n",
        "\n",
        "    vectors = np.array(vectors)\n",
        "    num_words = vectors.shape[0]\n",
        "\n",
        "    if num_words < 2:\n",
        "        print(f\"Participant {participant_id}: Not enough word vectors to plot.\")\n",
        "        return\n",
        "\n",
        "    # 1. Combine word vectors and centroid vectors for t-SNE\n",
        "    combined_vectors = vectors.copy()\n",
        "    centroid_labels = []  # To keep track of centroids and their phases\n",
        "\n",
        "    # Function to extract centroid vectors and labels\n",
        "    def extract_centroids(centroid_list, phase_type):\n",
        "        for centroid in centroid_list:\n",
        "            vector, cluster_name = centroid\n",
        "            combined_vectors = np.array(vector).reshape(1, -1)\n",
        "            centroid_labels.append((phase_type, cluster_name))\n",
        "            yield combined_vectors\n",
        "\n",
        "    # Extract exploitation centroids\n",
        "    exploitation_centroid_vectors = list(extract_centroids(centroids_exploitation, 'Exploitation'))\n",
        "\n",
        "    # Extract exploration centroids\n",
        "    exploration_centroid_vectors = list(extract_centroids(centroids_exploration, 'Exploration'))\n",
        "\n",
        "    # Combine all centroid vectors\n",
        "    if exploitation_centroid_vectors or exploration_centroid_vectors:\n",
        "        all_centroid_vectors = np.vstack(exploitation_centroid_vectors + exploration_centroid_vectors)\n",
        "        combined_vectors = np.vstack([vectors, all_centroid_vectors])\n",
        "    else:\n",
        "        all_centroid_vectors = np.array([])\n",
        "\n",
        "    # 2. Perform t-SNE on combined vectors\n",
        "    perplexity = min(30, max(5, num_words // 2))\n",
        "    tsne = TSNE(n_components=2, random_state=42, perplexity=perplexity)\n",
        "    vectors_2d = tsne.fit_transform(combined_vectors)\n",
        "\n",
        "    # 3. Separate word coordinates and centroid coordinates\n",
        "    word_vectors_2d = vectors_2d[:num_words]\n",
        "    centroid_vectors_2d = vectors_2d[num_words:] if all_centroid_vectors.size else np.array([])\n",
        "\n",
        "    # Create a mapping from item to its 2D coordinates\n",
        "    item_coords = {item: word_vectors_2d[i] for i, item in enumerate(items)}\n",
        "\n",
        "    # Create a list of centroid names and their 2D coordinates\n",
        "    centroid_names = [label for _, label in centroid_labels]\n",
        "    centroid_phases = [phase for phase, _ in centroid_labels]\n",
        "    # centroid_vectors_2d is already a numpy array\n",
        "\n",
        "    # 4. Assign sequence numbers based on 'items' list\n",
        "    sequence_numbers = {word: idx+1 for idx, word in enumerate(items)}\n",
        "\n",
        "    # 5. Initialize plot\n",
        "    plt.figure(figsize=(18, 12))\n",
        "\n",
        "    # Plot word points\n",
        "    plt.scatter(word_vectors_2d[:, 0], word_vectors_2d[:, 1], c='lightgray', s=250, zorder=5, label='Words')\n",
        "\n",
        "    # Annotate words with sequence numbers\n",
        "    for i, item in enumerate(items):\n",
        "        seq_num = sequence_numbers.get(item, '')\n",
        "        plt.annotate(f\"{seq_num}. {item}\",\n",
        "                     (word_vectors_2d[i, 0], word_vectors_2d[i, 1]),\n",
        "                     fontsize=10, ha='center', va='center', zorder=6,\n",
        "                     bbox=dict(facecolor='white', alpha=0.7, edgecolor='none', pad=1))\n",
        "\n",
        "    # 6. Define colors for phases\n",
        "    phase_colors = {'Exploitation': 'blue', 'Exploration': 'green'}\n",
        "\n",
        "    # 7. Plot Centroids\n",
        "    if centroid_vectors_2d.size > 0:\n",
        "        for idx, (phase, cluster_name) in enumerate(zip(centroid_phases, centroid_names)):\n",
        "            centroid_coord = centroid_vectors_2d[idx]\n",
        "\n",
        "            # Plot centroid\n",
        "            plt.scatter(centroid_coord[0], centroid_coord[1],\n",
        "                        c=phase_colors.get(phase, 'red'),\n",
        "                        s=400, marker='X', edgecolor='black', zorder=7)\n",
        "\n",
        "            # Annotate centroid with cluster name, offset for readability\n",
        "            plt.annotate(cluster_name,\n",
        "                         (centroid_coord[0], centroid_coord[1]),\n",
        "                         fontsize=12, ha='center', va='center', color='white',\n",
        "                         bbox=dict(facecolor=phase_colors.get(phase, 'blue'), alpha=0.8, edgecolor='none', pad=1),\n",
        "                         zorder=8)\n",
        "\n",
        "            # Draw circle around centroid using intra-phase mean and variance\n",
        "            if phase == 'Exploitation':\n",
        "                radius = participant_data.get('intra_phase_mean_exploitation', 0.5) * scaling_factor\n",
        "                alpha = max(0.3, 1 - participant_data.get('intra_phase_variance_exploitation', 0.1))\n",
        "            else:\n",
        "                radius = participant_data.get('intra_phase_mean_exploration', 0.5) * scaling_factor\n",
        "                alpha = max(0.3, 1 - participant_data.get('intra_phase_variance_exploration', 0.1))\n",
        "\n",
        "            circle = plt.Circle((centroid_coord[0], centroid_coord[1]), radius=radius,\n",
        "                                color=phase_colors.get(phase, 'green'),\n",
        "                                fill=False, linewidth=2, alpha=alpha, zorder=6)\n",
        "            plt.gca().add_patch(circle)\n",
        "\n",
        "    # 8. Add Legend for Centroids\n",
        "    handles = []\n",
        "    labels = []\n",
        "    if centroids_exploitation:\n",
        "        handles.append(plt.Line2D([0], [0], marker='X', color='w', label='Exploitation Cluster',\n",
        "                                  markerfacecolor=phase_colors['Exploitation'], markersize=10))\n",
        "        labels.append('Exploitation Cluster')\n",
        "    if centroids_exploration:\n",
        "        handles.append(plt.Line2D([0], [0], marker='X', color='w', label='Exploration Cluster',\n",
        "                                  markerfacecolor=phase_colors['Exploration'], markersize=10))\n",
        "        labels.append('Exploration Cluster')\n",
        "    if handles:\n",
        "        plt.legend(handles, labels, fontsize=12, loc='upper right')\n",
        "\n",
        "    # 9. Draw Arrows to Indicate Sequence\n",
        "    for i in range(len(items) - 1):\n",
        "        word_start = items[i]\n",
        "        word_end = items[i + 1]\n",
        "\n",
        "        if word_start not in item_coords or word_end not in item_coords:\n",
        "            continue  # Skip if words are missing\n",
        "\n",
        "        start_coord = item_coords[word_start]\n",
        "        end_coord = item_coords[word_end]\n",
        "\n",
        "        # Draw arrow\n",
        "        plt.annotate(\"\",\n",
        "                     xy=(end_coord[0], end_coord[1]),\n",
        "                     xytext=(start_coord[0], start_coord[1]),\n",
        "                     arrowprops=dict(arrowstyle=\"->\", color='gray', alpha=0.5, lw=1),\n",
        "                     zorder=4)\n",
        "\n",
        "    # 10. Final Plot Adjustments\n",
        "    plt.title(f\"Word Vector Projections for Participant: {participant_id}\", fontsize=20)\n",
        "    plt.xlabel(\"t-SNE Component 1\", fontsize=16)\n",
        "    plt.ylabel(\"t-SNE Component 2\", fontsize=16)\n",
        "    plt.grid(True, linestyle='--', alpha=0.5)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "participant_PD00020 = results_df.loc[results_df['participant'] == 'PD00020']\n",
        "for index, row in results_df.iterrows():\n",
        "    # Convert the row to a dictionary\n",
        "    participant_data = row.to_dict()\n",
        "\n",
        "    # Now, pass the properly structured dictionary to the plotting function\n",
        "    plot_word_vectors_with_phases(participant_data, scaling_factor=80)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Distribution of Phase Centroid Norms by Phase Type"
      ],
      "metadata": {
        "id": "5l8pK8huqHCU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wanJ0F_Jca-s"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Assuming 'merged_df_all' is available and contains phase centroid columns\n",
        "\n",
        "# Check if merged_df_all is available and has the necessary columns\n",
        "required_cols = [\n",
        "    'phase_centroids_exploitation',\n",
        "    'phase_centroids_exploration',\n",
        "    'phase_centroids_norms_exploitation',\n",
        "    'phase_centroids_norms_exploration',\n",
        "    'participant' # Ensure participant is also present for potential grouping/identification\n",
        "]\n",
        "\n",
        "if 'merged_df_all' not in locals() or not isinstance(merged_df_all, pd.DataFrame):\n",
        "    print(\"Error: 'merged_df_all' DataFrame not found or is not a DataFrame.\")\n",
        "elif not all(col in merged_df_all.columns for col in required_cols):\n",
        "    missing = [col for col in required_cols if col not in merged_df_all.columns]\n",
        "    print(f\"Error: Required columns not found in 'merged_df_all': {missing}\")\n",
        "else:\n",
        "    # Extract centroid norms for plotting\n",
        "    # Flatten the list of lists of norms for exploitation and exploration phases\n",
        "    all_exploitation_norms = [norm for norms_list in merged_df_all['phase_centroids_norms_exploitation'] for norm in norms_list]\n",
        "    all_exploration_norms = [norm for norms_list in merged_df_all['phase_centroids_norms_exploration'] for norm in norms_list]\n",
        "\n",
        "    # Create a DataFrame for plotting\n",
        "    plot_data = pd.DataFrame({\n",
        "        'Norm': all_exploitation_norms + all_exploration_norms,\n",
        "        'Phase Type': ['Exploitation'] * len(all_exploitation_norms) + ['Exploration'] * len(all_exploration_norms)\n",
        "    })\n",
        "\n",
        "    # Plotting distribution of centroid norms\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.histplot(data=plot_data, x='Norm', hue='Phase Type', kde=True, palette={'Exploitation': 'salmon', 'Exploration': 'skyblue'})\n",
        "    plt.title('Distribution of Phase Centroid Norms')\n",
        "    plt.xlabel('Centroid Norm (Magnitude)')\n",
        "    plt.ylabel('Frequency')\n",
        "    plt.show()\n",
        "\n",
        "    # Optional: Plotting mean norms per participant (requires aggregating norms per participant first)\n",
        "    # Example: Calculate mean norm per participant and phase type\n",
        "    # participant_norms = []\n",
        "    # for index, row in merged_df_all.iterrows():\n",
        "    #     participant_id = row['participant']\n",
        "    #     mean_exploit_norm = np.mean(row['phase_centroids_norms_exploitation']) if row['phase_centroids_norms_exploitation'] else np.nan\n",
        "    #     mean_explore_norm = np.mean(row['phase_centroids_norms_exploration']) if row['phase_centroids_norms_exploration'] else np.nan\n",
        "    #     participant_norms.append({'participant': participant_id, 'Mean Norm': mean_exploit_norm, 'Phase Type': 'Exploitation'})\n",
        "    #     participant_norms.append({'participant': participant_id, 'Mean Norm': mean_explore_norm, 'Phase Type': 'Exploration'})\n",
        "    #\n",
        "    # participant_norms_df = pd.DataFrame(participant_norms).dropna()\n",
        "    #\n",
        "    # plt.figure(figsize=(12, 6))\n",
        "    # sns.boxplot(data=participant_norms_df, x='Phase Type', y='Mean Norm', palette={'Exploitation': 'salmon', 'Exploration': 'skyblue'})\n",
        "    # plt.title('Mean Phase Centroid Norms per Participant by Phase Type')\n",
        "    # plt.ylabel('Mean Centroid Norm')\n",
        "    # plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Intra- and Inter-Phase Cosine Similarity Analysis"
      ],
      "metadata": {
        "id": "sdCrutCBqRzv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TPx7IA43-8vM"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def plot_similarity_distributions_per_participant(df):\n",
        "    \"\"\"\n",
        "    Plot intra-phase and inter-phase similarity distributions for each participant.\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): DataFrame containing analysis results, including\n",
        "                          'intra_phase_similarities_exploitation',\n",
        "                          'intra_phase_similarities_exploration',\n",
        "                          'inter_phase_similarities_exploitation',\n",
        "                          'inter_phase_similarities_exploration',\n",
        "                          and 'participant' columns.\n",
        "    \"\"\"\n",
        "\n",
        "    # Check if required columns exist\n",
        "    required_cols = [\n",
        "        'intra_phase_similarities_exploitation',\n",
        "        'intra_phase_mean_exploitation_proximity', # Use the merged column name\n",
        "        'intra_phase_variance_exploitation_proximity', # Use the merged column name\n",
        "        'intra_phase_similarities_exploration',\n",
        "        'intra_phase_mean_exploration_proximity', # Use the merged column name\n",
        "        'intra_phase_variance_exploration_proximity', # Use the merged column name\n",
        "        'inter_phase_similarities_consecutive',  # Use the merged column name for consecutive inter-phase sims\n",
        "        'inter_phase_mean_consecutive', # Use the merged column name\n",
        "        'inter_phase_variance_consecutive', # Use the merged column name\n",
        "        'participant'\n",
        "    ]\n",
        "\n",
        "    if not all(col in df.columns for col in required_cols):\n",
        "        missing = [col for col in required_cols if col not in df.columns]\n",
        "        print(f\"Error: Required columns not found in the DataFrame: {missing}\")\n",
        "        print(\"Please ensure the phase proximity calculations (cell g6l6nQnTB7I9) have been run and merged.\")\n",
        "        return\n",
        "\n",
        "    # Iterate over each participant in the provided DataFrame\n",
        "    for idx, row in df.iterrows():\n",
        "        participant = row['participant']\n",
        "        print(f\"\\nPlotting for Participant: {participant}\")\n",
        "\n",
        "        # -------------------------\n",
        "        # 1. Intra-Phase Exploitation\n",
        "        # -------------------------\n",
        "        # Access the lists directly from the row, using the correct merged column names\n",
        "        intra_exploit_sims_list_of_lists = row['intra_phase_similarities_exploitation']\n",
        "        exploit_data = []\n",
        "        # The structure is now a list of (list_of_sims, 'Phase Name') tuples\n",
        "        for sim_list, phase_name in intra_exploit_sims_list_of_lists:\n",
        "            exploit_data.extend([(phase_name, sim) for sim in sim_list])\n",
        "\n",
        "        if not exploit_data:\n",
        "            print(f\"No intra-phase exploitation data for {participant}. Skipping plot.\")\n",
        "            continue\n",
        "\n",
        "        exploit_df = pd.DataFrame(exploit_data, columns=['Phase', 'Similarity'])\n",
        "\n",
        "        # Use the pre-calculated means and variances from the merged DataFrame\n",
        "        intra_exploit_mean = row['intra_phase_mean_exploitation_proximity']\n",
        "        intra_exploit_variance = row['intra_phase_variance_exploitation_proximity']\n",
        "\n",
        "\n",
        "        # -------------------------\n",
        "        # 2. Intra-Phase Exploration\n",
        "        # -------------------------\n",
        "        intra_explore_sims_list_of_lists = row['intra_phase_similarities_exploration']\n",
        "        explore_data = []\n",
        "        for sim_list, phase_name in intra_explore_sims_list_of_lists:\n",
        "             explore_data.extend([(phase_name, sim) for sim in sim_list])\n",
        "\n",
        "        if not explore_data:\n",
        "            print(f\"No intra-phase exploration data for {participant}. Skipping plot.\")\n",
        "            continue\n",
        "\n",
        "        explore_df = pd.DataFrame(explore_data, columns=['Phase', 'Similarity'])\n",
        "\n",
        "        # Use the pre-calculated means and variances\n",
        "        intra_explore_mean = row['intra_phase_mean_exploration_proximity']\n",
        "        intra_explore_variance = row['intra_phase_variance_exploration_proximity']\n",
        "\n",
        "\n",
        "        # -------------------------\n",
        "        # 3. Inter-Phase Similarities (Consecutive Centroids)\n",
        "        # -------------------------\n",
        "        # Use the merged column name for consecutive inter-phase similarities\n",
        "        inter_sims_consecutive_list = row['inter_phase_similarities_consecutive'] # List of tuples (sim, 'Pair Name')\n",
        "\n",
        "        if not inter_sims_consecutive_list:\n",
        "            print(f\"No inter-phase consecutive similarity data for {participant}. Skipping plot.\")\n",
        "            continue\n",
        "\n",
        "        inter_consecutive_df = pd.DataFrame(inter_sims_consecutive_list, columns=['Similarity', 'Pair'])\n",
        "\n",
        "        # Use the pre-calculated means and variances\n",
        "        inter_mean_consecutive = row['inter_phase_mean_consecutive']\n",
        "        inter_variance_consecutive = row['inter_phase_variance_consecutive']\n",
        "\n",
        "\n",
        "        # -------------------------\n",
        "        # 4. Plotting\n",
        "        # -------------------------\n",
        "        fig, axs = plt.subplots(1, 3, figsize=(25, 8)) # Adjusted to 1 row, 3 columns\n",
        "        fig.suptitle(f'Similarity Distributions for Participant {participant}', fontsize=20)\n",
        "\n",
        "        # Helper function to plot each category\n",
        "        def plot_category(ax, data_df, x_col, y_col, title, color_palette, mean_val, variance_val, is_inter=False):\n",
        "            if data_df.empty:\n",
        "                ax.text(0.5, 0.5, 'No Data', horizontalalignment='center', verticalalignment='center', fontsize=12, color='gray')\n",
        "                ax.set_title(title, fontsize=16)\n",
        "                ax.axis('off')\n",
        "                return\n",
        "\n",
        "            sns.barplot(\n",
        "                x=x_col,\n",
        "                y=y_col,\n",
        "                hue=x_col,  # Assign hue to the same as x to apply palette per category\n",
        "                data=data_df,\n",
        "                palette=color_palette,\n",
        "                ax=ax,\n",
        "                legend=False # Remove legend from subplot\n",
        "            )\n",
        "            ax.set_title(title, fontsize=16)\n",
        "            ax.set_xlabel(x_col, fontsize=14)\n",
        "            ax.set_ylabel('Average Cosine Similarity', fontsize=14)\n",
        "            if not is_inter: # Only rotate x-ticks for intra-phase plots\n",
        "                ax.tick_params(axis='x', labelrotation=45, labelsize=12) # Use labelrotation\n",
        "            else:\n",
        "                 ax.tick_params(axis='x', labelrotation=45, labelsize=10) # Use labelrotation\n",
        "\n",
        "\n",
        "            # Add mean and variance annotation\n",
        "            if not np.isnan(mean_val):\n",
        "                 textstr = f'Mean: {mean_val:.2f}\\nVar: {variance_val:.2f}'\n",
        "                 props = dict(boxstyle='round', facecolor='white', alpha=0.8, edgecolor='gray')\n",
        "                 ax.text(0.95, 0.95, textstr, transform=ax.transAxes, fontsize=12,\n",
        "                         verticalalignment='top', horizontalalignment='right', bbox=props)\n",
        "\n",
        "\n",
        "        # Plot Intra-Phase Exploitation\n",
        "        plot_category(\n",
        "            ax=axs[0],\n",
        "            data_df=exploit_df.groupby('Phase')['Similarity'].mean().reset_index(name='Mean_Similarity'),\n",
        "            x_col='Phase',\n",
        "            y_col='Mean_Similarity',\n",
        "            title='Intra-Phase Exploitation Similarities',\n",
        "            color_palette='Blues_d',\n",
        "            mean_val=intra_exploit_mean,\n",
        "            variance_val=intra_exploit_variance\n",
        "        )\n",
        "\n",
        "        # Plot Intra-Phase Exploration\n",
        "        plot_category(\n",
        "            ax=axs[1],\n",
        "            data_df=explore_df.groupby('Phase')['Similarity'].mean().reset_index(name='Mean_Similarity'),\n",
        "            x_col='Phase',\n",
        "            y_col='Mean_Similarity',\n",
        "            title='Intra-Phase Exploration Similarities',\n",
        "            color_palette='Reds_d',\n",
        "            mean_val=intra_explore_mean,\n",
        "            variance_val=intra_explore_variance\n",
        "        )\n",
        "\n",
        "        # Plot Inter-Phase Similarities (Consecutive)\n",
        "        plot_category(\n",
        "            ax=axs[2],\n",
        "            data_df=inter_consecutive_df, # Use the df directly for inter-phase\n",
        "            x_col='Pair',\n",
        "            y_col='Similarity', # Use Similarity directly as it's already the value\n",
        "            title='Inter-Phase Similarities (Consecutive)',\n",
        "            color_palette='Greens_d',\n",
        "            mean_val=inter_mean_consecutive,\n",
        "            variance_val=inter_variance_consecutive,\n",
        "            is_inter=True\n",
        "        )\n",
        "\n",
        "\n",
        "        plt.tight_layout(rect=[0, 0.03, 1, 0.95])  # Adjust layout to accommodate the suptitle\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "# Example usage for participant PD00020 - Now call with the full merged_df_all\n",
        "# Filter merged_df_all to only include PD00020 for this specific plot\n",
        "participant_PD00020_df = merged_df_all.loc[merged_df_all['participant'] == 'PD00020'].copy()\n",
        "\n",
        "# Call the plotting function with the filtered DataFrame\n",
        "plot_similarity_distributions_per_participant(participant_PD00020_df)\n",
        "\n",
        "# You can call this function for other participants by filtering merged_df_all\n",
        "# For example:\n",
        "# participant_PD00048_df = merged_df_all.loc[merged_df_all['participant'] == 'PD00048'].copy()\n",
        "# plot_similarity_distributions_per_participant(participant_PD00048_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q5smUTFuL6aP"
      },
      "source": [
        "**Plots for the clustering data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QFL6Nd0PD7gJ",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "# Sort the DataFrame by participant IDs for consistent ordering\n",
        "# results_df = results_df.sort_values('participant')\n",
        "\n",
        "# Extract data\n",
        "participants = results_df['participant']\n",
        "exploitation = results_df['exploitation_percentage']\n",
        "exploration = results_df['exploration_percentage']\n",
        "print(f'participant={participants}')\n",
        "print(f'exploitation_percentage: {exploitation}')\n",
        "print(f'exploration_percentage: {exploration}')\n",
        "\n",
        "# Set up the bar plot\n",
        "bar_width = 0.35\n",
        "index = np.arange(len(participants))\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(14, 7))\n",
        "\n",
        "# Plot exploitation percentages\n",
        "ax.bar(index, exploitation, bar_width, label='Exploitation', color='skyblue')\n",
        "\n",
        "# Plot exploration percentages next to exploitation\n",
        "ax.bar(index + bar_width, exploration, bar_width, label='Exploration', color='salmon')\n",
        "\n",
        "# Set labels and title\n",
        "ax.set_xlabel('Participant ID')\n",
        "ax.set_ylabel('Percentage')\n",
        "ax.set_title('Exploitation and Exploration Percentages per Participant')\n",
        "ax.set_xticks(index + bar_width / 2)\n",
        "ax.set_xticklabels(participants, rotation=90)\n",
        "ax.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# Plot Average Similarity\n",
        "plt.figure(figsize=(14, 6))\n",
        "\n",
        "plt.plot(results_df['participant'], results_df['avg_similarity'], marker='o', linestyle='-', color='purple')\n",
        "\n",
        "plt.xlabel('Participant ID')\n",
        "plt.ylabel('Average Similarity')\n",
        "plt.title('Average Similarity per Participant')\n",
        "plt.xticks(rotation=90)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# Plot Number of Phases\n",
        "plt.figure(figsize=(14, 6))\n",
        "\n",
        "plt.scatter(results_df['participant'], results_df['num_phases'], color='green')\n",
        "\n",
        "plt.xlabel('Participant ID')\n",
        "plt.ylabel('Number of Phases')\n",
        "plt.title('Number of Phases per Participant')\n",
        "plt.xticks(rotation=90)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# Plot Exploitation and Exploration Times\n",
        "exploitation_time = results_df['exploitation_time']\n",
        "exploration_time = results_df['exploration_time']\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(14, 7))\n",
        "\n",
        "# Plot exploitation times\n",
        "ax.bar(index, exploitation_time, bar_width, label='Exploitation Time', color='skyblue')\n",
        "\n",
        "# Plot exploration times next to exploitation times\n",
        "ax.bar(index + bar_width, exploration_time, bar_width, label='Exploration Time', color='salmon')\n",
        "\n",
        "# Set labels and title\n",
        "ax.set_xlabel('Participant ID')\n",
        "ax.set_ylabel('Time (Number of Items)')\n",
        "ax.set_title('Exploitation and Exploration Times per Participant')\n",
        "ax.set_xticks(index + bar_width / 2)\n",
        "ax.set_xticklabels(participants, rotation=90)\n",
        "ax.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# Plot Novelty Ratios\n",
        "plt.figure(figsize=(14, 6))\n",
        "\n",
        "sns.boxplot(x='participant', y='novelty_ratio', data=results_df)\n",
        "\n",
        "plt.xlabel('Participant ID')\n",
        "plt.ylabel('Novelty Ratio')\n",
        "plt.title('Novelty Ratios per Participant')\n",
        "plt.xticks(rotation=90)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# Combined Subplots\n",
        "fig, axs = plt.subplots(2, 1, figsize=(14, 12))\n",
        "\n",
        "# Subplot 1: Exploitation and Exploration Percentages\n",
        "axs[0].bar(index, exploitation, bar_width, label='Exploitation %', color='skyblue')\n",
        "axs[0].bar(index + bar_width, exploration, bar_width, label='Exploration %', color='salmon')\n",
        "axs[0].set_xlabel('Participant ID')\n",
        "axs[0].set_ylabel('Percentage')\n",
        "axs[0].set_title('Exploitation and Exploration Percentages per Participant')\n",
        "axs[0].set_xticks(index + bar_width / 2)\n",
        "axs[0].set_xticklabels(participants, rotation=90)\n",
        "axs[0].legend()\n",
        "\n",
        "# Subplot 2: Average Similarity\n",
        "axs[1].plot(participants, results_df['avg_similarity'], marker='o', linestyle='-', color='purple')\n",
        "axs[1].set_xlabel('Participant ID')\n",
        "axs[1].set_ylabel('Average Similarity')\n",
        "axs[1].set_title('Average Similarity per Participant')\n",
        "axs[1].set_xticks(participants)\n",
        "axs[1].set_xticklabels(participants, rotation=90)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# General Data Views\n",
        "\n",
        "# Assuming you have 'correlations' DataFrame/matrix\n",
        "# If not, compute it:\n",
        "\n",
        "plt.figure(figsize=(14, 6))\n",
        "\n",
        "# Ratios and Percentages\n",
        "ratios = [results_df['exploitation_time'].mean(), results_df['exploration_time'].mean()]\n",
        "percentages = [results_df['exploitation_percentage'].mean(), results_df['exploration_percentage'].mean()]\n",
        "phases_ratios = [results_df['exploitation_time'].mean() / results_df['exploitation_time'].sum(),\n",
        "                 results_df['exploration_time'].mean() / results_df['exploration_time'].sum()]\n",
        "labels = ['Exploitation', 'Exploration']\n",
        "\n",
        "# Create subplots\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
        "\n",
        "# Plot 1: Ratios\n",
        "axes[0].bar(labels, ratios, color=['skyblue', 'salmon'])\n",
        "axes[0].set_title('Group-Level Ratios')\n",
        "axes[0].set_ylabel('Ratio')\n",
        "axes[0].set_ylim(0, 1)\n",
        "\n",
        "# Plot 2: Percentages\n",
        "axes[1].bar(labels, percentages, color=['skyblue', 'salmon'])\n",
        "axes[1].set_title('Group-Level Percentages')\n",
        "axes[1].set_ylabel('Percentage')\n",
        "axes[1].set_ylim(0, 100)\n",
        "\n",
        "# Plot 3: Phases Ratios\n",
        "axes[2].bar(labels, phases_ratios, color=['skyblue', 'salmon'])\n",
        "axes[2].set_title('Group-Level Phases Ratios')\n",
        "axes[2].set_ylabel('Ratio')\n",
        "axes[2].set_ylim(0, 1)\n",
        "\n",
        "plt.suptitle('Group-Level Exploitation and Exploration Metrics', fontsize=16)\n",
        "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# Correlation Matrix Heatmap\n",
        "import seaborn as sns\n",
        "\n",
        "plt.figure(figsize=(12, 10))\n",
        "sns.heatmap(correlations, annot=True, fmt=\".2f\", cmap='coolwarm', square=True)\n",
        "plt.title('Correlation Matrix Heatmap', fontsize=16)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# Scatter Matrix\n",
        "from pandas.plotting import scatter_matrix\n",
        "\n",
        "# Select key variables\n",
        "key_variables = [\n",
        "    'num_items', 'avg_similarity', 'num_phases',\n",
        "    'exploitation_percentage', 'exploration_percentage', 'novelty_ratio'\n",
        "]\n",
        "\n",
        "# Create scatter matrix\n",
        "scatter_matrix(results_df[key_variables], figsize=(12, 12), diagonal='kde', alpha=0.7)\n",
        "\n",
        "plt.suptitle('Scatter Matrix of Key Variables', fontsize=16)\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Distribution of Mean Similarities\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Extract mean similarities\n",
        "intra_means = results_df['intra_phase_mean_exploitation']\n",
        "inter_means = results_df['inter_phase_mean_exploitation']\n",
        "\n",
        "# Plot density plots\n",
        "sns.kdeplot(intra_means, shade=True, color='blue', label='Exploitation Intra-Phase Mean Similarity')\n",
        "sns.kdeplot(inter_means, shade=True, color='green', label='Exploitation Inter-Phase Mean Similarity')\n",
        "\n",
        "plt.title('Distribution of Intra-Phase and Inter-Phase Mean Exploitation Similarities', fontsize=16)\n",
        "plt.xlabel('Mean Similarity')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# Combined Subplots\n",
        "fig, axs = plt.subplots(2, 2, figsize=(18, 12))\n",
        "\n",
        "# Subplot 1: Combined Bar Plot\n",
        "axs[0, 0].bar(labels, ratios, color=['skyblue', 'salmon'], alpha=0.7, label='Ratios')\n",
        "axs[0, 0].bar(labels, percentages, color=['navy', 'darkred'], alpha=0.5, label='Percentages')\n",
        "axs[0, 0].set_title('Group-Level Ratios and Percentages', fontsize=14)\n",
        "axs[0, 0].set_ylabel('Value')\n",
        "axs[0, 0].legend()\n",
        "\n",
        "# Subplot 2: Heatmap\n",
        "sns.heatmap(correlations, annot=True, fmt=\".2f\", cmap='coolwarm', square=True, ax=axs[0, 1])\n",
        "axs[0, 1].set_title('Correlation Matrix Heatmap', fontsize=14)\n",
        "\n",
        "# Subplot 3: Overlaid Density Plot\n",
        "sns.kdeplot(intra_means, shade=True, color='blue', label='Intra-Phase', ax=axs[1, 0])\n",
        "sns.kdeplot(inter_means, shade=True, color='green', label='Inter-Phase', ax=axs[1, 0])\n",
        "axs[1, 0].set_title('Mean Similarity Distributions', fontsize=14)\n",
        "axs[1, 0].set_xlabel('Mean Similarity')\n",
        "axs[1, 0].legend()\n",
        "\n",
        "# Subplot 4: Scatter Plot (Exploitation % vs. Avg Similarity)\n",
        "sns.scatterplot(\n",
        "    data=results_df, x='exploitation_percentage', y='avg_similarity', ax=axs[1, 1], color='purple'\n",
        ")\n",
        "axs[1, 1].set_title('Exploitation Percentage vs. Average Similarity', fontsize=14)\n",
        "axs[1, 1].set_xlabel('Exploitation Percentage (%)')\n",
        "axs[1, 1].set_ylabel('Average Similarity')\n",
        "\n",
        "plt.suptitle('Summary of Analysis', fontsize=18)\n",
        "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# Additional Group-Level Plots\n",
        "\n",
        "# Group-Level Ratios\n",
        "ratios = [results_df['exploitation_time'].mean(), results_df['exploration_time'].mean()]\n",
        "labels = ['Exploitation Ratio', 'Exploration Ratio']\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.bar(labels, ratios, color=['skyblue', 'salmon'])\n",
        "plt.title('Group-Level Exploitation and Exploration Ratios')\n",
        "plt.ylabel('Ratio')\n",
        "plt.ylim(0, 1)\n",
        "plt.show()\n",
        "\n",
        "# Group-Level Percentages\n",
        "percentages = [results_df['exploitation_percentage'].mean(), results_df['exploration_percentage'].mean()]\n",
        "labels = ['Exploitation Percentage', 'Exploration Percentage']\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.bar(labels, percentages, color=['skyblue', 'salmon'])\n",
        "plt.title('Group-Level Exploitation and Exploration Percentages')\n",
        "plt.ylabel('Percentage')\n",
        "plt.ylim(0, 100)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# Correlation Matrix Heatmap\n",
        "plt.figure(figsize=(12, 10))\n",
        "sns.heatmap(correlations, annot=True, fmt=\".2f\", cmap='coolwarm')\n",
        "plt.title('Correlation Matrix Heatmap')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# Exploitation Percentage vs. Average Similarity\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.scatterplot(data=results_df, x='exploitation_percentage', y='avg_similarity')\n",
        "plt.title('Exploitation Percentage vs. Average Similarity')\n",
        "plt.xlabel('Exploitation Percentage (%)')\n",
        "plt.ylabel('Average Similarity')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# Number of Items vs. Number of Phases\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.scatterplot(data=results_df, x='num_items', y='num_phases')\n",
        "plt.title('Number of Items vs. Number of Phases')\n",
        "plt.xlabel('Number of Items')\n",
        "plt.ylabel('Number of Phases')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "CUht2cXSmjnD",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RHd-Oq8UxBXp"
      },
      "source": [
        "**Plot Inter/Intra cluster similarities**\n",
        "Plots the calculated permutations of all cosine scores between each other words in the phase"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J9QeeFQi9PuA"
      },
      "outputs": [],
      "source": [
        "# import numpy as np\n",
        "# import pandas as pd\n",
        "# import seaborn as sns\n",
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# # Group the flattened similarities per participant for intra- and inter-phase\n",
        "# grouped_intra_phase_sims = results_df.groupby('participant')['flattened_intra_phase_similarities_exploitation'].apply(list)\n",
        "# grouped_inter_phase_sims = results_df.groupby('participant')['flattened_inter_phase_similarities_exploitation'].apply(list)\n",
        "\n",
        "# # Define function to plot per participant\n",
        "# def plot_similarity_distributions_per_participant(grouped_df):\n",
        "#     for participant, intra_sims in grouped_df['flattened_intra_phase_similarities_exploitation'].items():\n",
        "#         inter_sims = grouped_df.loc[participant, 'flattened_inter_phase_similarities_exploitation']\n",
        "#         intra_mean = grouped_df.loc[participant, 'intra_phase_mean_exploitation']\n",
        "#         intra_variance = grouped_df.loc[participant, 'intra_phase_variance_exploitation']\n",
        "#         inter_mean = grouped_df.loc[participant, 'inter_phase_mean_exploitation']\n",
        "#         inter_variance = grouped_df.loc[participant, 'inter_phase_variance_exploitation']\n",
        "\n",
        "#         plt.figure(figsize=(14, 6))\n",
        "\n",
        "#         # Intra-Phase Similarity Plot\n",
        "#         plt.subplot(1, 2, 1)\n",
        "#         sns.histplot(intra_sims, kde=True, bins=10, color='skyblue')\n",
        "#         plt.title(\n",
        "#             f'Participant {participant}\\nIntra-Phase Similarities Exploitation\\n'\n",
        "#             f'Mean = {intra_mean:.2f}, Variance = {intra_variance:.2f}'\n",
        "#         )\n",
        "#         plt.xlabel('Cosine Similarity')\n",
        "#         plt.ylabel('Frequency')\n",
        "\n",
        "#         # Inter-Phase Similarity Plot\n",
        "#         plt.subplot(1, 2, 2)\n",
        "#         sns.histplot(inter_sims, kde=True, bins=10, color='salmon')\n",
        "#         plt.title(\n",
        "#             f'Participant {participant}\\nInter-Phase Similarities Exploitation\\n'\n",
        "#             f'Mean = {inter_mean:.2f}, Variance = {inter_variance:.2f}'\n",
        "#         )\n",
        "#         plt.xlabel('Cosine Similarity')\n",
        "#         plt.ylabel('Frequency')\n",
        "\n",
        "#         plt.tight_layout()\n",
        "#         plt.show()\n",
        "\n",
        "# # Call the function with the grouped data\n",
        "# plot_similarity_distributions_per_participant(results_df.set_index('participant'))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implementation of Traditional, SoftMax, and MVT Models for Semantic Verbal Fluency"
      ],
      "metadata": {
        "id": "seRs9nYeqiwh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wKEVaZnKD4rt"
      },
      "outputs": [],
      "source": [
        "# import numpy as np\n",
        "# import pandas as pd\n",
        "# import seaborn as sns\n",
        "# import matplotlib.pyplot as plt\n",
        "# import ast\n",
        "# def plot_similarity_distributions_group_level(merged_df):\n",
        "#     \"\"\"\n",
        "#     Generates a combined plot displaying Intra-Phase and Inter-Phase similarity distributions\n",
        "#     for all participants at the group level.\n",
        "\n",
        "#     Parameters:\n",
        "#     - merged_df (pd.DataFrame): DataFrame containing participants' similarity data,\n",
        "#                                 including columns merged from phase proximity analysis.\n",
        "\n",
        "#     The DataFrame is expected to have the following columns (potentially with _proximity suffix for means/variances):\n",
        "#         - 'participant': str, participant identifier.\n",
        "#         - 'intra_phase_similarities_exploitation': list, list of intra-phase similarities lists.\n",
        "#         - 'intra_phase_mean_exploitation_proximity': float, mean of intra-phase exploitation similarities.\n",
        "#         - 'intra_phase_variance_exploitation_proximity': float, variance of intra-phase exploitation similarities.\n",
        "#         - 'inter_phase_similarities_consecutive': list, list of consecutive inter-phase similarities tuples.\n",
        "#         - 'inter_phase_mean_consecutive': float, mean of consecutive inter-phase similarities.\n",
        "#         - 'inter_phase_variance_consecutive': float, variance of consecutive inter-phase similarities.\n",
        "#         # Add exploration phase columns if needed for future plotting\n",
        "#         # - 'intra_phase_similarities_exploration': list\n",
        "#         # - 'intra_phase_mean_exploration_proximity': float\n",
        "#         # - 'intra_phase_variance_exploration_proximity': float\n",
        "#     \"\"\"\n",
        "\n",
        "#     # Create copies to avoid SettingWithCopyWarning\n",
        "#     df = merged_df.copy()\n",
        "\n",
        "#     # Columns for plotting\n",
        "#     # Use the actual column names from the merged_df_all after proximity analysis\n",
        "#     intra_exploit_sims_col = 'intra_phase_similarities_exploitation'\n",
        "#     intra_exploit_mean_col = 'intra_phase_mean_exploitation_proximity'\n",
        "#     intra_exploit_variance_col = 'intra_phase_variance_exploitation_proximity'\n",
        "#     inter_consecutive_sims_col = 'inter_phase_similarities_consecutive' # Use consecutive inter-phase\n",
        "#     inter_consecutive_mean_col = 'inter_phase_mean_consecutive'\n",
        "#     inter_consecutive_variance_col = 'inter_phase_variance_consecutive'\n",
        "\n",
        "#     # Check if required columns exist\n",
        "#     required_cols = [\n",
        "#         intra_exploit_sims_col, intra_exploit_mean_col, intra_exploit_variance_col,\n",
        "#         inter_consecutive_sims_col, inter_consecutive_mean_col, inter_consecutive_variance_col,\n",
        "#         'participant'\n",
        "#     ]\n",
        "#     if not all(col in df.columns for col in required_cols):\n",
        "#         missing = [col for col in required_cols if col not in df.columns]\n",
        "#         print(f\"Error: Required columns not found in the DataFrame: {missing}\")\n",
        "#         print(\"Please ensure the phase proximity calculations (cell g6l6nQnTB7I9) have been run and merged into merged_df_all.\")\n",
        "#         return\n",
        "\n",
        "\n",
        "#     # Prepare data for plotting Intra-Phase Exploitation distributions\n",
        "#     intra_exploit_data = []\n",
        "#     for index, row in df.iterrows():\n",
        "#         participant = row['participant']\n",
        "#         # The structure is a list of (list_of_sims, 'Phase Name') tuples\n",
        "#         if row[intra_exploit_sims_col] is not None:\n",
        "#             for sim_list, phase_name in row[intra_exploit_sims_col]:\n",
        "#                  intra_exploit_data.extend([(participant, phase_name, sim) for sim in sim_list])\n",
        "\n",
        "#     if not intra_exploit_data:\n",
        "#         print(\"No intra-phase exploitation data available for plotting.\")\n",
        "#         intra_exploit_df_grouped = pd.DataFrame(columns=['participant', 'Phase', 'Mean_Similarity']) # Empty DataFrame\n",
        "#     else:\n",
        "#         intra_exploit_df_flat = pd.DataFrame(intra_exploit_data, columns=['participant', 'Phase', 'Similarity'])\n",
        "#         # Group by participant and phase to get mean similarity per phase\n",
        "#         intra_exploit_df_grouped = intra_exploit_df_flat.groupby(['participant', 'Phase'])['Similarity'].mean().reset_index(name='Mean_Similarity')\n",
        "\n",
        "\n",
        "#     # Prepare data for plotting Inter-Phase Consecutive distributions\n",
        "#     inter_consecutive_data = []\n",
        "#     for index, row in df.iterrows():\n",
        "#         participant = row['participant']\n",
        "#         # The structure is a list of (sim, 'Pair Name') tuples\n",
        "#         if row[inter_consecutive_sims_col] is not None:\n",
        "#             for sim, pair_name in row[inter_consecutive_sims_col]:\n",
        "#                  inter_consecutive_data.append((participant, pair_name, sim))\n",
        "\n",
        "#     if not inter_consecutive_data:\n",
        "#          print(\"No inter-phase consecutive similarity data available for plotting.\")\n",
        "#          inter_consecutive_df = pd.DataFrame(columns=['participant', 'Pair', 'Similarity']) # Empty DataFrame\n",
        "#     else:\n",
        "#         inter_consecutive_df = pd.DataFrame(inter_consecutive_data, columns=['participant', 'Pair', 'Similarity'])\n",
        "\n",
        "\n",
        "#     # Set the style\n",
        "#     sns.set(style=\"whitegrid\")\n",
        "\n",
        "#     # Initialize the matplotlib figure\n",
        "#     # Using 2 rows, 1 column to avoid too many bars in a single plot if many phases\n",
        "#     fig, axes = plt.subplots(2, 1, figsize=(20, 12), sharey=True) # Adjusted layout\n",
        "#     fig.suptitle('Phase Similarity Distributions Across Participants', fontsize=20, y=1.02)\n",
        "\n",
        "\n",
        "#     # Plot Intra-Phase Exploitation Mean Similarities per Phase per Participant\n",
        "#     if not intra_exploit_df_grouped.empty:\n",
        "#         sns.barplot(ax=axes[0], x='participant', y='Mean_Similarity', hue='Phase',\n",
        "#                     data=intra_exploit_df_grouped, palette='Blues_d', ci=None) # Use hue for phases within participant\n",
        "#         axes[0].set_title('Intra-Phase Exploitation Mean Similarities per Phase', fontsize=16)\n",
        "#         axes[0].set_xlabel('Participant', fontsize=14)\n",
        "#         axes[0].set_ylabel('Mean Cosine Similarity', fontsize=14)\n",
        "#         axes[0].tick_params(axis='x', rotation=45, ha='right', labelsize=10)\n",
        "#         axes[0].legend(title='Exploitation Phase', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "#     else:\n",
        "#          axes[0].text(0.5, 0.5, 'No Intra-Phase Exploitation Data', horizontalalignment='center', verticalalignment='center', fontsize=12, color='gray', transform=axes[0].transAxes)\n",
        "#          axes[0].set_title('Intra-Phase Exploitation Mean Similarities per Phase', fontsize=16)\n",
        "#          axes[0].set_xlabel('Participant', fontsize=14)\n",
        "#          axes[0].set_ylabel('Mean Cosine Similarity', fontsize=14)\n",
        "#          axes[0].tick_params(axis='x', rotation=45, ha='right', labelsize=10)\n",
        "\n",
        "\n",
        "#     # Plot Inter-Phase Consecutive Similarities per Pair per Participant\n",
        "#     if not inter_consecutive_df.empty:\n",
        "#         # Plotting each inter-phase similarity score as a point or a bar\n",
        "#         # Using a scatter plot with lines to show sequence might be better than a bar plot for many pairs\n",
        "#         # Let's use a scatter plot for simplicity, or a line plot if we can order by transition index\n",
        "#         # For simplicity, let's plot mean inter-phase similarity per participant as a bar\n",
        "#         inter_consecutive_mean_per_participant = df.groupby('participant')[inter_consecutive_mean_col].mean().reset_index(name='Mean_Similarity')\n",
        "\n",
        "#         sns.barplot(ax=axes[1], x='participant', y='Mean_Similarity',\n",
        "#                     data=inter_consecutive_mean_per_participant, palette='Reds_d', ci=None)\n",
        "#         # Add error bars for variance (standard deviation)\n",
        "#         # Need to calculate std of mean inter-phase similarity per participant\n",
        "#         inter_consecutive_std_per_participant = df.groupby('participant')[inter_consecutive_mean_col].std().reset_index(name='Std_Similarity')\n",
        "#         # Merge mean and std for error bars\n",
        "#         inter_plot_data = pd.merge(inter_consecutive_mean_per_participant, inter_consecutive_std_per_participant, on='participant')\n",
        "\n",
        "#         axes[1].errorbar(x=np.arange(len(inter_plot_data)),\n",
        "#                          y=inter_plot_data['Mean_Similarity'],\n",
        "#                          yerr=inter_plot_data['Std_Similarity'], # Using std of means here, or std of all inter-phase sims?\n",
        "#                          fmt='none', c='black', capsize=5)\n",
        "\n",
        "#         axes[1].set_title('Inter-Phase Consecutive Mean Similarities per Participant', fontsize=16)\n",
        "#         axes[1].set_xlabel('Participant', fontsize=14)\n",
        "#         axes[1].set_ylabel('Mean Cosine Similarity', fontsize=14)\n",
        "#         axes[1].tick_params(axis='x', rotation=45, ha='right', labelsize=10)\n",
        "#     else:\n",
        "#         axes[1].text(0.5, 0.5, 'No Inter-Phase Consecutive Data', horizontalalignment='center', verticalalignment='center', fontsize=12, color='gray', transform=axes[1].transAxes)\n",
        "#         axes[1].set_title('Inter-Phase Consecutive Mean Similarities per Participant', fontsize=16)\n",
        "#         axes[1].set_xlabel('Participant', fontsize=14)\n",
        "#         axes[1].set_ylabel('Mean Cosine Similarity', fontsize=14)\n",
        "#         axes[1].tick_params(axis='x', rotation=45, ha='right', labelsize=10)\n",
        "\n",
        "#     # Adjust layout\n",
        "#     plt.tight_layout(rect=[0, 0.03, 1, 0.98]) # Adjusted rect for suptitle\n",
        "#     plt.show()\n",
        "\n",
        "# # Call the function with merged_df_all\n",
        "# if 'merged_df_all' in locals() and isinstance(merged_df_all, pd.DataFrame):\n",
        "#     plot_similarity_distributions_group_level(merged_df_all)\n",
        "# else:\n",
        "#     print(\"Error: merged_df_all DataFrame is not available. Please run the preceding cells including the phase proximity analysis.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bPy7Ghq_HsbW"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "from scipy.optimize import minimize_scalar, minimize\n",
        "from scipy.stats import pearsonr, spearmanr\n",
        "import spacy\n",
        "import io\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set the style for plots\n",
        "plt.style.use('ggplot')\n",
        "sns.set_context(\"talk\")\n",
        "\n",
        "plt.rcParams['figure.figsize'] = (12, 8)\n",
        "plt.rcParams['font.size'] = 12\n",
        "plt.rcParams['svg.fonttype'] = 'none'  # Ensures text remains as text in SVG (not paths)\n",
        "\n",
        "# Load spaCy model for word vectors\n",
        "print(\"Loading spaCy model...\")\n",
        "nlp = spacy.load(\"en_core_web_md\")\n",
        "print(\"SpaCy model loaded successfully\")\n",
        "\n",
        "# Load the data\n",
        "def load_data():\n",
        "    \"\"\"\n",
        "    Load and prepare SVF data and MEG/LC data\n",
        "    \"\"\"\n",
        "    # Sample data string (replace with your actual data loading code)\n",
        "    data_str = '''ID,Item\n",
        "    PD00020,\"Lion,Tiger,Sheep,Dog,Cat,Camel,Monkey,Chimpanzee,Buffalo,Hyena,Dog,Cat,Elephant,Hyena,Dog,Cat,Mouse,Bird,Camel,Dragon\"\n",
        "    PD00048,\"Lion,Hare,Elephant,Rhinoceros,Monkey,Giraffe,Cow,Elk,Fish,Horse,Tiger,Leopard,Jaguar\"\n",
        "    PD00119,\"Lion,Tiger,Duck,Goose,Deer,Horse,Zebra,Elephant,Bird,Giraffe,Hippo,Crocodile,Elephant,Sheep,Goat,Ewe,Duck\"\n",
        "    PD00146,\"Dog,Pig,Chicken,Partridge,Swallow,Squirrel,Rabbit,Horse,Hare,Calf,Bull,Cow,Lion,Tiger,Monkey,Giraffe,Elephant,Snake,Frog,Shark,Whale,Dolphin\"\n",
        "    PD00215,\"Donkey,Horse,Cow,Ox,Elephant,Llama,Cat,Dog,Mouse,Tiger,Lion,Leopard,Cheetah,Hyena,Bear,Goat,Partridge,Hare,Manatee,Turtle,Iguana,Frog,Toad\"\n",
        "    '''\n",
        "\n",
        "    # Load the data into a DataFrame\n",
        "    compressed_data = pd.read_csv(io.StringIO(data_str))\n",
        "\n",
        "    # Expand the data\n",
        "    data = compressed_data.set_index('ID')['Item'].str.split(',', expand=True).stack().reset_index(level=1, drop=True).reset_index(name='Item')\n",
        "\n",
        "    # Preprocess the data\n",
        "    data['Item'] = data['Item'].str.lower()\n",
        "    data = data.dropna().reset_index(drop=True)\n",
        "\n",
        "    # Load the MEG PSD and LC data\n",
        "    meg_lc_data = pd.read_csv(io.StringIO('''\n",
        "    PD00020,0.005821693,PD,MRI01,1.14817625,1.158620797,1.044436934,1.016706475,1.153398524,1.030571705\n",
        "    PD00048,0.002184409,PD,MRI01,1.098492193,1.109323313,1.085092243,0.965901336,1.103907753,1.02549679\n",
        "    PD00146,0.005128224,PD,MRI01,1.12043934,1.125366723,1.041352235,1.026072416,1.122903032,1.033712326\n",
        "    PD00215,0.010895761,PD,MRI01,1.124369462,1.147340095,1.107812477,1.04618484,1.135854779,1.076998659\n",
        "    '''), header=None, names=['ID','alpha_NET_mean','status','visit','norm_SN_l','norm_SN_r','norm_LC_l','norm_LC_r','norm_SN_avg','norm_LC_avg'])\n",
        "\n",
        "    meg_lc_data = meg_lc_data[meg_lc_data['norm_SN_avg'].notna()]\n",
        "\n",
        "    # Remove 'PD' and leading zeros\n",
        "    clean_id = lambda x: str(int(x.replace('PD', '')))\n",
        "    data['clean_ID'] = data['ID'].apply(clean_id)\n",
        "    meg_lc_data['clean_ID'] = meg_lc_data['ID'].apply(clean_id)\n",
        "\n",
        "    print(f\"Loaded data for {len(data['ID'].unique())} participants with SVF data\")\n",
        "    print(f\"Loaded MEG/LC data for {len(meg_lc_data)} participants\")\n",
        "\n",
        "    return data, meg_lc_data\n",
        "\n",
        "# Function to calculate cosine similarity\n",
        "def cosine_similarity(vec1, vec2):\n",
        "    \"\"\"\n",
        "    Calculate cosine similarity between two vectors\n",
        "    \"\"\"\n",
        "    return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))\n",
        "\n",
        "# Function to identify exploitation and exploration phases\n",
        "def identify_phases(similarities, items, vectors, threshold):\n",
        "    \"\"\"\n",
        "    Identify exploitation and exploration phases based on similarity threshold\n",
        "    \"\"\"\n",
        "    if len(similarities) < 1:\n",
        "        return []\n",
        "    phases = []\n",
        "    current_phase = \"Exploitation\" if similarities[0] > threshold else \"Exploration\"\n",
        "    phase_start = 0\n",
        "\n",
        "    for i in range(1, len(similarities)):\n",
        "        if (current_phase == \"Exploitation\" and similarities[i] <= threshold) or \\\n",
        "           (current_phase == \"Exploration\" and similarities[i] > threshold):\n",
        "            phase = (current_phase, phase_start, i, items[phase_start:i+1], vectors[phase_start:i+1], similarities[phase_start:i+1])\n",
        "            phases.append(phase)\n",
        "\n",
        "            current_phase = \"Exploration\" if current_phase == \"Exploitation\" else \"Exploitation\"\n",
        "            phase_start = i\n",
        "\n",
        "    # Add the final phase\n",
        "    lastone = len(similarities)\n",
        "    phase = (current_phase, phase_start, lastone, items[phase_start:lastone+1], vectors[phase_start:lastone+1], similarities[phase_start:lastone+1])\n",
        "    phases.append(phase)\n",
        "\n",
        "    return phases\n",
        "\n",
        "# Function to analyze participant responses\n",
        "def analyze_responses(participant_data, threshold):\n",
        "    \"\"\"\n",
        "    Analyze participant's SVF responses using traditional phase identification\n",
        "    \"\"\"\n",
        "    participant = participant_data['participant']\n",
        "    items = participant_data['items']\n",
        "    vectors = participant_data['vectors']\n",
        "    similarities = participant_data['similarities']\n",
        "\n",
        "    # Identify phases based on threshold\n",
        "    phases = identify_phases(similarities, items, vectors, threshold)\n",
        "\n",
        "    # Perform hierarchical clustering\n",
        "    clustering = AgglomerativeClustering(n_clusters=None, distance_threshold=0.5)\n",
        "    clusters = clustering.fit_predict([vector for vector in vectors])\n",
        "\n",
        "    # Calculate novelty scores (new words vs. repetitions)\n",
        "    unique_items = set()\n",
        "    novelty_scores = []\n",
        "    for item in items:\n",
        "        if item not in unique_items:\n",
        "            novelty_scores.append(1)\n",
        "            unique_items.add(item)\n",
        "        else:\n",
        "            novelty_scores.append(0)\n",
        "\n",
        "    # Calculate phase statistics\n",
        "    num_switches = len(phases) - 1\n",
        "    exploitation_phase_size = [end - start for phase, start, end, words, vects, sims in phases if phase == \"Exploitation\"]\n",
        "    exploration_phase_size = [end - start for phase, start, end, words, vects, sims in phases if phase == \"Exploration\"]\n",
        "\n",
        "    # Calculate mean phase sizes\n",
        "    exploitation_mean_phase_size = np.mean(exploitation_phase_size) if exploitation_phase_size else 0\n",
        "    exploration_mean_phase_size = np.mean(exploration_phase_size) if exploration_phase_size else 0\n",
        "    mean_phase_size = np.mean(exploitation_phase_size + exploration_phase_size) if (exploitation_phase_size + exploration_phase_size) else 0\n",
        "\n",
        "    # Calculate exploration-exploitation tradeoff\n",
        "    ee_tradeoff = mean_phase_size / num_switches if num_switches > 0 else 0\n",
        "\n",
        "    # Calculate exploitation and exploration times\n",
        "    exploitation_time = sum(exploitation_phase_size)\n",
        "    exploration_time = sum(exploration_phase_size)\n",
        "    total_time = exploitation_time + exploration_time\n",
        "\n",
        "    # Calculate percentages\n",
        "    exploitation_percentage = (exploitation_time / total_time) * 100 if total_time > 0 else 0\n",
        "    exploration_percentage = (exploration_time / total_time) * 100 if total_time > 0 else 0\n",
        "\n",
        "    return {\n",
        "        'participant': participant,\n",
        "        'items': items,\n",
        "        'vectors': vectors,\n",
        "        'phases': phases,\n",
        "        'avg_similarity': np.mean(similarities) if similarities else 0,\n",
        "        'novelty_scores': novelty_scores,\n",
        "        'exploitation_time': exploitation_time,\n",
        "        'exploration_time': exploration_time,\n",
        "        'exploitation_percentage': exploitation_percentage,\n",
        "        'exploration_percentage': exploration_percentage,\n",
        "        'clusters': clusters,\n",
        "        'mean_phase_size': mean_phase_size,\n",
        "        'exploitation_mean_phase_size': exploitation_mean_phase_size,\n",
        "        'exploration_mean_phase_size': exploration_mean_phase_size,\n",
        "        'ee_tradeoff': ee_tradeoff\n",
        "    }\n",
        "\n",
        "# SoftMax Model Functions\n",
        "def softmax_likelihood(beta, word_sequence, similarity_matrix, word_to_idx):\n",
        "    \"\"\"\n",
        "    Calculate the log-likelihood of a word sequence given a SoftMax temperature parameter.\n",
        "\n",
        "    Parameters:\n",
        "    beta (float): SoftMax temperature parameter\n",
        "    word_sequence (list): Sequence of words\n",
        "    similarity_matrix (np.array): Matrix of semantic similarities\n",
        "    word_to_idx (dict): Mapping from words to matrix indices\n",
        "\n",
        "    Returns:\n",
        "    float: Log-likelihood of the sequence\n",
        "    \"\"\"\n",
        "    log_likelihood = 0\n",
        "\n",
        "    for i in range(len(word_sequence) - 1):\n",
        "        current_word = word_sequence[i]\n",
        "        next_word = word_sequence[i + 1]\n",
        "\n",
        "        # Get indices\n",
        "        current_idx = word_to_idx[current_word]\n",
        "        next_idx = word_to_idx[next_word]\n",
        "\n",
        "        # Get similarities to all words from current word\n",
        "        similarities = similarity_matrix[current_idx, :]\n",
        "\n",
        "        # Calculate SoftMax probabilities\n",
        "        numerators = np.exp(beta * similarities)\n",
        "        denominator = np.sum(numerators)\n",
        "        probabilities = numerators / denominator\n",
        "\n",
        "        # Add log probability of the actual chosen word\n",
        "        if probabilities[next_idx] > 0:  # Avoid log(0)\n",
        "            log_likelihood += np.log(probabilities[next_idx])\n",
        "        else:\n",
        "            log_likelihood += -100  # Very low log probability as penalty\n",
        "\n",
        "    return log_likelihood\n",
        "\n",
        "def find_optimal_beta(word_sequence, similarity_data):\n",
        "    \"\"\"\n",
        "    Find the optimal SoftMax temperature parameter for a given word sequence.\n",
        "    \"\"\"\n",
        "    similarity_matrix = similarity_data['matrix']\n",
        "    word_to_idx = similarity_data['word_to_idx']\n",
        "\n",
        "    # Only proceed if we have at least 2 words\n",
        "    if len(word_sequence) < 2:\n",
        "        return np.nan, {'status': 'failed', 'reason': 'sequence too short'}\n",
        "\n",
        "    # Check all words are in the mapping\n",
        "    if not all(word in word_to_idx for word in word_sequence):\n",
        "        missing_words = [word for word in word_sequence if word not in word_to_idx]\n",
        "        return np.nan, {'status': 'failed', 'reason': f'missing words: {missing_words}'}\n",
        "\n",
        "    # Define negative log-likelihood function to minimize\n",
        "    def neg_log_likelihood(beta):\n",
        "        return -softmax_likelihood(beta, word_sequence, similarity_matrix, word_to_idx)\n",
        "\n",
        "    # Find optimal beta using bounded optimization\n",
        "    try:\n",
        "        result = minimize_scalar(\n",
        "            neg_log_likelihood,\n",
        "            bounds=(0.1, 10),\n",
        "            method='bounded'\n",
        "        )\n",
        "\n",
        "        optimal_beta = result.x\n",
        "        min_neg_log_likelihood = result.fun\n",
        "\n",
        "        # Calculate log-likelihood at optimal beta\n",
        "        log_likelihood = -min_neg_log_likelihood\n",
        "\n",
        "        # Calculate exploitation ratio based on beta\n",
        "        # Higher values mean more deterministic (exploitation) behavior\n",
        "        exploitation_ratio = 1 - np.exp(-optimal_beta)\n",
        "\n",
        "        return optimal_beta, {\n",
        "            'status': 'success',\n",
        "            'log_likelihood': log_likelihood,\n",
        "            'avg_likelihood': log_likelihood / (len(word_sequence) - 1),\n",
        "            'exploitation_ratio': exploitation_ratio,\n",
        "            'success': result.success,\n",
        "            'message': str(result.message)\n",
        "        }\n",
        "    except Exception as e:\n",
        "        print(f\"Error in SoftMax optimization: {e}\")\n",
        "        return np.nan, {'status': 'failed', 'reason': str(e)}\n",
        "\n",
        "# MVT Model Functions\n",
        "def mvt_retrieval_rate(t, a, b):\n",
        "    \"\"\"\n",
        "    Calculate the instantaneous retrieval rate at time t\n",
        "\n",
        "    Parameters:\n",
        "    t (float): Time spent in current patch\n",
        "    a (float): Initial retrieval rate\n",
        "    b (float): Decay rate\n",
        "\n",
        "    Returns:\n",
        "    float: Instantaneous retrieval rate\n",
        "    \"\"\"\n",
        "    return a * np.exp(-b * t)\n",
        "\n",
        "def mvt_cumulative_gain(t, a, b):\n",
        "    \"\"\"\n",
        "    Calculate the cumulative gain at time t\n",
        "\n",
        "    Parameters:\n",
        "    t (float): Time spent in current patch\n",
        "    a (float): Initial retrieval rate\n",
        "    b (float): Decay rate\n",
        "\n",
        "    Returns:\n",
        "    float: Cumulative gain\n",
        "    \"\"\"\n",
        "    return (a / b) * (1 - np.exp(-b * t))\n",
        "\n",
        "def mvt_average_rate(t, a, b, c):\n",
        "    \"\"\"\n",
        "    Calculate the average rate of gain including travel costs\n",
        "\n",
        "    Parameters:\n",
        "    t (float): Time spent in current patch\n",
        "    a (float): Initial retrieval rate\n",
        "    b (float): Decay rate\n",
        "    c (float): Travel/switch cost\n",
        "\n",
        "    Returns:\n",
        "    float: Average rate of gain\n",
        "    \"\"\"\n",
        "    return mvt_cumulative_gain(t, a, b) / (t + c)\n",
        "\n",
        "def mvt_fit_error(params, similarity_sequence, threshold):\n",
        "    \"\"\"\n",
        "    Calculate error between MVT model and observed exploitation/exploration pattern\n",
        "\n",
        "    Parameters:\n",
        "    params (tuple): (a, b, c) = initial rate, decay rate, switch cost\n",
        "    similarity_sequence (list): Sequence of similarity values\n",
        "    threshold (float): Threshold for exploitation/exploration\n",
        "\n",
        "    Returns:\n",
        "    float: Sum of squared errors\n",
        "    \"\"\"\n",
        "    a, b, c = params\n",
        "\n",
        "    # Calculate predicted optimal leaving time\n",
        "    try:\n",
        "        t_opt = (1/b) * np.log(a * b * c)\n",
        "    except:\n",
        "        return np.inf\n",
        "\n",
        "    if t_opt <= 0:\n",
        "        return np.inf\n",
        "\n",
        "    # Convert similarity sequence to exploitation/exploration phases\n",
        "    observed_phases = []\n",
        "    current_phase = \"exploitation\" if similarity_sequence[0] > threshold else \"exploration\"\n",
        "    phase_start = 0\n",
        "\n",
        "    for i in range(1, len(similarity_sequence)):\n",
        "        if (current_phase == \"exploitation\" and similarity_sequence[i] <= threshold) or \\\n",
        "           (current_phase == \"exploration\" and similarity_sequence[i] > threshold):\n",
        "\n",
        "            observed_phases.append((current_phase, phase_start, i-1))\n",
        "            current_phase = \"exploration\" if current_phase == \"exploitation\" else \"exploitation\"\n",
        "            phase_start = i\n",
        "\n",
        "    # Add final phase\n",
        "    observed_phases.append((current_phase, phase_start, len(similarity_sequence)-1))\n",
        "\n",
        "    # Calculate expected exploitation phase lengths based on MVT\n",
        "    exploitation_phases = [phase for phase in observed_phases if phase[0] == \"exploitation\"]\n",
        "    phase_lengths = [end - start + 1 for _, start, end in exploitation_phases]\n",
        "\n",
        "    # Calculate squared error between observed and predicted\n",
        "    error = 0\n",
        "    for length in phase_lengths:\n",
        "        error += (length - t_opt)**2\n",
        "\n",
        "    return error\n",
        "\n",
        "def find_optimal_mvt_params(similarity_sequence, threshold):\n",
        "    \"\"\"\n",
        "    Find optimal MVT parameters for a given sequence\n",
        "\n",
        "    Parameters:\n",
        "    similarity_sequence (list): Sequence of similarity values\n",
        "    threshold (float): Threshold for exploitation/exploration\n",
        "\n",
        "    Returns:\n",
        "    tuple: (a, b, c, t_opt) optimal parameters and leaving time\n",
        "    dict: Additional information\n",
        "    \"\"\"\n",
        "    # Initial guesses for a, b, c\n",
        "    initial_params = [1.0, 0.5, 2.0]\n",
        "\n",
        "    # Bounds for parameters\n",
        "    bounds = ((0.1, 5.0), (0.1, 5.0), (0.1, 10.0))\n",
        "\n",
        "    try:\n",
        "        # Find optimal parameters\n",
        "        result = minimize(\n",
        "            lambda params: mvt_fit_error(params, similarity_sequence, threshold),\n",
        "            initial_params,\n",
        "            bounds=bounds,\n",
        "            method='L-BFGS-B'\n",
        "        )\n",
        "\n",
        "        a, b, c = result.x\n",
        "\n",
        "        # Calculate optimal leaving time\n",
        "        t_opt = (1/b) * np.log(a * b * c)\n",
        "\n",
        "        # Calculate model fit\n",
        "        error = result.fun\n",
        "\n",
        "        return (a, b, c, t_opt), {\n",
        "            'status': 'success',\n",
        "            'error': error,\n",
        "            'success': result.success,\n",
        "            'message': str(result.message)\n",
        "        }\n",
        "    except Exception as e:\n",
        "        print(f\"Error in MVT optimization: {e}\")\n",
        "        return (np.nan, np.nan, np.nan, np.nan), {'status': 'failed', 'reason': str(e)}\n",
        "\n",
        "def prepare_data_for_modeling(data):\n",
        "    \"\"\"\n",
        "    Prepare SVF data for SoftMax and MVT modeling\n",
        "    \"\"\"\n",
        "    all_data = []  # Structure to store participant data\n",
        "    all_similarities = []  # List for global similarity calculation\n",
        "\n",
        "    for participant, group in data.groupby(['ID','clean_ID']):\n",
        "        items = group['Item'].tolist()\n",
        "\n",
        "        # Remove repetitions for cleaner analysis\n",
        "        unique_items = []\n",
        "        for item in items:\n",
        "            if item not in unique_items:\n",
        "                unique_items.append(item)\n",
        "\n",
        "        # Compute word vectors for each unique item\n",
        "        docs = [nlp(item) for item in unique_items if nlp(item).has_vector]\n",
        "        vectors = [doc.vector for doc in docs]\n",
        "\n",
        "        # Skip if not enough valid vectors\n",
        "        if len(vectors) < 2:\n",
        "            print(f\"Warning: Not enough valid vectors for {participant[0]}\")\n",
        "            continue\n",
        "\n",
        "        # Calculate cosine similarities\n",
        "        similarities = [cosine_similarity(vectors[i], vectors[i+1]) for i in range(len(vectors) - 1)]\n",
        "\n",
        "        # Append similarities to global list\n",
        "        all_similarities.extend(similarities)\n",
        "\n",
        "        # Create similarity matrix for SoftMax modeling\n",
        "        unique_words = [doc.text for doc in docs]\n",
        "        n_words = len(unique_words)\n",
        "        word_to_idx = {word: i for i, word in enumerate(unique_words)}\n",
        "\n",
        "        sim_matrix = np.zeros((n_words, n_words))\n",
        "        for i, vec1 in enumerate(vectors):\n",
        "            for j, vec2 in enumerate(vectors):\n",
        "                sim = cosine_similarity(vec1, vec2)\n",
        "                sim_matrix[i, j] = sim\n",
        "\n",
        "        # Store participant data\n",
        "        all_data.append({\n",
        "            'participant': participant[0],\n",
        "            'clean_ID': participant[1],\n",
        "            'items': unique_items[:len(docs)],  # Only include items with valid vectors\n",
        "            'vectors': vectors,\n",
        "            'similarities': similarities,\n",
        "            'similarity_data': {\n",
        "                'matrix': sim_matrix,\n",
        "                'word_to_idx': word_to_idx\n",
        "            }\n",
        "        })\n",
        "\n",
        "    # Calculate global mean similarity for thresholding\n",
        "    mean_similarity = np.mean(all_similarities)\n",
        "    std_similarity = np.std(all_similarities)\n",
        "    print(f\"Mean Similarity: {mean_similarity:.4f}, Std: {std_similarity:.4f}\")\n",
        "\n",
        "    return all_data, mean_similarity\n",
        "\n",
        "def run_model_comparison(all_data, mean_similarity, meg_lc_data):\n",
        "    \"\"\"\n",
        "    Run model comparison between traditional, SoftMax, and MVT models\n",
        "    \"\"\"\n",
        "    results = []\n",
        "\n",
        "    for participant_data in tqdm(all_data, desc=\"Processing participants\"):\n",
        "        participant = participant_data['participant']\n",
        "        items = participant_data['items']\n",
        "        vectors = participant_data['vectors']\n",
        "        similarities = participant_data['similarities']\n",
        "\n",
        "        # Skip if not enough data\n",
        "        if len(similarities) < 2:\n",
        "            print(f\"Skipping {participant}: Not enough similarity data\")\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            # 1. Traditional threshold-based analysis\n",
        "            threshold_analysis = analyze_responses(participant_data, mean_similarity)\n",
        "\n",
        "            # 2. SoftMax model\n",
        "            softmax_beta, softmax_info = find_optimal_beta(\n",
        "                items,\n",
        "                participant_data['similarity_data']\n",
        "            )\n",
        "\n",
        "            # 3. MVT model\n",
        "            mvt_params, mvt_info = find_optimal_mvt_params(\n",
        "                similarities,\n",
        "                mean_similarity\n",
        "            )\n",
        "\n",
        "            # Extract parameters\n",
        "            mvt_a, mvt_b, mvt_c, mvt_t_opt = mvt_params\n",
        "\n",
        "            # Calculate model fit metrics\n",
        "            softmax_fit = softmax_info.get('log_likelihood', np.nan)\n",
        "            mvt_fit = -mvt_info.get('error', np.inf)  # Negative because error is minimized\n",
        "\n",
        "            # Prepare record for this participant\n",
        "            record = {\n",
        "                'participant': participant,\n",
        "                'clean_ID': participant_data['clean_ID'],\n",
        "                'num_items': len(items),\n",
        "                'avg_similarity': np.mean(similarities),\n",
        "\n",
        "                # Traditional analysis\n",
        "                'threshold_similarity': mean_similarity,\n",
        "                'exploitation_percentage': threshold_analysis['exploitation_percentage'],\n",
        "                'exploration_percentage': threshold_analysis['exploration_percentage'],\n",
        "                'num_phases': len(threshold_analysis['phases']),\n",
        "                'exploitation_mean_phase_size': threshold_analysis['exploitation_mean_phase_size'],\n",
        "                'exploration_mean_phase_size': threshold_analysis['exploration_mean_phase_size'],\n",
        "                'ee_tradeoff': threshold_analysis['ee_tradeoff'],\n",
        "\n",
        "                # SoftMax model\n",
        "                'softmax_beta': softmax_beta,\n",
        "                'softmax_exploitation_ratio': softmax_info.get('exploitation_ratio', np.nan),\n",
        "                'softmax_log_likelihood': softmax_fit,\n",
        "\n",
        "                # MVT model\n",
        "                'mvt_initial_rate': mvt_a,\n",
        "                'mvt_decay_rate': mvt_b,\n",
        "                'mvt_switch_cost': mvt_c,\n",
        "                'mvt_optimal_leaving': mvt_t_opt,\n",
        "                'mvt_fit': mvt_fit\n",
        "            }\n",
        "\n",
        "            # Compare model fits\n",
        "            if not np.isnan(softmax_fit) and not np.isnan(mvt_fit):\n",
        "                # Normalize fit values to [0,1] for comparison\n",
        "                max_fit = max(softmax_fit, mvt_fit)\n",
        "                min_fit = min(softmax_fit, mvt_fit)\n",
        "                range_fit = max_fit - min_fit if max_fit != min_fit else 1\n",
        "\n",
        "                softmax_relative_fit = (softmax_fit - min_fit) / range_fit if range_fit > 0 else 0.5\n",
        "                mvt_relative_fit = (mvt_fit - min_fit) / range_fit if range_fit > 0 else 0.5\n",
        "\n",
        "                # Determine better model\n",
        "                if softmax_relative_fit > mvt_relative_fit:\n",
        "                    better_model = 'SoftMax'\n",
        "                elif mvt_relative_fit > softmax_relative_fit:\n",
        "                    better_model = 'MVT'\n",
        "                else:\n",
        "                    better_model = 'Tie'\n",
        "\n",
        "                record['softmax_relative_fit'] = softmax_relative_fit\n",
        "                record['mvt_relative_fit'] = mvt_relative_fit\n",
        "                record['better_model'] = better_model\n",
        "            else:\n",
        "                record['softmax_relative_fit'] = np.nan\n",
        "                record['mvt_relative_fit'] = np.nan\n",
        "                record['better_model'] = 'Unknown'\n",
        "\n",
        "            results.append(record)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {participant}: {str(e)}\")\n",
        "\n",
        "    # Create dataframe\n",
        "    results_df = pd.DataFrame(results)\n",
        "\n",
        "    # Merge with clinical data\n",
        "    if meg_lc_data is not None:\n",
        "        merged_df = pd.merge(results_df, meg_lc_data, on='clean_ID', how='inner')\n",
        "        print(f\"Merged {len(merged_df)} participants with clinical data\")\n",
        "    else:\n",
        "        merged_df = results_df\n",
        "\n",
        "    return results_df, merged_df\n",
        "\n",
        "def analyze_model_comparison(results_df, merged_df):\n",
        "    \"\"\"\n",
        "    Analyze the results of model comparison\n",
        "    \"\"\"\n",
        "    # 1. Overall model performance\n",
        "    if 'better_model' in results_df.columns:\n",
        "        model_counts = results_df['better_model'].value_counts()\n",
        "        print(\"\\nModel Comparison Results:\")\n",
        "        print(model_counts)\n",
        "\n",
        "        # Calculate percentages\n",
        "        model_percentages = model_counts / model_counts.sum() * 100\n",
        "        print(\"\\nModel Percentages:\")\n",
        "        for model, percentage in model_percentages.items():\n",
        "            print(f\"{model}: {percentage:.2f}%\")\n",
        "\n",
        "    # 2. Parameter distributions\n",
        "    param_cols = ['softmax_beta', 'mvt_initial_rate', 'mvt_decay_rate',\n",
        "                  'mvt_switch_cost', 'mvt_optimal_leaving']\n",
        "\n",
        "    param_stats = results_df[param_cols].describe()\n",
        "    print(\"\\nParameter Statistics:\")\n",
        "    print(param_stats)\n",
        "\n",
        "    # 3. Correlations between parameters and clinical measures\n",
        "    if len(merged_df) > 0:\n",
        "        clinical_cols = ['alpha_NET_mean', 'norm_SN_avg', 'norm_LC_avg']\n",
        "\n",
        "        correlation_cols = param_cols + ['exploitation_percentage',\n",
        "                                         'exploration_percentage',\n",
        "                                         'softmax_exploitation_ratio',\n",
        "                                         'ee_tradeoff']\n",
        "\n",
        "        correlations = {}\n",
        "        pvalues = {}\n",
        "\n",
        "        for model_param in correlation_cols:\n",
        "            correlations[model_param] = {}\n",
        "            pvalues[model_param] = {}\n",
        "\n",
        "            for clinical_measure in clinical_cols:\n",
        "                # Remove NaN values\n",
        "                data = merged_df[[model_param, clinical_measure]].dropna()\n",
        "\n",
        "                if len(data) >= 3:\n",
        "                    r, p = pearsonr(data[model_param], data[clinical_measure])\n",
        "                    correlations[model_param][clinical_measure] = r\n",
        "                    pvalues[model_param][clinical_measure] = p\n",
        "                else:\n",
        "                    correlations[model_param][clinical_measure] = np.nan\n",
        "                    pvalues[model_param][clinical_measure] = np.nan\n",
        "\n",
        "        # Convert to dataframes\n",
        "        corr_df = pd.DataFrame(correlations)\n",
        "        pval_df = pd.DataFrame(pvalues)\n",
        "\n",
        "        print(\"\\nCorrelations with Clinical Measures:\")\n",
        "        for clinical_measure in clinical_cols:\n",
        "            print(f\"\\n{clinical_measure}:\")\n",
        "            for model_param in correlation_cols:\n",
        "                r = correlations[model_param][clinical_measure]\n",
        "                p = pvalues[model_param][clinical_measure]\n",
        "                if not np.isnan(r) and not np.isnan(p):\n",
        "                    sig = '*' if p < 0.05 else ''\n",
        "                    print(f\"  {model_param}: r = {r:.3f}, p = {p:.3f} {sig}\")\n",
        "\n",
        "    # 4. Correlation between different model parameters\n",
        "    param_corr = results_df[param_cols].corr()\n",
        "    print(\"\\nParameter Correlations:\")\n",
        "    print(param_corr)\n",
        "\n",
        "    return {\n",
        "        'param_stats': param_stats,\n",
        "        'correlations': correlations if 'correlations' in locals() else None,\n",
        "        'pvalues': pvalues if 'pvalues' in locals() else None,\n",
        "        'param_corr': param_corr\n",
        "    }\n",
        "\n",
        "def visualize_model_comparison(results_df, merged_df, analysis_results):\n",
        "    \"\"\"\n",
        "    Create visualizations for model comparison\n",
        "    \"\"\"\n",
        "    figures = []\n",
        "\n",
        "    # 1. Model comparison pie chart\n",
        "    if 'better_model' in results_df.columns:\n",
        "        fig, ax = plt.subplots(figsize=(8, 8))\n",
        "        model_counts = results_df['better_model'].value_counts()\n",
        "\n",
        "        # Filter out 'Unknown' for better visualization\n",
        "        if 'Unknown' in model_counts:\n",
        "            model_counts = model_counts.drop('Unknown')\n",
        "\n",
        "        colors = ['#ff9999', '#66b3ff', '#99ff99', '#ffcc99']\n",
        "        ax.pie(model_counts, labels=model_counts.index, autopct='%1.1f%%',\n",
        "               startangle=90, colors=colors, wedgeprops={'edgecolor': 'w'})\n",
        "        ax.axis('equal')\n",
        "        ax.set_title('Better Fitting Model Comparison', fontsize=16)\n",
        "        figures.append(('model_comparison_pie.png', fig))\n",
        "\n",
        "    # 2. Parameter distributions\n",
        "    param_cols = ['softmax_beta', 'mvt_initial_rate', 'mvt_decay_rate',\n",
        "                  'mvt_switch_cost', 'mvt_optimal_leaving']\n",
        "    param_names = ['SoftMax β', 'MVT Initial Rate (a)', 'MVT Decay Rate (b)',\n",
        "                   'MVT Switch Cost (c)', 'MVT Optimal Leaving Time']\n",
        "\n",
        "    fig, axes = plt.subplots(len(param_cols), 1, figsize=(12, 15))\n",
        "    for i, (param, name) in enumerate(zip(param_cols, param_names)):\n",
        "        valid_data = results_df[param].dropna()\n",
        "        if len(valid_data) > 0:\n",
        "            sns.histplot(valid_data, kde=True, ax=axes[i])\n",
        "            axes[i].set_title(f'Distribution of {name}', fontsize=14)\n",
        "            axes[i].set_xlabel(name)\n",
        "            axes[i].set_ylabel('Count')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    figures.append(('parameter_distributions.png', fig))\n",
        "\n",
        "    # 3. Model parameters vs exploitation percentage\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "    # SoftMax beta vs exploitation\n",
        "    sns.scatterplot(x='softmax_beta', y='exploitation_percentage',\n",
        "                    data=results_df.dropna(subset=['softmax_beta']),\n",
        "                    ax=axes[0])\n",
        "    axes[0].set_title('SoftMax β vs Exploitation %', fontsize=14)\n",
        "    axes[0].set_xlabel('SoftMax β')\n",
        "    axes[0].set_ylabel('Exploitation %')\n",
        "\n",
        "    # MVT optimal leaving vs exploitation\n",
        "    sns.scatterplot(x='mvt_optimal_leaving', y='exploitation_percentage',\n",
        "                    data=results_df.dropna(subset=['mvt_optimal_leaving']),\n",
        "                    ax=axes[1])\n",
        "    axes[1].set_title('MVT Optimal Leaving Time vs Exploitation %', fontsize=14)\n",
        "    axes[1].set_xlabel('MVT Optimal Leaving Time')\n",
        "    axes[1].set_ylabel('Exploitation %')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    figures.append(('model_parameters_vs_exploitation.png', fig))\n",
        "\n",
        "    # 4. Clinical correlations heatmap\n",
        "    if len(merged_df) > 0:\n",
        "        try:\n",
        "            clinical_cols = ['alpha_NET_mean', 'norm_SN_avg', 'norm_LC_avg']\n",
        "            model_cols = param_cols + ['exploitation_percentage', 'softmax_exploitation_ratio']\n",
        "\n",
        "            correlation_matrix = np.zeros((len(model_cols), len(clinical_cols)))\n",
        "\n",
        "            for i, model_param in enumerate(model_cols):\n",
        "                for j, clinical_measure in enumerate(clinical_cols):\n",
        "                    if analysis_results['correlations'] is not None:\n",
        "                        correlation_matrix[i, j] = analysis_results['correlations'][model_param][clinical_measure]\n",
        "\n",
        "            fig, ax = plt.subplots(figsize=(12, 10))\n",
        "            im = ax.imshow(correlation_matrix, cmap='coolwarm', vmin=-0.8, vmax=0.8)\n",
        "\n",
        "            # Add clinical measure labels\n",
        "            ax.set_xticks(np.arange(len(clinical_cols)))\n",
        "            ax.set_xticklabels(clinical_cols, rotation=45, ha='right')\n",
        "\n",
        "            # Add model parameter labels\n",
        "            ax.set_yticks(np.arange(len(model_cols)))\n",
        "            ax.set_yticklabels(model_cols)\n",
        "\n",
        "            # Add colorbar\n",
        "            cbar = plt.colorbar(im)\n",
        "            cbar.set_label('Pearson Correlation (r)')\n",
        "\n",
        "            # Add correlation values in cells\n",
        "            for i in range(len(model_cols)):\n",
        "                for j in range(len(clinical_cols)):\n",
        "                    r = correlation_matrix[i, j]\n",
        "                    if analysis_results['pvalues'] is not None:\n",
        "                        p = analysis_results['pvalues'][model_cols[i]][clinical_cols[j]]\n",
        "                        text = f\"{r:.2f}\"\n",
        "                        if not np.isnan(p) and p < 0.05:\n",
        "                            text += \"*\"\n",
        "                        if not np.isnan(p) and p < 0.01:\n",
        "                            text += \"*\"\n",
        "                        ax.text(j, i, text, ha='center', va='center',\n",
        "                                color='white' if abs(r) > 0.4 else 'black')\n",
        "\n",
        "            ax.set_title('Correlations: Model Parameters vs Clinical Measures', fontsize=16)\n",
        "            plt.tight_layout()\n",
        "            figures.append(('clinical_correlations_heatmap.png', fig))\n",
        "        except Exception as e:\n",
        "            print(f\"Error creating correlation heatmap: {e}\")\n",
        "\n",
        "    # 5. SoftMax vs MVT parameter correlation\n",
        "    fig, ax = plt.subplots(figsize=(10, 8))\n",
        "\n",
        "    # Create scatter plot of SoftMax beta vs MVT optimal leaving time\n",
        "    scatter = sns.scatterplot(x='softmax_beta', y='mvt_optimal_leaving',\n",
        "                             data=results_df.dropna(subset=['softmax_beta', 'mvt_optimal_leaving']),\n",
        "                             hue='better_model', size='num_items',\n",
        "                             sizes=(50, 200), alpha=0.7, ax=ax)\n",
        "\n",
        "    ax.set_title('SoftMax β vs MVT Optimal Leaving Time', fontsize=16)\n",
        "    ax.set_xlabel('SoftMax β', fontsize=14)\n",
        "    ax.set_ylabel('MVT Optimal Leaving Time', fontsize=14)\n",
        "\n",
        "    # Add correlation line\n",
        "    valid_data = results_df.dropna(subset=['softmax_beta', 'mvt_optimal_leaving'])\n",
        "    if len(valid_data) >= 2:\n",
        "        x = valid_data['softmax_beta']\n",
        "        y = valid_data['mvt_optimal_leaving']\n",
        "        r, p = pearsonr(x, y)\n",
        "        ax.text(0.05, 0.95, f\"r = {r:.3f}, p = {p:.3f}\", transform=ax.transAxes,\n",
        "                fontsize=12,\n",
        "                verticalalignment='top', horizontalalignment='left',\n",
        "                bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
        "\n",
        "    plt.tight_layout()\n",
        "    figures.append(('softmax_vs_mvt_correlation.png', fig))\n",
        "\n",
        "    return figures\n",
        "\n",
        "def simulate_softmax_mvt_behavior(results_df):\n",
        "    \"\"\"\n",
        "    Simulate and compare behavior predicted by SoftMax and MVT models\n",
        "    \"\"\"\n",
        "    # Select a few representative participants\n",
        "    if len(results_df) <= 3:\n",
        "        selected_ids = results_df['participant'].tolist()\n",
        "    else:\n",
        "        # Choose participants with diverse model fits\n",
        "        softmax_better = results_df[results_df['better_model'] == 'SoftMax']\n",
        "        mvt_better = results_df[results_df['better_model'] == 'MVT']\n",
        "\n",
        "        selected_ids = []\n",
        "\n",
        "        if len(softmax_better) > 0:\n",
        "            selected_ids.append(softmax_better.iloc[0]['participant'])\n",
        "\n",
        "        if len(mvt_better) > 0:\n",
        "            selected_ids.append(mvt_better.iloc[0]['participant'])\n",
        "\n",
        "        # Add one more random participant if needed\n",
        "        if len(selected_ids) < 2:\n",
        "            remaining = results_df[~results_df['participant'].isin(selected_ids)]\n",
        "            if len(remaining) > 0:\n",
        "                selected_ids.append(remaining.iloc[0]['participant'])\n",
        "\n",
        "    figures = []\n",
        "\n",
        "    for participant_id in selected_ids:\n",
        "        # Get participant data\n",
        "        participant_data = results_df[results_df['participant'] == participant_id].iloc[0]\n",
        "\n",
        "        # Extract model parameters\n",
        "        softmax_beta = participant_data['softmax_beta']\n",
        "        mvt_a = participant_data['mvt_initial_rate']\n",
        "        mvt_b = participant_data['mvt_decay_rate']\n",
        "        mvt_c = participant_data['mvt_switch_cost']\n",
        "        mvt_t_opt = participant_data['mvt_optimal_leaving']\n",
        "\n",
        "        # Skip if missing parameters\n",
        "        if np.isnan(softmax_beta) or np.isnan(mvt_t_opt):\n",
        "            continue\n",
        "\n",
        "        # Simulate behavior over time\n",
        "        time_points = np.linspace(0, 10, 100)\n",
        "\n",
        "        # SoftMax probabilities (probability of staying in category)\n",
        "        softmax_probs = 1 / (1 + np.exp(-softmax_beta * (0.5 - time_points/10)))\n",
        "\n",
        "        # MVT retrieval rate\n",
        "        mvt_rates = mvt_a * np.exp(-mvt_b * time_points)\n",
        "\n",
        "        # MVT average rate\n",
        "        mvt_avg_rates = np.array([mvt_average_rate(t, mvt_a, mvt_b, mvt_c) for t in time_points])\n",
        "\n",
        "        # Create figure\n",
        "        fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10), sharex=True)\n",
        "\n",
        "        # Plot SoftMax probabilities\n",
        "        ax1.plot(time_points, softmax_probs, 'b-', linewidth=2, label='SoftMax P(stay)')\n",
        "        ax1.axhline(y=0.5, color='b', linestyle='--', alpha=0.5, label='SoftMax threshold')\n",
        "        ax1.set_ylabel('Probability of Staying in Category', color='b')\n",
        "        ax1.tick_params(axis='y', labelcolor='b')\n",
        "        ax1.set_ylim(0, 1)\n",
        "        ax1.legend(loc='upper right')\n",
        "\n",
        "        # Plot MVT rates\n",
        "        ax2.plot(time_points, mvt_rates, 'r-', linewidth=2, label='MVT instantaneous rate')\n",
        "        ax2.plot(time_points, mvt_avg_rates, 'r--', linewidth=2, label='MVT average rate')\n",
        "\n",
        "        # Mark optimal leaving time\n",
        "        if not np.isnan(mvt_t_opt) and mvt_t_opt > 0 and mvt_t_opt < 10:\n",
        "            opt_rate = mvt_retrieval_rate(mvt_t_opt, mvt_a, mvt_b)\n",
        "            ax2.axvline(x=mvt_t_opt, color='r', linestyle=':', label=f'MVT optimal leaving (t={mvt_t_opt:.2f})')\n",
        "            ax2.plot(mvt_t_opt, opt_rate, 'ro', markersize=8)\n",
        "\n",
        "        ax2.set_ylabel('Retrieval Rate', color='r')\n",
        "        ax2.tick_params(axis='y', labelcolor='r')\n",
        "        ax2.set_xlabel('Time in Category')\n",
        "        ax2.legend(loc='upper right')\n",
        "\n",
        "        # Add title\n",
        "        fig.suptitle(f'Participant {participant_id}: Model Predictions\\n' +\n",
        "                    f'SoftMax β={softmax_beta:.2f}, MVT params: a={mvt_a:.2f}, b={mvt_b:.2f}, c={mvt_c:.2f}, t*={mvt_t_opt:.2f}',\n",
        "                    fontsize=16)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        figures.append((f'participant_{participant_id}_model_simulation.png', fig))\n",
        "\n",
        "    return figures\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Main function to run the complete analysis\n",
        "    \"\"\"\n",
        "    print(\"Starting SVF model comparison analysis...\")\n",
        "\n",
        "    # 1. Load and prepare data\n",
        "    data, meg_lc_data = load_data()\n",
        "\n",
        "    # 2. Prepare data for modeling\n",
        "    all_data, mean_similarity = prepare_data_for_modeling(data)\n",
        "\n",
        "    # 3. Run model comparison\n",
        "    results_df, merged_df = run_model_comparison(all_data, mean_similarity, meg_lc_data)\n",
        "\n",
        "    # 4. Analyze results\n",
        "    analysis_results = analyze_model_comparison(results_df, merged_df)\n",
        "\n",
        "    # 5. Create visualizations\n",
        "    figures = visualize_model_comparison(results_df, merged_df, analysis_results)\n",
        "\n",
        "    # 6. Simulate model behavior\n",
        "    simulation_figures = simulate_softmax_mvt_behavior(results_df)\n",
        "    figures.extend(simulation_figures)\n",
        "\n",
        "    # Save figures\n",
        "    output_dir = 'model_comparison_output'\n",
        "    import os\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    for filename, fig in figures:\n",
        "        fig.savefig(os.path.join(output_dir, filename), dpi=300, bbox_inches='tight')\n",
        "        plt.close(fig)\n",
        "\n",
        "    # Save results\n",
        "    results_df.to_csv(os.path.join(output_dir, 'model_comparison_results.csv'), index=False)\n",
        "    if len(merged_df) > 0:\n",
        "        merged_df.to_csv(os.path.join(output_dir, 'model_clinical_merged_results.csv'), index=False)\n",
        "\n",
        "    print(f\"Analysis complete. Results saved to {output_dir} directory.\")\n",
        "    return results_df, merged_df, figures\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "68ZHLnOsPXe8"
      },
      "outputs": [],
      "source": [
        "# import numpy as np\n",
        "# import pandas as pd\n",
        "# import matplotlib.pyplot as plt\n",
        "# import seaborn as sns\n",
        "# from scipy import optimize\n",
        "# from sklearn.metrics import r2_score\n",
        "# import time\n",
        "# import warnings\n",
        "# warnings.filterwarnings('ignore')\n",
        "# import spacy\n",
        "# from tqdm.notebook import tqdm\n",
        "# import math\n",
        "# from scipy.stats import norm\n",
        "# from matplotlib.colors import ListedColormap\n",
        "# import re\n",
        "# from collections import Counter\n",
        "# import io\n",
        "\n",
        "# # Set random seed for reproducibility\n",
        "# np.random.seed(42)\n",
        "\n",
        "# # Load spaCy model for word embeddings\n",
        "# try:\n",
        "#     nlp = spacy.load('en_core_web_md')\n",
        "# except:\n",
        "#     print(\"Installing spaCy model...\")\n",
        "#     !python -m spacy download en_core_web_md\n",
        "#     nlp = spacy.load('en_core_web_md')\n",
        "\n",
        "# # Helper functions for semantic similarity\n",
        "# def get_word_vector(word):\n",
        "#     \"\"\"Get the word embedding vector for a given word.\"\"\"\n",
        "#     return nlp(word.lower()).vector\n",
        "\n",
        "# def cosine_similarity(vec1, vec2):\n",
        "#     \"\"\"Calculate cosine similarity between two vectors.\"\"\"\n",
        "#     if np.linalg.norm(vec1) * np.linalg.norm(vec2) == 0:\n",
        "#         return 0\n",
        "#     return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))\n",
        "\n",
        "# # ===== Data Loading and Preparation =====\n",
        "\n",
        "# # Your animal data from PD patients\n",
        "# animal_data_str = \"\"\"ID,Item\n",
        "# PD00020,\"Lion,Tiger,Sheep,Dog,Cat,Camel,Monkey,Chimpanzee,Buffalo,Hyena,Dog,Cat,Elephant,Hyena,Dog,Cat,Mouse,Bird,Camel,Dragon\"\n",
        "# PD00048,\"Lion,Hare,Elephant,Rhinoceros,Monkey,Giraffe,Cow,Elk,Fish,Horse,Tiger,Leopard,Jaguar\"\n",
        "# PD00119,\"Lion,Tiger,Duck,Goose,Deer,Horse,Zebra,Elephant,Bird,Giraffe,Hippo,Crocodile,Elephant,Sheep,Goat,Ewe,Duck\"\n",
        "# PD00146,\"Dog,Pig,Chicken,Partridge,Swallow,Squirrel,Rabbit,Horse,Hare,Calf,Bull,Cow,Lion,Tiger,Monkey,Giraffe,Elephant,Snake,Frog,Shark,Whale,Dolphin\"\n",
        "# PD00215,\"Donkey,Horse,Cow,Ox,Elephant,Llama,Cat,Dog,Mouse,Tiger,Lion,Leopard,Cheetah,Hyena,Bear,Goat,Partridge,Hare,Manatee,Turtle,Iguana,Frog,Toad\"\n",
        "# PD00219,\"Monkey,Lion,Tiger,Horse,Cat,Dog,Snake,Wolf,Coyote,Horse,Cow,Camel,Scorpion\"\n",
        "# PD00267,\"Cat,Dog,Lion,Beaver,Jaguar,Elephant,Gazelle,Bear,Fox,Horse,Ox,Calf,Giraffe\"\n",
        "# PD00457,\"rhinoceros,fox,tiger,hippopotamus,tiger,lion,leopard,gazelle,dog,cat,horse,cow,sheep,horse,lion,gazelle,turkey\"\n",
        "# PD00458,\"Dog,Cat,Hamster,Tiger,Fox,Lion,Rhinoceros,Wolf,Partridge,Coyote,Eagle,Pigeon,Parrot,Crocodile,Whale,Dolphin,Marmot\"\n",
        "# PD00471,\"Cat,Dog,Horse,Cow,Calf,Lion,Pig,Monkey,Rhinoceros,Zebra,Elephant,Antelope,Fish,Panther,Camel,Lion,Hare,Crocodile,Rabbit,Mouse,Butterfly,Monkey\"\n",
        "# PD00472,\"Cat,dog,duck,Fish,Lark,Horse,pig,snake,crocodile,lion,Gazelle,Zebra,Elephant,Wolf,Fox,Panther,jaguar,Chimpanzee,Panda,Hen,Rooster\"\n",
        "# PD00576,\"Wolf,Horse,Camel,Cat,Dog,Tiger,Leopard,Lion,Elephant,Antelope,Caterpillar,Ostrich,Wasp,Ant,Fish,Shark,Crow,Trout,Salmon,Frog,Swallow,Spider,Panther\"\n",
        "# PD00583,\"Dog,Cat,Goat,Wolf,Fox,Hippopotamus,Elephant,Rooster,Hen,Turkey,Rabbit,Parrot,Crocodile,Butterfly,Grasshopper\"\n",
        "# PD00647,\"Elephant,Tiger,Alligator,Monkey,Butterfly,Whale,Dog,Cat,Rat,Chimpanzee,Cow,Cat,Flea,bird,Insect,Fish\"\n",
        "# PD00653,\"Cow,Cat,Bear,Horse,Pig,Dog,Wolf,Bird,Elk,Crocodile,Hippopotamus,Lion,Tiger,Bird,Snake,Pig,Cow,Chicken,Lamb\"\n",
        "# PD00660,\"Dog,Cat,Rat,Crocodile,Lion,Tiger,Horse,Cow,Fish,Bird,Hen,Giraffe,Hippopotamus,Chimpanzee,Goat,Fox\"\n",
        "# PD00666,\"Cat,Goat,Mouse,Weasel,Cow,Bizon,Horse,Lion,Panther,Elephant,Gazelle,Orangutan,Cat,Eagle,Marmot,Moray eel,Snake,Whale,Shark\"\n",
        "# PD00757,\"Dog,Cat,Lion,Tiger,Fox,Snake,Spider,Elephant,Sheep\"\n",
        "# PD00786,\"Cat,Dog,Monkey,Hen,Rooster,Pig,Horse,Cow,Calf,Lamb,Sheep,Ox,Chicken,Duck\"\n",
        "# PD00849,\"Lion,Hare,Wolf,Fox,Cat,Dog,Tiger,Elephant,Rhinoceros,Ostrich,Zebra,Pheasant,Giraffe,Leopard,Tiger,Cougar\"\n",
        "# PD00869,\"Cow,Calf,Horse,Lion,Hippopotamus,Rhinoceros,Monkey,Hen,Rabbit,Pheasant,Parrot,Gazelle,Giraffe,Lion,Marmot,dog,Donkey,Cheetah,Swan,Duck,Mule\"\n",
        "# PD00955,\"Dog,Cat,Rat,Mole,Lion,Tiger,Giraffe,Hyena,Leopard,Lynx,Fox,Ram,Horse\"\n",
        "# PD00959,\"Tiger,Lion,Hen,Rhino,Hippo,Llama,Giraffe,Goat,Sheep\"\n",
        "# PD00999,\"Lion,Tiger,Elephant,Rhinoceros,Crocodile,Coyote,Duck,Camel,Wolf,Hare,Lynx,Turtle,Horse,Cat,Dog,Snake,Panther,Whale,Dolphin\"\n",
        "# PD01003,\"Ostrich,Bison,Goat,Zebra,Dog,Cat,Cow,Pig,Hare,Lion,Tiger,Donkey,Monkey,Dog,Vulture,Turtle,Rhinoceros,Whale\"\n",
        "# PD01126,\"Dog,Cat,Tiger,Elephant,Cow,Calf,Horse,Panda\"\n",
        "# PD01133,\"Dog,Cat,Monkey,Mule,Eel,Tiger,Lion,Moose,Elk,Wolf,Fox,Marmot,Beaver,Gopher,Crow,Giraffe\"\n",
        "# PD01145,\"Lion,Tiger,Bear,Wolf,Cat,Goat,Duck,Goose,Bull,Antelope\"\n",
        "# PD01146,\"Lion,Cat,Dog,Cow,Sheep,Duck,Giraffe,Pig,Hare,Antelope,Zebra,Camel,Elephant,Rhinoceros,Dog,Donkey,Horse,Goat,Mouse\"\n",
        "# PD01156,\"Reptile,Cow,Deer,Salamander,Bear,Fish,Cat,Mouse\"\n",
        "# PD01160,\"Lion,Bear,Tiger,Fox,Rat,Cat,Dog,Horse,Monkey,Hippo,Wolf,Deer,Roe deer,Crocodile,Salamander,Reptile,Panda\"\n",
        "# PD01161,\"Horse,Cow,Sheep,Ewe,Camel,Hippo,Elephant,Turkey,Cat,Otter,Rabbit,Hare,Tiger,Lion,Snake,Bee,Wasp,Mosquito,Wolf,Fox,Zebra,Coyote,Hen,Bird,Crow\"\n",
        "# PD01199,\"Lion,Tiger,Duck,Goose,Roe Deer,Horse,Zebra,Elephant,Bird,Giraffe,Hippopotamus,Crocodile,Elephant,Sheep,Goat,Ewe,Duck\"\n",
        "# PD01201,\"Cat,Dog,Elephant,Lion,Hippopotamus,Rhinoceros,Eagle,Zebra,Panther,Pigeon,Cow\"\n",
        "# PD01223,\"Elephant,Lion,Crocodile,Caiman,Snake,Dog,Cat,Fish,Turtle,Skunk\"\n",
        "# PD01225,\"Lion,Dog,Cat,Horse,Bird,Eagle,Donkey,Rabbit,Deer,Hare,Bird,Mouse,Rat,Snake,Bird,Camel,Dromedary,Alligator,Crocodile\"\n",
        "# PD01237,\"Cat,Dog,Horse,Pig,Pig,Goose,Goat,Dromedary,Gazelle,Zebra,Bull,Swallow,Pigeon,Llama,Fox,Elephant,Marmot,Wildcat,Spider,Seagull,Mongoose,Penguin\"\n",
        "# PD01247,\"Albatross,Whale,Bulldog,Poodle,Toad,Donkey,Monkey,Hippopotamus,Ram,Bull,Cat,Dog,Porcupine\"\n",
        "# PD01270,\"Lion,Giraffe,Tiger,Panther,Pigeon,Monkey,Wolf,Dog,Cat,Mouse,Horse,Sheep,Camel,Leopard,Emu\"\n",
        "# PD01282,\"Cow,Tiger,Lion,Horse,Dog,Cat,Mouse,Snake,Squirrel,Slug,Snail,Monkey,Giraffe,Elephant,Wolf,Fish,Bird\"\n",
        "# PD01284,\"Lion,Tiger,Caribou,Owl,Shark,Fish,Monkey,Dog,Cat,Alligator,Crocodile,Pelican,Jaguar,Penguin,Cow,Pig,Rooster,Raccoon,Beaver\"\n",
        "# PD01290,\"Dog,Cat,Rabbit,Lion,Lamb,Unicorn,Tiger,Elephant,Camel,Mole\"\n",
        "# PD01306,\"Dog,Cat,Raccoon,Lion,Elephant,Giraffe,Leopard,Tiger,Eagle,Turtle,Horse,Wolf,Hare,Horse,Cow,Mule,Sheep,Llama,Donkey,Parrot,Crow,Finch\"\n",
        "# PD01312,\"Dog,Cat,Horse,Goat,Sheep,Hen,Weasel,Hedgehog,Rabbit,Lion,Tiger,Monkey,Meerkat,Hippopotamus,Rhino,Zebra,Elephant,Panther,Jaguar,Chimpanzee,Gibbon,Fox,Raccoon,Rat,Elephant,Otter,Camel\"\n",
        "# PD01319,\"Dog,Cat,Mouse,Rat,Lion,Elephant,Tiger,Giraffe,Zebra,Eagle,Deer,Wolf,Fox,Bear,Cow,Ox\"\n",
        "# PD01369,\"Cat,Dog,Mouse,Rat,Snake,Caiman,Tiger,Giraffe,Fox,Crocodile,Lion,Elephant,Tiger,Deer,Crocodile,Dolphin,Otter,Whale,Dog,Swallow,Jaguar,Zebra,Mouse\"\n",
        "# PD01377,\"Cat,Dog,Mosquito,Vulture,Cow,Bull,Dromedary,Goat,Parrot,Monkey,Leopard,Lion,Tiger,Zebra,Giraffe,Squirrel,Bird,Crocodile,Hen,Wolf,Rabbit\"\n",
        "# PD01435,\"Rhinoceros,Dog,Mouse,Zebra,Raccoon,Wildcat,Kangaroo,Bear,Weasel,Skunk,Elephant,Monkey,Bull,Cow,Wolf,Wild boar,Fox\"\n",
        "# PD01440,\"Horse,Fox,Dog,Deer,Eagle,Goat,Cat,Raccoon,Dromedary,Camel,Rhinoceros,Lion,Tiger,Whale,Dolphin,Elephant\"\n",
        "# PD01457,\"Horse,Dog,Cat,Lion,Bird,Sheep,Giraffe,Whale,Hummingbird,Hippopotamus,Leopard,Deer,Panther\"\n",
        "# PD01485,\"Horse,Cow,Hen,Pig,Parrot,Parakeet,Snake,Tiger,Lion,Crow,Sheep,Goat,Mare,Moose,Zebra,Pig,Squirrel\"\n",
        "# PD01559,\"Dog,Cat,Perch,Golden eagle,Blackbird,Panther,Cow,Pig,Fox,Partridge,Gazelle,Hare,Jellyfish,Lizard,Tench,Fish,Shark,Cod\"\n",
        "# PD01623,\"Dog,Cat,Hippopotamus,Giraffe,Lion,Zebra,Mammoth,Blue Whale,Dolphin,Humpback Whale,Whale,Eel,Tiger,Chimpanzee\"\n",
        "# PD01660,\"Lion,Bear,Tiger,Fox,Dog,Cat,Rat,Mouse,Horse,Monkey,Hippopotamus,Ox,Deer,Roe Deer,Crocodile,Salamander,Turtle\"\n",
        "# PD01667,\"Dog,Cat,Horse,Cow,Hen,Chick,Swan,Bird,Giraffe,Lion,Zebra,Gazelle,Monkey,Chimpanzee,Squirrel,Frog,Fish,Ox,Chicken\"\n",
        "# PD01715,\"Donkey,Boa,Goat,Frog,Zebra,Hippopotamus,Elephant,Bird,Crocodile,Caiman,Fox,Wolf,Dog,Horse,Turkey,Chicken\"\n",
        "# \"\"\"\n",
        "\n",
        "# # Parse animal data into a dataframe\n",
        "# animal_df = pd.read_csv(io.StringIO(animal_data_str))\n",
        "\n",
        "# # Process the Item column to create a list of animals for each subject\n",
        "# subject_dict = {}\n",
        "\n",
        "# for _, row in animal_df.iterrows():\n",
        "#     subject_id = row['ID']\n",
        "#     # Some items might have spaces after commas, so strip whitespace\n",
        "#     animals = [animal.strip() for animal in row['Item'].split(',')]\n",
        "#     subject_dict[subject_id] = {'words': animals}\n",
        "\n",
        "# print(f\"Loaded data for {len(subject_dict)} subjects\")\n",
        "\n",
        "# # Create a more structured DataFrame for analysis\n",
        "# all_words = []\n",
        "# for subject_id, subject_data in subject_dict.items():\n",
        "#     for i, word in enumerate(subject_data['words']):\n",
        "#         all_words.append({\n",
        "#             'subject_id': subject_id,\n",
        "#             'word': word,\n",
        "#             'position': i + 1  # 1-indexed position\n",
        "#         })\n",
        "\n",
        "# df = pd.DataFrame(all_words)\n",
        "\n",
        "# # Display sample of the data\n",
        "# print(\"\\nSample of the data:\")\n",
        "# print(df.head(10))\n",
        "\n",
        "# # ===== Data Visualization and Basic Statistics =====\n",
        "\n",
        "# # Calculate basic statistics similar to Figure 1\n",
        "# print(\"\\nCalculating basic statistics...\")\n",
        "\n",
        "# # Count total and unique words per subject\n",
        "# word_counts = df.groupby('subject_id')['word'].agg(['count', 'nunique'])\n",
        "# word_counts.columns = ['total_words', 'unique_words']\n",
        "# word_counts['repetition_rate'] = 1 - (word_counts['unique_words'] / word_counts['total_words'])\n",
        "\n",
        "# print(\"\\nWord count statistics:\")\n",
        "# print(word_counts.describe())\n",
        "\n",
        "# # Count most common animals\n",
        "# most_common = df['word'].value_counts().head(10)\n",
        "# print(\"\\nMost common animals mentioned:\")\n",
        "# print(most_common)\n",
        "\n",
        "# # Visualization of the data (similar to Figure 1)\n",
        "# def plot_svf_statistics(word_counts, most_common):\n",
        "#     \"\"\"Create plots similar to Figure 1 in the prompt.\"\"\"\n",
        "#     fig, axs = plt.subplots(2, 2, figsize=(15, 12))\n",
        "\n",
        "#     # Plot a: Total vs Unique Words by Subject\n",
        "#     subjects = word_counts.index\n",
        "#     total = word_counts['total_words']\n",
        "#     unique = word_counts['unique_words']\n",
        "\n",
        "#     x = np.arange(len(subjects))\n",
        "#     width = 0.35\n",
        "\n",
        "#     axs[0, 0].bar(x - width/2, total, width, label='Total Words', color='red', alpha=0.7)\n",
        "#     axs[0, 0].bar(x + width/2, unique, width, label='Unique Words', color='blue', alpha=0.7)\n",
        "#     axs[0, 0].set_ylabel('Word Count')\n",
        "#     axs[0, 0].set_title('Total vs. Unique Words by Subject')\n",
        "#     axs[0, 0].set_xticks([])\n",
        "#     axs[0, 0].legend()\n",
        "\n",
        "#     # Plot b: Repetition Rate by Subject\n",
        "#     sorted_rep_rate = word_counts.sort_values('repetition_rate', ascending=False)\n",
        "#     axs[0, 1].bar(np.arange(len(sorted_rep_rate)), sorted_rep_rate['repetition_rate'],\n",
        "#                  color='blue', alpha=0.7)\n",
        "#     axs[0, 1].set_ylabel('Repetition Rate (repetitions/total words)')\n",
        "#     axs[0, 1].set_title('Repetition Rate by Subject')\n",
        "#     axs[0, 1].set_xticks([])\n",
        "\n",
        "#     # Plot c: Distribution of Total Words\n",
        "#     axs[1, 0].hist(total, bins=10, alpha=0.7, color='green', edgecolor='black')\n",
        "#     axs[1, 0].axvline(total.mean(), color='g', linestyle='dashed', linewidth=2, label=f'Mean: {total.mean():.1f}')\n",
        "#     axs[1, 0].axvline(total.median(), color='r', linestyle='dashed', linewidth=2, label=f'Median: {total.median():.1f}')\n",
        "#     axs[1, 0].set_xlabel('Number of Words')\n",
        "#     axs[1, 0].set_ylabel('Frequency')\n",
        "#     axs[1, 0].set_title('Distribution of Total Words Across Subjects')\n",
        "#     axs[1, 0].legend()\n",
        "\n",
        "#     # Plot d: Most Common Animals\n",
        "#     y_pos = np.arange(len(most_common))\n",
        "#     colors = plt.cm.viridis(np.linspace(0, 0.8, len(most_common)))\n",
        "\n",
        "#     axs[1, 1].barh(y_pos, most_common.values, color=colors)\n",
        "#     axs[1, 1].set_yticks(y_pos)\n",
        "#     axs[1, 1].set_yticklabels(most_common.index)\n",
        "#     axs[1, 1].set_xlabel('Frequency')\n",
        "#     axs[1, 1].set_title('Most Common Animals Mentioned Across All Subjects')\n",
        "\n",
        "#     plt.tight_layout()\n",
        "#     return fig\n",
        "\n",
        "# # Plot the SVF statistics\n",
        "# fig = plot_svf_statistics(word_counts, most_common)\n",
        "# plt.show()\n",
        "\n",
        "# # ===== Model Implementation =====\n",
        "\n",
        "# # 1. SoftMax Model\n",
        "# def softmax_model(words, beta=1.0):\n",
        "#     \"\"\"\n",
        "#     Implement the SoftMax model for word selection in SVF.\n",
        "\n",
        "#     Parameters:\n",
        "#     -----------\n",
        "#     words : list\n",
        "#         List of words produced by the subject\n",
        "#     beta : float\n",
        "#         Temperature parameter controlling exploration vs exploitation\n",
        "\n",
        "#     Returns:\n",
        "#     --------\n",
        "#     log_likelihood : float\n",
        "#         Log likelihood of the observed sequence under this model\n",
        "#     probabilities : list\n",
        "#         Probability of each transition under the model\n",
        "#     \"\"\"\n",
        "#     # Get word embeddings\n",
        "#     word_vectors = {word: get_word_vector(word) for word in set(words)}\n",
        "\n",
        "#     log_likelihood = 0\n",
        "#     probabilities = []\n",
        "\n",
        "#     # For first word, we assume uniform probability over all animals\n",
        "#     # This is a simplification - in reality you might use corpus frequency\n",
        "#     probabilities.append(1.0)  # Placeholder probability for first word\n",
        "\n",
        "#     # Calculate likelihood of each subsequent word given the previous word\n",
        "#     for i in range(1, len(words)):\n",
        "#         prev_word = words[i-1]\n",
        "#         current_word = words[i]\n",
        "\n",
        "#         # In a real model, you would consider all possible animal words\n",
        "#         # Here we'll simplify by just considering the actual words used by the subject\n",
        "#         possible_words = list(set(words))\n",
        "\n",
        "#         # Calculate similarity to previous word for all possible next words\n",
        "#         similarities = []\n",
        "#         for word in possible_words:\n",
        "#             sim = cosine_similarity(word_vectors[prev_word], word_vectors[word])\n",
        "#             similarities.append(sim)\n",
        "\n",
        "#         # Apply softmax to calculate probabilities\n",
        "#         similarities = np.array(similarities)\n",
        "#         exp_sim = np.exp(beta * similarities)\n",
        "#         probs = exp_sim / np.sum(exp_sim)\n",
        "\n",
        "#         # Find probability of the actual word chosen\n",
        "#         chosen_idx = possible_words.index(current_word)\n",
        "#         word_prob = probs[chosen_idx]\n",
        "\n",
        "#         # Add to log likelihood\n",
        "#         log_likelihood += np.log(word_prob)\n",
        "#         probabilities.append(word_prob)\n",
        "\n",
        "#     return log_likelihood, probabilities\n",
        "\n",
        "# def fit_softmax_model(words):\n",
        "#     \"\"\"\n",
        "#     Fit the SoftMax model to find the optimal beta parameter.\n",
        "\n",
        "#     Parameters:\n",
        "#     -----------\n",
        "#     words : list\n",
        "#         List of words produced by the subject\n",
        "\n",
        "#     Returns:\n",
        "#     --------\n",
        "#     optimal_beta : float\n",
        "#         The best-fitting beta parameter\n",
        "#     max_log_likelihood : float\n",
        "#         The log likelihood at the optimal beta\n",
        "#     probabilities : list\n",
        "#         Probabilities of each transition under the optimal model\n",
        "#     \"\"\"\n",
        "#     def neg_log_likelihood(beta):\n",
        "#         ll, _ = softmax_model(words, beta=beta)\n",
        "#         return -ll\n",
        "\n",
        "#     # Find the best beta parameter (bounded between 0.1 and 10)\n",
        "#     result = optimize.minimize_scalar(neg_log_likelihood, bounds=(0.1, 10), method='bounded')\n",
        "#     optimal_beta = result.x\n",
        "\n",
        "#     # Calculate the log likelihood and probabilities at the optimal beta\n",
        "#     max_log_likelihood, probabilities = softmax_model(words, beta=optimal_beta)\n",
        "\n",
        "#     return optimal_beta, max_log_likelihood, probabilities\n",
        "\n",
        "# # 2. MVT (Marginal Value Theorem) Model\n",
        "# def identify_clusters(words, threshold=0.6):\n",
        "#     \"\"\"\n",
        "#     Identify semantic clusters in the word sequence.\n",
        "\n",
        "#     Parameters:\n",
        "#     -----------\n",
        "#     words : list\n",
        "#         List of words produced by the subject\n",
        "#     threshold : float\n",
        "#         Similarity threshold for considering words part of the same cluster\n",
        "\n",
        "#     Returns:\n",
        "#     --------\n",
        "#     clusters : list\n",
        "#         List of cluster assignments for each word\n",
        "#     \"\"\"\n",
        "#     # Get word embeddings\n",
        "#     word_vectors = {word: get_word_vector(word) for word in set(words)}\n",
        "\n",
        "#     # Initialize clusters\n",
        "#     clusters = [0]  # First word starts cluster 0\n",
        "#     current_cluster = 0\n",
        "\n",
        "#     # Assign each subsequent word to a cluster\n",
        "#     for i in range(1, len(words)):\n",
        "#         prev_word = words[i-1]\n",
        "#         current_word = words[i]\n",
        "\n",
        "#         # Calculate similarity between current and previous word\n",
        "#         sim = cosine_similarity(word_vectors[prev_word], word_vectors[current_word])\n",
        "\n",
        "#         # If similarity is below threshold, start a new cluster\n",
        "#         if sim < threshold:\n",
        "#             current_cluster += 1\n",
        "\n",
        "#         clusters.append(current_cluster)\n",
        "\n",
        "#     return clusters\n",
        "\n",
        "# def mvt_model(words, giving_up_threshold=0.5, search_cost=0.1, expected_return=1.0):\n",
        "#     \"\"\"\n",
        "#     Implement the Marginal Value Theorem model for cluster switching in SVF.\n",
        "\n",
        "#     Parameters:\n",
        "#     -----------\n",
        "#     words : list\n",
        "#         List of words produced by the subject\n",
        "#     giving_up_threshold : float\n",
        "#         Threshold at which to switch to a new cluster\n",
        "#     search_cost : float\n",
        "#         Cost of searching within the current cluster\n",
        "#     expected_return : float\n",
        "#         Expected return from switching to a new cluster\n",
        "\n",
        "#     Returns:\n",
        "#     --------\n",
        "#     sse : float\n",
        "#         Sum of squared errors between predicted and actual switches\n",
        "#     predicted_switches : list\n",
        "#         Binary indicators of predicted switches at each position\n",
        "#     actual_switches : list\n",
        "#         Binary indicators of actual switches at each position\n",
        "#     \"\"\"\n",
        "#     # Identify actual clusters in the data\n",
        "#     actual_clusters = identify_clusters(words)\n",
        "\n",
        "#     # Create binary switch indicators (1 = switch, 0 = stay)\n",
        "#     actual_switches = [0]  # First word isn't a switch\n",
        "#     for i in range(1, len(words)):\n",
        "#         if actual_clusters[i] != actual_clusters[i-1]:\n",
        "#             actual_switches.append(1)\n",
        "#         else:\n",
        "#             actual_switches.append(0)\n",
        "\n",
        "#     # Get word embeddings\n",
        "#     word_vectors = {word: get_word_vector(word) for word in set(words)}\n",
        "\n",
        "#     # Model each word transition using MVT\n",
        "#     predicted_switches = [0]  # First word isn't a switch\n",
        "#     current_return = expected_return\n",
        "\n",
        "#     for i in range(1, len(words)):\n",
        "#         prev_word = words[i-1]\n",
        "\n",
        "#         # Calculate average similarity to all previously retrieved words in current cluster\n",
        "#         cluster_start = actual_clusters.index(actual_clusters[i-1])\n",
        "#         cluster_words = words[cluster_start:i]\n",
        "\n",
        "#         similarities = []\n",
        "#         for word in set(cluster_words):\n",
        "#             sim = cosine_similarity(word_vectors[prev_word], word_vectors[word])\n",
        "#             similarities.append(sim)\n",
        "\n",
        "#         # Average similarity represents diminishing returns within cluster\n",
        "#         if similarities:\n",
        "#             avg_similarity = np.mean(similarities)\n",
        "#         else:\n",
        "#             avg_similarity = 0\n",
        "\n",
        "#         # Current return decreases with each word in the cluster\n",
        "#         current_return = current_return - search_cost\n",
        "\n",
        "#         # Predict switch based on MVT\n",
        "#         if current_return < giving_up_threshold:\n",
        "#             # Predict a switch\n",
        "#             predicted_switches.append(1)\n",
        "#             # Reset current return for new cluster\n",
        "#             current_return = expected_return\n",
        "#         else:\n",
        "#             # Predict staying in the same cluster\n",
        "#             predicted_switches.append(0)\n",
        "\n",
        "#     # Calculate sum of squared errors\n",
        "#     sse = sum((np.array(actual_switches) - np.array(predicted_switches))**2)\n",
        "\n",
        "#     return sse, predicted_switches, actual_switches\n",
        "\n",
        "# def fit_mvt_model(words):\n",
        "#     \"\"\"\n",
        "#     Fit the MVT model to find optimal parameters.\n",
        "\n",
        "#     Parameters:\n",
        "#     -----------\n",
        "#     words : list\n",
        "#         List of words produced by the subject\n",
        "\n",
        "#     Returns:\n",
        "#     --------\n",
        "#     optimal_params : dict\n",
        "#         The best-fitting MVT parameters\n",
        "#     min_sse : float\n",
        "#         The SSE at the optimal parameters\n",
        "#     predicted_switches : list\n",
        "#         Predicted switches under the optimal model\n",
        "#     actual_switches : list\n",
        "#         Actual switches in the data\n",
        "#     \"\"\"\n",
        "#     def mvt_error(params):\n",
        "#         giving_up_threshold, search_cost, expected_return = params\n",
        "#         sse, _, _ = mvt_model(words,\n",
        "#                              giving_up_threshold=giving_up_threshold,\n",
        "#                              search_cost=search_cost,\n",
        "#                              expected_return=expected_return)\n",
        "#         return sse\n",
        "\n",
        "#     # Find the best parameters\n",
        "#     # Initial guess and bounds for parameters\n",
        "#     initial_guess = [0.5, 0.1, 1.0]\n",
        "#     bounds = [(0.1, 0.9), (0.01, 0.5), (0.5, 2.0)]\n",
        "\n",
        "#     result = optimize.minimize(mvt_error, initial_guess, bounds=bounds, method='L-BFGS-B')\n",
        "#     optimal_params = result.x\n",
        "\n",
        "#     # Calculate SSE and predictions at the optimal parameters\n",
        "#     min_sse, predicted_switches, actual_switches = mvt_model(\n",
        "#         words,\n",
        "#         giving_up_threshold=optimal_params[0],\n",
        "#         search_cost=optimal_params[1],\n",
        "#         expected_return=optimal_params[2]\n",
        "#     )\n",
        "\n",
        "#     # Package results\n",
        "#     param_dict = {\n",
        "#         'giving_up_threshold': optimal_params[0],\n",
        "#         'search_cost': optimal_params[1],\n",
        "#         'expected_return': optimal_params[2]\n",
        "#     }\n",
        "\n",
        "#     return param_dict, min_sse, predicted_switches, actual_switches\n",
        "\n",
        "# # ===== Model Comparison =====\n",
        "\n",
        "# def compare_models(subject_dict):\n",
        "#     \"\"\"\n",
        "#     Compare SoftMax and MVT models for all subjects.\n",
        "\n",
        "#     Parameters:\n",
        "#     -----------\n",
        "#     subject_dict : dict\n",
        "#         Dictionary mapping subject IDs to their word sequences\n",
        "\n",
        "#     Returns:\n",
        "#     --------\n",
        "#     results_df : DataFrame\n",
        "#         DataFrame with model comparison results for all subjects\n",
        "#     \"\"\"\n",
        "#     results = []\n",
        "\n",
        "#     for subject_id, subject_data in tqdm(subject_dict.items(), desc=\"Comparing models\"):\n",
        "#         words = subject_data['words']\n",
        "\n",
        "#         # Skip subjects with too few words\n",
        "#         if len(words) < 10:\n",
        "#             print(f\"Skipping subject {subject_id} with only {len(words)} words\")\n",
        "#             continue\n",
        "\n",
        "#         # Fit SoftMax model\n",
        "#         try:\n",
        "#             sm_beta, sm_ll, sm_probs = fit_softmax_model(words)\n",
        "#             sm_n_params = 1  # Beta is the only parameter\n",
        "\n",
        "#             # Calculate AIC and BIC for SoftMax\n",
        "#             sm_aic = -2 * sm_ll + 2 * sm_n_params\n",
        "#             sm_bic = -2 * sm_ll + sm_n_params * np.log(len(words))\n",
        "\n",
        "#             # Calculate AICc for small sample sizes\n",
        "#             sm_aicc = sm_aic + (2 * sm_n_params**2 + 2 * sm_n_params) / (len(words) - sm_n_params - 1)\n",
        "\n",
        "#             # Calculate R² for SoftMax (pseudo-R² based on null model)\n",
        "#             # Null model assumes uniform probability for all words\n",
        "#             null_prob = 1.0 / len(set(words))\n",
        "#             null_ll = len(words) * np.log(null_prob)\n",
        "#             sm_r2 = 1 - (sm_ll / null_ll)\n",
        "#         except Exception as e:\n",
        "#             print(f\"Error fitting SoftMax for subject {subject_id}: {e}\")\n",
        "#             continue\n",
        "\n",
        "#         # Fit MVT model\n",
        "#         try:\n",
        "#             mvt_params, mvt_sse, mvt_pred_switches, mvt_actual_switches = fit_mvt_model(words)\n",
        "#             mvt_n_params = 3  # Three parameters in MVT\n",
        "\n",
        "#             # Convert SSE to pseudo-log-likelihood for fair comparison\n",
        "#             # Assuming normally distributed errors with constant variance\n",
        "#             n = len(words)\n",
        "#             mvt_ll = -n/2 * np.log(mvt_sse/n) - n/2 * (np.log(2*np.pi) + 1)\n",
        "\n",
        "#             # Calculate AIC and BIC for MVT\n",
        "#             mvt_aic = -2 * mvt_ll + 2 * mvt_n_params\n",
        "#             mvt_bic = -2 * mvt_ll + mvt_n_params * np.log(len(words))\n",
        "\n",
        "#             # Calculate AICc for small sample sizes\n",
        "#             mvt_aicc = mvt_aic + (2 * mvt_n_params**2 + 2 * mvt_n_params) / (len(words) - mvt_n_params - 1)\n",
        "\n",
        "#             # Calculate R² for MVT\n",
        "#             # For MVT, R² is based on the null model predicting no switches\n",
        "#             null_sse = sum(np.array(mvt_actual_switches)**2)  # Null model predicts all 0s\n",
        "#             mvt_r2 = 1 - (mvt_sse / null_sse) if null_sse > 0 else 0\n",
        "#         except Exception as e:\n",
        "#             print(f\"Error fitting MVT for subject {subject_id}: {e}\")\n",
        "#             continue\n",
        "\n",
        "#         # Determine which model is better\n",
        "#         delta_aic = sm_aic - mvt_aic\n",
        "#         delta_bic = sm_bic - mvt_bic\n",
        "#         delta_aicc = sm_aicc - mvt_aicc\n",
        "\n",
        "#         if abs(delta_aic) < 2:\n",
        "#             aic_evidence = \"Both models equally supported\"\n",
        "#         elif delta_aic > 0:\n",
        "#             aic_evidence = \"Strong evidence for MVT\" if delta_aic > 6 else \"Moderate evidence for MVT\"\n",
        "#         else:\n",
        "#             aic_evidence = \"Strong evidence for SoftMax\" if delta_aic < -6 else \"Moderate evidence for SoftMax\"\n",
        "\n",
        "#         # Store results\n",
        "#         results.append({\n",
        "#             'subject_id': subject_id,\n",
        "#             'n_words': len(words),\n",
        "#             'n_unique_words': len(set(words)),\n",
        "\n",
        "#             # SoftMax results\n",
        "#             'sm_beta': sm_beta,\n",
        "#             'sm_log_likelihood': sm_ll,\n",
        "#             'sm_aic': sm_aic,\n",
        "#             'sm_bic': sm_bic,\n",
        "#             'sm_aicc': sm_aicc,\n",
        "#             'sm_r2': sm_r2,\n",
        "\n",
        "#             # MVT results\n",
        "#             'mvt_giving_up_threshold': mvt_params['giving_up_threshold'],\n",
        "#             'mvt_search_cost': mvt_params['search_cost'],\n",
        "#             'mvt_expected_return': mvt_params['expected_return'],\n",
        "#             'mvt_sse': mvt_sse,\n",
        "#             'mvt_log_likelihood': mvt_ll,\n",
        "#             'mvt_aic': mvt_aic,\n",
        "#             'mvt_bic': mvt_bic,\n",
        "#             'mvt_aicc': mvt_aicc,\n",
        "#             'mvt_r2': mvt_r2,\n",
        "\n",
        "#             # Model comparison\n",
        "#             'delta_aic': delta_aic,\n",
        "#             'delta_bic': delta_bic,\n",
        "#             'delta_aicc': delta_aicc,\n",
        "#             'aic_evidence': aic_evidence\n",
        "#         })\n",
        "\n",
        "#     # Convert to DataFrame\n",
        "#     results_df = pd.DataFrame(results)\n",
        "\n",
        "#     return results_df\n",
        "\n",
        "# # Run the model comparison\n",
        "# print(\"\\nComparing SoftMax and MVT models for all subjects...\")\n",
        "# results_df = compare_models(subject_dict)\n",
        "\n",
        "# # ===== Results Visualization =====\n",
        "\n",
        "# def visualize_model_comparison(results_df):\n",
        "#     \"\"\"Visualize the results of the model comparison.\"\"\"\n",
        "#     # Create plots to visualize the results\n",
        "#     fig, axs = plt.subplots(2, 2, figsize=(15, 12))\n",
        "\n",
        "#     # Plot 1: Distribution of delta AIC\n",
        "#     sns.histplot(results_df['delta_aic'], ax=axs[0, 0], kde=True)\n",
        "#     axs[0, 0].axvline(x=0, color='r', linestyle='--')\n",
        "#     axs[0, 0].axvline(x=2, color='g', linestyle='--')\n",
        "#     axs[0, 0].axvline(x=-2, color='g', linestyle='--')\n",
        "#     axs[0, 0].set_xlabel('Delta AIC (SoftMax - MVT)')\n",
        "#     axs[0, 0].set_ylabel('Frequency')\n",
        "#     axs[0, 0].set_title('Distribution of Delta AIC\\nNegative values favor SoftMax, positive values favor MVT')\n",
        "\n",
        "#     # Plot 2: Model preference pie chart\n",
        "#     model_counts = results_df['aic_evidence'].value_counts()\n",
        "#     axs[0, 1].pie(model_counts, labels=model_counts.index, autopct='%1.1f%%',\n",
        "#                  colors=sns.color_palette(\"Set2\"))\n",
        "#     axs[0, 1].set_title('Model Preference Based on AIC')\n",
        "\n",
        "#     # Plot 3: SoftMax beta vs. number of words\n",
        "#     sns.scatterplot(x='n_words', y='sm_beta', hue='aic_evidence', data=results_df, ax=axs[1, 0])\n",
        "#     axs[1, 0].set_xlabel('Number of Words')\n",
        "#     axs[1, 0].set_ylabel('SoftMax Beta')\n",
        "#     axs[1, 0].set_title('SoftMax Beta vs. Sequence Length')\n",
        "\n",
        "#     # Plot 4: Relationship between MVT threshold and SoftMax beta\n",
        "#     g = sns.scatterplot(x='sm_beta', y='mvt_giving_up_threshold',\n",
        "#                         hue='aic_evidence', data=results_df, ax=axs[1, 1])\n",
        "#     axs[1, 1].set_xlabel('SoftMax Beta')\n",
        "#     axs[1, 1].set_ylabel('MVT Giving-Up Threshold')\n",
        "#     axs[1, 1].set_title('Relationship Between Model Parameters')\n",
        "#     plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "\n",
        "#     plt.tight_layout()\n",
        "#     return fig\n",
        "\n",
        "# # Visualize the model comparison results\n",
        "# if not results_df.empty:\n",
        "#     fig_comparison = visualize_model_comparison(results_df)\n",
        "#     plt.show()\n",
        "# else:\n",
        "#     print(\"No results to visualize. Check for errors in model fitting.\")\n",
        "\n",
        "# # Additional analysis: Cross-validation\n",
        "# def cross_validate_models(subject_dict, k=5):\n",
        "#     \"\"\"\n",
        "#     Perform k-fold cross-validation to assess predictive accuracy.\n",
        "\n",
        "#     Parameters:\n",
        "#     -----------\n",
        "#     subject_dict : dict\n",
        "#         Dictionary mapping subject IDs to their word sequences\n",
        "#     k : int\n",
        "#         Number of folds\n",
        "\n",
        "#     Returns:\n",
        "#     --------\n",
        "#     cv_results : DataFrame\n",
        "#         DataFrame with cross-validation results\n",
        "#     \"\"\"\n",
        "#     cv_results = []\n",
        "\n",
        "#     for subject_id, subject_data in tqdm(subject_dict.items(), desc=\"Cross-validating\"):\n",
        "#         words = subject_data['words']\n",
        "\n",
        "#         # Skip subjects with too few words\n",
        "#         if len(words) < 10:\n",
        "#             continue\n",
        "\n",
        "#         # Create k folds\n",
        "#         n_words = len(words)\n",
        "#         fold_size = n_words // k\n",
        "\n",
        "#         # Skip if fold size is too small\n",
        "#         if fold_size < 2:\n",
        "#             print(f\"Skipping subject {subject_id} for CV: too few words per fold\")\n",
        "#             continue\n",
        "\n",
        "#         sm_cv_ll = []\n",
        "#         mvt_cv_sse = []\n",
        "\n",
        "#         for i in range(k):\n",
        "#             # Define test and training sets\n",
        "#             test_start = i * fold_size\n",
        "#             test_end = (i+1) * fold_size if i < k-1 else n_words\n",
        "\n",
        "#             test_indices = list(range(test_start, test_end))\n",
        "#             train_indices = [j for j in range(n_words) if j not in test_indices]\n",
        "\n",
        "#             train_words = [words[j] for j in train_indices]\n",
        "#             test_words = [words[j] for j in test_indices]\n",
        "\n",
        "#             # Skip if too few words in train or test\n",
        "#             if len(train_words) < 5 or len(test_words) < 3:\n",
        "#                 continue\n",
        "\n",
        "#             # Fit SoftMax on training data\n",
        "#             try:\n",
        "#                 sm_beta, _, _ = fit_softmax_model(train_words)\n",
        "\n",
        "#                 # Test on test data\n",
        "#                 test_ll, _ = softmax_model(test_words, beta=sm_beta)\n",
        "#                 sm_cv_ll.append(test_ll)\n",
        "#             except Exception as e:\n",
        "#                 print(f\"SoftMax CV error for subject {subject_id}, fold {i}: {e}\")\n",
        "\n",
        "#             # Fit MVT on training data\n",
        "#             try:\n",
        "#                 mvt_params, _, _, _ = fit_mvt_model(train_words)\n",
        "\n",
        "#                 # Test on test data\n",
        "#                 test_sse, _, _ = mvt_model(\n",
        "#                     test_words,\n",
        "#                     giving_up_threshold=mvt_params['giving_up_threshold'],\n",
        "#                     search_cost=mvt_params['search_cost'],\n",
        "#                     expected_return=mvt_params['expected_return']\n",
        "#                 )\n",
        "#                 mvt_cv_sse.append(test_sse)\n",
        "#             except Exception as e:\n",
        "#                 print(f\"MVT CV error for subject {subject_id}, fold {i}: {e}\")\n",
        "\n",
        "#         # Calculate average CV performance\n",
        "#         if sm_cv_ll and mvt_cv_sse:\n",
        "#             avg_sm_cv_ll = np.mean(sm_cv_ll)\n",
        "#             avg_mvt_cv_sse = np.mean(mvt_cv_sse)\n",
        "\n",
        "#             # Convert MVT SSE to pseudo-log-likelihood\n",
        "#             avg_n_test = fold_size\n",
        "#             avg_mvt_cv_ll = -avg_n_test/2 * np.log(avg_mvt_cv_sse/avg_n_test) - avg_n_test/2 * (np.log(2*np.pi) + 1)\n",
        "\n",
        "#             # Determine which model has better CV performance\n",
        "#             cv_delta_ll = avg_sm_cv_ll - avg_mvt_cv_ll\n",
        "\n",
        "#             if abs(cv_delta_ll) < 2:\n",
        "#                 cv_evidence = \"Both models equally supported\"\n",
        "#             elif cv_delta_ll > 0:\n",
        "#                 cv_evidence = \"Strong evidence for SoftMax\" if cv_delta_ll > 6 else \"Moderate evidence for SoftMax\"\n",
        "#             else:\n",
        "#                 cv_evidence = \"Strong evidence for MVT\" if cv_delta_ll < -6 else \"Moderate evidence for MVT\"\n",
        "\n",
        "#             cv_results.append({\n",
        "#                 'subject_id': subject_id,\n",
        "#                 'avg_sm_cv_ll': avg_sm_cv_ll,\n",
        "#                 'avg_mvt_cv_sse': avg_mvt_cv_sse,\n",
        "#                 'avg_mvt_cv_ll': avg_mvt_cv_ll,\n",
        "#                 'cv_delta_ll': cv_delta_ll,\n",
        "#                 'cv_evidence': cv_evidence\n",
        "#             })\n",
        "\n",
        "#     # Convert to DataFrame\n",
        "#     cv_results_df = pd.DataFrame(cv_results)\n",
        "\n",
        "#     return cv_results_df\n",
        "\n",
        "# # Run cross-validation for subjects with enough data\n",
        "# print(\"\\nPerforming cross-validation...\")\n",
        "# cv_results_df = cross_validate_models(subject_dict, k=3)  # Using k=3 for smaller sequences\n",
        "\n",
        "# # Merge with main results\n",
        "# if not results_df.empty and not cv_results_df.empty:\n",
        "#     full_results = pd.merge(results_df, cv_results_df, on='subject_id', how='inner')\n",
        "\n",
        "#     # Compare model evidence from fitting vs. cross-validation\n",
        "#     if not full_results.empty:\n",
        "#         agreement = (full_results['aic_evidence'] == full_results['cv_evidence']).mean()\n",
        "#         print(f\"\\nAgreement between AIC and CV evidence: {agreement:.2%}\")\n",
        "\n",
        "#         # Visualize cross-validation results\n",
        "#         plt.figure(figsize=(10, 6))\n",
        "#         sns.countplot(y='cv_evidence', data=full_results)\n",
        "#         plt.title('Model Preference Based on Cross-Validation')\n",
        "#         plt.tight_layout()\n",
        "#         plt.show()\n",
        "# else:\n",
        "#     print(\"Unable to perform cross-validation comparison due to insufficient data.\")\n",
        "\n",
        "# # ===== Individual Analysis =====\n",
        "\n",
        "# def analyze_individual_subject(subject_id, words, results_df, cv_results_df=None):\n",
        "#     \"\"\"Detailed analysis of a single subject.\"\"\"\n",
        "#     # Get results for this subject\n",
        "#     if subject_id not in results_df['subject_id'].values:\n",
        "#         print(f\"No results available for subject {subject_id}\")\n",
        "#         return None\n",
        "\n",
        "#     subj_results = results_df[results_df['subject_id'] == subject_id].iloc[0]\n",
        "\n",
        "#     print(f\"\\nDetailed analysis for Subject {subject_id}\")\n",
        "#     print(f\"Number of words: {len(words)}\")\n",
        "#     print(f\"Number of unique words: {len(set(words))}\")\n",
        "\n",
        "#     print(\"\\nSoftMax Model:\")\n",
        "#     print(f\"  Beta: {subj_results['sm_beta']:.4f}\")\n",
        "#     print(f\"  Log-likelihood: {subj_results['sm_log_likelihood']:.4f}\")\n",
        "#     print(f\"  AIC: {subj_results['sm_aic']:.4f}\")\n",
        "#     print(f\"  R²: {subj_results['sm_r2']:.4f}\")\n",
        "\n",
        "#     print(\"\\nMVT Model:\")\n",
        "#     print(f\"  Giving-up threshold: {subj_results['mvt_giving_up_threshold']:.4f}\")\n",
        "#     print(f\"  Search cost: {subj_results['mvt_search_cost']:.4f}\")\n",
        "#     print(f\"  Expected return: {subj_results['mvt_expected_return']:.4f}\")\n",
        "#     print(f\"  SSE: {subj_results['mvt_sse']:.4f}\")\n",
        "#     print(f\"  Pseudo-log-likelihood: {subj_results['mvt_log_likelihood']:.4f}\")\n",
        "#     print(f\"  AIC: {subj_results['mvt_aic']:.4f}\")\n",
        "#     print(f\"  R²: {subj_results['mvt_r2']:.4f}\")\n",
        "\n",
        "#     print(\"\\nModel Comparison:\")\n",
        "#     print(f\"  Delta AIC: {subj_results['delta_aic']:.4f}\")\n",
        "#     print(f\"  Evidence: {subj_results['aic_evidence']}\")\n",
        "\n",
        "#     if cv_results_df is not None and subject_id in cv_results_df['subject_id'].values:\n",
        "#         cv_result = cv_results_df[cv_results_df['subject_id'] == subject_id].iloc[0]\n",
        "#         print(\"\\nCross-Validation Results:\")\n",
        "#         print(f\"  Average SoftMax CV log-likelihood: {cv_result['avg_sm_cv_ll']:.4f}\")\n",
        "#         print(f\"  Average MVT CV SSE: {cv_result['avg_mvt_cv_sse']:.4f}\")\n",
        "#         print(f\"  CV Evidence: {cv_result['cv_evidence']}\")\n",
        "\n",
        "#     # Visualize the subject's words and model predictions\n",
        "#     plt.figure(figsize=(12, 8))\n",
        "\n",
        "#     # Word sequence\n",
        "#     plt.subplot(2, 1, 1)\n",
        "#     plt.title(f\"Word Sequence for Subject {subject_id}\")\n",
        "#     plt.bar(range(len(words)), [1] * len(words), color='lightblue')\n",
        "#     plt.xticks(range(len(words)), words, rotation=45, ha='right')\n",
        "#     plt.ylabel(\"Occurrence\")\n",
        "\n",
        "#     # Model predictions\n",
        "#     plt.subplot(2, 1, 2)\n",
        "\n",
        "#     # Refit models to get predictions\n",
        "#     _, _, sm_probs = softmax_model(words, beta=subj_results['sm_beta'])\n",
        "\n",
        "#     _, mvt_pred_switches, mvt_actual_switches = mvt_model(\n",
        "#         words,\n",
        "#         giving_up_threshold=subj_results['mvt_giving_up_threshold'],\n",
        "#         search_cost=subj_results['mvt_search_cost'],\n",
        "#         expected_return=subj_results['mvt_expected_return']\n",
        "#     )\n",
        "\n",
        "#     plt.plot(range(len(sm_probs)), sm_probs, 'b-', label='SoftMax Probability')\n",
        "#     plt.plot(range(len(mvt_actual_switches)), mvt_actual_switches, 'r-', label='Actual Switches')\n",
        "#     plt.plot(range(len(mvt_pred_switches)), mvt_pred_switches, 'g--', label='MVT Predicted Switches')\n",
        "\n",
        "#     plt.xlabel(\"Word Position\")\n",
        "#     plt.ylabel(\"Probability / Switch\")\n",
        "#     plt.legend()\n",
        "\n",
        "#     plt.tight_layout()\n",
        "#     plt.show()\n",
        "\n",
        "#     return subj_results\n",
        "\n",
        "# # Analyze an example subject\n",
        "# if not results_df.empty:\n",
        "#     # Find a subject with clear model preference\n",
        "#     if 'Strong evidence for SoftMax' in results_df['aic_evidence'].values:\n",
        "#         example_subject_id = results_df[results_df['aic_evidence'] == 'Strong evidence for SoftMax']['subject_id'].iloc[0]\n",
        "#     elif 'Strong evidence for MVT' in results_df['aic_evidence'].values:\n",
        "#         example_subject_id = results_df[results_df['aic_evidence'] == 'Strong evidence for MVT']['subject_id'].iloc[0]\n",
        "#     else:\n",
        "#         example_subject_id = results_df['subject_id'].iloc[0]\n",
        "\n",
        "#     example_words = subject_dict[example_subject_id]['words']\n",
        "\n",
        "#     print(\"\\nAnalyzing an example subject...\")\n",
        "#     example_analysis = analyze_individual_subject(example_subject_id, example_words, results_df, cv_results_df)\n",
        "\n",
        "# # ===== Summary of Findings =====\n",
        "\n",
        "# if not results_df.empty:\n",
        "#     print(\"\\nSummary of Findings:\")\n",
        "#     print(\"-\" * 50)\n",
        "\n",
        "#     # Overall model preference\n",
        "#     model_preference = results_df['aic_evidence'].value_counts(normalize=True)\n",
        "#     print(\"Model Preference Based on AIC:\")\n",
        "#     for model, prop in model_preference.items():\n",
        "#         print(f\"  {model}: {prop:.2%}\")\n",
        "\n",
        "#     # Cross-validation agreement\n",
        "#     if not cv_results_df.empty:\n",
        "#         cv_preference = cv_results_df['cv_evidence'].value_counts(normalize=True)\n",
        "#         print(\"\\nModel Preference Based on Cross-Validation:\")\n",
        "#         for model, prop in cv_preference.items():\n",
        "#             print(f\"  {model}: {prop:.2%}\")\n",
        "\n",
        "#         # Check agreement between AIC and CV\n",
        "#         if not full_results.empty:\n",
        "#             agreement = (full_results['aic_evidence'] == full_results['cv_evidence']).mean()\n",
        "#             print(f\"\\nAgreement between AIC and CV evidence: {agreement:.2%}\")\n",
        "\n",
        "#     # Parameter distributions\n",
        "#     print(\"\\nParameter Distributions:\")\n",
        "#     print(f\"  SoftMax Beta: Mean = {results_df['sm_beta'].mean():.4f}, SD = {results_df['sm_beta'].std():.4f}\")\n",
        "#     print(f\"  MVT Giving-up Threshold: Mean = {results_df['mvt_giving_up_threshold'].mean():.4f}, SD = {results_df['mvt_giving_up_threshold'].std():.4f}\")\n",
        "\n",
        "#     # Correlation between parameters\n",
        "#     sm_mvt_corr = results_df[['sm_beta', 'mvt_giving_up_threshold']].corr().iloc[0, 1]\n",
        "#     print(f\"\\nCorrelation between SoftMax Beta and MVT Threshold: {sm_mvt_corr:.4f}\")\n",
        "\n",
        "#     # Delta AIC analysis\n",
        "#     print(f\"\\nMean Delta AIC: {results_df['delta_aic'].mean():.4f}\")\n",
        "#     print(f\"Standard Deviation of Delta AIC: {results_df['delta_aic'].std():.4f}\")\n",
        "\n",
        "#     print(\"\\nConclusions:\")\n",
        "#     if results_df['delta_aic'].mean() < -2:\n",
        "#         print(\"Overall, the SoftMax model provides a better account of the exploration-exploitation dynamics in semantic verbal fluency for this dataset of PD patients.\")\n",
        "#     elif results_df['delta_aic'].mean() > 2:\n",
        "#         print(\"Overall, the MVT model provides a better account of the exploration-exploitation dynamics in semantic verbal fluency for this dataset of PD patients.\")\n",
        "#     else:\n",
        "#         print(\"Both models provide comparable accounts of the exploration-exploitation dynamics in semantic verbal fluency for this dataset of PD patients.\")\n",
        "\n",
        "#     # Save results to CSV\n",
        "#     results_df.to_csv('softmax_mvt_comparison_results.csv', index=False)\n",
        "#     print(\"\\nDetailed results saved to 'softmax_mvt_comparison_results.csv'\")\n",
        "\n",
        "#     if not cv_results_df.empty:\n",
        "#         cv_results_df.to_csv('cross_validation_results.csv', index=False)\n",
        "#         print(\"Cross-validation results saved to 'cross_validation_results.csv'\")\n",
        "# else:\n",
        "#     print(\"No valid results were produced. Check the model implementation and data.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gLQyKUNRza33"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Sample data (replace with your actual data)\n",
        "data = {'Subject': ['PD00020'],\n",
        "        'Number of words': [20],\n",
        "        'Number of unique words': [14],\n",
        "        'SoftMax Beta': [1.0646],\n",
        "        'SoftMax Log-likelihood': [-49.3998],\n",
        "        'SoftMax AIC': [100.7995],\n",
        "        'SoftMax R²': [0.0641],\n",
        "        'MVT Giving-up threshold': [0.5],\n",
        "        'MVT Search cost': [0.1],\n",
        "        'MVT Expected return': [1.0],\n",
        "        'MVT SSE': [12.0],\n",
        "        'MVT Pseudo-log-likelihood': [-23.2705],\n",
        "        'MVT AIC': [52.5410],\n",
        "        'MVT R²': [0.0769],\n",
        "        'Delta AIC': [48.2585],\n",
        "        'Evidence': ['Strong evidence for MVT'],\n",
        "        'Average SoftMax CV log-likelihood': [-11.1623],\n",
        "        'Average MVT CV SSE': [4.0],\n",
        "        'CV Evidence': ['Moderate evidence for MVT']}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Display basic statistics\n",
        "print(df.describe())\n",
        "\n",
        "# Visualizations\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(['SoftMax', 'MVT'], [df['SoftMax AIC'][0], df['MVT AIC'][0]])\n",
        "plt.title('AIC Comparison for Subject PD00020')\n",
        "plt.ylabel('AIC')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(['SoftMax', 'MVT'], [df['SoftMax R²'][0], df['MVT R²'][0]])\n",
        "plt.title('R² Comparison for Subject PD00020')\n",
        "plt.ylabel('R²')\n",
        "plt.show()\n",
        "\n",
        "#Further analysis, add more visualizations and statistics as needed based on your data.\n",
        "#Example: Scatter plot matrix for relevant variables.\n",
        "#Example: Box plots for model parameters.\n",
        "\n",
        "# If you have multiple subjects, you can group and analyze by subject,\n",
        "# perform comparisons between subjects etc.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Application of the Marginal Value Theorem (MVT) to semantic search dynamics"
      ],
      "metadata": {
        "id": "BdZ8HRhQqsQS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "u77VwGH3028P"
      },
      "outputs": [],
      "source": [
        "# Create a combined figure with all three plots\n",
        "fig = plt.figure(figsize=(12, 9))\n",
        "gs = fig.add_gridspec(2, 2, height_ratios=[1, 1.2])\n",
        "\n",
        "# First plot: MVT Rate Visualization\n",
        "ax1 = fig.add_subplot(gs[0, 0])\n",
        "\n",
        "# Parameters\n",
        "a = 1.6  # Initial rate\n",
        "b = 0.5  # Decay rate\n",
        "t_opt = 2.0  # Optimal time\n",
        "t = np.linspace(0, 10, 1000)  # Time vector with high resolution for smooth curves\n",
        "\n",
        "# Calculate rates\n",
        "marginal_rate = a * np.exp(-b * t)  # Exponential decay\n",
        "average_rate = (a/b) * (1 - np.exp(-b * t_opt)) / t_opt  # Average rate at optimal time\n",
        "\n",
        "# Plot the curves\n",
        "ax1.plot(t, marginal_rate, '-', color='#0033A0', linewidth=2.5, label='Marginal Rate', zorder=5)\n",
        "ax1.plot(t, np.ones_like(t) * average_rate, '--', color='#FF8C00', linewidth=2, label='Average Rate', zorder=4)\n",
        "ax1.axvline(x=t_opt, color='#FF0066', linestyle=':', linewidth=1.8, alpha=0.7, zorder=3)\n",
        "optimal_rate = marginal_rate[np.abs(t - t_opt).argmin()]\n",
        "ax1.plot(t_opt, optimal_rate, 'o', markersize=8, color='#FF0066', markeredgecolor='black', markeredgewidth=1, zorder=6)\n",
        "\n",
        "# Add equation and annotation\n",
        "eq_box = dict(boxstyle='round,pad=0.5', facecolor='white', alpha=0.9, edgecolor='#CCCCCC')\n",
        "ax1.text(0.95, 0.95, r\"$g(t^*) = \\frac{g(t^*)}{t^*+\\tau}$\",\n",
        "        transform=ax1.transAxes, fontsize=12, ha='right', va='top',\n",
        "        bbox=eq_box, zorder=7)\n",
        "\n",
        "anno_box = dict(boxstyle=\"round,pad=0.4\", fc='white', ec=\"#999999\", lw=1)\n",
        "ax1.annotate('Optimal time = 2.00', xy=(t_opt, optimal_rate), xytext=(4, 0.35),\n",
        "            arrowprops=dict(arrowstyle='->', lw=1.2, color='black', shrinkA=0, shrinkB=5),\n",
        "            fontsize=10, bbox=anno_box, zorder=7)\n",
        "\n",
        "# Configure the plot\n",
        "ax1.set_xlabel('Time in Patch', fontweight='bold')\n",
        "ax1.set_ylabel('Rate (items/time)', fontweight='bold')\n",
        "ax1.set_title('Marginal Value Theorem - Rate Visualization', fontweight='bold')\n",
        "ax1.set_xlim(0, 10)\n",
        "ax1.set_ylim(0, 1.6)\n",
        "ax1.grid(True, linestyle='--', alpha=0.3, linewidth=0.8, zorder=0)\n",
        "ax1.spines['top'].set_visible(False)\n",
        "ax1.spines['right'].set_visible(False)\n",
        "ax1.xaxis.set_minor_locator(MultipleLocator(0.5))\n",
        "ax1.yaxis.set_minor_locator(MultipleLocator(0.1))\n",
        "ax1.legend(frameon=True, loc='upper right', framealpha=0.9, edgecolor='#CCCCCC', fancybox=True, fontsize=10)\n",
        "\n",
        "# Second plot: Effect of Threshold on Exploitation\n",
        "ax2 = fig.add_subplot(gs[0, 1])\n",
        "\n",
        "# Data\n",
        "thresholds = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
        "exp_tc_005 = [80, 60, 53, 67, 53, 60, 53, 53, 47]  # Travel Cost = 0.05\n",
        "exp_tc_01 = [79, 59, 52, 65, 52, 59, 52, 52, 52]   # Travel Cost = 0.1\n",
        "exp_tc_02 = [78, 58, 51, 63, 51, 58, 51, 51, 51]   # Travel Cost = 0.2\n",
        "exp_tc_03 = [80, 60, 53, 67, 53, 60, 53, 53, 53]   # Travel Cost = 0.3\n",
        "empirical = 52.44  # Empirical value\n",
        "\n",
        "# Plot data\n",
        "ax2.plot(thresholds, exp_tc_005, 'o-', color='#1b9e77', linewidth=2, markersize=6, label='Travel Cost = 0.05', zorder=5)\n",
        "ax2.plot(thresholds, exp_tc_01, 'o-', color='#d95f02', linewidth=2, markersize=6, label='Travel Cost = 0.1', zorder=4)\n",
        "ax2.plot(thresholds, exp_tc_02, 'o-', color='#7570b3', linewidth=2, markersize=6, label='Travel Cost = 0.2', zorder=3)\n",
        "ax2.plot(thresholds, exp_tc_03, 'o-', color='#e7298a', linewidth=2, markersize=6, label='Travel Cost = 0.3', zorder=2)\n",
        "ax2.axhline(y=empirical, color='#e41a1c', linestyle='--', linewidth=2, label=f'Empirical ({empirical}%)', zorder=1)\n",
        "\n",
        "# Configure plot\n",
        "ax2.set_xlabel('Threshold Parameter', fontweight='bold')\n",
        "ax2.set_ylabel('Exploitation Percentage (%)', fontweight='bold')\n",
        "ax2.set_title('MVT Model: Effect of Threshold on Exploitation Percentage', fontweight='bold')\n",
        "ax2.set_xlim(0.05, 0.95)\n",
        "ax2.set_ylim(40, 85)\n",
        "ax2.grid(True, linestyle='--', alpha=0.3, linewidth=0.8)\n",
        "ax2.xaxis.set_minor_locator(MultipleLocator(0.05))\n",
        "ax2.yaxis.set_minor_locator(MultipleLocator(5))\n",
        "ax2.spines['top'].set_visible(False)\n",
        "ax2.spines['right'].set_visible(False)\n",
        "ax2.legend(frameon=True, loc='upper right', framealpha=0.9, edgecolor='#CCCCCC', fancybox=True, fontsize=10)\n",
        "\n",
        "# Third plot: Simulated Search Sequence\n",
        "ax3 = fig.add_subplot(gs[1, :])\n",
        "\n",
        "# Parameters\n",
        "params_text = \"Parameters: a=1.0, b=0.5, τ=2.0\\nOptimal time per patch: 2.00\"\n",
        "\n",
        "# Patch data\n",
        "patches = [\n",
        "    [0.0, 2.0, 0.0, 1.5],    # Patch 1\n",
        "    [2.5, 5.0, 1.5, 2.9],    # Patch 2\n",
        "    [5.5, 7.5, 2.9, 4.2],    # Patch 3\n",
        "    [8.0, 12.5, 4.2, 5.7],   # Patch 4\n",
        "    [13.0, 17.0, 5.7, 7.1]    # Patch 5\n",
        "]\n",
        "\n",
        "# Colors\n",
        "patch_colors = ['#377eb8', '#ff7f00', '#4daf4a', '#e41a1c', '#984ea3']\n",
        "\n",
        "# Plot each patch\n",
        "for i, (start_t, end_t, start_g, end_g) in enumerate(patches):\n",
        "    t_patch = np.linspace(start_t, end_t, 100)\n",
        "    k = -np.log((end_g - start_g) / 1.0) / (end_t - start_t)\n",
        "    gain = start_g + 1.0 * (1 - np.exp(-k * (t_patch - start_t))) / k\n",
        "\n",
        "    ax3.plot(t_patch, gain, '-', color=patch_colors[i], linewidth=2.5, label=f'Patch {i+1}', zorder=5)\n",
        "    ax3.plot(start_t, start_g, 'o', color=patch_colors[i], markersize=7, markeredgecolor='black', markeredgewidth=1, zorder=6)\n",
        "    ax3.plot(end_t, end_g, 's', color=patch_colors[i], markersize=7, markeredgecolor='black', markeredgewidth=1, zorder=6)\n",
        "\n",
        "    if i < len(patches) - 1:\n",
        "        next_start = patches[i+1][0]\n",
        "        ax3.plot([end_t, next_start], [end_g, end_g], '--', color='gray', linewidth=1.5, zorder=4)\n",
        "        text_x = (end_t + next_start) / 2\n",
        "        text_y = end_g + 0.15\n",
        "        ax3.text(text_x, text_y, 'Travel', fontsize=10, ha='center', va='center',\n",
        "                bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.8, edgecolor='gray'), zorder=7)\n",
        "\n",
        "# Add parameters text\n",
        "param_box = dict(boxstyle='round,pad=0.5', facecolor='white', alpha=0.9, edgecolor='#CCCCCC')\n",
        "ax3.text(0.02, 0.97, params_text, transform=ax3.transAxes, fontsize=12,\n",
        "         verticalalignment='top', bbox=param_box, zorder=7)\n",
        "\n",
        "# Configure plot\n",
        "ax3.set_xlabel('Time', fontweight='bold')\n",
        "ax3.set_ylabel('Cumulative Gain', fontweight='bold')\n",
        "ax3.set_title('MVT: Simulated Search Sequence', fontweight='bold')\n",
        "ax3.set_xlim(-0.5, 18)\n",
        "ax3.set_ylim(-0.2, 7.5)\n",
        "ax3.grid(True, linestyle='--', alpha=0.3, linewidth=0.8, zorder=0)\n",
        "ax3.spines['top'].set_visible(False)\n",
        "ax3.spines['right'].set_visible(False)\n",
        "ax3.xaxis.set_minor_locator(MultipleLocator(0.5))\n",
        "ax3.yaxis.set_minor_locator(MultipleLocator(0.5))\n",
        "\n",
        "# Add figure title\n",
        "fig.suptitle('Application of the Marginal Value Theorem (MVT) to semantic search dynamics',\n",
        "             fontsize=16, fontweight='bold', y=0.98)\n",
        "\n",
        "# Adjust layout\n",
        "plt.tight_layout()\n",
        "fig.subplots_adjust(top=0.93, hspace=0.3, wspace=0.2)\n",
        "\n",
        "# Save in multiple formats\n",
        "plt.savefig('mvt_combined_figure.pdf', bbox_inches='tight')\n",
        "plt.savefig('mvt_combined_figure.svg', bbox_inches='tight')\n",
        "plt.savefig('mvt_combined_figure.eps', bbox_inches='tight')\n",
        "plt.savefig('mvt_combined_figure.png', bbox_inches='tight', dpi=600)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Qn4wrQZ6lNz"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from matplotlib.ticker import MultipleLocator\n",
        "\n",
        "# Create a combined figure with all three plots\n",
        "fig = plt.figure(figsize=(12, 9))\n",
        "gs = fig.add_gridspec(2, 2, height_ratios=[1, 1.2])\n",
        "\n",
        "# First plot: MVT Rate Visualization\n",
        "ax1 = fig.add_subplot(gs[0, 0])\n",
        "\n",
        "# Parameters\n",
        "a = 1.6  # Initial rate\n",
        "b = 0.5  # Decay rate\n",
        "t_opt = 2.0  # Optimal time\n",
        "t = np.linspace(0, 10, 1000)  # Time vector\n",
        "\n",
        "# Calculate rates\n",
        "marginal_rate = a * np.exp(-b * t)\n",
        "average_rate = (a/b) * (1 - np.exp(-b * t_opt)) / t_opt\n",
        "\n",
        "# Plot the curves and other elements (similar to your existing code)\n",
        "# ...\n",
        "\n",
        "# Second plot: Effect of Threshold on Exploitation (similar to your existing code)\n",
        "# ...\n",
        "\n",
        "# Third plot: Simulated Search Sequence\n",
        "ax3 = fig.add_subplot(gs[1, :])\n",
        "\n",
        "# Parameters and patch data (similar to your existing code)\n",
        "# ...\n",
        "\n",
        "\n",
        "# Plot each patch (similar to your existing code)\n",
        "# ...\n",
        "\n",
        "# Add figure title, adjust layout, and save (similar to your existing code)\n",
        "# ...\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7847fd51"
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Sample data from the user query\n",
        "data = {'Subject': ['PD00020'],\n",
        "        'Number of words': [20],\n",
        "        'Number of unique words': [14],\n",
        "        'SoftMax Beta': [1.0646],\n",
        "        'SoftMax Log-likelihood': [-49.3998],\n",
        "        'SoftMax AIC': [100.7995],\n",
        "        'SoftMax R²': [0.0641],\n",
        "        'MVT Giving-up threshold': [0.5],\n",
        "        'MVT Search cost': [0.1],\n",
        "        'MVT Expected return': [1.0],\n",
        "        'MVT SSE': [12.0],\n",
        "        'MVT Pseudo-log-likelihood': [-23.2705],\n",
        "        'MVT AIC': [52.5410],\n",
        "        'MVT R²': [0.0769],\n",
        "        'Delta AIC': [48.2585],\n",
        "        'Evidence': ['Strong evidence for MVT'],\n",
        "        'Average SoftMax CV log-likelihood': [-11.1623],\n",
        "        'Average MVT CV SSE': [4.0],\n",
        "        'CV Evidence': ['Moderate evidence for MVT']}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Display basic statistics\n",
        "print(df.describe())\n",
        "\n",
        "# Visualizations\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(['SoftMax', 'MVT'], [df['SoftMax AIC'][0], df['MVT AIC'][0]])\n",
        "plt.title('AIC Comparison for Subject PD00020')\n",
        "plt.ylabel('AIC')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(['SoftMax', 'MVT'], [df['SoftMax R²'][0], df['MVT R²'][0]])\n",
        "plt.title('R² Comparison for Subject PD00020')\n",
        "plt.ylabel('R²')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MEDIATION\n"
      ],
      "metadata": {
        "id": "cY0UqsuhoSFb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import statsmodels.formula.api as smf\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "# Ensure the required columns exist and are numeric\n",
        "required_cols = ['norm_LC_avg', 'alpha_NET_mean', 'num_items']\n",
        "for col in required_cols:\n",
        "    if col not in merged_df_all.columns:\n",
        "        raise ValueError(f\"Required column '{col}' not found in merged_df.\")\n",
        "    # Attempt to convert to numeric, coercing errors\n",
        "    merged_df_all[col] = pd.to_numeric(merged_df_all[col], errors='coerce')\n",
        "\n",
        "# Drop rows with missing values in the required columns for the analysis\n",
        "mediation_data = merged_df_all.dropna(subset=required_cols).copy()\n",
        "\n",
        "# --- Inspection step added ---\n",
        "print(\"\\nInspecting mediation_data DataFrame after dropna:\")\n",
        "print(\"Columns:\", mediation_data.columns.tolist())\n",
        "print(\"Head:\")\n",
        "display(mediation_data.head())\n",
        "print(f\"Number of rows after dropna: {len(mediation_data)}\")\n",
        "# --- End inspection step ---\n",
        "\n",
        "\n",
        "if len(mediation_data) < 10: # Arbitrary minimum for a meaningful analysis\n",
        "    print(\"Warning: Not enough complete cases for mediation analysis after dropping NaNs.\")\n",
        "    print(f\"Number of complete cases: {len(mediation_data)}\")\n",
        "else:\n",
        "    print(f\"Running mediation analysis on {len(mediation_data)} complete cases.\")\n",
        "\n",
        "    # Mediation analysis setup:\n",
        "    # Mediator (M): Alpha_PSD (alpha_NET_mean)\n",
        "    # Independent Variable (X): NMLC (norm_LC_avg)\n",
        "    # Dependent Variable (Y): SVF_score (num_items)\n",
        "    # Covariate: Age (age)\n",
        "\n",
        "    # Step 1: Regression of M on X and Covariate (Path a)\n",
        "    # Model: Alpha_PSD ~ NMLC + age\n",
        "    model_m = smf.ols('alpha_NET_mean ~ norm_LC_avg + age', data=mediation_data).fit()\n",
        "    print(\"\\nRegression of Alpha_PSD on NMLC and Age (Path a):\")\n",
        "    print(model_m.summary().tables[1])\n",
        "\n",
        "    # Step 2: Regression of Y on X, M, and Covariate (Paths c' and b)\n",
        "    # Model: SVF_score ~ NMLC + Alpha_PSD + age\n",
        "    model_y = smf.ols('num_items ~ norm_LC_avg + alpha_NET_mean + age', data=mediation_data).fit()\n",
        "    print(\"\\nRegression of SVF_score on NMLC, Alpha_PSD, and Age (Paths c' and b):\")\n",
        "    print(model_y.summary().tables[1])\n",
        "\n",
        "    # Calculate Indirect Effect (a*b) and Direct Effect (c')\n",
        "    # Path a coefficient (from model_m) - effect of NMLC on Alpha_PSD controlling for age\n",
        "    a_coeff = model_m.params['norm_LC_avg']\n",
        "\n",
        "    # Path b coefficient (from model_y) - effect of Alpha_PSD on SVF_score controlling for NMLC and age\n",
        "    b_coeff = model_y.params['alpha_NET_mean']\n",
        "\n",
        "    # Path c' coefficient (from model_y) - direct effect of NMLC on SVF_score controlling for Alpha_PSD and age\n",
        "    c_prime_coeff = model_y.params['norm_LC_avg']\n",
        "\n",
        "    # Indirect effect (a*b)\n",
        "    indirect_effect = a_coeff * b_coeff\n",
        "\n",
        "    # Total effect (c = c' + ab)\n",
        "    # To calculate the total effect controlling for age, we regress Y on X and age\n",
        "    model_total = smf.ols('num_items ~ norm_LC_avg + age', data=mediation_data).fit()\n",
        "    total_effect_coeff = model_total.params['norm_LC_avg']\n",
        "    print(\"\\nRegression of SVF_score on NMLC and Age (Total Effect, Path c):\")\n",
        "    print(model_total.summary().tables[1])\n",
        "\n",
        "\n",
        "    print(\"\\nMediation Analysis Summary (Controlling for Age):\")\n",
        "    print(f\"Path a (NMLC -> Alpha_PSD | controlling for Age): Coeff = {a_coeff:.4f}, p = {model_m.pvalues['norm_LC_avg']:.4f}\")\n",
        "    print(f\"Path b (Alpha_PSD -> SVF_score | controlling for NMLC and Age): Coeff = {b_coeff:.4f}, p = {model_y.pvalues['alpha_NET_mean']:.4f}\")\n",
        "    print(f\"Path c' (NMLC -> SVF_score | controlling for Alpha_PSD and Age - Direct Effect): Coeff = {c_prime_coeff:.4f}, p = {model_y.pvalues['norm_LC_avg']:.4f}\")\n",
        "    print(f\"Indirect Effect (a * b): {indirect_effect:.4f}\")\n",
        "    # Note: Statistical significance of the indirect effect typically requires bootstrapping (not included here)\n",
        "    print(f\"Total Effect (NMLC -> SVF_score | controlling for Age): Coeff = {total_effect_coeff:.4f}, p = {model_total.pvalues['norm_LC_avg']:.4f}\")\n",
        "\n",
        "    # Visualization of relationships (optional, based on the text's figures) - Updated to use mediation_data\n",
        "    plt.figure(figsize=(15, 5))\n",
        "\n",
        "    # Plot 1: NMLC vs. SVF_score (Direct/Total effect visualization)\n",
        "    plt.subplot(1, 3, 1)\n",
        "    sns.regplot(x='norm_LC_avg', y='num_items', data=mediation_data, scatter_kws={'alpha':0.6})\n",
        "    plt.title('NMLC vs. SVF Score (Controlling for Age)')\n",
        "    plt.xlabel('Locus Coeruleus Neuromelanin (NMLC)')\n",
        "    plt.ylabel('Verbal Fluency Score (num_items)')\n",
        "\n",
        "    # Plot 2: NMLC vs. Alpha_PSD (Path a visualization)\n",
        "    plt.subplot(1, 3, 2)\n",
        "    sns.regplot(x='norm_LC_avg', y='alpha_NET_mean', data=mediation_data, scatter_kws={'alpha':0.6})\n",
        "    plt.title('NMLC vs. Alpha Power (Controlling for Age)')\n",
        "    plt.xlabel('Locus Coeruleus Neuromelanin (NMLC)')\n",
        "    plt.ylabel('Alpha Power (alpha_NET_mean)')\n",
        "\n",
        "    # Plot 3: Alpha_PSD vs. SVF_score (Path b visualization, simplified)\n",
        "    # Note: This doesn't show the relationship *controlling for* NMLC and Age directly in the plot\n",
        "    plt.subplot(1, 3, 3)\n",
        "    sns.regplot(x='alpha_NET_mean', y='num_items', data=mediation_data, scatter_kws={'alpha':0.6})\n",
        "    plt.title('Alpha Power vs. SVF Score (Controlling for NMLC and Age)')\n",
        "    plt.xlabel('Alpha Power (alpha_NET_mean)')\n",
        "    plt.ylabel('Verbal Fluency Score (num_items)')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    print(\"\\nMediation analysis (controlling for age) complete.\")"
      ],
      "metadata": {
        "id": "veNnx4yrV9dy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cda5bfdc"
      },
      "source": [
        "# Load the Excel file containing age data\n",
        "excel_file_path = '/content/Dietta Chihade_BD_RPQ_UPDATE_Neuropsy (4).xlsx'\n",
        "try:\n",
        "    # Specify the sheet name to read\n",
        "    age_df = pd.read_excel(excel_file_path, sheet_name='Parkinson patients')\n",
        "    print(f\"Successfully loaded age data from '{'Parkinson patients'}' sheet in {excel_file_path}\")\n",
        "    display(age_df.head())\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: The file {excel_file_path} was not found.\")\n",
        "    age_df = None\n",
        "except Exception as e:\n",
        "    print(f\"Error loading Excel file: {e}\")\n",
        "    age_df = None\n",
        "\n",
        "# Merge age data into merged_df_all\n",
        "if age_df is not None and 'merged_df_all' in locals():\n",
        "    # Assuming there's a common column to merge on, like 'ID' or 'participant'\n",
        "    # Need to inspect the age_df structure to determine the correct column name\n",
        "    # Let's assume the participant ID is in a column named 'ID' or similar in age_df\n",
        "    # and it matches the 'participant' or 'clean_ID' column in merged_df_all\n",
        "\n",
        "    # Clean the ID column in age_df if necessary to match clean_ID in merged_df_all\n",
        "    # This is based on the cleaning logic applied to the SVF and MEG/LC data\n",
        "    # Assuming the ID column in age_df is the first column and contains 'PDXXXXX'\n",
        "    try:\n",
        "        # Handle non-numeric values in the first column by coercing to numeric,\n",
        "        # then dropping NaNs before converting to integer and string.\n",
        "        age_df['clean_ID_numeric'] = pd.to_numeric(age_df.iloc[:, 0].astype(str).str.replace('PD', '', regex=False), errors='coerce')\n",
        "        age_df = age_df.dropna(subset=['clean_ID_numeric']).copy() # Drop rows where conversion failed\n",
        "        age_df['clean_ID'] = age_df['clean_ID_numeric'].astype(int).astype(str)\n",
        "        age_df = age_df.drop(columns=['clean_ID_numeric']) # Drop the temporary numeric column\n",
        "        print(\"Created 'clean_ID' in age_df, handling non-numeric entries.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Could not create 'clean_ID' in age_df from the first column: {e}. Skipping merge.\")\n",
        "        age_df = None # Prevent merging if ID cleaning fails\n",
        "\n",
        "    if age_df is not None and 'clean_ID' in age_df.columns:\n",
        "        # Assuming the age column is named 'Age' or similar\n",
        "        # Need to inspect age_df to find the correct age column name\n",
        "        # Let's look for a column that seems to contain age values\n",
        "        age_column_name = None\n",
        "        # Manually specify the age column name based on previous inspection\n",
        "        age_column_name = 'Age at time of assessment'\n",
        "\n",
        "\n",
        "        if age_column_name and age_column_name in age_df.columns:\n",
        "            print(f\"Identified age column as '{age_column_name}'.\")\n",
        "            # Select only the necessary columns from age_df before merging\n",
        "            age_data_to_merge = age_df[['clean_ID', age_column_name]].copy()\n",
        "            age_data_to_merge.rename(columns={age_column_name: 'age'}, inplace=True)\n",
        "\n",
        "            # Convert age column to numeric, coercing errors\n",
        "            age_data_to_merge['age'] = pd.to_numeric(age_data_to_merge['age'], errors='coerce')\n",
        "\n",
        "\n",
        "            # Perform the merge\n",
        "            merged_df_all = pd.merge(merged_df_all, age_data_to_merge, on='clean_ID', how='left')\n",
        "            print(\"Age data merged into merged_df_all.\")\n",
        "\n",
        "            # Display the head of the updated merged_df_all including the new 'age' column\n",
        "            print('\\nUpdated Merged DataFrame head with age:')\n",
        "            # Include 'age' in the columns to display if it exists\n",
        "            display_cols = [col for col in merged_df_all.columns if col in ['participant', 'clean_ID', 'age'] or col in numerical_columns or col in ['items', 'similarities', 'phases']]\n",
        "            display(merged_df_all[display_cols].head())\n",
        "\n",
        "        else:\n",
        "            print(\"Could not automatically identify the age column in the Excel file.\")\n",
        "            print(\"Please manually specify the correct column name for age.\")\n",
        "            print(f\"Available columns: {age_df.columns.tolist()}\")\n",
        "    else:\n",
        "         print(\"Age data could not be prepared for merging.\")\n",
        "elif 'merged_df_all' not in locals():\n",
        "    print(\"Error: merged_df_all DataFrame is not available. Please run the preceding cells.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "232a66af"
      },
      "source": [
        "# Check the number of non-missing age values in merged_df_all\n",
        "if 'merged_df_all' in locals() and 'age' in merged_df_all.columns:\n",
        "    num_subjects_with_age = merged_df_all['age'].notna().sum()\n",
        "    total_subjects = len(merged_df_all)\n",
        "    print(f\"Found age data for {num_subjects_with_age} out of {total_subjects} participants.\")\n",
        "elif 'merged_df_all' not in locals():\n",
        "    print(\"Error: merged_df_all DataFrame is not available. Please run the preceding cells.\")\n",
        "else:\n",
        "    print(\"Error: 'age' column not found in merged_df_all. Please ensure the age data was merged correctly.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the age data, skipping the header row\n",
        "excel_file_path = '/content/PD AGES .xlsx'\n",
        "try:\n",
        "    age_df = pd.read_excel(excel_file_path, skiprows=1) # Skip the first row (header)\n",
        "    print(f\"Successfully loaded age data from {excel_file_path}\")\n",
        "    print(f\"\\nShape of age_df: {age_df.shape}\")\n",
        "    print(f\"\\nColumn names in age_df:\")\n",
        "    print(age_df.columns.tolist())\n",
        "    print(\"\\nFirst few rows:\")\n",
        "    display(age_df.head())\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: The file {excel_file_path} was not found.\")\n",
        "    age_df = None\n",
        "except Exception as e:\n",
        "    print(f\"Error loading Excel file: {e}\")\n",
        "    age_df = None\n",
        "\n",
        "# Merge age data into merged_df_all\n",
        "if age_df is not None and 'merged_df_all' in locals():\n",
        "    # Identify the participant ID and age columns based on previous inspection\n",
        "    # Column names will be different after skipping the header row\n",
        "    # Based on the previous head, 'Unnamed: 0' was participant ID, 'Unnamed: 7' was age\n",
        "    # After skipping the header, these should still be the correct column *indices*,\n",
        "    # but the column names in the dataframe might remain as 'Unnamed: 0', 'Unnamed: 7' etc.\n",
        "    # Let's assume the columns are still named 'Unnamed: 0' and 'Unnamed: 7' after skipping\n",
        "    participant_col = 'Unnamed: 0'\n",
        "    age_col = 'Unnamed: 7'\n",
        "\n",
        "\n",
        "    if participant_col in age_df.columns and age_col in age_df.columns:\n",
        "        # Rename and select only the columns we need\n",
        "        age_df_renamed = age_df[[participant_col, age_col]].copy()\n",
        "        age_df_renamed.columns = ['participant', 'age']\n",
        "\n",
        "        # Display sample of renamed data\n",
        "        print(f\"\\nUsing columns: '{participant_col}' as participant and '{age_col}' as age\")\n",
        "        print(\"\\nRenamed age data sample:\")\n",
        "        display(age_df_renamed.head())\n",
        "\n",
        "        # Convert participant columns to string for consistent merging\n",
        "        age_df_renamed['participant'] = age_df_renamed['participant'].astype(str).str.strip()\n",
        "        merged_df_all['participant'] = merged_df_all['participant'].astype(str).str.strip()\n",
        "\n",
        "        # Check if participant IDs match format in merged_df_all\n",
        "        print(\"\\nSample participant IDs from age_df:\")\n",
        "        print(age_df_renamed['participant'].head(10).tolist())\n",
        "        print(\"\\nSample participant IDs from merged_df_all:\")\n",
        "        print(merged_df_all['participant'].head(10).tolist())\n",
        "\n",
        "        # Convert age column to numeric, coercing errors\n",
        "        age_df_renamed['age'] = pd.to_numeric(age_df_renamed['age'], errors='coerce')\n",
        "        # Drop rows where age could not be converted to numeric (e.g., 'Age at time of assessment' row)\n",
        "        age_df_renamed = age_df_renamed.dropna(subset=['age']).copy()\n",
        "\n",
        "\n",
        "        # Perform the merge\n",
        "        print(\"\\nPerforming merge...\")\n",
        "        original_shape = merged_df_all.shape\n",
        "        merged_df_all = pd.merge(merged_df_all, age_df_renamed, on='participant', how='left', suffixes=('', '_new'))\n",
        "\n",
        "        # Handle potential duplicate age columns\n",
        "        if 'age_new' in merged_df_all.columns:\n",
        "            if 'age' in merged_df_all.columns:\n",
        "                # Fill missing values in the original 'age' column with values from the new column\n",
        "                print(\"Updating existing age column with new values...\")\n",
        "                merged_df_all['age'] = merged_df_all['age'].fillna(merged_df_all['age_new'])\n",
        "                merged_df_all = merged_df_all.drop(columns=['age_new'])\n",
        "            else:\n",
        "                # If no age column exists, use the new one\n",
        "                merged_df_all['age'] = merged_df_all['age_new']\n",
        "                merged_df_all = merged_df_all.drop(columns=['age_new'])\n",
        "\n",
        "        print(f\"\\nAge data successfully merged!\")\n",
        "        print(f\"Shape after merge: {merged_df_all.shape} (was {original_shape})\")\n",
        "        print(f\"Number of participants with age data: {merged_df_all['age'].notna().sum()}\")\n",
        "        # Now calculate statistics only on the numeric age column\n",
        "        print(f\"Age statistics: Mean={merged_df_all['age'].mean():.1f}, Min={merged_df_all['age'].min():.1f}, Max={merged_df_all['age'].max():.1f}\")\n",
        "\n",
        "        # Display result with age column prominently shown\n",
        "        display_cols = ['participant', 'age'] + [col for col in merged_df_all.columns[:5] if col not in ['participant', 'age']]\n",
        "        print(\"\\nMerged data sample (showing age column):\")\n",
        "        display(merged_df_all[display_cols].head(10))\n",
        "\n",
        "        # Check for any participants without age data\n",
        "        missing_age = merged_df_all[merged_df_all['age'].isna()]['participant'].nunique()\n",
        "        if missing_age > 0:\n",
        "            print(f\"\\nWarning: {missing_age} participants in merged_df_all do not have age data\")\n",
        "    else:\n",
        "        print(f\"\\nError: Could not find required columns\")\n",
        "        print(f\"Participant column found: {participant_col}\")\n",
        "        print(f\"Age column '{age_col}' exists: {age_col in age_df.columns}\")\n",
        "\n",
        "elif 'merged_df_all' not in locals():\n",
        "    print(\"Error: merged_df_all DataFrame is not available. Please run the preceding cells.\")"
      ],
      "metadata": {
        "id": "2BuSsgmeAkT2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import statsmodels.formula.api as smf\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "import numpy as np # Import numpy for np.percentile\n",
        "\n",
        "# Ensure the required columns exist and are numeric\n",
        "required_cols = ['norm_LC_avg', 'alpha_NET_mean', 'exploitation_percentage', 'age']\n",
        "for col in required_cols:\n",
        "    if col not in merged_df_all.columns:\n",
        "        raise ValueError(f\"Required column '{col}' not found in merged_df_all.\")\n",
        "    # Attempt to convert to numeric, coercing errors\n",
        "    merged_df_all[col] = pd.to_numeric(merged_df_all[col], errors='coerce')\n",
        "\n",
        "# Drop rows with missing values in the required columns for the analysis\n",
        "mediation_data = merged_df_all.dropna(subset=required_cols).copy()\n",
        "\n",
        "print(\"\\nInspecting mediation_data DataFrame after dropna:\")\n",
        "print(\"Columns:\", mediation_data.columns.tolist())\n",
        "print(\"Head:\")\n",
        "display(mediation_data.head())\n",
        "print(f\"Number of rows after dropna: {len(mediation_data)}\")\n",
        "\n",
        "# Initialize variables that might not be set if analysis is skipped\n",
        "boot_effects = []\n",
        "ci_lower = np.nan\n",
        "ci_upper = np.nan\n",
        "indirect_effect = np.nan\n",
        "a_coeff = np.nan\n",
        "b_coeff = np.nan\n",
        "c_prime_coeff = np.nan\n",
        "total_effect_coeff = np.nan # Initialize total_effect_coeff\n",
        "prop_mediated = np.nan # Initialize prop_mediated\n",
        "\n",
        "if len(mediation_data) < 10: # Arbitrary minimum for a meaningful analysis\n",
        "    print(\"Warning: Not enough complete cases for mediation analysis after dropping NaNs.\")\n",
        "    print(f\"Number of complete cases: {len(mediation_data)}\")\n",
        "else:\n",
        "    print(f\"Running mediation analysis on {len(mediation_data)} complete cases.\")\n",
        "\n",
        "    # Mediation analysis setup:\n",
        "    # Mediator (M): Alpha_PSD (alpha_NET_mean)\n",
        "    # Independent Variable (X): NMLC (norm_LC_avg)\n",
        "    # Dependent Variable (Y): Exploitation_Percentage (exploitation_percentage)\n",
        "    # Covariate: Age (age)\n",
        "\n",
        "    # Step 1: Regression of M on X and Covariate (Path a)\n",
        "    # Model: Alpha_PSD ~ NMLC + age\n",
        "    model_m = smf.ols('alpha_NET_mean ~ norm_LC_avg + age', data=mediation_data).fit()\n",
        "    print(\"\\nRegression of Alpha_PSD on NMLC and Age (Path a):\")\n",
        "    print(model_m.summary().tables[1])\n",
        "\n",
        "    # Step 2: Regression of Y on X, M, and Covariate (Paths c' and b)\n",
        "    # Model: Exploitation_Percentage ~ NMLC + Alpha_PSD + age\n",
        "    model_y = smf.ols('exploitation_percentage ~ norm_LC_avg + alpha_NET_mean + age', data=mediation_data).fit()\n",
        "    print(\"\\nRegression of Exploitation_Percentage on NMLC, Alpha_PSD, and Age (Paths c' and b):\")\n",
        "    print(model_y.summary().tables[1])\n",
        "\n",
        "    # Calculate Indirect Effect (a*b) and Direct Effect (c')\n",
        "    # Path a coefficient (from model_m) - effect of NMLC on Alpha_PSD controlling for age\n",
        "    a_coeff = model_m.params['norm_LC_avg']\n",
        "\n",
        "    # Path b coefficient (from model_y) - effect of Alpha_PSD on Exploitation_Percentage controlling for NMLC and age\n",
        "    b_coeff = model_y.params['alpha_NET_mean']\n",
        "\n",
        "    # Path c' coefficient (from model_y) - direct effect of NMLC on Exploitation_Percentage controlling for Alpha_PSD and age\n",
        "    c_prime_coeff = model_y.params['norm_LC_avg']\n",
        "\n",
        "    # Indirect effect (a*b)\n",
        "    indirect_effect = a_coeff * b_coeff\n",
        "\n",
        "    # Total effect (c = c' + ab)\n",
        "    # To calculate the total effect controlling for age, we regress Y on X and age\n",
        "    model_total = smf.ols('exploitation_percentage ~ norm_LC_avg + age', data=mediation_data).fit()\n",
        "    total_effect_coeff = model_total.params['norm_LC_avg']\n",
        "    print(\"\\nRegression of Exploitation_Percentage on NMLC and Age (Total Effect, Path c):\")\n",
        "    print(model_total.summary().tables[1])\n",
        "\n",
        "    print(\"\\nMediation Analysis Summary (Controlling for Age):\")\n",
        "    print(f\"Path a (NMLC -> Alpha_PSD | controlling for Age): Coeff = {a_coeff:.4f}, p = {model_m.pvalues['norm_LC_avg']:.4f}\")\n",
        "    print(f\"Path b (Alpha_PSD -> Exploitation_Percentage | controlling for NMLC and Age): Coeff = {b_coeff:.4f}, p = {model_y.pvalues['alpha_NET_mean']:.4f}\")\n",
        "    print(f\"Path c' (NMLC -> Exploitation_Percentage | controlling for Alpha_PSD and Age - Direct Effect): Coeff = {c_prime_coeff:.4f}, p = {model_y.pvalues['norm_LC_avg']:.4f}\")\n",
        "    print(f\"Indirect Effect (a * b): {indirect_effect:.4f}\")\n",
        "    # Note: Statistical significance of the indirect effect typically requires bootstrapping (not included here)\n",
        "    print(f\"Total Effect (NMLC -> Exploitation_Percentage | controlling for Age): Coeff = {total_effect_coeff:.4f}, p = {model_total.pvalues['norm_LC_avg']:.4f}\")\n",
        "\n",
        "    # Bootstrap confidence intervals\n",
        "    print(\"\\nRunning bootstrap (n=5000)...\")\n",
        "    boot_effects = [] # Initialize boot_effects list\n",
        "    n_bootstrap = 5000\n",
        "    alpha = 0.05\n",
        "\n",
        "    for i in range(n_bootstrap):\n",
        "        # Resample data with replacement\n",
        "        boot_data = mediation_data.sample(n=len(mediation_data), replace=True)\n",
        "\n",
        "        try:\n",
        "            # Fit models on bootstrap sample\n",
        "            model_m_boot = smf.ols('alpha_NET_mean ~ norm_LC_avg + age', data=boot_data).fit()\n",
        "            model_y_boot = smf.ols('exploitation_percentage ~ norm_LC_avg + alpha_NET_mean + age', data=boot_data).fit()\n",
        "\n",
        "            # Calculate indirect effect\n",
        "            a_boot = model_m_boot.params['norm_LC_avg']\n",
        "            b_boot = model_y_boot.params['alpha_NET_mean']\n",
        "            indirect_boot = a_boot * b_boot\n",
        "            boot_effects.append(indirect_boot)\n",
        "        except Exception as e:\n",
        "            # Print error message for debugging\n",
        "            # print(f\"Bootstrap iteration {i} failed: {e}\")\n",
        "            continue # Skip failed iterations\n",
        "\n",
        "    # Calculate confidence intervals\n",
        "    if len(boot_effects) > 0:\n",
        "        ci_lower = np.percentile(boot_effects, (alpha/2) * 100)\n",
        "        ci_upper = np.percentile(boot_effects, (1 - alpha/2) * 100)\n",
        "    else:\n",
        "        ci_lower = np.nan\n",
        "        ci_upper = np.nan\n",
        "        print(\"Warning: Bootstrap failed to produce any results.\")\n",
        "\n",
        "    # Calculate proportion mediated only if total effect is not zero and is a valid number\n",
        "    if not np.isnan(total_effect_coeff) and total_effect_coeff != 0:\n",
        "         prop_mediated = indirect_effect / total_effect_coeff\n",
        "\n",
        "\n",
        "    # Visualization of relationships (optional)\n",
        "    plt.figure(figsize=(15, 5))\n",
        "\n",
        "    # Plot 1: NMLC vs. Exploitation_Percentage (Direct/Total effect visualization)\n",
        "    plt.subplot(1, 3, 1)\n",
        "    sns.regplot(x='norm_LC_avg', y='exploitation_percentage', data=mediation_data, scatter_kws={'alpha':0.6})\n",
        "    plt.title('NMLC vs. Exploitation Percentage (Controlling for Age)')\n",
        "    plt.xlabel('Locus Coeruleus Neuromelanin (NMLC)')\n",
        "    plt.ylabel('Exploitation Percentage')\n",
        "\n",
        "    # Plot 2: NMLC vs. Alpha_PSD (Path a visualization)\n",
        "    plt.subplot(1, 3, 2)\n",
        "    sns.regplot(x='norm_LC_avg', y='alpha_NET_mean', data=mediation_data, scatter_kws={'alpha':0.6})\n",
        "    plt.title('NMLC vs. Alpha Power (Controlling for Age)')\n",
        "    plt.xlabel('Locus Coeruleus Neuromelanin (NMLC)')\n",
        "    plt.ylabel('Alpha Power (alpha_NET_mean)')\n",
        "\n",
        "    # Plot 3: Alpha_PSD vs. Exploitation_Percentage (Path b visualization, simplified)\n",
        "    # Note: This doesn't show the relationship *controlling for* NMLC and Age directly in the plot\n",
        "    plt.subplot(1, 3, 3)\n",
        "    sns.regplot(x='alpha_NET_mean', y='exploitation_percentage', data=mediation_data, scatter_kws={'alpha':0.6})\n",
        "    plt.title('Alpha Power vs. Exploitation Percentage (Controlling for NMLC and Age)')\n",
        "    plt.xlabel('Alpha Power (alpha_NET_mean)')\n",
        "    plt.ylabel('Exploitation Percentage')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    print(\"\\nMediation analysis (controlling for age) complete.\")\n",
        "\n",
        "\n",
        "# Final summary print statement (outside the else block)\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"MEDIATION ANALYSIS SUMMARY\")\n",
        "print(\"=\"*70)\n",
        "print(f\"\\nSample size: {len(mediation_data)}\")\n",
        "print(f\"\\nEffects (unstandardized):\")\n",
        "print(f\"  • Path a (NMLC → Alpha):        {a_coeff:.4f}\")\n",
        "print(f\"  • Path b (Alpha → Exploit):     {b_coeff:.4f}\")\n",
        "print(f\"  • Path c' (Direct effect):      {c_prime_coeff:.4f}\")\n",
        "print(f\"  • Path c (Total effect):        {total_effect_coeff:.4f}\") # Use total_effect_coeff\n",
        "print(f\"\\nIndirect effect (a×b):           {indirect_effect:.4f}\")\n",
        "print(f\"  • 95% CI: [{ci_lower:.4f}, {ci_upper:.4f}]\")\n",
        "# Check if CI is available and significant\n",
        "if not np.isnan(ci_lower) and not np.isnan(ci_upper):\n",
        "    print(f\"  • Significant: {'Yes' if ci_lower * ci_upper > 0 else 'No'}\")\n",
        "else:\n",
        "    print(f\"  • Significant: N/A (Bootstrap failed)\")\n",
        "\n",
        "\n",
        "if not np.isnan(prop_mediated):\n",
        "    print(f\"\\nProportion mediated: {prop_mediated:.1%}\")\n",
        "\n",
        "print(\"\\n✓ Analysis complete!\")"
      ],
      "metadata": {
        "id": "EKFhnKfqAmmF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import statsmodels.formula.api as smf\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set style - use a style that definitely exists\n",
        "try:\n",
        "    plt.style.use('seaborn-v0_8-whitegrid')\n",
        "except:\n",
        "    plt.style.use('seaborn-whitegrid')  # Fallback for older versions\n",
        "\n",
        "# Set color palette\n",
        "colors = {\n",
        "    'primary': '#2E86AB',\n",
        "    'secondary': '#E63946',\n",
        "    'tertiary': '#06D6A0',\n",
        "    'quaternary': '#F77F00',\n",
        "    'highlight': '#7209B7',\n",
        "    'neutral': '#264653'\n",
        "}\n",
        "\n",
        "# Function to calculate standardized coefficients\n",
        "def standardize_data(df, cols):\n",
        "    \"\"\"Standardize specified columns to have mean=0, std=1\"\"\"\n",
        "    df_std = df.copy()\n",
        "    for col in cols:\n",
        "        if col in df.columns:\n",
        "            df_std[f'{col}_std'] = (df[col] - df[col].mean()) / df[col].std()\n",
        "    return df_std\n",
        "\n",
        "# Function for bootstrap confidence intervals with progress indicator\n",
        "def bootstrap_indirect_effect(data, n_bootstrap=5000, alpha=0.05):\n",
        "    \"\"\"Calculate bootstrap confidence intervals for indirect effect\"\"\"\n",
        "    indirect_effects = []\n",
        "\n",
        "    print(f\"Running bootstrap (n={n_bootstrap})...\")\n",
        "    for i in range(n_bootstrap):\n",
        "        if i % 1000 == 0:\n",
        "            print(f\"  Progress: {i/n_bootstrap*100:.0f}%\")\n",
        "\n",
        "        # Resample data with replacement\n",
        "        boot_data = data.sample(n=len(data), replace=True)\n",
        "\n",
        "        try:\n",
        "            # Fit models on bootstrap sample\n",
        "            model_m_boot = smf.ols('alpha_NET_mean ~ norm_LC_avg + age', data=boot_data).fit()\n",
        "            model_y_boot = smf.ols('exploitation_percentage ~ norm_LC_avg + alpha_NET_mean + age', data=boot_data).fit()\n",
        "\n",
        "            # Calculate indirect effect\n",
        "            a_boot = model_m_boot.params['norm_LC_avg']\n",
        "            b_boot = model_y_boot.params['alpha_NET_mean']\n",
        "            indirect_boot = a_boot * b_boot\n",
        "            indirect_effects.append(indirect_boot)\n",
        "        except:\n",
        "            continue  # Skip failed iterations\n",
        "\n",
        "    print(\"  Progress: 100%\")\n",
        "\n",
        "    # Calculate confidence intervals\n",
        "    if len(indirect_effects) > 0:\n",
        "        lower = np.percentile(indirect_effects, (alpha/2) * 100)\n",
        "        upper = np.percentile(indirect_effects, (1 - alpha/2) * 100)\n",
        "    else:\n",
        "        lower, upper = np.nan, np.nan\n",
        "\n",
        "    return indirect_effects, lower, upper\n",
        "\n",
        "# Check required columns\n",
        "print(\"=\"*70)\n",
        "print(\"MEDIATION ANALYSIS: NMLC → Alpha Power → Exploitation %\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "required_cols = ['norm_LC_avg', 'alpha_NET_mean', 'exploitation_percentage', 'age']\n",
        "print(\"\\nChecking for required columns...\")\n",
        "\n",
        "missing_cols = [col for col in required_cols if col not in merged_df_all.columns]\n",
        "if missing_cols:\n",
        "    print(f\"ERROR: Missing columns: {missing_cols}\")\n",
        "    print(\"\\nAvailable columns:\", merged_df_all.columns.tolist()[:20], \"...\")\n",
        "    raise ValueError(f\"Required columns not found: {missing_cols}\")\n",
        "else:\n",
        "    print(\"✓ All required columns found\")\n",
        "\n",
        "# Convert to numeric and create clean dataset\n",
        "mediation_data = merged_df_all[required_cols].copy()\n",
        "\n",
        "print(\"\\nConverting to numeric...\")\n",
        "for col in required_cols:\n",
        "    before_count = mediation_data[col].notna().sum()\n",
        "    mediation_data[col] = pd.to_numeric(mediation_data[col], errors='coerce')\n",
        "    after_count = mediation_data[col].notna().sum()\n",
        "    if before_count != after_count:\n",
        "        print(f\"  Warning: {before_count - after_count} non-numeric values in {col}\")\n",
        "\n",
        "# Drop missing values\n",
        "initial_n = len(mediation_data)\n",
        "mediation_data = mediation_data.dropna()\n",
        "final_n = len(mediation_data)\n",
        "\n",
        "print(f\"\\nData preparation:\")\n",
        "print(f\"  - Initial sample size: {initial_n}\")\n",
        "print(f\"  - Final sample size: {final_n} (removed {initial_n - final_n} incomplete cases)\")\n",
        "\n",
        "if final_n < 20:\n",
        "    raise ValueError(f\"Insufficient sample size for mediation analysis (n={final_n})\")\n",
        "\n",
        "# Descriptive statistics\n",
        "print(\"\\nDescriptive Statistics:\")\n",
        "print(\"-\" * 70)\n",
        "desc_stats = mediation_data.describe().round(3)\n",
        "print(desc_stats)\n",
        "\n",
        "# Check for outliers\n",
        "print(\"\\nOutlier Detection (|z-score| > 3):\")\n",
        "outlier_info = {}\n",
        "for col in required_cols:\n",
        "    z_scores = np.abs(stats.zscore(mediation_data[col]))\n",
        "    outliers = np.sum(z_scores > 3)\n",
        "    outlier_info[col] = outliers\n",
        "    if outliers > 0:\n",
        "        print(f\"  - {col}: {outliers} potential outliers\")\n",
        "\n",
        "# Create standardized version\n",
        "mediation_data_std = standardize_data(mediation_data, required_cols[:-1])\n",
        "\n",
        "# ========== MEDIATION ANALYSIS ==========\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"MEDIATION ANALYSIS RESULTS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Fit all models\n",
        "try:\n",
        "    # Step 1: Path a (X → M)\n",
        "    print(\"\\n1. PATH A: NMLC → Alpha Power (controlling for Age)\")\n",
        "    model_m = smf.ols('alpha_NET_mean ~ norm_LC_avg + age', data=mediation_data).fit()\n",
        "    print(f\"   R² = {model_m.rsquared:.3f}, Adj R² = {model_m.rsquared_adj:.3f}\")\n",
        "\n",
        "    # Step 2: Paths b and c' (M,X → Y)\n",
        "    print(\"\\n2. PATHS B & C': Alpha Power & NMLC → Exploitation % (controlling for Age)\")\n",
        "    model_y = smf.ols('exploitation_percentage ~ norm_LC_avg + alpha_NET_mean + age', data=mediation_data).fit()\n",
        "    print(f\"   R² = {model_y.rsquared:.3f}, Adj R² = {model_y.rsquared_adj:.3f}\")\n",
        "\n",
        "    # Step 3: Total effect (c)\n",
        "    print(\"\\n3. TOTAL EFFECT (C): NMLC → Exploitation % (controlling for Age)\")\n",
        "    model_total = smf.ols('exploitation_percentage ~ norm_LC_avg + age', data=mediation_data).fit()\n",
        "    print(f\"   R² = {model_total.rsquared:.3f}, Adj R² = {model_total.rsquared_adj:.3f}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"ERROR in model fitting: {e}\")\n",
        "    raise\n",
        "\n",
        "# Calculate effects\n",
        "a_coeff = model_m.params['norm_LC_avg']\n",
        "b_coeff = model_y.params['alpha_NET_mean']\n",
        "c_prime_coeff = model_y.params['norm_LC_avg']\n",
        "c_coeff = model_total.params['norm_LC_avg']\n",
        "indirect_effect = a_coeff * b_coeff\n",
        "\n",
        "# Bootstrap confidence intervals\n",
        "print(\"\\n4. BOOTSTRAP ANALYSIS\")\n",
        "print(\"-\" * 50)\n",
        "boot_effects, ci_lower, ci_upper = bootstrap_indirect_effect(mediation_data, n_bootstrap=5000)\n",
        "\n",
        "# Calculate proportion mediated\n",
        "prop_mediated = indirect_effect / c_coeff if c_coeff != 0 else np.nan\n",
        "\n",
        "# ========== IMPROVED VISUALIZATIONS ==========\n",
        "print(\"\\nCreating visualizations...\")\n",
        "\n",
        "# Create a cleaner figure layout\n",
        "fig = plt.figure(figsize=(16, 12))\n",
        "gs = fig.add_gridspec(3, 3, hspace=0.35, wspace=0.25,\n",
        "                      left=0.06, right=0.94, top=0.93, bottom=0.05)\n",
        "\n",
        "# 1. Clean Path Diagram (simplified)\n",
        "ax1 = fig.add_subplot(gs[0, :])\n",
        "ax1.axis('off')\n",
        "\n",
        "# Title\n",
        "ax1.text(0.5, 0.95, 'Mediation Model: NMLC → Alpha Power → Exploitation %',\n",
        "         ha='center', va='top', fontsize=16, weight='bold')\n",
        "\n",
        "# Variables positions\n",
        "var_pos = {\n",
        "    'X': (0.2, 0.4),\n",
        "    'M': (0.5, 0.6),\n",
        "    'Y': (0.8, 0.4),\n",
        "    'Age': (0.5, 0.15)\n",
        "}\n",
        "\n",
        "# Draw variables as text with background\n",
        "for var, (x, y) in var_pos.items():\n",
        "    if var == 'X':\n",
        "        text = 'NMLC\\n(X)'\n",
        "        color = colors['primary']\n",
        "    elif var == 'M':\n",
        "        text = 'Alpha Power\\n(M)'\n",
        "        color = colors['secondary']\n",
        "    elif var == 'Y':\n",
        "        text = 'Exploitation %\\n(Y)'\n",
        "        color = colors['tertiary']\n",
        "    else:\n",
        "        text = 'Age\\n(Covariate)'\n",
        "        color = colors['neutral']\n",
        "\n",
        "    # Create box effect with rectangle\n",
        "    rect = plt.Rectangle((x-0.08, y-0.06), 0.16, 0.12,\n",
        "                        facecolor=color, alpha=0.2,\n",
        "                        edgecolor=color, linewidth=2)\n",
        "    ax1.add_patch(rect)\n",
        "    ax1.text(x, y, text, ha='center', va='center',\n",
        "            fontsize=11, weight='bold', color=color)\n",
        "\n",
        "# Draw paths with annotations\n",
        "# Path a\n",
        "ax1.annotate('', xy=var_pos['M'], xytext=var_pos['X'],\n",
        "            arrowprops=dict(arrowstyle='->', lw=2.5, color=colors['primary']))\n",
        "ax1.text(0.35, 0.52, f'a = {a_coeff:.3f}{\"*\" if model_m.pvalues[\"norm_LC_avg\"] < 0.05 else \"\"}',\n",
        "         ha='center', fontsize=10, weight='bold')\n",
        "\n",
        "# Path b\n",
        "ax1.annotate('', xy=var_pos['Y'], xytext=var_pos['M'],\n",
        "            arrowprops=dict(arrowstyle='->', lw=2.5, color=colors['secondary']))\n",
        "ax1.text(0.65, 0.52, f'b = {b_coeff:.3f}{\"*\" if model_y.pvalues[\"alpha_NET_mean\"] < 0.05 else \"\"}',\n",
        "         ha='center', fontsize=10, weight='bold')\n",
        "\n",
        "# Path c' (direct)\n",
        "ax1.annotate('', xy=(0.78, 0.38), xytext=(0.22, 0.38),\n",
        "            arrowprops=dict(arrowstyle='->', lw=2, color=colors['quaternary'],\n",
        "                          connectionstyle=\"arc3,rad=-0.3\"))\n",
        "ax1.text(0.5, 0.28, f\"c' = {c_prime_coeff:.3f}{'*' if model_y.pvalues['norm_LC_avg'] < 0.05 else ''}\",\n",
        "         ha='center', fontsize=10, weight='bold')\n",
        "\n",
        "# Age paths (dashed)\n",
        "ax1.annotate('', xy=(0.48, 0.54), xytext=(0.48, 0.21),\n",
        "            arrowprops=dict(arrowstyle='->', lw=1.5, color='gray', linestyle='dashed'))\n",
        "ax1.annotate('', xy=(0.76, 0.36), xytext=(0.54, 0.19),\n",
        "            arrowprops=dict(arrowstyle='->', lw=1.5, color='gray', linestyle='dashed'))\n",
        "\n",
        "# Add key results\n",
        "sig_indirect = '*' if ci_lower * ci_upper > 0 else ''\n",
        "ax1.text(0.5, 0.05,\n",
        "         f'Indirect effect (a×b) = {indirect_effect:.3f}{sig_indirect} [95% CI: {ci_lower:.3f}, {ci_upper:.3f}]',\n",
        "         ha='center', fontsize=11, style='italic', bbox=dict(boxstyle=\"round,pad=0.3\",\n",
        "                                                              facecolor='white',\n",
        "                                                              edgecolor='gray'))\n",
        "ax1.set_xlim(0, 1)\n",
        "ax1.set_ylim(0, 1)\n",
        "\n",
        "# 2-4. Main regression plots\n",
        "# Plot 2: Total effect\n",
        "ax2 = fig.add_subplot(gs[1, 0])\n",
        "sns.scatterplot(x='norm_LC_avg', y='exploitation_percentage', data=mediation_data,\n",
        "                alpha=0.6, color=colors['primary'], s=60, ax=ax2)\n",
        "sns.regplot(x='norm_LC_avg', y='exploitation_percentage', data=mediation_data,\n",
        "            scatter=False, color=colors['primary'], ax=ax2)\n",
        "ax2.set_title(f'Total Effect (Path c)\\nβ = {c_coeff:.3f}, p = {model_total.pvalues[\"norm_LC_avg\"]:.3f}',\n",
        "              fontsize=12, pad=10)\n",
        "ax2.set_xlabel('NMLC', fontsize=11)\n",
        "ax2.set_ylabel('Exploitation %', fontsize=11)\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "# Plot 3: Path a\n",
        "ax3 = fig.add_subplot(gs[1, 1])\n",
        "sns.scatterplot(x='norm_LC_avg', y='alpha_NET_mean', data=mediation_data,\n",
        "                alpha=0.6, color=colors['secondary'], s=60, ax=ax3)\n",
        "sns.regplot(x='norm_LC_avg', y='alpha_NET_mean', data=mediation_data,\n",
        "            scatter=False, color=colors['secondary'], ax=ax3)\n",
        "ax3.set_title(f'Path a: NMLC → Alpha\\nβ = {a_coeff:.3f}, p = {model_m.pvalues[\"norm_LC_avg\"]:.3f}',\n",
        "              fontsize=12, pad=10)\n",
        "ax3.set_xlabel('NMLC', fontsize=11)\n",
        "ax3.set_ylabel('Alpha Power', fontsize=11)\n",
        "ax3.grid(True, alpha=0.3)\n",
        "\n",
        "# Plot 4: Path b\n",
        "ax4 = fig.add_subplot(gs[1, 2])\n",
        "sns.scatterplot(x='alpha_NET_mean', y='exploitation_percentage', data=mediation_data,\n",
        "                alpha=0.6, color=colors['tertiary'], s=60, ax=ax4)\n",
        "sns.regplot(x='alpha_NET_mean', y='exploitation_percentage', data=mediation_data,\n",
        "            scatter=False, color=colors['tertiary'], ax=ax4)\n",
        "ax4.set_title(f'Path b: Alpha → Exploitation\\nβ = {b_coeff:.3f}, p = {model_y.pvalues[\"alpha_NET_mean\"]:.3f}',\n",
        "              fontsize=12, pad=10)\n",
        "ax4.set_xlabel('Alpha Power', fontsize=11)\n",
        "ax4.set_ylabel('Exploitation %', fontsize=11)\n",
        "ax4.grid(True, alpha=0.3)\n",
        "\n",
        "# 5. Bootstrap distribution\n",
        "ax5 = fig.add_subplot(gs[2, 0])\n",
        "if len(boot_effects) > 0:\n",
        "    ax5.hist(boot_effects, bins=50, alpha=0.7, color=colors['highlight'],\n",
        "             edgecolor='black', linewidth=0.5)\n",
        "    ax5.axvline(indirect_effect, color='red', linestyle='--', linewidth=2,\n",
        "                label=f'Observed ({indirect_effect:.3f})')\n",
        "    ax5.axvline(ci_lower, color='black', linestyle=':', linewidth=2)\n",
        "    ax5.axvline(ci_upper, color='black', linestyle=':', linewidth=2)\n",
        "    ax5.axvline(0, color='gray', linestyle='-', linewidth=1, alpha=0.5)\n",
        "\n",
        "    # Add shaded CI region\n",
        "    ax5.axvspan(ci_lower, ci_upper, alpha=0.2, color='gray', label='95% CI')\n",
        "\n",
        "    ax5.set_title('Bootstrap Distribution of Indirect Effect', fontsize=12, pad=10)\n",
        "    ax5.set_xlabel('Indirect Effect (a×b)', fontsize=11)\n",
        "    ax5.set_ylabel('Frequency', fontsize=11)\n",
        "    ax5.legend(loc='best')\n",
        "    ax5.grid(True, alpha=0.3)\n",
        "else:\n",
        "    ax5.text(0.5, 0.5, 'Bootstrap failed', ha='center', va='center')\n",
        "    ax5.set_title('Bootstrap Distribution', fontsize=12)\n",
        "\n",
        "# 6. Effect sizes comparison\n",
        "ax6 = fig.add_subplot(gs[2, 1])\n",
        "effects = ['Total (c)', 'Direct (c\\')', 'Indirect (a×b)']\n",
        "values = [c_coeff, c_prime_coeff, indirect_effect]\n",
        "colors_bar = [colors['primary'], colors['quaternary'], colors['highlight']]\n",
        "\n",
        "bars = ax6.barh(effects, values, color=colors_bar, alpha=0.7, edgecolor='black')\n",
        "ax6.axvline(0, color='black', linewidth=0.5)\n",
        "ax6.set_xlabel('Effect Size', fontsize=11)\n",
        "ax6.set_title('Comparison of Effects', fontsize=12, pad=10)\n",
        "ax6.grid(True, alpha=0.3, axis='x')\n",
        "\n",
        "# Add value labels\n",
        "for bar, val in zip(bars, values):\n",
        "    ax6.text(val + 0.01 if val > 0 else val - 0.01, bar.get_y() + bar.get_height()/2,\n",
        "             f'{val:.3f}', va='center', ha='left' if val > 0 else 'right', fontsize=10)\n",
        "\n",
        "# 7. Model diagnostics summary\n",
        "ax7 = fig.add_subplot(gs[2, 2])\n",
        "ax7.axis('off')\n",
        "\n",
        "# Create summary text\n",
        "summary_text = f\"\"\"Model Summary\n",
        "{'─' * 25}\n",
        "Sample size: {final_n}\n",
        "Outliers detected: {sum(outlier_info.values())}\n",
        "\n",
        "R² Values:\n",
        "- Path a model: {model_m.rsquared:.3f}\n",
        "- Full model: {model_y.rsquared:.3f}\n",
        "- Total effect: {model_total.rsquared:.3f}\n",
        "\n",
        "Mediation Results:\n",
        "- Indirect effect: {indirect_effect:.3f}\n",
        "- Proportion mediated: {prop_mediated:.1%}\n",
        "- Significant: {'Yes' if ci_lower * ci_upper > 0 else 'No'}\n",
        "\n",
        "All p-values < 0.05 marked with *\n",
        "\"\"\"\n",
        "\n",
        "ax7.text(0.1, 0.9, summary_text, transform=ax7.transAxes,\n",
        "         fontsize=10, verticalalignment='top', fontfamily='monospace',\n",
        "         bbox=dict(boxstyle=\"round,pad=0.5\", facecolor='lightgray', alpha=0.3))\n",
        "\n",
        "# Overall title\n",
        "fig.suptitle(f'Mediation Analysis: NMLC → Alpha Power → Exploitation % (n={final_n})',\n",
        "             fontsize=16, y=0.98, weight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Print final summary\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"MEDIATION ANALYSIS SUMMARY\")\n",
        "print(\"=\"*70)\n",
        "print(f\"\\nSample size: {final_n}\")\n",
        "print(f\"\\nEffects (unstandardized):\")\n",
        "print(f\"  • Path a (NMLC → Alpha):        {a_coeff:.4f} (p = {model_m.pvalues['norm_LC_avg']:.4f})\")\n",
        "print(f\"  • Path b (Alpha → Exploit):     {b_coeff:.4f} (p = {model_y.pvalues['alpha_NET_mean']:.4f})\")\n",
        "print(f\"  • Path c' (Direct effect):      {c_prime_coeff:.4f} (p = {model_y.pvalues['norm_LC_avg']:.4f})\")\n",
        "print(f\"  • Path c (Total effect):        {c_coeff:.4f} (p = {model_total.pvalues['norm_LC_avg']:.4f})\")\n",
        "print(f\"\\nIndirect effect (a×b):           {indirect_effect:.4f}\")\n",
        "print(f\"  • 95% CI: [{ci_lower:.4f}, {ci_upper:.4f}]\")\n",
        "print(f\"  • Significant: {'Yes' if ci_lower * ci_upper > 0 else 'No'}\")\n",
        "if not np.isnan(prop_mediated):\n",
        "    print(f\"\\nProportion mediated: {prop_mediated:.1%}\")\n",
        "\n",
        "print(\"\\n✓ Analysis complete!\")"
      ],
      "metadata": {
        "id": "Dj3-GxmPDe-_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Better formatting and interpretation of null results\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"MEDIATION ANALYSIS RESULTS\")\n",
        "print(\"=\"*70)\n",
        "print(f\"\\nSample size: {final_n}\")\n",
        "print(\"\\n\" + \"-\"*35)\n",
        "print(\"PATH COEFFICIENTS\")\n",
        "print(\"-\"*35)\n",
        "\n",
        "# Create a results table\n",
        "results_data = {\n",
        "    'Path': ['a (NMLC → Alpha)',\n",
        "             'b (Alpha → Exploitation)',\n",
        "             \"c' (Direct effect)\",\n",
        "             'c (Total effect)',\n",
        "             'a×b (Indirect effect)'],\n",
        "    'Coefficient': [f\"{a_coeff:.4f}\",\n",
        "                    f\"{b_coeff:.4f}\",\n",
        "                    f\"{c_prime_coeff:.4f}\",\n",
        "                    f\"{c_coeff:.4f}\",\n",
        "                    f\"{indirect_effect:.4f}\"],\n",
        "    'SE': [f\"{model_m.bse['norm_LC_avg']:.4f}\",\n",
        "           f\"{model_y.bse['alpha_NET_mean']:.4f}\",\n",
        "           f\"{model_y.bse['norm_LC_avg']:.4f}\",\n",
        "           f\"{model_total.bse['norm_LC_avg']:.4f}\",\n",
        "           \"\"],\n",
        "    'p-value': [f\"{model_m.pvalues['norm_LC_avg']:.3f}\",\n",
        "                f\"{model_y.pvalues['alpha_NET_mean']:.3f}\",\n",
        "                f\"{model_y.pvalues['norm_LC_avg']:.3f}\",\n",
        "                f\"{model_total.pvalues['norm_LC_avg']:.3f}\",\n",
        "                \"\"],\n",
        "    'Significant': ['No', 'No', 'No', 'No',\n",
        "                    'No' if ci_lower * ci_upper < 0 else 'Yes']\n",
        "}\n",
        "\n",
        "# Print as formatted table\n",
        "for i, path in enumerate(results_data['Path']):\n",
        "    if i < 4:\n",
        "        print(f\"{path:<30} β = {results_data['Coefficient'][i]:>8}  \"\n",
        "              f\"SE = {results_data['SE'][i]:>8}  \"\n",
        "              f\"p = {results_data['p-value'][i]:>6}  \"\n",
        "              f\"{results_data['Significant'][i]:>5}\")\n",
        "    else:\n",
        "        print(f\"\\n{path:<30} = {results_data['Coefficient'][i]:>8}\")\n",
        "        print(f\"{'':30} 95% CI: [{ci_lower:.4f}, {ci_upper:.4f}]\")\n",
        "        print(f\"{'':30} Significant: {results_data['Significant'][i]}\")\n",
        "\n",
        "# Model fit statistics\n",
        "print(\"\\n\" + \"-\"*35)\n",
        "print(\"MODEL FIT\")\n",
        "print(\"-\"*35)\n",
        "print(f\"Path a model R²: {model_m.rsquared:.3f}\")\n",
        "print(f\"Full model R²:   {model_y.rsquared:.3f}\")\n",
        "print(f\"Total model R²:  {model_total.rsquared:.3f}\")\n",
        "\n",
        "# Interpretation\n",
        "print(\"\\n\" + \"-\"*35)\n",
        "print(\"INTERPRETATION\")\n",
        "print(\"-\"*35)\n",
        "\n",
        "# Check if any paths are significant\n",
        "any_sig = any(p < 0.05 for p in [model_m.pvalues['norm_LC_avg'],\n",
        "                                  model_y.pvalues['alpha_NET_mean'],\n",
        "                                  model_y.pvalues['norm_LC_avg'],\n",
        "                                  model_total.pvalues['norm_LC_avg']])\n",
        "\n",
        "if not any_sig and ci_lower * ci_upper < 0:\n",
        "    print(\"❌ No significant mediation effect was found.\")\n",
        "    print(\"\\nKey findings:\")\n",
        "    print(\"• NMLC does not significantly predict Alpha Power\")\n",
        "    print(\"• Alpha Power does not significantly predict Exploitation %\")\n",
        "    print(\"• NMLC does not have a significant direct or total effect on Exploitation %\")\n",
        "    print(\"• The indirect effect is not significant (CI includes zero)\")\n",
        "    print(\"\\nConclusion: The hypothesized mediation model is not supported by the data.\")\n",
        "\n",
        "    # Don't report proportion mediated when effects are non-significant and in opposite directions\n",
        "    print(\"\\nNote: Proportion mediated is not meaningful when effects are\")\n",
        "    print(\"      non-significant and in opposite directions.\")\n",
        "else:\n",
        "    # Report normal results if any effects are significant\n",
        "    if not np.isnan(prop_mediated) and abs(prop_mediated) < 2:  # Only if reasonable\n",
        "        print(f\"\\nProportion mediated: {prop_mediated:.1%}\")\n",
        "\n",
        "# Additional diagnostic information\n",
        "print(\"\\n\" + \"-\"*35)\n",
        "print(\"DIAGNOSTICS\")\n",
        "print(\"-\"*35)\n",
        "print(f\"Sample size: {final_n}\")\n",
        "print(f\"Power consideration: With n={final_n}, this study may be underpowered\")\n",
        "print(\"                    to detect small mediation effects.\")\n",
        "\n",
        "# Create a cleaner visualization for null results\n",
        "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
        "fig.suptitle('Mediation Analysis: Null Results Summary', fontsize=16, y=0.98)\n",
        "\n",
        "# 1. Path coefficients with confidence intervals\n",
        "ax1 = axes[0, 0]\n",
        "paths = ['Path a\\n(X→M)', 'Path b\\n(M→Y)', \"Path c'\\n(Direct)\", 'Path c\\n(Total)']\n",
        "coeffs = [a_coeff, b_coeff, c_prime_coeff, c_coeff]\n",
        "ses = [model_m.bse['norm_LC_avg'], model_y.bse['alpha_NET_mean'],\n",
        "       model_y.bse['norm_LC_avg'], model_total.bse['norm_LC_avg']]\n",
        "\n",
        "# Calculate confidence intervals\n",
        "cis = [(coef - 1.96*se, coef + 1.96*se) for coef, se in zip(coeffs, ses)]\n",
        "\n",
        "# Plot\n",
        "y_pos = range(len(paths))\n",
        "ax1.errorbar(coeffs, y_pos, xerr=[1.96*se for se in ses],\n",
        "             fmt='o', color='darkgray', capsize=5, capthick=2)\n",
        "ax1.axvline(0, color='black', linestyle='--', alpha=0.5)\n",
        "ax1.set_yticks(y_pos)\n",
        "ax1.set_yticklabels(paths)\n",
        "ax1.set_xlabel('Coefficient (95% CI)')\n",
        "ax1.set_title('Path Coefficients')\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# 2. P-values\n",
        "ax2 = axes[0, 1]\n",
        "p_values = [model_m.pvalues['norm_LC_avg'],\n",
        "            model_y.pvalues['alpha_NET_mean'],\n",
        "            model_y.pvalues['norm_LC_avg'],\n",
        "            model_total.pvalues['norm_LC_avg']]\n",
        "\n",
        "colors_p = ['red' if p > 0.05 else 'green' for p in p_values]\n",
        "bars = ax2.barh(paths, p_values, color=colors_p, alpha=0.6)\n",
        "ax2.axvline(0.05, color='black', linestyle='--', label='α = 0.05')\n",
        "ax2.set_xlabel('p-value')\n",
        "ax2.set_title('Statistical Significance')\n",
        "ax2.legend()\n",
        "\n",
        "# Add value labels\n",
        "for bar, p in zip(bars, p_values):\n",
        "    ax2.text(bar.get_width() + 0.01, bar.get_y() + bar.get_height()/2,\n",
        "             f'{p:.3f}', va='center')\n",
        "\n",
        "# 3. Bootstrap distribution with better annotation\n",
        "ax3 = axes[1, 0]\n",
        "if len(boot_effects) > 0:\n",
        "    ax3.hist(boot_effects, bins=50, alpha=0.7, color='lightblue', edgecolor='black')\n",
        "    ax3.axvline(0, color='black', linestyle='-', linewidth=2, label='Null hypothesis')\n",
        "    ax3.axvline(indirect_effect, color='red', linestyle='--', linewidth=2,\n",
        "                label=f'Observed ({indirect_effect:.3f})')\n",
        "    ax3.axvspan(ci_lower, ci_upper, alpha=0.2, color='gray', label='95% CI')\n",
        "    ax3.set_xlabel('Indirect Effect (a×b)')\n",
        "    ax3.set_ylabel('Frequency')\n",
        "    ax3.set_title('Bootstrap Distribution')\n",
        "    ax3.legend()\n",
        "\n",
        "# 4. Summary text\n",
        "ax4 = axes[1, 1]\n",
        "ax4.axis('off')\n",
        "summary = f\"\"\"\n",
        "RESULTS SUMMARY\n",
        "─────────────────────────\n",
        "No mediation effect detected\n",
        "\n",
        "Sample size: {final_n}\n",
        "Bootstrap iterations: {len(boot_effects)}\n",
        "\n",
        "All paths non-significant (p > 0.05)\n",
        "Indirect effect CI includes zero\n",
        "\n",
        "Recommendation:\n",
        "- Consider larger sample size\n",
        "- Re-examine theoretical model\n",
        "- Check measurement reliability\n",
        "\"\"\"\n",
        "ax4.text(0.1, 0.9, summary, transform=ax4.transAxes,\n",
        "         fontsize=11, verticalalignment='top',\n",
        "         fontfamily='monospace',\n",
        "         bbox=dict(boxstyle=\"round,pad=0.5\", facecolor='lightyellow'))\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"✓ Analysis complete - No significant mediation found\")\n",
        "print(\"=\"*70)"
      ],
      "metadata": {
        "id": "qnVipgaDEl-Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import statsmodels.formula.api as smf\n",
        "import statsmodels.api as sm\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "import matplotlib.patches as mpatches\n",
        "from matplotlib.patches import FancyBboxPatch, Circle, FancyArrowPatch\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set up professional plotting style\n",
        "plt.rcParams['font.family'] = 'sans-serif'\n",
        "plt.rcParams['font.sans-serif'] = ['Arial', 'Helvetica', 'DejaVu Sans']\n",
        "plt.rcParams['font.size'] = 10\n",
        "plt.rcParams['axes.linewidth'] = 0.5\n",
        "plt.rcParams['lines.linewidth'] = 1.5\n",
        "plt.rcParams['patch.linewidth'] = 0.5\n",
        "plt.rcParams['grid.linewidth'] = 0.5\n",
        "plt.rcParams['xtick.labelsize'] = 9\n",
        "plt.rcParams['ytick.labelsize'] = 9\n",
        "plt.rcParams['legend.fontsize'] = 9\n",
        "plt.rcParams['figure.dpi'] = 300\n",
        "plt.rcParams['savefig.dpi'] = 300\n",
        "plt.rcParams['savefig.bbox'] = 'tight'\n",
        "plt.rcParams['savefig.pad_inches'] = 0.1\n",
        "\n",
        "# Professional color palette\n",
        "colors = {\n",
        "    'primary': '#2C3E50',      # Dark blue-gray\n",
        "    'secondary': '#E74C3C',    # Soft red\n",
        "    'tertiary': '#27AE60',     # Green\n",
        "    'quaternary': '#F39C12',   # Orange\n",
        "    'accent': '#8E44AD',       # Purple\n",
        "    'neutral': '#7F8C8D',      # Gray\n",
        "    'light': '#ECF0F1',        # Light gray\n",
        "    'white': '#FFFFFF'\n",
        "}\n",
        "\n",
        "# Function to add figure labels (A, B, C, etc.)\n",
        "def add_subplot_label(ax, label, x=-0.15, y=1.05):\n",
        "    ax.text(x, y, label, transform=ax.transAxes, fontsize=12, fontweight='bold')\n",
        "\n",
        "# Create output directory for PDFs\n",
        "import os\n",
        "output_dir = 'mediation_analysis_figures'\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "print(f\"Creating publication-quality figures in '{output_dir}' directory...\")\n",
        "\n",
        "# ========== FIGURE 1: Conceptual Model ==========\n",
        "fig1 = plt.figure(figsize=(10, 6))\n",
        "ax1 = fig1.add_subplot(111)\n",
        "ax1.set_xlim(0, 10)\n",
        "ax1.set_ylim(0, 6)\n",
        "ax1.axis('off')\n",
        "\n",
        "# Title\n",
        "ax1.text(5, 5.5, 'Conceptual Mediation Model', ha='center', fontsize=14, fontweight='bold')\n",
        "\n",
        "# Create boxes for variables\n",
        "box_style = \"round,pad=0.3\"\n",
        "box_props = dict(boxstyle=box_style, linewidth=2, edgecolor=colors['primary'])\n",
        "\n",
        "# Independent variable\n",
        "iv_box = FancyBboxPatch((0.5, 2.5), 2, 1, facecolor=colors['light'], **box_props)\n",
        "ax1.add_patch(iv_box)\n",
        "ax1.text(1.5, 3, 'NMLC\\n(X)', ha='center', va='center', fontsize=11, fontweight='bold')\n",
        "\n",
        "# Mediator\n",
        "med_box = FancyBboxPatch((4, 3.5), 2, 1, facecolor=colors['light'], **box_props)\n",
        "ax1.add_patch(med_box)\n",
        "ax1.text(5, 4, 'Alpha Power\\n(M)', ha='center', va='center', fontsize=11, fontweight='bold')\n",
        "\n",
        "# Dependent variable\n",
        "dv_box = FancyBboxPatch((7.5, 2.5), 2, 1, facecolor=colors['light'], **box_props)\n",
        "ax1.add_patch(dv_box)\n",
        "ax1.text(8.5, 3, 'Exploitation %\\n(Y)', ha='center', va='center', fontsize=11, fontweight='bold')\n",
        "\n",
        "# Covariate\n",
        "cov_box = FancyBboxPatch((4, 0.5), 2, 0.8, facecolor=colors['white'],\n",
        "                         boxstyle=box_style, linewidth=1.5,\n",
        "                         edgecolor=colors['neutral'], linestyle='--')\n",
        "ax1.add_patch(cov_box)\n",
        "ax1.text(5, 0.9, 'Age (Covariate)', ha='center', va='center', fontsize=10, style='italic')\n",
        "\n",
        "# Arrows\n",
        "arrow_props = dict(arrowstyle='->', lw=2, color=colors['primary'])\n",
        "# Path a\n",
        "ax1.annotate('', xy=(3.9, 4), xytext=(2.6, 3.2), arrowprops=arrow_props)\n",
        "ax1.text(3.2, 3.8, 'a', ha='center', fontsize=11, fontweight='bold')\n",
        "\n",
        "# Path b\n",
        "ax1.annotate('', xy=(7.4, 3.2), xytext=(6.1, 4), arrowprops=arrow_props)\n",
        "ax1.text(6.7, 3.8, 'b', ha='center', fontsize=11, fontweight='bold')\n",
        "\n",
        "# Path c'\n",
        "ax1.annotate('', xy=(7.4, 2.7), xytext=(2.6, 2.7),\n",
        "             arrowprops=dict(arrowstyle='->', lw=2, color=colors['quaternary'],\n",
        "                           connectionstyle=\"arc3,rad=-.3\"))\n",
        "ax1.text(5, 2, \"c'\", ha='center', fontsize=11, fontweight='bold', color=colors['quaternary'])\n",
        "\n",
        "# Covariate arrows (dashed)\n",
        "cov_arrow_props = dict(arrowstyle='->', lw=1.5, color=colors['neutral'], linestyle='--')\n",
        "ax1.annotate('', xy=(4.8, 3.4), xytext=(5, 1.4), arrowprops=cov_arrow_props)\n",
        "ax1.annotate('', xy=(7.6, 2.5), xytext=(5.8, 1.3), arrowprops=cov_arrow_props)\n",
        "\n",
        "# Add equation\n",
        "ax1.text(5, 0.2, 'Indirect effect = a × b', ha='center', fontsize=10,\n",
        "         style='italic', bbox=dict(boxstyle=\"round,pad=0.3\", facecolor='white',\n",
        "                                  edgecolor=colors['neutral']))\n",
        "\n",
        "plt.tight_layout()\n",
        "fig1.savefig(f'{output_dir}/figure1_conceptual_model.pdf', format='pdf', bbox_inches='tight')\n",
        "plt.close()\n",
        "print(\"✓ Figure 1 saved: conceptual_model.pdf\")\n",
        "\n",
        "# ========== FIGURE 2: Path Coefficients and Confidence Intervals ==========\n",
        "fig2, (ax2a, ax2b) = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "# Left panel: Forest plot of coefficients\n",
        "paths = ['Path a\\n(NMLC→Alpha)', 'Path b\\n(Alpha→Exploit)',\n",
        "         \"Path c'\\n(Direct)\", 'Path c\\n(Total)']\n",
        "coeffs = [a_coeff, b_coeff, c_prime_coeff, c_coeff]\n",
        "ses = [model_m.bse['norm_LC_avg'], model_y.bse['alpha_NET_mean'],\n",
        "       model_y.bse['norm_LC_avg'], model_total.bse['norm_LC_avg']]\n",
        "\n",
        "y_pos = range(len(paths))\n",
        "ax2a.errorbar(coeffs, y_pos, xerr=[1.96*se for se in ses],\n",
        "              fmt='o', color=colors['primary'], markersize=8,\n",
        "              capsize=6, capthick=2, elinewidth=2)\n",
        "\n",
        "# Add null line\n",
        "ax2a.axvline(0, color='black', linestyle='--', alpha=0.5, linewidth=1)\n",
        "\n",
        "# Styling\n",
        "ax2a.set_yticks(y_pos)\n",
        "ax2a.set_yticklabels(paths)\n",
        "ax2a.set_xlabel('Coefficient (95% CI)', fontsize=11)\n",
        "ax2a.set_title('Path Coefficients', fontsize=12, fontweight='bold', pad=10)\n",
        "ax2a.grid(True, alpha=0.3, linestyle=':')\n",
        "ax2a.set_axisbelow(True)\n",
        "\n",
        "# Add coefficient values\n",
        "for i, (coef, se) in enumerate(zip(coeffs, ses)):\n",
        "    ax2a.text(coef + 2.5*se, i, f'{coef:.3f}', va='center', fontsize=9)\n",
        "\n",
        "add_subplot_label(ax2a, 'A')\n",
        "\n",
        "# Right panel: P-values with significance threshold\n",
        "p_values = [model_m.pvalues['norm_LC_avg'],\n",
        "            model_y.pvalues['alpha_NET_mean'],\n",
        "            model_y.pvalues['norm_LC_avg'],\n",
        "            model_total.pvalues['norm_LC_avg']]\n",
        "\n",
        "bars = ax2b.barh(y_pos, p_values,\n",
        "                 color=[colors['secondary'] if p > 0.05 else colors['tertiary'] for p in p_values],\n",
        "                 alpha=0.7, edgecolor='black', linewidth=0.5)\n",
        "\n",
        "# Add significance line\n",
        "ax2b.axvline(0.05, color='black', linestyle='--', linewidth=2, label='α = 0.05')\n",
        "\n",
        "# Styling\n",
        "ax2b.set_yticks(y_pos)\n",
        "ax2b.set_yticklabels(paths)\n",
        "ax2b.set_xlabel('p-value', fontsize=11)\n",
        "ax2b.set_title('Statistical Significance', fontsize=12, fontweight='bold', pad=10)\n",
        "ax2b.set_xlim(0, max(p_values) * 1.2)\n",
        "ax2b.legend(loc='lower right', frameon=True, fancybox=True, shadow=True)\n",
        "\n",
        "# Add p-value labels\n",
        "for i, (bar, p) in enumerate(zip(bars, p_values)):\n",
        "    ax2b.text(bar.get_width() + 0.02, bar.get_y() + bar.get_height()/2,\n",
        "              f'{p:.3f}', va='center', fontsize=9)\n",
        "\n",
        "add_subplot_label(ax2b, 'B')\n",
        "\n",
        "plt.tight_layout()\n",
        "fig2.savefig(f'{output_dir}/figure2_coefficients_pvalues.pdf', format='pdf', bbox_inches='tight')\n",
        "plt.close()\n",
        "print(\"✓ Figure 2 saved: coefficients_pvalues.pdf\")\n",
        "\n",
        "# ========== FIGURE 3: Bootstrap Analysis ==========\n",
        "fig3, (ax3a, ax3b) = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "# Left panel: Bootstrap distribution\n",
        "if len(boot_effects) > 0:\n",
        "    n, bins, patches = ax3a.hist(boot_effects, bins=50, alpha=0.7,\n",
        "                                  color=colors['accent'], edgecolor='black',\n",
        "                                  linewidth=0.5, density=True)\n",
        "\n",
        "    # Add kernel density estimate\n",
        "    kde_x = np.linspace(min(boot_effects), max(boot_effects), 200)\n",
        "    kde = stats.gaussian_kde(boot_effects)\n",
        "    ax3a.plot(kde_x, kde(kde_x), color=colors['primary'], linewidth=2, label='KDE')\n",
        "\n",
        "    # Add reference lines\n",
        "    ax3a.axvline(0, color='black', linestyle='-', linewidth=2, label='Null hypothesis')\n",
        "    ax3a.axvline(indirect_effect, color=colors['secondary'], linestyle='--',\n",
        "                 linewidth=2, label=f'Observed ({indirect_effect:.3f})')\n",
        "\n",
        "    # Shade confidence interval\n",
        "    ax3a.axvspan(ci_lower, ci_upper, alpha=0.2, color=colors['neutral'],\n",
        "                 label=f'95% CI [{ci_lower:.2f}, {ci_upper:.2f}]')\n",
        "\n",
        "    ax3a.set_xlabel('Indirect Effect (a×b)', fontsize=11)\n",
        "    ax3a.set_ylabel('Density', fontsize=11)\n",
        "    ax3a.set_title('Bootstrap Distribution of Indirect Effect', fontsize=12, fontweight='bold', pad=10)\n",
        "    ax3a.legend(loc='best', frameon=True, fancybox=True, shadow=True)\n",
        "    ax3a.grid(True, alpha=0.3, linestyle=':')\n",
        "    ax3a.set_axisbelow(True)\n",
        "\n",
        "add_subplot_label(ax3a, 'A')\n",
        "\n",
        "# Right panel: Effect size comparison\n",
        "effects = ['Total\\n(c)', 'Direct\\n(c\\')', 'Indirect\\n(a×b)']\n",
        "values = [c_coeff, c_prime_coeff, indirect_effect]\n",
        "colors_bar = [colors['primary'], colors['quaternary'], colors['accent']]\n",
        "\n",
        "bars = ax3b.bar(effects, values, color=colors_bar, alpha=0.7,\n",
        "                 edgecolor='black', linewidth=1)\n",
        "\n",
        "# Add error bars for indirect effect\n",
        "if len(boot_effects) > 0:\n",
        "    ci_err = [[indirect_effect - ci_lower], [ci_upper - indirect_effect]]\n",
        "    ax3b.errorbar(2, indirect_effect, yerr=ci_err, fmt='none',\n",
        "                  color='black', capsize=5, capthick=2)\n",
        "\n",
        "ax3b.axhline(0, color='black', linewidth=0.5)\n",
        "ax3b.set_ylabel('Effect Size', fontsize=11)\n",
        "ax3b.set_title('Decomposition of Effects', fontsize=12, fontweight='bold', pad=10)\n",
        "ax3b.grid(True, alpha=0.3, linestyle=':', axis='y')\n",
        "ax3b.set_axisbelow(True)\n",
        "\n",
        "# Add value labels\n",
        "for bar, val in zip(bars, values):\n",
        "    height = bar.get_height()\n",
        "    ax3b.text(bar.get_x() + bar.get_width()/2,\n",
        "              height + 0.5 if height > 0 else height - 0.5,\n",
        "              f'{val:.3f}', ha='center', va='bottom' if height > 0 else 'top',\n",
        "              fontsize=10, fontweight='bold')\n",
        "\n",
        "add_subplot_label(ax3b, 'B')\n",
        "\n",
        "plt.tight_layout()\n",
        "fig3.savefig(f'{output_dir}/figure3_bootstrap_effects.pdf', format='pdf', bbox_inches='tight')\n",
        "plt.close()\n",
        "print(\"✓ Figure 3 saved: bootstrap_effects.pdf\")\n",
        "\n",
        "# ========== FIGURE 4: Scatter Plots Matrix ==========\n",
        "fig4 = plt.figure(figsize=(14, 5))\n",
        "gs = fig4.add_gridspec(1, 3, wspace=0.25)\n",
        "\n",
        "# Plot 1: X vs Y (Total effect)\n",
        "ax4a = fig4.add_subplot(gs[0])\n",
        "sns.scatterplot(x='norm_LC_avg', y='exploitation_percentage', data=mediation_data,\n",
        "                alpha=0.6, color=colors['primary'], s=50, ax=ax4a)\n",
        "sns.regplot(x='norm_LC_avg', y='exploitation_percentage', data=mediation_data,\n",
        "            scatter=False, color=colors['primary'], ax=ax4a, line_kws={'linewidth': 2})\n",
        "\n",
        "ax4a.set_xlabel('NMLC', fontsize=11)\n",
        "ax4a.set_ylabel('Exploitation %', fontsize=11)\n",
        "ax4a.set_title(f'Total Effect (c = {c_coeff:.3f}, p = {model_total.pvalues[\"norm_LC_avg\"]:.3f})',\n",
        "               fontsize=11, fontweight='bold')\n",
        "ax4a.grid(True, alpha=0.3, linestyle=':')\n",
        "ax4a.set_axisbelow(True)\n",
        "add_subplot_label(ax4a, 'A', x=-0.12)\n",
        "\n",
        "# Plot 2: X vs M (Path a)\n",
        "ax4b = fig4.add_subplot(gs[1])\n",
        "sns.scatterplot(x='norm_LC_avg', y='alpha_NET_mean', data=mediation_data,\n",
        "                alpha=0.6, color=colors['secondary'], s=50, ax=ax4b)\n",
        "sns.regplot(x='norm_LC_avg', y='alpha_NET_mean', data=mediation_data,\n",
        "            scatter=False, color=colors['secondary'], ax=ax4b, line_kws={'linewidth': 2})\n",
        "\n",
        "ax4b.set_xlabel('NMLC', fontsize=11)\n",
        "ax4b.set_ylabel('Alpha Power', fontsize=11)\n",
        "ax4b.set_title(f'Path a (β = {a_coeff:.3f}, p = {model_m.pvalues[\"norm_LC_avg\"]:.3f})',\n",
        "               fontsize=11, fontweight='bold')\n",
        "ax4b.grid(True, alpha=0.3, linestyle=':')\n",
        "ax4b.set_axisbelow(True)\n",
        "add_subplot_label(ax4b, 'B', x=-0.12)\n",
        "\n",
        "# Plot 3: M vs Y (Path b)\n",
        "ax4c = fig4.add_subplot(gs[2])\n",
        "sns.scatterplot(x='alpha_NET_mean', y='exploitation_percentage', data=mediation_data,\n",
        "                alpha=0.6, color=colors['tertiary'], s=50, ax=ax4c)\n",
        "sns.regplot(x='alpha_NET_mean', y='exploitation_percentage', data=mediation_data,\n",
        "            scatter=False, color=colors['tertiary'], ax=ax4c, line_kws={'linewidth': 2})\n",
        "\n",
        "ax4c.set_xlabel('Alpha Power', fontsize=11)\n",
        "ax4c.set_ylabel('Exploitation %', fontsize=11)\n",
        "ax4c.set_title(f'Path b (β = {b_coeff:.3f}, p = {model_y.pvalues[\"alpha_NET_mean\"]:.3f})',\n",
        "               fontsize=11, fontweight='bold')\n",
        "ax4c.grid(True, alpha=0.3, linestyle=':')\n",
        "ax4c.set_axisbelow(True)\n",
        "add_subplot_label(ax4c, 'C', x=-0.12)\n",
        "\n",
        "plt.tight_layout()\n",
        "fig4.savefig(f'{output_dir}/figure4_scatter_plots.pdf', format='pdf', bbox_inches='tight')\n",
        "plt.close()\n",
        "print(\"✓ Figure 4 saved: scatter_plots.pdf\")\n",
        "\n",
        "# ========== FIGURE 5: Summary Results (Alternative to Table) ==========\n",
        "fig5 = plt.figure(figsize=(10, 8))\n",
        "ax5 = fig5.add_subplot(111)\n",
        "ax5.axis('off')\n",
        "\n",
        "# Title\n",
        "title_y = 0.95\n",
        "ax5.text(0.5, title_y, 'Mediation Analysis Summary', ha='center', fontsize=16,\n",
        "         fontweight='bold', transform=ax5.transAxes)\n",
        "\n",
        "# Create structured text summary instead of table\n",
        "summary_y = 0.85\n",
        "line_height = 0.06\n",
        "\n",
        "# Path coefficients section\n",
        "section_headers = {\n",
        "    'Path Coefficients': 0.85,\n",
        "    'Model Fit': 0.45,\n",
        "    'Bootstrap Results': 0.25,\n",
        "    'Conclusion': 0.05\n",
        "}\n",
        "\n",
        "# Path coefficients\n",
        "ax5.text(0.1, section_headers['Path Coefficients'], 'Path Coefficients:',\n",
        "         fontsize=12, fontweight='bold', transform=ax5.transAxes)\n",
        "\n",
        "path_info = [\n",
        "    ('Path a (NMLC → Alpha):', a_coeff, model_m.bse['norm_LC_avg'], model_m.pvalues['norm_LC_avg']),\n",
        "    ('Path b (Alpha → Exploitation):', b_coeff, model_y.bse['alpha_NET_mean'], model_y.pvalues['alpha_NET_mean']),\n",
        "    (\"Path c' (Direct effect):\", c_prime_coeff, model_y.bse['norm_LC_avg'], model_y.pvalues['norm_LC_avg']),\n",
        "    ('Path c (Total effect):', c_coeff, model_total.bse['norm_LC_avg'], model_total.pvalues['norm_LC_avg'])\n",
        "]\n",
        "\n",
        "y_pos = section_headers['Path Coefficients'] - 0.05\n",
        "for label, coef, se, pval in path_info:\n",
        "    sig_marker = '*' if pval < 0.05 else ''\n",
        "    text = f'{label:<35} β = {coef:>7.4f} (SE = {se:.4f}), p = {pval:.3f}{sig_marker}'\n",
        "    ax5.text(0.15, y_pos, text, fontsize=10, fontfamily='monospace', transform=ax5.transAxes)\n",
        "    y_pos -= line_height\n",
        "\n",
        "# Model fit section\n",
        "ax5.text(0.1, section_headers['Model Fit'], 'Model Fit:',\n",
        "         fontsize=12, fontweight='bold', transform=ax5.transAxes)\n",
        "\n",
        "fit_info = [\n",
        "    f'Path a model R² = {model_m.rsquared:.3f}',\n",
        "    f'Full model R² = {model_y.rsquared:.3f}',\n",
        "    f'Total effect model R² = {model_total.rsquared:.3f}',\n",
        "    f'Sample size: n = {final_n}'\n",
        "]\n",
        "\n",
        "y_pos = section_headers['Model Fit'] - 0.05\n",
        "for info in fit_info:\n",
        "    ax5.text(0.15, y_pos, info, fontsize=10, fontfamily='monospace', transform=ax5.transAxes)\n",
        "    y_pos -= line_height\n",
        "\n",
        "# Bootstrap results section\n",
        "ax5.text(0.1, section_headers['Bootstrap Results'], 'Bootstrap Results:',\n",
        "         fontsize=12, fontweight='bold', transform=ax5.transAxes)\n",
        "\n",
        "boot_info = [\n",
        "    f'Indirect effect (a×b) = {indirect_effect:.4f}',\n",
        "    f'95% CI: [{ci_lower:.4f}, {ci_upper:.4f}]',\n",
        "    f'Bootstrap iterations: {len(boot_effects)}',\n",
        "    f'Significant: {\"No (CI includes zero)\" if ci_lower * ci_upper < 0 else \"Yes\"}'\n",
        "]\n",
        "\n",
        "y_pos = section_headers['Bootstrap Results'] - 0.05\n",
        "for info in boot_info:\n",
        "    ax5.text(0.15, y_pos, info, fontsize=10, fontfamily='monospace', transform=ax5.transAxes)\n",
        "    y_pos -= line_height\n",
        "\n",
        "# Conclusion box\n",
        "conclusion_text = ('No significant mediation effect was detected.\\n'\n",
        "                  'All path coefficients are non-significant (p > 0.05).\\n'\n",
        "                  'The indirect effect confidence interval includes zero.')\n",
        "\n",
        "ax5.text(0.5, section_headers['Conclusion'], conclusion_text,\n",
        "         ha='center', va='center', fontsize=11,\n",
        "         bbox=dict(boxstyle=\"round,pad=0.5\", facecolor='#ffeeee',\n",
        "                  edgecolor=colors['secondary'], linewidth=2),\n",
        "         transform=ax5.transAxes)\n",
        "\n",
        "plt.tight_layout()\n",
        "fig5.savefig(f'{output_dir}/figure5_summary_results.pdf', format='pdf', bbox_inches='tight')\n",
        "plt.close()\n",
        "print(\"✓ Figure 5 saved: summary_results.pdf\")\n",
        "\n",
        "print(f\"\\n✓ All figures saved successfully in '{output_dir}' directory:\")\n",
        "print(f\"  - figure1_conceptual_model.pdf\")\n",
        "print(f\"  - figure2_coefficients_pvalues.pdf\")\n",
        "print(f\"  - figure3_bootstrap_effects.pdf\")\n",
        "print(f\"  - figure4_scatter_plots.pdf\")\n",
        "print(f\"  - figure5_summary_results.pdf\")\n",
        "print(\"\\nThese figures are publication-ready and optimized for academic presentations.\")\n",
        "\n",
        "# Also create a combined PDF if you have PyPDF2 installed\n",
        "try:\n",
        "    from PyPDF2 import PdfMerger\n",
        "    merger = PdfMerger()\n",
        "\n",
        "    pdf_files = [\n",
        "        'figure1_conceptual_model.pdf',\n",
        "        'figure2_coefficients_pvalues.pdf',\n",
        "        'figure3_bootstrap_effects.pdf',\n",
        "        'figure4_scatter_plots.pdf',\n",
        "        'figure5_summary_results.pdf'\n",
        "    ]\n",
        "\n",
        "    for pdf in pdf_files:\n",
        "        merger.append(f'{output_dir}/{pdf}')\n",
        "\n",
        "    merger.write(f'{output_dir}/all_figures_combined.pdf')\n",
        "    merger.close()\n",
        "    print(f\"\\n✓ Also created: all_figures_combined.pdf\")\n",
        "except ImportError:\n",
        "    print(\"\\nNote: Install PyPDF2 to automatically combine all figures into one PDF\")"
      ],
      "metadata": {
        "id": "j5037o6dGAkQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import statsmodels.formula.api as smf\n",
        "import statsmodels.api as sm\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "import matplotlib.patches as mpatches\n",
        "from matplotlib.patches import FancyBboxPatch, Circle, FancyArrowPatch\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Load your data\n",
        "# mediation_data = pd.read_csv('your_data.csv')  # Update with your data path\n",
        "\n",
        "# MEDIATION ANALYSIS WITH NUM_ITEMS AS OUTCOME\n",
        "# =============================================\n",
        "\n",
        "# Step 1: Check data and remove missing values\n",
        "print(\"Original data shape:\", mediation_data.shape)\n",
        "mediation_data_clean = mediation_data[['norm_LC_avg', 'alpha_NET_mean', 'num_items', 'Age']].dropna()\n",
        "print(\"Clean data shape:\", mediation_data_clean.shape)\n",
        "final_n = len(mediation_data_clean)\n",
        "\n",
        "# Step 2: Run mediation models\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"MEDIATION ANALYSIS: NMLC → Alpha → Number of Items\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Model 1: X → M (Path a)\n",
        "print(\"\\n1. Path a: NMLC → Alpha Power\")\n",
        "model_m = smf.ols('alpha_NET_mean ~ norm_LC_avg + Age', data=mediation_data_clean).fit()\n",
        "a_coeff = model_m.params['norm_LC_avg']\n",
        "print(f\"   Coefficient: {a_coeff:.6f}\")\n",
        "print(f\"   p-value: {model_m.pvalues['norm_LC_avg']:.6f}\")\n",
        "\n",
        "# Model 2: X + M → Y (Paths b and c')\n",
        "print(\"\\n2. Full model: NMLC + Alpha → Number of Items\")\n",
        "model_y = smf.ols('num_items ~ norm_LC_avg + alpha_NET_mean + Age', data=mediation_data_clean).fit()\n",
        "b_coeff = model_y.params['alpha_NET_mean']\n",
        "c_prime_coeff = model_y.params['norm_LC_avg']\n",
        "print(f\"   Path b (Alpha → Items): {b_coeff:.6f}, p = {model_y.pvalues['alpha_NET_mean']:.6f}\")\n",
        "print(f\"   Path c' (Direct effect): {c_prime_coeff:.6f}, p = {model_y.pvalues['norm_LC_avg']:.6f}\")\n",
        "\n",
        "# Model 3: Total effect (c)\n",
        "print(\"\\n3. Total effect: NMLC → Number of Items\")\n",
        "model_total = smf.ols('num_items ~ norm_LC_avg + Age', data=mediation_data_clean).fit()\n",
        "c_coeff = model_total.params['norm_LC_avg']\n",
        "print(f\"   Coefficient: {c_coeff:.6f}\")\n",
        "print(f\"   p-value: {model_total.pvalues['norm_LC_avg']:.6f}\")\n",
        "\n",
        "# Calculate indirect effect\n",
        "indirect_effect = a_coeff * b_coeff\n",
        "print(f\"\\n4. Indirect effect (a × b): {indirect_effect:.6f}\")\n",
        "\n",
        "# Bootstrap confidence interval\n",
        "print(\"\\n5. Bootstrap confidence interval (5000 iterations)...\")\n",
        "n_boot = 5000\n",
        "boot_effects = []\n",
        "\n",
        "for i in range(n_boot):\n",
        "    # Resample data with replacement\n",
        "    boot_indices = np.random.choice(len(mediation_data_clean), size=len(mediation_data_clean), replace=True)\n",
        "    boot_data = mediation_data_clean.iloc[boot_indices]\n",
        "\n",
        "    try:\n",
        "        # Fit models on bootstrap sample\n",
        "        boot_m = smf.ols('alpha_NET_mean ~ norm_LC_avg + Age', data=boot_data).fit()\n",
        "        boot_y = smf.ols('num_items ~ norm_LC_avg + alpha_NET_mean + Age', data=boot_data).fit()\n",
        "\n",
        "        # Calculate indirect effect\n",
        "        boot_a = boot_m.params['norm_LC_avg']\n",
        "        boot_b = boot_y.params['alpha_NET_mean']\n",
        "        boot_effects.append(boot_a * boot_b)\n",
        "    except:\n",
        "        continue\n",
        "\n",
        "# Calculate confidence interval\n",
        "ci_lower = np.percentile(boot_effects, 2.5)\n",
        "ci_upper = np.percentile(boot_effects, 97.5)\n",
        "\n",
        "print(f\"   95% CI: [{ci_lower:.6f}, {ci_upper:.6f}]\")\n",
        "print(f\"   Significant: {'No (CI includes zero)' if ci_lower * ci_upper < 0 else 'Yes'}\")\n",
        "\n",
        "# Summary statistics\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"SUMMARY\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Sample size: n = {final_n}\")\n",
        "print(f\"Path a (NMLC → Alpha): β = {a_coeff:.4f}, p = {model_m.pvalues['norm_LC_avg']:.3f}\")\n",
        "print(f\"Path b (Alpha → Items): β = {b_coeff:.4f}, p = {model_y.pvalues['alpha_NET_mean']:.3f}\")\n",
        "print(f\"Path c' (Direct): β = {c_prime_coeff:.4f}, p = {model_y.pvalues['norm_LC_avg']:.3f}\")\n",
        "print(f\"Path c (Total): β = {c_coeff:.4f}, p = {model_total.pvalues['norm_LC_avg']:.3f}\")\n",
        "print(f\"Indirect effect: {indirect_effect:.4f}, 95% CI [{ci_lower:.4f}, {ci_upper:.4f}]\")\n",
        "print(\"\\nConclusion:\", \"Significant mediation\" if ci_lower * ci_upper > 0 else \"No significant mediation\")\n",
        "\n",
        "# VISUALIZATION CODE\n",
        "# ==================\n",
        "\n",
        "# Set up professional plotting style\n",
        "plt.rcParams['font.family'] = 'sans-serif'\n",
        "plt.rcParams['font.sans-serif'] = ['Arial', 'Helvetica', 'DejaVu Sans']\n",
        "plt.rcParams['font.size'] = 10\n",
        "plt.rcParams['axes.linewidth'] = 0.5\n",
        "plt.rcParams['lines.linewidth'] = 1.5\n",
        "plt.rcParams['patch.linewidth'] = 0.5\n",
        "plt.rcParams['grid.linewidth'] = 0.5\n",
        "plt.rcParams['xtick.labelsize'] = 9\n",
        "plt.rcParams['ytick.labelsize'] = 9\n",
        "plt.rcParams['legend.fontsize'] = 9\n",
        "plt.rcParams['figure.dpi'] = 300\n",
        "plt.rcParams['savefig.dpi'] = 300\n",
        "plt.rcParams['savefig.bbox'] = 'tight'\n",
        "plt.rcParams['savefig.pad_inches'] = 0.1\n",
        "\n",
        "# Professional color palette\n",
        "colors = {\n",
        "    'primary': '#2C3E50',      # Dark blue-gray\n",
        "    'secondary': '#E74C3C',    # Soft red\n",
        "    'tertiary': '#27AE60',     # Green\n",
        "    'quaternary': '#F39C12',   # Orange\n",
        "    'accent': '#8E44AD',       # Purple\n",
        "    'neutral': '#7F8C8D',      # Gray\n",
        "    'light': '#ECF0F1',        # Light gray\n",
        "    'white': '#FFFFFF'\n",
        "}\n",
        "\n",
        "# Function to add figure labels (A, B, C, etc.)\n",
        "def add_subplot_label(ax, label, x=-0.15, y=1.05):\n",
        "    ax.text(x, y, label, transform=ax.transAxes, fontsize=12, fontweight='bold')\n",
        "\n",
        "# Create output directory for PDFs\n",
        "import os\n",
        "output_dir = 'mediation_analysis_num_items'\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "print(f\"\\nCreating publication-quality figures in '{output_dir}' directory...\")\n",
        "\n",
        "# ========== FIGURE 1: Conceptual Model ==========\n",
        "fig1 = plt.figure(figsize=(10, 6))\n",
        "ax1 = fig1.add_subplot(111)\n",
        "ax1.set_xlim(0, 10)\n",
        "ax1.set_ylim(0, 6)\n",
        "ax1.axis('off')\n",
        "\n",
        "# Title\n",
        "ax1.text(5, 5.5, 'Conceptual Mediation Model', ha='center', fontsize=14, fontweight='bold')\n",
        "\n",
        "# Create boxes for variables\n",
        "box_style = \"round,pad=0.3\"\n",
        "box_props = dict(boxstyle=box_style, linewidth=2, edgecolor=colors['primary'])\n",
        "\n",
        "# Independent variable\n",
        "iv_box = FancyBboxPatch((0.5, 2.5), 2, 1, facecolor=colors['light'], **box_props)\n",
        "ax1.add_patch(iv_box)\n",
        "ax1.text(1.5, 3, 'NMLC\\n(X)', ha='center', va='center', fontsize=11, fontweight='bold')\n",
        "\n",
        "# Mediator\n",
        "med_box = FancyBboxPatch((4, 3.5), 2, 1, facecolor=colors['light'], **box_props)\n",
        "ax1.add_patch(med_box)\n",
        "ax1.text(5, 4, 'Alpha Power\\n(M)', ha='center', va='center', fontsize=11, fontweight='bold')\n",
        "\n",
        "# Dependent variable - UPDATED\n",
        "dv_box = FancyBboxPatch((7.5, 2.5), 2, 1, facecolor=colors['light'], **box_props)\n",
        "ax1.add_patch(dv_box)\n",
        "ax1.text(8.5, 3, 'Number of Items\\n(Y)', ha='center', va='center', fontsize=11, fontweight='bold')\n",
        "\n",
        "# Covariate\n",
        "cov_box = FancyBboxPatch((4, 0.5), 2, 0.8, facecolor=colors['white'],\n",
        "                         boxstyle=box_style, linewidth=1.5,\n",
        "                         edgecolor=colors['neutral'], linestyle='--')\n",
        "ax1.add_patch(cov_box)\n",
        "ax1.text(5, 0.9, 'Age (Covariate)', ha='center', va='center', fontsize=10, style='italic')\n",
        "\n",
        "# Arrows\n",
        "arrow_props = dict(arrowstyle='->', lw=2, color=colors['primary'])\n",
        "# Path a\n",
        "ax1.annotate('', xy=(3.9, 4), xytext=(2.6, 3.2), arrowprops=arrow_props)\n",
        "ax1.text(3.2, 3.8, 'a', ha='center', fontsize=11, fontweight='bold')\n",
        "\n",
        "# Path b\n",
        "ax1.annotate('', xy=(7.4, 3.2), xytext=(6.1, 4), arrowprops=arrow_props)\n",
        "ax1.text(6.7, 3.8, 'b', ha='center', fontsize=11, fontweight='bold')\n",
        "\n",
        "# Path c'\n",
        "ax1.annotate('', xy=(7.4, 2.7), xytext=(2.6, 2.7),\n",
        "             arrowprops=dict(arrowstyle='->', lw=2, color=colors['quaternary'],\n",
        "                           connectionstyle=\"arc3,rad=-.3\"))\n",
        "ax1.text(5, 2, \"c'\", ha='center', fontsize=11, fontweight='bold', color=colors['quaternary'])\n",
        "\n",
        "# Covariate arrows (dashed)\n",
        "cov_arrow_props = dict(arrowstyle='->', lw=1.5, color=colors['neutral'], linestyle='--')\n",
        "ax1.annotate('', xy=(4.8, 3.4), xytext=(5, 1.4), arrowprops=cov_arrow_props)\n",
        "ax1.annotate('', xy=(7.6, 2.5), xytext=(5.8, 1.3), arrowprops=cov_arrow_props)\n",
        "\n",
        "# Add equation\n",
        "ax1.text(5, 0.2, 'Indirect effect = a × b', ha='center', fontsize=10,\n",
        "         style='italic', bbox=dict(boxstyle=\"round,pad=0.3\", facecolor='white',\n",
        "                                  edgecolor=colors['neutral']))\n",
        "\n",
        "plt.tight_layout()\n",
        "fig1.savefig(f'{output_dir}/figure1_conceptual_model.pdf', format='pdf', bbox_inches='tight')\n",
        "plt.close()\n",
        "print(\"✓ Figure 1 saved: conceptual_model.pdf\")\n",
        "\n",
        "# ========== FIGURE 2: Path Coefficients and Confidence Intervals ==========\n",
        "fig2, (ax2a, ax2b) = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "# Left panel: Forest plot of coefficients\n",
        "paths = ['Path a\\n(NMLC→Alpha)', 'Path b\\n(Alpha→Items)',\n",
        "         \"Path c'\\n(Direct)\", 'Path c\\n(Total)']\n",
        "coeffs = [a_coeff, b_coeff, c_prime_coeff, c_coeff]\n",
        "ses = [model_m.bse['norm_LC_avg'], model_y.bse['alpha_NET_mean'],\n",
        "       model_y.bse['norm_LC_avg'], model_total.bse['norm_LC_avg']]\n",
        "\n",
        "y_pos = range(len(paths))\n",
        "ax2a.errorbar(coeffs, y_pos, xerr=[1.96*se for se in ses],\n",
        "              fmt='o', color=colors['primary'], markersize=8,\n",
        "              capsize=6, capthick=2, elinewidth=2)\n",
        "\n",
        "# Add null line\n",
        "ax2a.axvline(0, color='black', linestyle='--', alpha=0.5, linewidth=1)\n",
        "\n",
        "# Styling\n",
        "ax2a.set_yticks(y_pos)\n",
        "ax2a.set_yticklabels(paths)\n",
        "ax2a.set_xlabel('Coefficient (95% CI)', fontsize=11)\n",
        "ax2a.set_title('Path Coefficients', fontsize=12, fontweight='bold', pad=10)\n",
        "ax2a.grid(True, alpha=0.3, linestyle=':')\n",
        "ax2a.set_axisbelow(True)\n",
        "\n",
        "# Add coefficient values\n",
        "for i, (coef, se) in enumerate(zip(coeffs, ses)):\n",
        "    ax2a.text(coef + 2.5*se, i, f'{coef:.3f}', va='center', fontsize=9)\n",
        "\n",
        "add_subplot_label(ax2a, 'A')\n",
        "\n",
        "# Right panel: P-values with significance threshold\n",
        "p_values = [model_m.pvalues['norm_LC_avg'],\n",
        "            model_y.pvalues['alpha_NET_mean'],\n",
        "            model_y.pvalues['norm_LC_avg'],\n",
        "            model_total.pvalues['norm_LC_avg']]\n",
        "\n",
        "bars = ax2b.barh(y_pos, p_values,\n",
        "                 color=[colors['secondary'] if p > 0.05 else colors['tertiary'] for p in p_values],\n",
        "                 alpha=0.7, edgecolor='black', linewidth=0.5)\n",
        "\n",
        "# Add significance line\n",
        "ax2b.axvline(0.05, color='black', linestyle='--', linewidth=2, label='α = 0.05')\n",
        "\n",
        "# Styling\n",
        "ax2b.set_yticks(y_pos)\n",
        "ax2b.set_yticklabels(paths)\n",
        "ax2b.set_xlabel('p-value', fontsize=11)\n",
        "ax2b.set_title('Statistical Significance', fontsize=12, fontweight='bold', pad=10)\n",
        "ax2b.set_xlim(0, max(p_values) * 1.2)\n",
        "ax2b.legend(loc='lower right', frameon=True, fancybox=True, shadow=True)\n",
        "\n",
        "# Add p-value labels\n",
        "for i, (bar, p) in enumerate(zip(bars, p_values)):\n",
        "    ax2b.text(bar.get_width() + 0.02, bar.get_y() + bar.get_height()/2,\n",
        "              f'{p:.3f}', va='center', fontsize=9)\n",
        "\n",
        "add_subplot_label(ax2b, 'B')\n",
        "\n",
        "plt.tight_layout()\n",
        "fig2.savefig(f'{output_dir}/figure2_coefficients_pvalues.pdf', format='pdf', bbox_inches='tight')\n",
        "plt.close()\n",
        "print(\"✓ Figure 2 saved: coefficients_pvalues.pdf\")\n",
        "\n",
        "# ========== FIGURE 3: Bootstrap Analysis ==========\n",
        "fig3, (ax3a, ax3b) = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "# Left panel: Bootstrap distribution\n",
        "if len(boot_effects) > 0:\n",
        "    n, bins, patches = ax3a.hist(boot_effects, bins=50, alpha=0.7,\n",
        "                                  color=colors['accent'], edgecolor='black',\n",
        "                                  linewidth=0.5, density=True)\n",
        "\n",
        "    # Add kernel density estimate\n",
        "    kde_x = np.linspace(min(boot_effects), max(boot_effects), 200)\n",
        "    kde = stats.gaussian_kde(boot_effects)\n",
        "    ax3a.plot(kde_x, kde(kde_x), color=colors['primary'], linewidth=2, label='KDE')\n",
        "\n",
        "    # Add reference lines\n",
        "    ax3a.axvline(0, color='black', linestyle='-', linewidth=2, label='Null hypothesis')\n",
        "    ax3a.axvline(indirect_effect, color=colors['secondary'], linestyle='--',\n",
        "                 linewidth=2, label=f'Observed ({indirect_effect:.3f})')\n",
        "\n",
        "    # Shade confidence interval\n",
        "    ax3a.axvspan(ci_lower, ci_upper, alpha=0.2, color=colors['neutral'],\n",
        "                 label=f'95% CI [{ci_lower:.2f}, {ci_upper:.2f}]')\n",
        "\n",
        "    ax3a.set_xlabel('Indirect Effect (a×b)', fontsize=11)\n",
        "    ax3a.set_ylabel('Density', fontsize=11)\n",
        "    ax3a.set_title('Bootstrap Distribution of Indirect Effect', fontsize=12, fontweight='bold', pad=10)\n",
        "    ax3a.legend(loc='best', frameon=True, fancybox=True, shadow=True)\n",
        "    ax3a.grid(True, alpha=0.3, linestyle=':')\n",
        "    ax3a.set_axisbelow(True)\n",
        "\n",
        "add_subplot_label(ax3a, 'A')\n",
        "\n",
        "# Right panel: Effect size comparison\n",
        "effects = ['Total\\n(c)', 'Direct\\n(c\\')', 'Indirect\\n(a×b)']\n",
        "values = [c_coeff, c_prime_coeff, indirect_effect]\n",
        "colors_bar = [colors['primary'], colors['quaternary'], colors['accent']]\n",
        "\n",
        "bars = ax3b.bar(effects, values, color=colors_bar, alpha=0.7,\n",
        "                 edgecolor='black', linewidth=1)\n",
        "\n",
        "# Add error bars for indirect effect\n",
        "if len(boot_effects) > 0:\n",
        "    ci_err = [[indirect_effect - ci_lower], [ci_upper - indirect_effect]]\n",
        "    ax3b.errorbar(2, indirect_effect, yerr=ci_err, fmt='none',\n",
        "                  color='black', capsize=5, capthick=2)\n",
        "\n",
        "ax3b.axhline(0, color='black', linewidth=0.5)\n",
        "ax3b.set_ylabel('Effect Size', fontsize=11)\n",
        "ax3b.set_title('Decomposition of Effects', fontsize=12, fontweight='bold', pad=10)\n",
        "ax3b.grid(True, alpha=0.3, linestyle=':', axis='y')\n",
        "ax3b.set_axisbelow(True)\n",
        "\n",
        "# Add value labels\n",
        "for bar, val in zip(bars, values):\n",
        "    height = bar.get_height()\n",
        "    ax3b.text(bar.get_x() + bar.get_width()/2,\n",
        "              height + 0.5 if height > 0 else height - 0.5,\n",
        "              f'{val:.3f}', ha='center', va='bottom' if height > 0 else 'top',\n",
        "              fontsize=10, fontweight='bold')\n",
        "\n",
        "add_subplot_label(ax3b, 'B')\n",
        "\n",
        "plt.tight_layout()\n",
        "fig3.savefig(f'{output_dir}/figure3_bootstrap_effects.pdf', format='pdf', bbox_inches='tight')\n",
        "plt.close()\n",
        "print(\"✓ Figure 3 saved: bootstrap_effects.pdf\")\n",
        "\n",
        "# ========== FIGURE 4: Scatter Plots Matrix ==========\n",
        "fig4 = plt.figure(figsize=(14, 5))\n",
        "gs = fig4.add_gridspec(1, 3, wspace=0.25)\n",
        "\n",
        "# Plot 1: X vs Y (Total effect) - UPDATED\n",
        "ax4a = fig4.add_subplot(gs[0])\n",
        "sns.scatterplot(x='norm_LC_avg', y='num_items', data=mediation_data_clean,\n",
        "                alpha=0.6, color=colors['primary'], s=50, ax=ax4a)\n",
        "sns.regplot(x='norm_LC_avg', y='num_items', data=mediation_data_clean,\n",
        "            scatter=False, color=colors['primary'], ax=ax4a, line_kws={'linewidth': 2})\n",
        "\n",
        "ax4a.set_xlabel('NMLC', fontsize=11)\n",
        "ax4a.set_ylabel('Number of Items', fontsize=11)\n",
        "ax4a.set_title(f'Total Effect (c = {c_coeff:.3f}, p = {model_total.pvalues[\"norm_LC_avg\"]:.3f})',\n",
        "               fontsize=11, fontweight='bold')\n",
        "ax4a.grid(True, alpha=0.3, linestyle=':')\n",
        "ax4a.set_axisbelow(True)\n",
        "add_subplot_label(ax4a, 'A', x=-0.12)\n",
        "\n",
        "# Plot 2: X vs M (Path a)\n",
        "ax4b = fig4.add_subplot(gs[1])\n",
        "sns.scatterplot(x='norm_LC_avg', y='alpha_NET_mean', data=mediation_data_clean,\n",
        "                alpha=0.6, color=colors['secondary'], s=50, ax=ax4b)\n",
        "sns.regplot(x='norm_LC_avg', y='alpha_NET_mean', data=mediation_data_clean,\n",
        "            scatter=False, color=colors['secondary'], ax=ax4b, line_kws={'linewidth': 2})\n",
        "\n",
        "ax4b.set_xlabel('NMLC', fontsize=11)\n",
        "ax4b.set_ylabel('Alpha Power', fontsize=11)\n",
        "ax4b.set_title(f'Path a (β = {a_coeff:.3f}, p = {model_m.pvalues[\"norm_LC_avg\"]:.3f})',\n",
        "               fontsize=11, fontweight='bold')\n",
        "ax4b.grid(True, alpha=0.3, linestyle=':')\n",
        "ax4b.set_axisbelow(True)\n",
        "add_subplot_label(ax4b, 'B', x=-0.12)\n",
        "\n",
        "# Plot 3: M vs Y (Path b) - UPDATED\n",
        "ax4c = fig4.add_subplot(gs[2])\n",
        "sns.scatterplot(x='alpha_NET_mean', y='num_items', data=mediation_data_clean,\n",
        "                alpha=0.6, color=colors['tertiary'], s=50, ax=ax4c)\n",
        "sns.regplot(x='alpha_NET_mean', y='num_items', data=mediation_data_clean,\n",
        "            scatter=False, color=colors['tertiary'], ax=ax4c, line_kws={'linewidth': 2})\n",
        "\n",
        "ax4c.set_xlabel('Alpha Power', fontsize=11)\n",
        "ax4c.set_ylabel('Number of Items', fontsize=11)\n",
        "ax4c.set_title(f'Path b (β = {b_coeff:.3f}, p = {model_y.pvalues[\"alpha_NET_mean\"]:.3f})',\n",
        "               fontsize=11, fontweight='bold')\n",
        "ax4c.grid(True, alpha=0.3, linestyle=':')\n",
        "ax4c.set_axisbelow(True)\n",
        "add_subplot_label(ax4c, 'C', x=-0.12)\n",
        "\n",
        "plt.tight_layout()\n",
        "fig4.savefig(f'{output_dir}/figure4_scatter_plots.pdf', format='pdf', bbox_inches='tight')\n",
        "plt.close()\n",
        "print(\"✓ Figure 4 saved: scatter_plots.pdf\")\n",
        "\n",
        "# ========== FIGURE 5: Summary Results ==========\n",
        "fig5 = plt.figure(figsize=(10, 8))\n",
        "ax5 = fig5.add_subplot(111)\n",
        "ax5.axis('off')\n",
        "\n",
        "# Title - UPDATED\n",
        "title_y = 0.95\n",
        "ax5.text(0.5, title_y, 'Mediation Analysis Summary: Number of Items', ha='center', fontsize=16,\n",
        "         fontweight='bold', transform=ax5.transAxes)\n",
        "\n",
        "# Create structured text summary\n",
        "summary_y = 0.85\n",
        "line_height = 0.06\n",
        "\n",
        "section_headers = {\n",
        "    'Path Coefficients': 0.85,\n",
        "    'Model Fit': 0.45,\n",
        "    'Bootstrap Results': 0.25,\n",
        "    'Conclusion': 0.05\n",
        "}\n",
        "\n",
        "# Path coefficients\n",
        "ax5.text(0.1, section_headers['Path Coefficients'], 'Path Coefficients:',\n",
        "         fontsize=12, fontweight='bold', transform=ax5.transAxes)\n",
        "\n",
        "path_info = [\n",
        "    ('Path a (NMLC → Alpha):', a_coeff, model_m.bse['norm_LC_avg'], model_m.pvalues['norm_LC_avg']),\n",
        "    ('Path b (Alpha → Num Items):', b_coeff, model_y.bse['alpha_NET_mean'], model_y.pvalues['alpha_NET_mean']),\n",
        "    (\"Path c' (Direct effect):\", c_prime_coeff, model_y.bse['norm_LC_avg'], model_y.pvalues['norm_LC_avg']),\n",
        "    ('Path c (Total effect):', c_coeff, model_total.bse['norm_LC_avg'], model_total.pvalues['norm_LC_avg'])\n",
        "]\n",
        "\n",
        "y_pos = section_headers['Path Coefficients'] - 0.05\n",
        "for label, coef, se, pval in path_info:\n",
        "    sig_marker = '*' if pval < 0.05 else ''\n",
        "    text = f'{label:<35} β = {coef:>7.4f} (SE = {se:.4f}), p = {pval:.3f}{sig_marker}'\n",
        "    ax5.text(0.15, y_pos, text, fontsize=10, fontfamily='monospace', transform=ax5.transAxes)\n",
        "    y_pos -= line_height\n",
        "\n",
        "# Model fit section\n",
        "ax5.text(0.1, section_headers['Model Fit'], 'Model Fit:',\n",
        "         fontsize=12, fontweight='bold', transform=ax5.transAxes)\n",
        "\n",
        "fit_info = [\n",
        "    f'Path a model R² = {model_m.rsquared:.3f}',\n",
        "    f'Full model R² = {model_y.rsquared:.3f}',\n",
        "    f'Total effect model R² = {model_total.rsquared:.3f}',\n",
        "    f'Sample size: n = {final_n}'\n",
        "]\n",
        "\n",
        "y_pos = section_headers['Model Fit'] - 0.05\n",
        "for info in fit_info:\n",
        "    ax5.text(0.15, y_pos, info, fontsize=10, fontfamily='monospace', transform=ax5.transAxes)\n",
        "    y_pos -= line_height\n",
        "\n",
        "# Bootstrap results section\n",
        "ax5.text(0.1, section_headers['Bootstrap Results'], 'Bootstrap Results:',\n",
        "         fontsize=12, fontweight='bold', transform=ax5.transAxes)\n",
        "\n",
        "boot_info = [\n",
        "    f'Indirect effect (a×b) = {indirect_effect:.4f}',\n",
        "    f'95% CI: [{ci_lower:.4f}, {ci_upper:.4f}]',\n",
        "    f'Bootstrap iterations: {len(boot_effects)}',\n",
        "    f'Significant: {\"No (CI includes zero)\" if ci_lower * ci_upper < 0 else \"Yes\"}'\n",
        "]\n",
        "\n",
        "y_pos = section_headers['Bootstrap Results'] - 0.05\n",
        "for info in boot_info:\n",
        "    ax5.text(0.15, y_pos, info, fontsize=10, fontfamily='monospace', transform=ax5.transAxes)\n",
        "    y_pos -= line_height\n",
        "\n",
        "# Conclusion box - Will be updated based on results\n",
        "if ci_lower * ci_upper > 0:\n",
        "    conclusion_text = ('Significant mediation effect detected.\\n'\n",
        "                      f'Alpha Power mediates the relationship between\\n'\n",
        "                      f'NMLC and Number of Items.')\n",
        "    box_color = '#eeffee'\n",
        "    edge_color = colors['tertiary']\n",
        "else:\n",
        "    conclusion_text = ('No significant mediation effect detected.\\n'\n",
        "                      'The indirect effect confidence interval includes zero.')\n",
        "    box_color = '#ffeeee'\n",
        "    edge_color = colors['secondary']\n",
        "\n",
        "ax5.text(0.5, section_headers['Conclusion'], conclusion_text,\n",
        "         ha='center', va='center', fontsize=11,\n",
        "         bbox=dict(boxstyle=\"round,pad=0.5\", facecolor=box_color,\n",
        "                  edgecolor=edge_color, linewidth=2),\n",
        "         transform=ax5.transAxes)\n",
        "\n",
        "plt.tight_layout()\n",
        "fig5.savefig(f'{output_dir}/figure5_summary_results.pdf', format='pdf', bbox_inches='tight')\n",
        "plt.close()\n",
        "print(\"✓ Figure 5 saved: summary_results.pdf\")\n",
        "\n",
        "print(f\"\\n✓ All figures saved successfully in '{output_dir}' directory:\")\n",
        "print(f\"  - figure1_conceptual_model.pdf\")\n",
        "print(f\"  - figure2_coefficients_pvalues.pdf\")\n",
        "print(f\"  - figure3_bootstrap_effects.pdf\")\n",
        "print(f\"  - figure4_scatter_plots.pdf\")\n",
        "print(f\"  - figure5_summary_results.pdf\")\n",
        "print(\"\\nThese figures are publication-ready and optimized for academic presentations.\")\n",
        "\n",
        "# Also create a combined PDF if you have PyPDF2 installed\n",
        "try:\n",
        "    from PyPDF2 import PdfMerger\n",
        "    merger = PdfMerger()\n",
        "\n",
        "    pdf_files = [\n",
        "        'figure1_conceptual_model.pdf',\n",
        "        'figure2_coefficients_pvalues.pdf',\n",
        "        'figure3_bootstrap_effects.pdf',\n",
        "        'figure4_scatter_plots.pdf',\n",
        "        'figure5_summary_results.pdf'\n",
        "    ]\n",
        "\n",
        "    for pdf in pdf_files:\n",
        "        merger.append(f'{output_dir}/{pdf}')\n",
        "\n",
        "    merger.write(f'{output_dir}/all_figures_combined.pdf')\n",
        "    merger.close()\n",
        "    print(f\"\\n✓ Also created: all_figures_combined.pdf\")\n",
        "except ImportError:\n",
        "    print(\"\\nNote: Install PyPDF2 to automatically combine all figures into one PDF\")"
      ],
      "metadata": {
        "id": "3bI-eU8ILAYW"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}